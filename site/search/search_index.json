{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documentation for CompNeuroPy","text":"<p>CompNeuroPy is an assisting Python package for working with ANNarchy (GitHub, documentation, DOI). It is intended to help structure simulations with computational neuroscience models in a modular way and to make them more easily replicable. People who want to start working with ANNarchy are strongly recommended to first learn exclusively the functionality of ANNarchy. CompNeuroPy uses very few features of ANNarchy at this time. But also adds various special features.</p>"},{"location":"license/","title":"License","text":""},{"location":"license/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2022 Oliver Maith</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"additional/analysis_functions/","title":"Analysis Functions","text":""},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.my_raster_plot","title":"<code>my_raster_plot(spikes)</code>","text":"<p>Returns two vectors representing for each recorded spike 1) the spike times and 2) the ranks of the neurons. The spike times are always in simulation steps (in contrast to default ANNarchy raster_plot).</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dict</code> <p>ANNarchy spike dict of one population</p> required <p>Returns:</p> Name Type Description <code>t</code> <code>array</code> <p>spike times in simulation steps</p> <code>n</code> <code>array</code> <p>ranks of the neurons</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def my_raster_plot(spikes: dict):\n    \"\"\"\n    Returns two vectors representing for each recorded spike 1) the spike times and 2)\n    the ranks of the neurons. The spike times are always in simulation steps (in\n    contrast to default ANNarchy raster_plot).\n\n    Args:\n        spikes (dict):\n            ANNarchy spike dict of one population\n\n    Returns:\n        t (array):\n            spike times in simulation steps\n        n (array):\n            ranks of the neurons\n    \"\"\"\n    t, n = raster_plot(spikes)\n    np.zeros(10)\n    t = np.round(t / dt(), 0).astype(int)\n    return t, n\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_nanmean","title":"<code>get_nanmean(a, axis=None, dtype=None)</code>","text":"<p>Same as np.nanmean but without printing warnings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Array containing numbers whose mean is desired. If <code>a</code> is not an array, a conversion is attempted.</p> required <code>axis</code> <code>None or int or tuple of ints</code> <p>Axis or axes along which the means are computed. The default is to compute the mean of the flattened array.</p> <p>.. numpy versionadded:: 1.7.0</p> <p>If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before.</p> <code>None</code> <code>dtype</code> <code>data - type</code> <p>Type to use in computing the mean.  For integer inputs, the default is <code>float64</code>; for floating point inputs, it is the same as the input dtype.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>m</code> <code>ndarray, see dtype parameter above</code> <p>If <code>out=None</code>, returns a new array containing the mean values, otherwise a reference to the output array is returned.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_nanmean(a, axis=None, dtype=None):\n    \"\"\"\n    Same as np.nanmean but without printing warnings.\n\n    Args:\n        a (array_like):\n            Array containing numbers whose mean is desired. If `a` is not an\n            array, a conversion is attempted.\n        axis (None or int or tuple of ints, optional):\n            Axis or axes along which the means are computed. The default is to\n            compute the mean of the flattened array.\n\n            .. numpy versionadded:: 1.7.0\n\n            If this is a tuple of ints, a mean is performed over multiple axes,\n            instead of a single axis or all the axes as before.\n        dtype (data-type, optional):\n            Type to use in computing the mean.  For integer inputs, the default\n            is `float64`; for floating point inputs, it is the same as the\n            input dtype.\n\n    Returns:\n        m (ndarray, see dtype parameter above):\n            If `out=None`, returns a new array containing the mean values,\n            otherwise a reference to the output array is returned.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        ret = np.nanmean(a, axis=axis, dtype=dtype)\n    return ret\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_nanstd","title":"<code>get_nanstd(a, axis=None, dtype=None)</code>","text":"<p>Same as np.nanstd but without printing warnings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Calculate the standard deviation of these values.</p> required <code>axis</code> <code>None or int or tuple of ints</code> <p>Axis or axes along which the standard deviation is computed. The default is to compute the standard deviation of the flattened array.</p> <p>.. numpy versionadded:: 1.7.0</p> <p>If this is a tuple of ints, a standard deviation is performed over multiple axes, instead of a single axis or all the axes as before.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>Type to use in computing the standard deviation. For arrays of integer type the default is float64, for arrays of float types it is the same as the array type.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>standard_deviation</code> <code>ndarray, see dtype parameter above</code> <p>If <code>out</code> is None, return a new array containing the standard deviation, otherwise return a reference to the output array.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_nanstd(a, axis=None, dtype=None):\n    \"\"\"\n    Same as np.nanstd but without printing warnings.\n\n    Args:\n        a (array_like):\n            Calculate the standard deviation of these values.\n        axis (None or int or tuple of ints, optional):\n            Axis or axes along which the standard deviation is computed. The\n            default is to compute the standard deviation of the flattened array.\n\n            .. numpy versionadded:: 1.7.0\n\n            If this is a tuple of ints, a standard deviation is performed over\n            multiple axes, instead of a single axis or all the axes as before.\n        dtype (dtype, optional):\n            Type to use in computing the standard deviation. For arrays of\n            integer type the default is float64, for arrays of float types it is\n            the same as the array type.\n\n    Returns:\n        standard_deviation (ndarray, see dtype parameter above):\n            If `out` is None, return a new array containing the standard deviation,\n            otherwise return a reference to the output array.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        ret = np.nanstd(a, axis=axis, dtype=dtype)\n    return ret\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_population_power_spectrum","title":"<code>get_population_power_spectrum(spikes, time_step, t_start=None, t_end=None, fft_size=None)</code>","text":"<p>Generates power spectrum of population spikes, returns frequency_arr and power_spectrum_arr. Using the Welch methode from: Welch, P. (1967). The use of fast Fourier transform for the estimation of power spectra: a method based on time averaging over short, modified periodograms. IEEE Transactions on audio and electroacoustics, 15(2), 70-73.</p> <p>The spike arrays are splitted into multiple arrays and then multiple FFTs are performed and the results are averaged.</p> <p>Size of splitted signals and the time step of the simulation determine the frequency resolution and the maximum frequency:     maximum frequency [Hz] = 500 / time_step     frequency resolution [Hz] = 1000 / (time_step * fftSize)</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dicitonary</code> <p>ANNarchy spike dict of one population</p> required <code>time_step</code> <code>float</code> <p>time step of the simulation in ms</p> required <code>t_start</code> <code>float or int</code> <p>start time of analyzed data in ms. Default: time of first spike</p> <code>None</code> <code>t_end</code> <code>float or int</code> <p>end time of analyzed data in ms. Default: time of last spike</p> <code>None</code> <code>fft_size</code> <code>int</code> <p>signal size for the FFT (size of splitted arrays) has to be a power of 2. Default: maximum</p> <code>None</code> <p>Returns:</p> Name Type Description <code>frequency_arr</code> <code>array</code> <p>array with frequencies</p> <code>spectrum</code> <code>array</code> <p>array with power spectrum</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_population_power_spectrum(\n    spikes,\n    time_step,\n    t_start=None,\n    t_end=None,\n    fft_size=None,\n):\n    \"\"\"\n    Generates power spectrum of population spikes, returns frequency_arr and\n    power_spectrum_arr. Using the Welch methode from: Welch, P. (1967). The use of fast\n    Fourier transform for the estimation of power spectra: a method based on time\n    averaging over short, modified periodograms. IEEE Transactions on audio and\n    electroacoustics, 15(2), 70-73.\n\n    The spike arrays are splitted into multiple arrays and then multiple FFTs are\n    performed and the results are averaged.\n\n    Size of splitted signals and the time step of the simulation determine the frequency\n    resolution and the maximum frequency:\n        maximum frequency [Hz] = 500 / time_step\n        frequency resolution [Hz] = 1000 / (time_step * fftSize)\n\n    Args:\n        spikes (dicitonary):\n            ANNarchy spike dict of one population\n        time_step (float):\n            time step of the simulation in ms\n        t_start (float or int, optional):\n            start time of analyzed data in ms. Default: time of first spike\n        t_end (float or int, optional):\n            end time of analyzed data in ms. Default: time of last spike\n        fft_size (int, optional):\n            signal size for the FFT (size of splitted arrays)\n            has to be a power of 2. Default: maximum\n\n    Returns:\n        frequency_arr (array):\n            array with frequencies\n        spectrum (array):\n            array with power spectrum\n    \"\"\"\n\n    def ms_to_s(x):\n        return x / 1000\n\n    ### get population_size / sampling_frequency\n    populations_size = len(list(spikes.keys()))\n    sampling_frequency = 1 / ms_to_s(time_step)  # in Hz\n\n    ### check if there are spikes in data\n    t, _ = my_raster_plot(spikes)\n    if len(t) &lt; 2:\n        ### there are no 2 spikes\n        print(\"WARNING: get_population_power_spectrum: &lt;2 spikes!\")\n        ### --&gt; return None or zeros\n        if fft_size == None:\n            print(\n                \"ERROR: get_population_power_spectrum: &lt;2 spikes and no fft_size given!\"\n            )\n            quit()\n        else:\n            frequency_arr = np.fft.fftfreq(fft_size, 1.0 / sampling_frequency)\n            frequency_arr_ret = frequency_arr[2 : int(fft_size / 2)]\n            spectrum_ret = np.zeros(frequency_arr_ret.shape)\n            return [frequency_arr_ret, spectrum_ret]\n\n    ### check if t_start / t_end are None\n    if t_start == None:\n        t_start = round(t.min() * time_step, get_number_of_decimals(time_step))\n    if t_end == None:\n        t_end = round(t.max() * time_step, get_number_of_decimals(time_step))\n\n    ### calculate time\n    simulation_time = round(t_end - t_start, get_number_of_decimals(time_step))  # in ms\n\n    ### get fft_size\n    ### if None --&gt; as large as possible\n    if fft_size is None:\n        pow = 1\n        while (2 ** (pow + 1)) / sampling_frequency &lt; ms_to_s(simulation_time):\n            pow = pow + 1\n        fft_size = 2**pow\n\n    if ms_to_s(simulation_time) &lt; (fft_size / sampling_frequency):\n        ### catch a too large fft_size\n        print(\n            f\"Too large fft_size {fft_size} for duration {simulation_time} ms. FFT_size has to be smaller than {int(ms_to_s(simulation_time)*sampling_frequency)}!\"\n        )\n        return [np.zeros(int(fft_size / 2 - 2)), np.zeros(int(fft_size / 2 - 2))]\n    elif (np.log2(fft_size) - int(np.log2(fft_size))) != 0:\n        ### catch fft_size if its not power of 2\n        print(\"FFT_size hast to be power of 2!\")\n        return [np.zeros(int(fft_size / 2 - 2)), np.zeros(int(fft_size / 2 - 2))]\n    else:\n        print(\n            f\"power sepctrum, min = {1000 / (time_step * fft_size)}, max = {500 / time_step}\"\n        )\n        ### calculate frequency powers\n        spectrum = np.zeros((populations_size, fft_size))\n        for neuron in range(populations_size):\n            ### sampling steps array\n            spiketrain = np.zeros(\n                int(np.round(ms_to_s(simulation_time) * sampling_frequency))\n            )\n            ### spike times as sampling steps\n            idx = (\n                np.round(\n                    ms_to_s((np.array(spikes[neuron]) * time_step)) * sampling_frequency\n                )\n            ).astype(np.int32)\n            ### cut the spikes before t_start and after t_end\n            idx_start = ms_to_s(t_start) * sampling_frequency\n            idx_end = ms_to_s(t_end) * sampling_frequency\n            mask = ((idx &gt; idx_start).astype(int) * (idx &lt; idx_end).astype(int)).astype(\n                bool\n            )\n            idx = (idx[mask] - idx_start).astype(np.int32)\n\n            ### set spiketrain array to one if there was a spike at sampling step\n            spiketrain[idx] = 1\n\n            ### generate multiple overlapping sequences out of the spike trains\n            spiketrain_sequences = _hanning_split_overlap(\n                spiketrain, fft_size, int(fft_size / 2)\n            )\n\n            ### generate power spectrum\n            spectrum[neuron] = get_nanmean(\n                np.abs(np.fft.fft(spiketrain_sequences)) ** 2, 0\n            )\n\n        ### mean spectrum over all neurons\n        spectrum = get_nanmean(spectrum, 0)\n\n        frequency_arr = np.fft.fftfreq(fft_size, 1.0 / sampling_frequency)\n\n        return (frequency_arr[2 : int(fft_size / 2)], spectrum[2 : int(fft_size / 2)])\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_power_spektrum_from_time_array","title":"<code>get_power_spektrum_from_time_array(arr, presimulationTime, simulationTime, simulation_dt, samplingfrequency=250, fftSize=1024)</code>","text":"<p>Generates power spectrum of time signal (returns frequencies_arr and power_arr). Using the Welch methode (Welch,1967).</p> <p>amplingfrequency: to sample the arr, in Hz --&gt; max frequency = samplingfrequency / 2 fftSize: signal size for FFT, duration (in s) = fftSize / samplingfrequency --&gt; frequency resolution = samplingfrequency / fftSize</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>array</code> <p>time array, value for each timestep</p> required <code>presimulationTime</code> <code>float or int</code> <p>simulation time which will not be analyzed</p> required <code>simulationTime</code> <code>float or int</code> <p>analyzed simulation time</p> required <code>simulation_dt</code> <code>float or int</code> <p>simulation timestep</p> required <code>samplingfrequency</code> <code>float or int</code> <p>sampling frequency for sampling the time array. Default: 250</p> <code>250</code> <code>fftSize</code> <code>int</code> <p>signal size for the FFT (size of splitted arrays) has to be a power of 2. Default: 1024</p> <code>1024</code> <p>Returns:</p> Name Type Description <code>frequency_arr</code> <code>array</code> <p>array with frequencies</p> <code>spectrum</code> <code>array</code> <p>array with power spectrum</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_power_spektrum_from_time_array(\n    arr,\n    presimulationTime,\n    simulationTime,\n    simulation_dt,\n    samplingfrequency=250,\n    fftSize=1024,\n):\n    \"\"\"\n    Generates power spectrum of time signal (returns frequencies_arr and power_arr).\n    Using the Welch methode (Welch,1967).\n\n    amplingfrequency: to sample the arr, in Hz --&gt; max frequency = samplingfrequency / 2\n    fftSize: signal size for FFT, duration (in s) = fftSize / samplingfrequency\n    --&gt; frequency resolution = samplingfrequency / fftSize\n\n    Args:\n        arr (array):\n            time array, value for each timestep\n        presimulationTime (float or int):\n            simulation time which will not be analyzed\n        simulationTime (float or int):\n            analyzed simulation time\n        simulation_dt (float or int):\n            simulation timestep\n        samplingfrequency (float or int, optional):\n            sampling frequency for sampling the time array. Default: 250\n        fftSize (int, optional):\n            signal size for the FFT (size of splitted arrays)\n            has to be a power of 2. Default: 1024\n\n    Returns:\n        frequency_arr (array):\n            array with frequencies\n        spectrum (array):\n            array with power spectrum\n    \"\"\"\n\n    if (simulationTime / 1000) &lt; (fftSize / samplingfrequency):\n        print(\"Simulation time has to be &gt;=\", fftSize / samplingfrequency, \"s for FFT!\")\n        return [np.zeros(int(fftSize / 2 - 2)), np.zeros(int(fftSize / 2 - 2))]\n    else:\n        ### sampling steps array\n        sampling_arr = arr[0 :: int((1 / samplingfrequency) * 1000 / simulation_dt)]\n\n        ### generate multiple overlapping sequences\n        sampling_arr_sequences = _hanning_split_overlap(\n            sampling_arr, fftSize, int(fftSize / 2)\n        )\n\n        ### generate power spectrum\n        spektrum = get_nanmean(np.abs(np.fft.fft(sampling_arr_sequences)) ** 2, 0)\n\n        frequenzen = np.fft.fftfreq(fftSize, 1.0 / samplingfrequency)\n\n        return (frequenzen[2 : int(fftSize / 2)], spektrum[2 : int(fftSize / 2)])\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_pop_rate","title":"<code>get_pop_rate(spikes, t_start=None, t_end=None, time_step=1, t_smooth_ms=-1)</code>","text":"<p>Generates a smoothed population firing rate. Returns a time array and a firing rate array.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dictionary</code> <p>ANNarchy spike dict of one population</p> required <code>t_start</code> <code>float or int</code> <p>start time of analyzed data in ms. Default: time of first spike</p> <code>None</code> <code>t_end</code> <code>float or int</code> <p>end time of analyzed data in ms. Default: time of last spike</p> <code>None</code> <code>time_step</code> <code>float or int</code> <p>time step of the simulation in ms. Default: 1</p> <code>1</code> <code>t_smooth_ms</code> <code>float or int</code> <p>time window for firing rate calculation in ms, if -1 --&gt; time window sizes are automatically detected. Default: -1</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>array with time steps in ms</p> <code>rate</code> <code>array</code> <p>array with population rate in Hz for each time step</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_pop_rate(\n    spikes: dict,\n    t_start: float | int | None = None,\n    t_end: float | int | None = None,\n    time_step: float | int = 1,\n    t_smooth_ms: float | int = -1,\n):\n    \"\"\"\n    Generates a smoothed population firing rate. Returns a time array and a firing rate\n    array.\n\n    Args:\n        spikes (dictionary):\n            ANNarchy spike dict of one population\n        t_start (float or int, optional):\n            start time of analyzed data in ms. Default: time of first spike\n        t_end (float or int, optional):\n            end time of analyzed data in ms. Default: time of last spike\n        time_step (float or int, optional):\n            time step of the simulation in ms. Default: 1\n        t_smooth_ms (float or int, optional):\n            time window for firing rate calculation in ms, if -1 --&gt; time window sizes\n            are automatically detected. Default: -1\n\n    Returns:\n        time_arr (array):\n            array with time steps in ms\n        rate (array):\n            array with population rate in Hz for each time step\n    \"\"\"\n    dt = time_step\n\n    t, _ = my_raster_plot(spikes)\n\n    ### check if there are spikes in population at all\n    if len(t) &gt; 1:\n        if t_start == None:\n            t_start = round(t.min() * time_step, get_number_of_decimals(time_step))\n        if t_end == None:\n            t_end = round(t.max() * time_step, get_number_of_decimals(time_step))\n\n        duration = round(t_end - t_start, get_number_of_decimals(time_step))\n\n        ### if t_smooth is given --&gt; use classic time_window method\n        if t_smooth_ms &gt; 0:\n            return _get_pop_rate_old(\n                spikes, duration, dt=dt, t_start=t_start, t_smooth_ms=t_smooth_ms\n            )\n        else:\n            ### concatenate all spike times and sort them\n            spike_arr = dt * np.sort(\n                np.concatenate(\n                    [np.array(spikes[neuron]).astype(int) for neuron in spikes.keys()]\n                )\n            )\n            nr_neurons = len(list(spikes.keys()))\n            nr_spikes = spike_arr.size\n\n            ### use _recursive_rate to get firing rate\n            ### spike array is splitted in time bins\n            ### time bins widths are automatically found\n            time_population_rate, population_rate = _recursive_rate(\n                spike_arr / 1000.0,\n                t0=t_start / 1000.0,\n                t1=(t_start + duration) / 1000.0,\n                duration_init=duration / 1000.0,\n                nr_neurons=nr_neurons,\n                nr_spikes=nr_spikes,\n            )\n            ### time_population_rate was returned in s --&gt; transform it into ms\n            time_population_rate = time_population_rate * 1000\n            time_arr0 = np.arange(t_start, t_start + duration, dt)\n            if len(time_population_rate) &gt; 1:\n                ### interpolate\n                interpolate_func = interp1d(\n                    time_population_rate,\n                    population_rate,\n                    kind=\"linear\",\n                    bounds_error=False,\n                    fill_value=(population_rate[0], population_rate[-1]),\n                )\n                population_rate_arr = interpolate_func(time_arr0)\n            else:\n                population_rate_arr = np.zeros(len(time_arr0))\n                mask = time_arr0 == time_population_rate[0]\n                population_rate_arr[mask] = population_rate[0]\n\n            ret = population_rate_arr\n    else:\n        if t_start == None or t_end == None:\n            return None\n        else:\n            duration = t_end - t_start\n            ret = np.zeros(int(duration / dt))\n\n    return (np.arange(t_start, t_start + duration, dt), ret)\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.plot_recordings","title":"<code>plot_recordings(figname, recordings, recording_times, chunk, shape, plan, time_lim=[], dpi=300)</code>","text":"<p>Plots the recordings of a single chunk from recordings. Plotted variables are specified in plan.</p> <p>Parameters:</p> Name Type Description Default <code>figname</code> <code>str</code> <p>path + name of figure (e.g. \"figures/my_figure.png\")</p> required <code>recordings</code> <code>list</code> <p>a recordings list from CompNeuroPy obtained with the function get_recordings() from a Monitors object.</p> required <code>recording_times</code> <code>object</code> <p>recording_times object from CompNeuroPy obtained with the function get_recording_times() from a Monitors object.</p> required <code>chunk</code> <code>int</code> <p>which chunk of recordings should be used (the index of chunk)</p> required <code>shape</code> <code>tuple</code> <p>Defines the subplot arrangement e.g. (3,2) = 3 rows, 2 columns</p> required <code>plan</code> <code>list of strings</code> <p>Defines which recordings are plotted in which subplot and how. Entries of the list have the structure:     \"subplot_nr;model_component_name;variable_to_plot;format\",     e.g. \"1,my_pop1;v;line\".     mode: defines how the data is plotted, available modes:         - for spike data: raster, mean, hybrid         - for other data: line, mean, matrix         - only for projection data: matrix_mean</p> required <code>time_lim</code> <code>list</code> <p>Defines the x-axis for all subplots. The list contains two numbers: start and end time in ms. The times have to be within the chunk. Default: time lims of chunk</p> <code>[]</code> <code>dpi</code> <code>int</code> <p>The dpi of the saved figure. Default: 300</p> <code>300</code> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def plot_recordings(\n    figname, recordings, recording_times, chunk, shape, plan, time_lim=[], dpi=300\n):\n    \"\"\"\n    Plots the recordings of a single chunk from recordings. Plotted variables are\n    specified in plan.\n\n    Args:\n        figname (str):\n            path + name of figure (e.g. \"figures/my_figure.png\")\n        recordings (list):\n            a recordings list from CompNeuroPy obtained with the function\n            get_recordings() from a Monitors object.\n        recording_times (object):\n            recording_times object from CompNeuroPy obtained with the\n            function get_recording_times() from a Monitors object.\n        chunk (int):\n            which chunk of recordings should be used (the index of chunk)\n        shape (tuple):\n            Defines the subplot arrangement e.g. (3,2) = 3 rows, 2 columns\n        plan (list of strings):\n            Defines which recordings are plotted in which subplot and how.\n            Entries of the list have the structure:\n                \"subplot_nr;model_component_name;variable_to_plot;format\",\n                e.g. \"1,my_pop1;v;line\".\n                mode: defines how the data is plotted, available modes:\n                    - for spike data: raster, mean, hybrid\n                    - for other data: line, mean, matrix\n                    - only for projection data: matrix_mean\n        time_lim (list, optional):\n            Defines the x-axis for all subplots. The list contains two\n            numbers: start and end time in ms. The times have to be\n            within the chunk. Default: time lims of chunk\n        dpi (int, optional):\n            The dpi of the saved figure. Default: 300\n    \"\"\"\n    proc = Process(\n        target=_plot_recordings,\n        args=(figname, recordings, recording_times, chunk, shape, plan, time_lim, dpi),\n    )\n    proc.start()\n    proc.join()\n    if proc.exitcode != 0:\n        quit()\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_number_of_zero_decimals","title":"<code>get_number_of_zero_decimals(nr)</code>","text":"<p>For numbers which are smaller than zero get the number of digits after the decimal point which are zero (plus 1). For the number 0 or numbers &gt;=1 return zero, e.g.:</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>the number from which the number of digits are obtained</p> required <p>Returns:</p> Name Type Description <code>decimals</code> <code>int</code> <p>number of digits after the decimal point which are zero (plus 1)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_number_of_zero_decimals(0.12)\n1\n&gt;&gt;&gt; get_number_of_zero_decimals(0.012)\n2\n&gt;&gt;&gt; get_number_of_zero_decimals(1.012)\n0\n</code></pre> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_number_of_zero_decimals(nr):\n    \"\"\"\n    For numbers which are smaller than zero get the number of digits after the decimal\n    point which are zero (plus 1). For the number 0 or numbers &gt;=1 return zero, e.g.:\n\n    Args:\n        nr (float or int):\n            the number from which the number of digits are obtained\n\n    Returns:\n        decimals (int):\n            number of digits after the decimal point which are zero (plus 1)\n\n    Examples:\n        &gt;&gt;&gt; get_number_of_zero_decimals(0.12)\n        1\n        &gt;&gt;&gt; get_number_of_zero_decimals(0.012)\n        2\n        &gt;&gt;&gt; get_number_of_zero_decimals(1.012)\n        0\n    \"\"\"\n    decimals = 0\n    if nr != 0:\n        while abs(nr) &lt; 1:\n            nr = nr * 10\n            decimals = decimals + 1\n\n    return decimals\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_number_of_decimals","title":"<code>get_number_of_decimals(nr)</code>","text":"<p>Get number of digits after the decimal point.</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>the number from which the number of digits are obtained</p> required <p>Returns:</p> Name Type Description <code>decimals</code> <code>int</code> <p>number of digits after the decimal point</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_number_of_decimals(5)\n0\n&gt;&gt;&gt; get_number_of_decimals(5.1)\n1\n&gt;&gt;&gt; get_number_of_decimals(0.0101)\n4\n</code></pre> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_number_of_decimals(nr):\n    \"\"\"\n    Get number of digits after the decimal point.\n\n    Args:\n        nr (float or int):\n            the number from which the number of digits are obtained\n\n    Returns:\n        decimals (int):\n            number of digits after the decimal point\n\n    Examples:\n        &gt;&gt;&gt; get_number_of_decimals(5)\n        0\n        &gt;&gt;&gt; get_number_of_decimals(5.1)\n        1\n        &gt;&gt;&gt; get_number_of_decimals(0.0101)\n        4\n    \"\"\"\n\n    if nr != int(nr):\n        decimals = len(str(nr).split(\".\")[1])\n    else:\n        decimals = 0\n\n    return decimals\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.sample_data_with_timestep","title":"<code>sample_data_with_timestep(time_arr, data_arr, timestep)</code>","text":"<p>Samples a data array each timestep using interpolation</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>array</code> <p>array with data values from which will be sampled</p> required <code>timestep</code> <code>float or int</code> <p>timestep in ms for sampling</p> required <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>sampled time array</p> <code>data_arr</code> <code>array</code> <p>sampled data array</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def sample_data_with_timestep(time_arr, data_arr, timestep):\n    \"\"\"\n    Samples a data array each timestep using interpolation\n\n    Args:\n        time_arr (array):\n            times of data_arr in ms\n        data_arr (array):\n            array with data values from which will be sampled\n        timestep (float or int):\n            timestep in ms for sampling\n\n    Returns:\n        time_arr (array):\n            sampled time array\n        data_arr (array):\n            sampled data array\n    \"\"\"\n    interpolate_func = interp1d(\n        time_arr, data_arr, bounds_error=False, fill_value=\"extrapolate\"\n    )\n    min_time = round(\n        round(time_arr[0] / timestep, 0) * timestep,\n        get_number_of_decimals(timestep),\n    )\n    max_time = round(\n        round(time_arr[-1] / timestep, 0) * timestep,\n        get_number_of_decimals(timestep),\n    )\n    new_time_arr = np.arange(min_time, max_time + timestep, timestep)\n    new_data_arr = interpolate_func(new_time_arr)\n\n    return (new_time_arr, new_data_arr)\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.time_data_add_nan","title":"<code>time_data_add_nan(time_arr, data_arr, fill_time_step=None, axis=0)</code>","text":"<p>If there are gaps in time_arr --&gt; fill them with respective time values. Fill the corresponding data_arr values with nan.</p> <p>By default it is tried to fill the time array with continuously increasing times based on the smallest time difference found there can still be discontinuities after filling the arrays (because existing time values are not changed).</p> <p>But one can also give a fixed fill time step.</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>1D array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>nD array</code> <p>the size of the specified dimension of data array must have the same length as time_arr</p> required <code>fill_time_step</code> <code>number, optional, default=None</code> <p>if there are gaps they are filled with this time step</p> <code>None</code> <code>axis</code> <code>int</code> <p>which dimension of the data_arr belongs to the time_arr</p> <code>0</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>1D array</code> <p>time array with gaps filled</p> <code>data_arr</code> <code>nD array</code> <p>data array with gaps filled</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def time_data_add_nan(time_arr, data_arr, fill_time_step=None, axis=0):\n    \"\"\"\n    If there are gaps in time_arr --&gt; fill them with respective time values.\n    Fill the corresponding data_arr values with nan.\n\n    By default it is tried to fill the time array with continuously increasing times\n    based on the smallest time difference found there can still be discontinuities after\n    filling the arrays (because existing time values are not changed).\n\n    But one can also give a fixed fill time step.\n\n    Args:\n        time_arr (1D array):\n            times of data_arr in ms\n        data_arr (nD array):\n            the size of the specified dimension of data array must have the same length\n            as time_arr\n        fill_time_step (number, optional, default=None):\n            if there are gaps they are filled with this time step\n        axis (int):\n            which dimension of the data_arr belongs to the time_arr\n\n    Returns:\n        time_arr (1D array):\n            time array with gaps filled\n        data_arr (nD array):\n            data array with gaps filled\n    \"\"\"\n    time_arr = time_arr.astype(float)\n    data_arr = data_arr.astype(float)\n    data_arr_shape = data_arr.shape\n\n    if data_arr_shape[axis] != time_arr.size:\n        print(\n            \"ERROR time_data_add_nan: time_arr must have same length as specified axis (default=0) of data_arr!\"\n        )\n        quit()\n\n    ### find gaps\n    time_diff_arr = np.round(np.diff(time_arr), 6)\n    if isinstance(fill_time_step, type(None)):\n        time_diff_min = time_diff_arr.min()\n    else:\n        time_diff_min = fill_time_step\n    gaps_arr = time_diff_arr &gt; time_diff_min\n\n    ### split arrays at gaps\n    time_arr_split = np.split(\n        time_arr, indices_or_sections=np.where(gaps_arr)[0] + 1, axis=0\n    )\n    data_arr_split = np.split(\n        data_arr, indices_or_sections=np.where(gaps_arr)[0] + 1, axis=axis\n    )\n\n    ### fill gaps between splits\n    data_arr_append_shape = list(data_arr_shape)\n    for split_arr_idx in range(len(time_arr_split) - 1):\n        ### get gaps boundaries\n        current_end = time_arr_split[split_arr_idx][-1]\n        next_start = time_arr_split[split_arr_idx + 1][0]\n        ### create gap filling arrays\n        time_arr_append = np.arange(\n            current_end + time_diff_min, next_start, time_diff_min\n        )\n        data_arr_append_shape[axis] = time_arr_append.size\n        data_arr_append = np.zeros(tuple(data_arr_append_shape)) * np.nan\n        ### append gap filling arrays to splitted arrays\n        time_arr_split[split_arr_idx] = np.append(\n            arr=time_arr_split[split_arr_idx],\n            values=time_arr_append,\n            axis=0,\n        )\n        data_arr_split[split_arr_idx] = np.append(\n            arr=data_arr_split[split_arr_idx],\n            values=data_arr_append,\n            axis=axis,\n        )\n\n    ### combine splitted arrays again\n    time_arr = np.concatenate(time_arr_split, axis=0)\n    data_arr = np.concatenate(data_arr_split, axis=axis)\n\n    return (time_arr, data_arr)\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.rmse","title":"<code>rmse(a, b)</code>","text":"<p>Calculates the root-mean-square error between two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array</code> <p>first array</p> required <code>b</code> <code>array</code> <p>second array</p> required <p>Returns:</p> Name Type Description <code>rmse</code> <code>float</code> <p>root-mean-square error</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def rmse(a, b):\n    \"\"\"\n    Calculates the root-mean-square error between two arrays.\n\n    Args:\n        a (array):\n            first array\n        b (array):\n            second array\n\n    Returns:\n        rmse (float):\n            root-mean-square error\n    \"\"\"\n\n    return np.sqrt(np.mean((a - b) ** 2))\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.rsse","title":"<code>rsse(a, b)</code>","text":"<p>Calculates the root-sum-square error between two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array</code> <p>first array</p> required <code>b</code> <code>array</code> <p>second array</p> required <p>Returns:</p> Name Type Description <code>rsse</code> <code>float</code> <p>root-sum-square error</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def rsse(a, b):\n    \"\"\"\n    Calculates the root-sum-square error between two arrays.\n\n    Args:\n        a (array):\n            first array\n        b (array):\n            second array\n\n    Returns:\n        rsse (float):\n            root-sum-square error\n    \"\"\"\n\n    return np.sqrt(np.sum((a - b) ** 2))\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_minimum","title":"<code>get_minimum(input_data)</code>","text":"<p>Returns the minimum of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>list, np.ndarray, tuple, or float</code> <p>The input data from which the minimum is to be obtained.</p> required <p>Returns:</p> Name Type Description <code>minimum</code> <code>float</code> <p>The minimum of the input data.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_minimum(input_data):\n    \"\"\"\n    Returns the minimum of the input data.\n\n    Args:\n        input_data (list, np.ndarray, tuple, or float):\n            The input data from which the minimum is to be obtained.\n\n    Returns:\n        minimum (float):\n            The minimum of the input data.\n    \"\"\"\n    if isinstance(input_data, (list, np.ndarray, tuple)):\n        # If the input is a list, numpy array, or tuple, we handle them as follows\n        flattened_list = [\n            item\n            for sublist in input_data\n            for item in (\n                sublist if isinstance(sublist, (list, np.ndarray, tuple)) else [sublist]\n            )\n        ]\n        return min(flattened_list)\n    else:\n        # If the input is a single value, return it as the minimum\n        return input_data\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_maximum","title":"<code>get_maximum(input_data)</code>","text":"<p>Returns the maximum of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>list, np.ndarray, tuple, or float</code> <p>The input data from which the maximum is to be obtained.</p> required <p>Returns:</p> Name Type Description <code>maximum</code> <code>float</code> <p>The maximum of the input data.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_maximum(input_data):\n    \"\"\"\n    Returns the maximum of the input data.\n\n    Args:\n        input_data (list, np.ndarray, tuple, or float):\n            The input data from which the maximum is to be obtained.\n\n    Returns:\n        maximum (float):\n            The maximum of the input data.\n    \"\"\"\n\n    if isinstance(input_data, (list, np.ndarray, tuple)):\n        # If the input is a list, numpy array, or tuple, we handle them as follows\n        flattened_list = [\n            item\n            for sublist in input_data\n            for item in (\n                sublist if isinstance(sublist, (list, np.ndarray, tuple)) else [sublist]\n            )\n        ]\n        return max(flattened_list)\n    else:\n        # If the input is a single value, return it as the maximum\n        return input_data\n</code></pre>"},{"location":"main/dbs_stimulator/","title":"DBS Stimulator","text":""},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator","title":"<code>src.CompNeuroPy.dbs.DBSstimulator</code>","text":"<p>Class for stimulating a population with DBS.</p> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>class DBSstimulator:\n    \"\"\"\n    Class for stimulating a population with DBS.\n    \"\"\"\n\n    @check_types()\n    def __init__(\n        self,\n        stimulated_population: Population,\n        population_proportion: float = 1.0,\n        excluded_populations_list: list[Population] = [],\n        dbs_depolarization: float = 0.0,\n        orthodromic: bool = False,\n        antidromic: bool = False,\n        efferents: bool = False,\n        afferents: bool = False,\n        passing_fibres: bool = False,\n        passing_fibres_list: list[Projection] = [],\n        passing_fibres_strength: float | list[float] = 1.0,\n        sum_branches: bool = True,\n        dbs_pulse_frequency_Hz: float = 130.0,\n        dbs_pulse_width_us: float = 300.0,\n        axon_spikes_per_pulse: float = 1.0,\n        axon_rate_amp: float | dict[Population | str, float] = 1.0,\n        seed: int | None = None,\n        auto_implement: bool = False,\n        model: generate_model | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize DBS stimulator.\n\n        !!! warning\n            Do this before compiling the model!\n\n        Args:\n            stimulated_population (Population):\n                Population which is stimulated by DBS\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: 1.0.\n            excluded_populations_list (list, optional):\n                List of populations which are excluded from DBS effects, they are not\n                affected and their axons do not generate axon spikes. Default: [].\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: 0.0.\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically.\n                Default: False.\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: False.\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: False.\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: False.\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: False.\n            passing_fibres_list (list of Projections, optional):\n                List of projections which pass the DBS stimulated region and therefore\n                are activated by DBS. Default: [], also set passing_fibres True!\n            passing_fibres_strength (float or list of float, optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: 1.\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: True.\n            dbs_pulse_frequency_Hz (float, optional):\n                Frequency of the DBS pulse. Default: 130 Hz.\n            dbs_pulse_width_us (float, optional):\n                Width of the DBS pulse. Default: 300 us.\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: 1.\n            axon_rate_amp (float or dict of float, optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value)\n                You can specify the default value by using the key \"default\", e.g.\n                {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n                pop forward a rate of 1.0 during DBS. Default: 1.0.\n            seed (int, optional):\n                Seed for the random distribution of affected neurons based on\n                population_proportion. Default: None.\n            auto_implement (bool, optional):\n                If True, automatically implement DBS mechanisms to the model. Only\n                supported for Izhikevich spiking models and rate-coded models.\n                Default: False.\n                TODO test what happens with mixed models\n            model (generate_model, optional):\n                CompNeuroPy model which is used to automatically implement DBS\n                mechanisms, should not be compiled!. Default: None, i.e., use all\n                populations and projections of the current magic model\n        \"\"\"\n\n        if auto_implement:\n            ### recreate model with DBS mechanisms\n            ### give all variables containing Populations and Projections\n            ### and also recreate them during recreating the model\n            ### variables are:\n            ### - stimulated_population\n            ### - excluded_populations_list\n            ### - passing_fibres_list\n            ### - axon_rate_amp\n            if not isinstance(model, type(None)):\n                ### CompNeuroPy model given\n                ### recreate model with DBS mechanisms\n                create_dbs_model_obj = _CreateDBSmodelcnp(\n                    model,\n                    stimulated_population,\n                    excluded_populations_list,\n                    passing_fibres_list,\n                    axon_rate_amp,\n                )\n                ### get the new CompNeuroPy model\n                model = create_dbs_model_obj.model\n            else:\n                ### no CompNeuroPy model given --&gt; use all populations and projections of the current magic model\n                ### recreate model with DBS mechanisms\n                create_dbs_model_obj = _CreateDBSmodel(\n                    stimulated_population,\n                    excluded_populations_list,\n                    passing_fibres_list,\n                    axon_rate_amp,\n                )\n            ### get the new variables containing Populations and Projections\n            stimulated_population = create_dbs_model_obj.stimulated_population\n            excluded_populations_list = create_dbs_model_obj.excluded_populations_list\n            passing_fibres_list = create_dbs_model_obj.passing_fibres_list\n            axon_rate_amp = create_dbs_model_obj.axon_rate_amp\n\n        ### set parameters\n        self.stimulated_population = stimulated_population\n        self.population_proportion = population_proportion\n        self.excluded_populations_list = excluded_populations_list\n        self.dbs_depolarization = dbs_depolarization\n        self.orthodromic = orthodromic\n        self.antidromic = antidromic\n        self.efferents = efferents\n        self.afferents = afferents\n        self.passing_fibres = passing_fibres\n        self.passing_fibres_list = passing_fibres_list\n        self.passing_fibres_strength = passing_fibres_strength\n        self.sum_branches = sum_branches\n        self.dbs_pulse_width_us = dbs_pulse_width_us\n        self.axon_spikes_per_pulse = axon_spikes_per_pulse\n        self.axon_rate_amp = axon_rate_amp\n        self.seed = seed\n        self.model = model\n\n        ### ANNarchy constants for DBS\n        self._set_constants(dbs_pulse_frequency_Hz)\n\n        ### randomly select affected neurons i.e. create dbs_on_array\n        self.dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n\n    def _create_dbs_on_array(self, population_proportion: float, seed: int):\n        \"\"\"\n        Create an array with the shape of the stimulated population with ones and zeros\n        randomly distributed with the specified population_proportion.\n\n        Args:\n            population_proportion (float):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly\n            seed (int):\n                Seed for the random distribution of affected neurons based on\n                population_proportion\n\n        Returns:\n            dbs_on_array (np.array):\n                Array with the shape of the stimulated population with ones and zeros\n                randomly distributed with the specified population_proportion\n        \"\"\"\n        ### create random number generator\n        rng = np.random.default_rng(seed)\n        ### create an array of zeros with the shape of the population, then flatten it\n        dbs_on_array = np.zeros(self.stimulated_population.geometry).flatten()\n        ### get the number of affected neurons based on the population_proportion\n        number_of_affected_neurons = population_proportion * dbs_on_array.size\n        ### randomly ceil or floor the number of affected neurons\n        number_of_affected_neurons = int(\n            rng.choice(\n                [\n                    np.ceil(number_of_affected_neurons),\n                    np.floor(number_of_affected_neurons),\n                ]\n            )\n        )\n        ### insert ones to the dbs_on_array\n        dbs_on_array[:number_of_affected_neurons] = 1\n        ### shuffle array\n        rng.shuffle(dbs_on_array)\n        ### reshape array to the shape of the population\n        dbs_on_array = dbs_on_array.reshape(self.stimulated_population.geometry)\n        ### return array\n        return dbs_on_array\n\n    def _set_constants(self, dbs_pulse_frequency_Hz: float):\n        \"\"\"\n        Set constants for DBS.\n\n        Args:\n            dbs_pulse_frequency_Hz (float):\n                Frequency of the DBS pulse in Hz\n        \"\"\"\n        # pulse frequency:\n        Constant(\"dbs_pulse_frequency_Hz\", dbs_pulse_frequency_Hz)\n        # pulse width:\n        # Neumant et al.. 2023: 60us but Meier et al. 2022: 300us... 60us = 0.06ms is very small for ANNarchy simulations\n        Constant(\"dbs_pulse_width_us\", self.dbs_pulse_width_us)\n\n        ### add global function for DBS pulse\n        add_function(\n            \"pulse(time_ms) = ite(modulo(time_ms*1000, 1000000./dbs_pulse_frequency_Hz) &lt; dbs_pulse_width_us, 1., 0.)\"\n        )\n\n    def _axon_spikes_per_pulse_to_prob(self, axon_spikes_per_pulse: float):\n        \"\"\"\n        Convert number of axon spikes per pulse to probability of axon spikes per\n        timestep during DBS pulse\n\n        Args:\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n\n        Returns:\n            prob_axon_spike_time_step (float):\n                Probability of axon spikes per timestep during DBS pulse\n        \"\"\"\n        return np.clip(\n            (axon_spikes_per_pulse * 1000 * dt() / self.dbs_pulse_width_us), 0, 1\n        )\n\n    def _set_depolarization(self, dbs_depolarization: float | None = None):\n        \"\"\"\n        Set depolarization of population.\n\n        Args:\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: None,\n                i.e., use value from initialization\n        \"\"\"\n        ### either use given depolarization or use default value\n        if isinstance(dbs_depolarization, type(None)):\n            dbs_depolarization = self.dbs_depolarization\n\n        ### set depolarization of population\n        for pop in populations():\n            if pop == self.stimulated_population:\n                pop.dbs_depolarization = dbs_depolarization\n            else:\n                pop.dbs_depolarization = 0\n\n    def _set_axon_spikes(\n        self,\n        orthodromic: bool | None = None,\n        antidromic: bool | None = None,\n        efferents: bool | None = None,\n        afferents: bool | None = None,\n        passing_fibres: bool | None = None,\n        passing_fibres_strength: float | list[float] | None = None,\n        sum_branches: bool | None = None,\n        axon_spikes_per_pulse: float | None = None,\n        axon_rate_amp: float | dict[Population | str, float] | None = None,\n    ):\n        \"\"\"\n        Set axon spikes forwarding orthodromic\n\n        Args:\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically,\n                Default: None, i.e., use value from initialization\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: None, i.e., use value from\n                initialization\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: None, i.e., use value from initialization\n            passing_fibres_strength (float | list[float], optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: None, i.e., use value from initialization\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: None, i.e., use value from initialization\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: None, i.e., use\n                value from initialization\n            axon_rate_amp (float | dict[Population | str, float], optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value)\n                You can specify the default value by using the key \"default\", e.g.\n                {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n                pop forward a rate of 1.0 during DBS. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n\n        ### either use given orthodromic or use default value\n        if isinstance(orthodromic, type(None)):\n            orthodromic = self.orthodromic\n        ### either use given antidromic or use default value\n        if isinstance(antidromic, type(None)):\n            antidromic = self.antidromic\n        ### either use given efferents or use default value\n        if isinstance(efferents, type(None)):\n            efferents = self.efferents\n        ### either use given afferents or use default value\n        if isinstance(afferents, type(None)):\n            afferents = self.afferents\n        ### either use given afferents or use default value\n        if isinstance(passing_fibres, type(None)):\n            passing_fibres = self.passing_fibres\n        ### either use given passing_fibres_strength or use default value\n        if isinstance(passing_fibres_strength, type(None)):\n            passing_fibres_strength = self.passing_fibres_strength\n        ### either use given sum_branches or use default value\n        if isinstance(sum_branches, type(None)):\n            sum_branches = self.sum_branches\n        ### either use given axon_spikes_per_pulse or use default value\n        if isinstance(axon_spikes_per_pulse, type(None)):\n            axon_spikes_per_pulse = self.axon_spikes_per_pulse\n        ### either use given axon_rate_amp or use default value\n        if isinstance(axon_rate_amp, type(None)):\n            axon_rate_amp = self.axon_rate_amp\n\n        ### check if passing_fibres_strength is a list\n        if not isinstance(passing_fibres_strength, list):\n            passing_fibres_strength = [passing_fibres_strength] * len(\n                self.passing_fibres_list\n            )\n        ### check if axon_rate_amp is a dict or float\n        if isinstance(axon_rate_amp, dict):\n            ### check if default key is missing\n            if \"default\" not in axon_rate_amp.keys():\n                ### add the key \"default\" with the value 1.0 to the dict\n                axon_rate_amp[\"default\"] = 1.0\n        else:\n            ### create dict with default value\n            axon_rate_amp = {\"default\": axon_rate_amp}\n\n        ### deactivate DBS axon transmission\n        self._deactivate_axon_DBS()\n\n        ### activate orthodromic transmission for all projections\n        if orthodromic:\n            self._set_orthodromic(\n                efferents,\n                afferents,\n                passing_fibres,\n                passing_fibres_strength,\n                axon_spikes_per_pulse,\n                axon_rate_amp,\n            )\n\n        ### activate antidromic transmission for all populations\n        if antidromic:\n            self._set_antidromic(\n                efferents,\n                afferents,\n                passing_fibres,\n                passing_fibres_strength,\n                sum_branches,\n                axon_spikes_per_pulse,\n            )\n\n    def _deactivate_axon_DBS(self):\n        \"\"\"\n        Deactivate axon spikes forwarding for both orthodromic and antidromic.\n        \"\"\"\n        for pop in populations():\n            ### deactivate axon spike genearation for all populations\n            pop.prob_axon_spike = 0\n            pop.axon_rate_amp = 0\n            ### deactivate antidromic transmission for all populations\n            pop.antidromic = 0\n            pop.antidromic_prob = 0\n\n        ### deactivate orthodromic transmission for all projections\n        for proj in projections():\n            proj.axon_transmission = 0\n            proj.p_axon_spike_trans = 0\n\n    def _set_orthodromic(\n        self,\n        efferents: bool,\n        afferents: bool,\n        passing_fibres: bool,\n        passing_fibres_strength: list[float],\n        axon_spikes_per_pulse: float,\n        axon_rate_amp: dict[Population | str, float],\n    ):\n        \"\"\"\n        Set orthodromic axon spikes forwarding.\n\n        Args:\n            efferents (bool):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            afferents (bool):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            passing_fibres (bool):\n                If True, DBS affects the passing fibres of the stimulated population\n                (orthodromic and/or antidromic have to be True too and there have to\n                be passing fibres in the passing_fibres_list)\n            passing_fibres_strength (list[float]):\n                List of float values between 0 and 1 defining how strong the passing\n                fibres are activated by DBS (0: not activated, 1: fully activated\n                like projections in DBS stimulated region)\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n            axon_rate_amp (dict[Population | str, float]):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded\n                on axons caused by DBS. The dictionary has to contain the key\n                \"default\" with the default value for all projections and can contain\n                keys for each population with a different value for the axon_rate of\n                the efferent axons of this population.\n        \"\"\"\n        if efferents:\n            ### activate all efferent projections\n            projection_list = projections(pre=self.stimulated_population)\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.post in self.excluded_populations_list:\n                    continue\n                ### activate axon transmission\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = 1\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n        if afferents:\n            ### activate all afferent projections\n            projection_list = projections(post=self.stimulated_population)\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.pre in self.excluded_populations_list:\n                    continue\n                ### activate axon transmission\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = 1\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n        if passing_fibres:\n            ### activate all passing projections\n            for proj_idx, proj in enumerate(self.passing_fibres_list):\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = passing_fibres_strength[proj_idx]\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n    def _set_antidromic(\n        self,\n        efferents: bool,\n        afferents: bool,\n        passing_fibres: bool,\n        passing_fibres_strength: list[float],\n        sum_branches: bool,\n        axon_spikes_per_pulse: float,\n    ):\n        \"\"\"\n        Set antidromic axon spikes forwarding.\n\n        Args:\n            efferents (bool):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            afferents (bool):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            passing_fibres (bool):\n                If True, DBS affects the passing fibres of the stimulated population\n                (orthodromic and/or antidromic have to be True too and there have to\n                be passing fibres in the passing_fibres_list)\n            passing_fibres_strength (list[float]):\n                List of float values between 0 and 1 defining how strong the passing\n                fibres are activated by DBS (0: not activated, 1: fully activated\n                like projections in DBS stimulated region)\n            sum_branches (bool):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n        \"\"\"\n\n        if efferents:\n            ### activate all efferent projections, i.e. antodromic activation of stimulated population\n            pop = self.stimulated_population\n            pop.antidromic = 1\n            pop.antidromic_prob = 1\n            pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                axon_spikes_per_pulse\n            )\n        if afferents:\n            ### activate all afferent projections, i.e. all presynaptic populations of stimulated population\n            ### get presynaptic projections\n            projection_list = projections(post=self.stimulated_population)\n            ### get presynaptic populations from projections\n            presyn_pop_list = []\n            presyn_pop_name_list = []\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.pre in self.excluded_populations_list:\n                    continue\n                ### check if presynaptic population is already in list\n                if proj.pre.name not in presyn_pop_name_list:\n                    presyn_pop_name_list.append(proj.pre.name)\n                    presyn_pop_list.append(proj.pre)\n            ### set antidromic for all presynaptic populations\n            for pop in presyn_pop_list:\n                pop.antidromic = 1\n                pop.antidromic_prob = np.mean(self.stimulated_population.dbs_on)\n                pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n        if passing_fibres:\n            ### get presynaptic populations from passing fibres projections\n            presyn_pop_list = []\n            presyn_pop_name_list = []\n            for proj in self.passing_fibres_list:\n                ### check if presynaptic population is already in list\n                if proj.pre.name not in presyn_pop_name_list:\n                    presyn_pop_name_list.append(proj.pre.name)\n                    presyn_pop_list.append(proj.pre)\n            ### get antidomic_prob for each presynatic population with the passing_fibres_strength\n            antidromic_prob_list = [0] * len(presyn_pop_list)\n            for pop_idx, pop in enumerate(presyn_pop_list):\n                ### get all passing fibres and their strength of a presynaptic pop\n                passing_fibres_strength_of_pop_list = []\n                for proj_idx, proj in enumerate(self.passing_fibres_list):\n                    if proj.pre.name == pop.name:\n                        passing_fibres_strength_of_pop_list.append(\n                            passing_fibres_strength[proj_idx]\n                        )\n                ### check if the probs of the single axon branches should be summed up\n                ### if for example a presynaptic pop contributes to two passing fibres, the axons of the presynaptic pop split up into two branches\n                ### thus, if these two branches are both stimulated, they both forward APs antidromic\n                ### thus, sum up the antidromic_prob of the single branches to obtain the antidromic spikes which affect the presynaptic pop\n                ### if sum_branches is False, then this would represent that the stimulation at the axon is before it splits up into multiple branches and there should not be different passing_fibres_strengths for the same presynaptic pop\n                if sum_branches:\n                    antidromic_prob_list[pop_idx] = sum(\n                        passing_fibres_strength_of_pop_list\n                    )\n                else:\n                    if len(set(passing_fibres_strength_of_pop_list)) != 1:\n                        ### list contains different values\n                        raise ValueError(\n                            \"Different passing fibres strengths for the same presynaptic population detected. This is not possible if sum_branches is False.\"\n                        )\n                    ### all values are the same, thus take the first one\n                    antidromic_prob_list[pop_idx] = passing_fibres_strength_of_pop_list[\n                        0\n                    ]\n\n                ### TODO\n                ### if summing axon branches leads to a prob &gt; 1, then\n                ### the prob should be set to 1\n                ### the axon spike generation in this pop should be increased\n                ### and all axon spike transmissions from this pop should be decreased by the same factor\n                ### this is not implemented yet... maybe in the future\n                if antidromic_prob_list[pop_idx] &gt; 1:\n                    raise ValueError(\n                        \"Summing the passing fibres strengths of a presynaptic population leads to a antidromic spike probability &gt; 1. This is not possible yet.\"\n                    )\n\n            ### set antidromic for all presynaptic populations\n            for pop_idx, pop in enumerate(presyn_pop_list):\n                pop.antidromic = 1\n                pop.antidromic_prob = antidromic_prob_list[pop_idx]\n                pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n\n    @check_types()\n    def on(\n        self,\n        population_proportion: float | None = None,\n        dbs_depolarization: float | None = None,\n        orthodromic: bool | None = None,\n        antidromic: bool | None = None,\n        efferents: bool | None = None,\n        afferents: bool | None = None,\n        passing_fibres: bool | None = None,\n        passing_fibres_strength: float | list[float] | None = None,\n        sum_branches: bool | None = None,\n        axon_spikes_per_pulse: float | None = None,\n        axon_rate_amp: float | dict[Population | str, float] | None = None,\n        seed: int | None = None,\n    ):\n        \"\"\"\n        Activate DBS.\n\n        Args:\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: None, i.e., use value from\n                initialization\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: None,\n                i.e., use value from initialization\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically.\n                Default: None, i.e., use value from initialization\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: None, i.e., use value from\n                initialization\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: None, i.e., use value from initialization\n            passing_fibres_strength (float | list[float], optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: None, i.e., use value from initialization\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: None, i.e., use value from initialization\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: None, i.e., use\n                value from initialization\n            axon_rate_amp (float | dict[Population | str, float], optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value). You can specify the default value by using the key \"default\",\n                e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations\n                except pop forward a rate of 1.0 during DBS. Default: None, i.e., use\n                value from initialization\n            seed (int, optional):\n                Seed for the random number generator. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n\n        ### set DBS on for all populations\n        ### also sets the proportion of affected neurons, call this before set_depolarization and set_axon_spikes!\n        self._set_dbs_on(population_proportion, seed)\n\n        ### set depolarization of population\n        self._set_depolarization(dbs_depolarization)\n\n        ### set axon spikes forwarding\n        self._set_axon_spikes(\n            orthodromic,\n            antidromic,\n            efferents,\n            afferents,\n            passing_fibres,\n            passing_fibres_strength,\n            sum_branches,\n            axon_spikes_per_pulse,\n            axon_rate_amp,\n        )\n\n    def _set_dbs_on(self, population_proportion: float | None, seed: int | None):\n        \"\"\"\n        Set DBS on for all populations, for the stimulated population only the specified\n        proportion is affected by DBS.\n\n        Args:\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: None, i.e., use value from\n                initialization\n            seed (int, optional):\n                Seed for the random number generator. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n        ### set parameters for the creation of the DBS on array\n        ### either use given population_proportion or use default value\n        if isinstance(population_proportion, type(None)):\n            population_proportion = self.population_proportion\n        ### either use given seed or use default value\n        if isinstance(seed, type(None)):\n            seed = self.seed\n\n        ### if seed and population_propotion are the same as in the initialization, use the same dbs_on_array\n        if seed == self.seed and population_proportion == self.population_proportion:\n            ### use the same dbs_on_array as in the initialization\n            dbs_on_array = self.dbs_on_array\n        else:\n            ### create new dbs_on_array\n            dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n\n        ### set DBS on for all populations\n        for pop in populations():\n            ### of the stimulated population only the specified proportion is affected by DBS\n            if pop == self.stimulated_population:\n                pop.dbs_on = dbs_on_array\n            else:\n                pop.dbs_on = 1\n\n    def off(self):\n        \"\"\"\n        Deactivate DBS.\n        \"\"\"\n        ### set DBS off for all populations\n        for pop in populations():\n            pop.dbs_on = 0\n            pop.prob_axon_spike = 0\n            pop.axon_rate_amp = 0\n\n        ### deactivate DBS axon transmission\n        self._deactivate_axon_DBS()\n</code></pre>"},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator.__init__","title":"<code>__init__(stimulated_population, population_proportion=1.0, excluded_populations_list=[], dbs_depolarization=0.0, orthodromic=False, antidromic=False, efferents=False, afferents=False, passing_fibres=False, passing_fibres_list=[], passing_fibres_strength=1.0, sum_branches=True, dbs_pulse_frequency_Hz=130.0, dbs_pulse_width_us=300.0, axon_spikes_per_pulse=1.0, axon_rate_amp=1.0, seed=None, auto_implement=False, model=None)</code>","text":"<p>Initialize DBS stimulator.</p> <p>Warning</p> <p>Do this before compiling the model!</p> <p>Parameters:</p> Name Type Description Default <code>stimulated_population</code> <code>Population</code> <p>Population which is stimulated by DBS</p> required <code>population_proportion</code> <code>float</code> <p>Proportion of the stimulated population which is affected by DBS, neurons are distributed randomly. Default: 1.0.</p> <code>1.0</code> <code>excluded_populations_list</code> <code>list</code> <p>List of populations which are excluded from DBS effects, they are not affected and their axons do not generate axon spikes. Default: [].</p> <code>[]</code> <code>dbs_depolarization</code> <code>float</code> <p>Depolarization effect of the DBS pulse to local soma. Default: 0.0.</p> <code>0.0</code> <code>orthodromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded orthodromically. Default: False.</p> <code>False</code> <code>antidromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded antidromically, only available in spiking networks. Default: False.</p> <code>False</code> <code>efferents</code> <code>bool</code> <p>If True, DBS affects the efferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>afferents</code> <code>bool</code> <p>If True, DBS affects the afferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>passing_fibres</code> <code>bool</code> <p>If True, DBS affects the passing fibres of the stimulated region defined in passing_fibres_list (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>passing_fibres_list</code> <code>list of Projections</code> <p>List of projections which pass the DBS stimulated region and therefore are activated by DBS. Default: [], also set passing_fibres True!</p> <code>[]</code> <code>passing_fibres_strength</code> <code>float or list of float</code> <p>Single value or list of float values between 0 and 1 defining how strong the passing fibres are activated by DBS (0: not activated, 1: fully activated like the projections in the DBS stimulated region). Default: 1.</p> <code>1.0</code> <code>sum_branches</code> <code>bool</code> <p>If True, the antidromic_prob of a presynaptic population (defining how many axon spikes affect the pop antidromically) of passing fibres is the sum of the passing_fibres_strengths of the single axon branches. Default: True.</p> <code>True</code> <code>dbs_pulse_frequency_Hz</code> <code>float</code> <p>Frequency of the DBS pulse. Default: 130 Hz.</p> <code>130.0</code> <code>dbs_pulse_width_us</code> <code>float</code> <p>Width of the DBS pulse. Default: 300 us.</p> <code>300.0</code> <code>axon_spikes_per_pulse</code> <code>float</code> <p>Number of average axon spikes per DBS pulse. Default: 1.</p> <code>1.0</code> <code>axon_rate_amp</code> <code>float or dict of float</code> <p>Similar to prob_axon_spike in spiking model. Which rate is forwarded on axons caused by DBS. You can specify this for each population individually by using a dictionary (keys = Population instances) axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate of 1.5 during DBS (all other affected projections forward the default value) You can specify the default value by using the key \"default\", e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except pop forward a rate of 1.0 during DBS. Default: 1.0.</p> <code>1.0</code> <code>seed</code> <code>int</code> <p>Seed for the random distribution of affected neurons based on population_proportion. Default: None.</p> <code>None</code> <code>auto_implement</code> <code>bool</code> <p>If True, automatically implement DBS mechanisms to the model. Only supported for Izhikevich spiking models and rate-coded models. Default: False. TODO test what happens with mixed models</p> <code>False</code> <code>model</code> <code>generate_model</code> <p>CompNeuroPy model which is used to automatically implement DBS mechanisms, should not be compiled!. Default: None, i.e., use all populations and projections of the current magic model</p> <code>None</code> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    stimulated_population: Population,\n    population_proportion: float = 1.0,\n    excluded_populations_list: list[Population] = [],\n    dbs_depolarization: float = 0.0,\n    orthodromic: bool = False,\n    antidromic: bool = False,\n    efferents: bool = False,\n    afferents: bool = False,\n    passing_fibres: bool = False,\n    passing_fibres_list: list[Projection] = [],\n    passing_fibres_strength: float | list[float] = 1.0,\n    sum_branches: bool = True,\n    dbs_pulse_frequency_Hz: float = 130.0,\n    dbs_pulse_width_us: float = 300.0,\n    axon_spikes_per_pulse: float = 1.0,\n    axon_rate_amp: float | dict[Population | str, float] = 1.0,\n    seed: int | None = None,\n    auto_implement: bool = False,\n    model: generate_model | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize DBS stimulator.\n\n    !!! warning\n        Do this before compiling the model!\n\n    Args:\n        stimulated_population (Population):\n            Population which is stimulated by DBS\n        population_proportion (float, optional):\n            Proportion of the stimulated population which is affected by DBS,\n            neurons are distributed randomly. Default: 1.0.\n        excluded_populations_list (list, optional):\n            List of populations which are excluded from DBS effects, they are not\n            affected and their axons do not generate axon spikes. Default: [].\n        dbs_depolarization (float, optional):\n            Depolarization effect of the DBS pulse to local soma. Default: 0.0.\n        orthodromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded orthodromically.\n            Default: False.\n        antidromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded antidromically,\n            only available in spiking networks. Default: False.\n        efferents (bool, optional):\n            If True, DBS affects the efferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: False.\n        afferents (bool, optional):\n            If True, DBS affects the afferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: False.\n        passing_fibres (bool, optional):\n            If True, DBS affects the passing fibres of the stimulated region defined\n            in passing_fibres_list (orthodromic and/or antidromic have to be True\n            too). Default: False.\n        passing_fibres_list (list of Projections, optional):\n            List of projections which pass the DBS stimulated region and therefore\n            are activated by DBS. Default: [], also set passing_fibres True!\n        passing_fibres_strength (float or list of float, optional):\n            Single value or list of float values between 0 and 1 defining how strong\n            the passing fibres are activated by DBS (0: not activated, 1: fully\n            activated like the projections in the DBS stimulated region).\n            Default: 1.\n        sum_branches (bool, optional):\n            If True, the antidromic_prob of a presynaptic population (defining how\n            many axon spikes affect the pop antidromically) of passing fibres is\n            the sum of the passing_fibres_strengths of the single axon branches.\n            Default: True.\n        dbs_pulse_frequency_Hz (float, optional):\n            Frequency of the DBS pulse. Default: 130 Hz.\n        dbs_pulse_width_us (float, optional):\n            Width of the DBS pulse. Default: 300 us.\n        axon_spikes_per_pulse (float, optional):\n            Number of average axon spikes per DBS pulse. Default: 1.\n        axon_rate_amp (float or dict of float, optional):\n            Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n            axons caused by DBS. You can specify this for each population\n            individually by using a dictionary (keys = Population instances)\n            axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n            of 1.5 during DBS (all other affected projections forward the default\n            value)\n            You can specify the default value by using the key \"default\", e.g.\n            {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n            pop forward a rate of 1.0 during DBS. Default: 1.0.\n        seed (int, optional):\n            Seed for the random distribution of affected neurons based on\n            population_proportion. Default: None.\n        auto_implement (bool, optional):\n            If True, automatically implement DBS mechanisms to the model. Only\n            supported for Izhikevich spiking models and rate-coded models.\n            Default: False.\n            TODO test what happens with mixed models\n        model (generate_model, optional):\n            CompNeuroPy model which is used to automatically implement DBS\n            mechanisms, should not be compiled!. Default: None, i.e., use all\n            populations and projections of the current magic model\n    \"\"\"\n\n    if auto_implement:\n        ### recreate model with DBS mechanisms\n        ### give all variables containing Populations and Projections\n        ### and also recreate them during recreating the model\n        ### variables are:\n        ### - stimulated_population\n        ### - excluded_populations_list\n        ### - passing_fibres_list\n        ### - axon_rate_amp\n        if not isinstance(model, type(None)):\n            ### CompNeuroPy model given\n            ### recreate model with DBS mechanisms\n            create_dbs_model_obj = _CreateDBSmodelcnp(\n                model,\n                stimulated_population,\n                excluded_populations_list,\n                passing_fibres_list,\n                axon_rate_amp,\n            )\n            ### get the new CompNeuroPy model\n            model = create_dbs_model_obj.model\n        else:\n            ### no CompNeuroPy model given --&gt; use all populations and projections of the current magic model\n            ### recreate model with DBS mechanisms\n            create_dbs_model_obj = _CreateDBSmodel(\n                stimulated_population,\n                excluded_populations_list,\n                passing_fibres_list,\n                axon_rate_amp,\n            )\n        ### get the new variables containing Populations and Projections\n        stimulated_population = create_dbs_model_obj.stimulated_population\n        excluded_populations_list = create_dbs_model_obj.excluded_populations_list\n        passing_fibres_list = create_dbs_model_obj.passing_fibres_list\n        axon_rate_amp = create_dbs_model_obj.axon_rate_amp\n\n    ### set parameters\n    self.stimulated_population = stimulated_population\n    self.population_proportion = population_proportion\n    self.excluded_populations_list = excluded_populations_list\n    self.dbs_depolarization = dbs_depolarization\n    self.orthodromic = orthodromic\n    self.antidromic = antidromic\n    self.efferents = efferents\n    self.afferents = afferents\n    self.passing_fibres = passing_fibres\n    self.passing_fibres_list = passing_fibres_list\n    self.passing_fibres_strength = passing_fibres_strength\n    self.sum_branches = sum_branches\n    self.dbs_pulse_width_us = dbs_pulse_width_us\n    self.axon_spikes_per_pulse = axon_spikes_per_pulse\n    self.axon_rate_amp = axon_rate_amp\n    self.seed = seed\n    self.model = model\n\n    ### ANNarchy constants for DBS\n    self._set_constants(dbs_pulse_frequency_Hz)\n\n    ### randomly select affected neurons i.e. create dbs_on_array\n    self.dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n</code></pre>"},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator.on","title":"<code>on(population_proportion=None, dbs_depolarization=None, orthodromic=None, antidromic=None, efferents=None, afferents=None, passing_fibres=None, passing_fibres_strength=None, sum_branches=None, axon_spikes_per_pulse=None, axon_rate_amp=None, seed=None)</code>","text":"<p>Activate DBS.</p> <p>Parameters:</p> Name Type Description Default <code>population_proportion</code> <code>float</code> <p>Proportion of the stimulated population which is affected by DBS, neurons are distributed randomly. Default: None, i.e., use value from initialization</p> <code>None</code> <code>dbs_depolarization</code> <code>float</code> <p>Depolarization effect of the DBS pulse to local soma. Default: None, i.e., use value from initialization</p> <code>None</code> <code>orthodromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded orthodromically. Default: None, i.e., use value from initialization</p> <code>None</code> <code>antidromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded antidromically, only available in spiking networks. Default: None, i.e., use value from initialization</p> <code>None</code> <code>efferents</code> <code>bool</code> <p>If True, DBS affects the efferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>afferents</code> <code>bool</code> <p>If True, DBS affects the afferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>passing_fibres</code> <code>bool</code> <p>If True, DBS affects the passing fibres of the stimulated region defined in passing_fibres_list (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>passing_fibres_strength</code> <code>float | list[float]</code> <p>Single value or list of float values between 0 and 1 defining how strong the passing fibres are activated by DBS (0: not activated, 1: fully activated like the projections in the DBS stimulated region). Default: None, i.e., use value from initialization</p> <code>None</code> <code>sum_branches</code> <code>bool</code> <p>If True, the antidromic_prob of a presynaptic population (defining how many axon spikes affect the pop antidromically) of passing fibres is the sum of the passing_fibres_strengths of the single axon branches. Default: None, i.e., use value from initialization</p> <code>None</code> <code>axon_spikes_per_pulse</code> <code>float</code> <p>Number of average axon spikes per DBS pulse. Default: None, i.e., use value from initialization</p> <code>None</code> <code>axon_rate_amp</code> <code>float | dict[Population | str, float]</code> <p>Similar to prob_axon_spike in spiking model. Which rate is forwarded on axons caused by DBS. You can specify this for each population individually by using a dictionary (keys = Population instances) axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate of 1.5 during DBS (all other affected projections forward the default value). You can specify the default value by using the key \"default\", e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except pop forward a rate of 1.0 during DBS. Default: None, i.e., use value from initialization</p> <code>None</code> <code>seed</code> <code>int</code> <p>Seed for the random number generator. Default: None, i.e., use value from initialization</p> <code>None</code> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>@check_types()\ndef on(\n    self,\n    population_proportion: float | None = None,\n    dbs_depolarization: float | None = None,\n    orthodromic: bool | None = None,\n    antidromic: bool | None = None,\n    efferents: bool | None = None,\n    afferents: bool | None = None,\n    passing_fibres: bool | None = None,\n    passing_fibres_strength: float | list[float] | None = None,\n    sum_branches: bool | None = None,\n    axon_spikes_per_pulse: float | None = None,\n    axon_rate_amp: float | dict[Population | str, float] | None = None,\n    seed: int | None = None,\n):\n    \"\"\"\n    Activate DBS.\n\n    Args:\n        population_proportion (float, optional):\n            Proportion of the stimulated population which is affected by DBS,\n            neurons are distributed randomly. Default: None, i.e., use value from\n            initialization\n        dbs_depolarization (float, optional):\n            Depolarization effect of the DBS pulse to local soma. Default: None,\n            i.e., use value from initialization\n        orthodromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded orthodromically.\n            Default: None, i.e., use value from initialization\n        antidromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded antidromically,\n            only available in spiking networks. Default: None, i.e., use value from\n            initialization\n        efferents (bool, optional):\n            If True, DBS affects the efferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: None,\n            i.e., use value from initialization\n        afferents (bool, optional):\n            If True, DBS affects the afferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: None,\n            i.e., use value from initialization\n        passing_fibres (bool, optional):\n            If True, DBS affects the passing fibres of the stimulated region defined\n            in passing_fibres_list (orthodromic and/or antidromic have to be True\n            too). Default: None, i.e., use value from initialization\n        passing_fibres_strength (float | list[float], optional):\n            Single value or list of float values between 0 and 1 defining how strong\n            the passing fibres are activated by DBS (0: not activated, 1: fully\n            activated like the projections in the DBS stimulated region).\n            Default: None, i.e., use value from initialization\n        sum_branches (bool, optional):\n            If True, the antidromic_prob of a presynaptic population (defining how\n            many axon spikes affect the pop antidromically) of passing fibres is\n            the sum of the passing_fibres_strengths of the single axon branches.\n            Default: None, i.e., use value from initialization\n        axon_spikes_per_pulse (float, optional):\n            Number of average axon spikes per DBS pulse. Default: None, i.e., use\n            value from initialization\n        axon_rate_amp (float | dict[Population | str, float], optional):\n            Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n            axons caused by DBS. You can specify this for each population\n            individually by using a dictionary (keys = Population instances)\n            axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n            of 1.5 during DBS (all other affected projections forward the default\n            value). You can specify the default value by using the key \"default\",\n            e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations\n            except pop forward a rate of 1.0 during DBS. Default: None, i.e., use\n            value from initialization\n        seed (int, optional):\n            Seed for the random number generator. Default: None, i.e., use value\n            from initialization\n    \"\"\"\n\n    ### set DBS on for all populations\n    ### also sets the proportion of affected neurons, call this before set_depolarization and set_axon_spikes!\n    self._set_dbs_on(population_proportion, seed)\n\n    ### set depolarization of population\n    self._set_depolarization(dbs_depolarization)\n\n    ### set axon spikes forwarding\n    self._set_axon_spikes(\n        orthodromic,\n        antidromic,\n        efferents,\n        afferents,\n        passing_fibres,\n        passing_fibres_strength,\n        sum_branches,\n        axon_spikes_per_pulse,\n        axon_rate_amp,\n    )\n</code></pre>"},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator.off","title":"<code>off()</code>","text":"<p>Deactivate DBS.</p> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>def off(self):\n    \"\"\"\n    Deactivate DBS.\n    \"\"\"\n    ### set DBS off for all populations\n    for pop in populations():\n        pop.dbs_on = 0\n        pop.prob_axon_spike = 0\n        pop.axon_rate_amp = 0\n\n    ### deactivate DBS axon transmission\n    self._deactivate_axon_DBS()\n</code></pre>"},{"location":"main/define_experiment/","title":"Define an Experiment","text":""},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.Experiment","title":"<code>src.CompNeuroPy.experiment.Experiment</code>","text":"<p>Experiment combining simulations and recordings.</p> <p>Use this class as a parent class for your experiment. You have to additionally implement a run function which runs the simulations and controlls the recordings. The run function should return the results of the experiment by calling the results function of the Experiment class.</p> <p>Attributes:</p> Name Type Description <code>mon</code> <code>Monitors</code> <p>Monitors object for recordings</p> <code>data</code> <code>dict</code> <p>dict for storing optional data</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from CompNeuroPy import Experiment\n&gt;&gt;&gt; from ANNarchy import simulate\n&gt;&gt;&gt;\n&gt;&gt;&gt; class MyExperiment(Experiment):\n&gt;&gt;&gt;     def run(self):\n&gt;&gt;&gt;         # run simulations and control recordings\n&gt;&gt;&gt;         self.mon.start()\n&gt;&gt;&gt;         simulate(1000)\n&gt;&gt;&gt;         self.reset()\n&gt;&gt;&gt;         simulate(1000)\n&gt;&gt;&gt;         # store optional data\n&gt;&gt;&gt;         self.data[\"duration\"] = 2000\n&gt;&gt;&gt;         # return results\n&gt;&gt;&gt;         return self.results()\n</code></pre> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>class Experiment:\n    \"\"\"\n    Experiment combining simulations and recordings.\n\n    Use this class as a parent class for your experiment. You have to additionally\n    implement a run function which runs the simulations and controlls the recordings.\n    The run function should return the results of the experiment by calling the results\n    function of the Experiment class.\n\n    Attributes:\n        mon (Monitors):\n            Monitors object for recordings\n        data (dict):\n            dict for storing optional data\n\n    Examples:\n        &gt;&gt;&gt; from CompNeuroPy import Experiment\n        &gt;&gt;&gt; from ANNarchy import simulate\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; class MyExperiment(Experiment):\n        &gt;&gt;&gt;     def run(self):\n        &gt;&gt;&gt;         # run simulations and control recordings\n        &gt;&gt;&gt;         self.mon.start()\n        &gt;&gt;&gt;         simulate(1000)\n        &gt;&gt;&gt;         self.reset()\n        &gt;&gt;&gt;         simulate(1000)\n        &gt;&gt;&gt;         # store optional data\n        &gt;&gt;&gt;         self.data[\"duration\"] = 2000\n        &gt;&gt;&gt;         # return results\n        &gt;&gt;&gt;         return self.results()\n    \"\"\"\n\n    def __init__(self, monitors: Monitors, reset_function=None, reset_kwargs={}):\n        \"\"\"\n        Initialize the Experiment.\n\n        Args:\n            monitors (Monitors):\n                Monitors object for recordings\n            reset_function (function, optional):\n                A function which resets the ANNarchy model.\n                Default: None, i.e., ANNarchys' reset function\n            reset_kwargs (dict, optional):\n                Arguments of the reset_function besides the ones which are used by\n                ANNarchys' reset function. Default: {}.\n        \"\"\"\n        self.recordings = {}  # save dict for monitor recordings\n        self.mon = monitors\n        self.data = {}  # dict for optional data\n\n        ### check function to reset network\n        if reset_function is None:\n            self.reset_function = reset\n        else:\n            self.reset_function = reset_function\n        self.reset_kwargs = reset_kwargs\n\n    def reset(self, populations=True, projections=False, synapses=False):\n        \"\"\"\n        Reset the ANNarchy model and monitors and the CompNeuroPy Monitors used for the\n        Experiment. The reset function of the Experiment is used which can be set during\n        initialization and can have additional arguments besides the ones which are used\n        by ANNarchys' reset function which are also set during initialization.\n\n        Args:\n            populations (bool, optional):\n                reset populations. Defaults to True.\n            projections (bool, optional):\n                reset projections. Defaults to False.\n            synapses (bool, optional):\n                reset synapses. Defaults to False.\n            monitors (bool, optional):\n                reset monitors. Defaults to True.\n        \"\"\"\n        self.reset_kwargs[\"populations\"] = populations\n        self.reset_kwargs[\"projections\"] = projections\n        self.reset_kwargs[\"synapses\"] = synapses\n        self.reset_kwargs[\"monitors\"] = True\n        ### reset monitors\n        self.mon.reset()\n        ### reset ANNarchy model\n        self.reset_function(**self.reset_kwargs)\n\n    def results(self):\n        \"\"\"\n        !!! warning\n            Call this function at the end of the run function of the experiment!\n\n        Returns:\n            results_obj (Experiment._ResultsCl):\n                Object with with attributes:\n                    recordings (list):\n                        list of recordings\n                    recording_times (recording_times_cl):\n                        recording times object\n                    monDict (dict):\n                        dict of recorded variables of the monitors\n                    data (dict):\n                        dict with optional data stored during the experiment\n        \"\"\"\n        obj = self._ResultsCl()\n        obj.recordings, obj.recording_times = self.mon.get_recordings_and_clear()\n        obj.monDict = self.mon.monDict\n        obj.data = self.data\n\n        return obj\n\n    class _ResultsCl:\n        \"\"\"\n        Class for storing the results of the experiment.\n\n        Attributes:\n            recordings (list):\n                list of recordings\n            recording_times (recording_times_cl):\n                recording times object\n            monDict (dict):\n                dict of recorded variables of the monitors\n            data (dict):\n                dict with optional data stored during the experiment\n        \"\"\"\n\n        def __init__(self) -&gt; None:\n            self.recordings: list\n            self.recording_times: recording_times_cl\n            self.monDict: dict\n            self.data: dict\n</code></pre>"},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.Experiment.__init__","title":"<code>__init__(monitors, reset_function=None, reset_kwargs={})</code>","text":"<p>Initialize the Experiment.</p> <p>Parameters:</p> Name Type Description Default <code>monitors</code> <code>Monitors</code> <p>Monitors object for recordings</p> required <code>reset_function</code> <code>function</code> <p>A function which resets the ANNarchy model. Default: None, i.e., ANNarchys' reset function</p> <code>None</code> <code>reset_kwargs</code> <code>dict</code> <p>Arguments of the reset_function besides the ones which are used by ANNarchys' reset function. Default: {}.</p> <code>{}</code> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def __init__(self, monitors: Monitors, reset_function=None, reset_kwargs={}):\n    \"\"\"\n    Initialize the Experiment.\n\n    Args:\n        monitors (Monitors):\n            Monitors object for recordings\n        reset_function (function, optional):\n            A function which resets the ANNarchy model.\n            Default: None, i.e., ANNarchys' reset function\n        reset_kwargs (dict, optional):\n            Arguments of the reset_function besides the ones which are used by\n            ANNarchys' reset function. Default: {}.\n    \"\"\"\n    self.recordings = {}  # save dict for monitor recordings\n    self.mon = monitors\n    self.data = {}  # dict for optional data\n\n    ### check function to reset network\n    if reset_function is None:\n        self.reset_function = reset\n    else:\n        self.reset_function = reset_function\n    self.reset_kwargs = reset_kwargs\n</code></pre>"},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.Experiment.reset","title":"<code>reset(populations=True, projections=False, synapses=False)</code>","text":"<p>Reset the ANNarchy model and monitors and the CompNeuroPy Monitors used for the Experiment. The reset function of the Experiment is used which can be set during initialization and can have additional arguments besides the ones which are used by ANNarchys' reset function which are also set during initialization.</p> <p>Parameters:</p> Name Type Description Default <code>populations</code> <code>bool</code> <p>reset populations. Defaults to True.</p> <code>True</code> <code>projections</code> <code>bool</code> <p>reset projections. Defaults to False.</p> <code>False</code> <code>synapses</code> <code>bool</code> <p>reset synapses. Defaults to False.</p> <code>False</code> <code>monitors</code> <code>bool</code> <p>reset monitors. Defaults to True.</p> required Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def reset(self, populations=True, projections=False, synapses=False):\n    \"\"\"\n    Reset the ANNarchy model and monitors and the CompNeuroPy Monitors used for the\n    Experiment. The reset function of the Experiment is used which can be set during\n    initialization and can have additional arguments besides the ones which are used\n    by ANNarchys' reset function which are also set during initialization.\n\n    Args:\n        populations (bool, optional):\n            reset populations. Defaults to True.\n        projections (bool, optional):\n            reset projections. Defaults to False.\n        synapses (bool, optional):\n            reset synapses. Defaults to False.\n        monitors (bool, optional):\n            reset monitors. Defaults to True.\n    \"\"\"\n    self.reset_kwargs[\"populations\"] = populations\n    self.reset_kwargs[\"projections\"] = projections\n    self.reset_kwargs[\"synapses\"] = synapses\n    self.reset_kwargs[\"monitors\"] = True\n    ### reset monitors\n    self.mon.reset()\n    ### reset ANNarchy model\n    self.reset_function(**self.reset_kwargs)\n</code></pre>"},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.Experiment.results","title":"<code>results()</code>","text":"<p>Warning</p> <p>Call this function at the end of the run function of the experiment!</p> <p>Returns:</p> Name Type Description <code>results_obj</code> <code>_ResultsCl</code> <p>Object with with attributes:     recordings (list):         list of recordings     recording_times (recording_times_cl):         recording times object     monDict (dict):         dict of recorded variables of the monitors     data (dict):         dict with optional data stored during the experiment</p> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def results(self):\n    \"\"\"\n    !!! warning\n        Call this function at the end of the run function of the experiment!\n\n    Returns:\n        results_obj (Experiment._ResultsCl):\n            Object with with attributes:\n                recordings (list):\n                    list of recordings\n                recording_times (recording_times_cl):\n                    recording times object\n                monDict (dict):\n                    dict of recorded variables of the monitors\n                data (dict):\n                    dict with optional data stored during the experiment\n    \"\"\"\n    obj = self._ResultsCl()\n    obj.recordings, obj.recording_times = self.mon.get_recordings_and_clear()\n    obj.monDict = self.mon.monDict\n    obj.data = self.data\n\n    return obj\n</code></pre>"},{"location":"main/generate_models/","title":"Generate Models","text":""},{"location":"main/generate_models/#introduction","title":"Introduction","text":"<p>One can create a CompNeuroPy-model using the <code>generate_model</code> class. The <code>generate_model</code> class takes as one argument the <code>model_creation_function</code>. In this function a classical ANNarchy model is created (populations, projections). The <code>generate_model</code> class only adds a framework to the model. Neccessary for a CompNeuroPy-model is to define unique names for all populations and projections. Models are created in three steps:</p> <ol> <li>model initialization: the initialization of the <code>generate_model</code> object, initializes the framework of the model without creating the ANNarchy objects (populations, projections)</li> <li>model creation: create the ANNarchy objects (populations, projections), i.e., run the <code>model_creation function</code></li> <li>model compilation: compile all created models</li> </ol>"},{"location":"main/generate_models/#example","title":"Example","text":"<pre><code>from CompNeuroPy import generate_model\nmy_model = generate_model(model_creation_function=create_model,  ### the most important part, this function creates the model (populations, projections)\n                          model_kwargs={'a':1, 'b':2},           ### define the two arguments a and b of function create_model\n                          name='my_model',                       ### you can give the model a name\n                          description='my simple example model', ### you can give the model a description\n                          do_create=True,                        ### create the model directly\n                          do_compile=True,                       ### let the model (and all models created before) compile directly\n                          compile_folder_name='my_model')        ### name of the saved compilation folder\n</code></pre> <p>The following function could be the corresponding model_creation_function:</p> <pre><code>from ANNarchy import Population, Izhikevich\ndef create_model(a, b):\n    pop = Population(geometry=a, neuron=Izhikevich, name='Izh_pop_a') ### first population, size a\n    pop.b = 0                                                         ### some parameter adjustment\n    Population(geometry=b, neuron=Izhikevich, name='Izh_pop_b')       ### second population, size b\n</code></pre> <p>Here, two populations are created (both use built-in Izhikevich neuron model of ANNarchy). The function does not require a return value. It is important that all populations and projections have unique names.</p> <p>A more detailed example is available in the Examples.</p>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.generate_model","title":"<code>src.CompNeuroPy.generate_model.generate_model</code>","text":"<p>Class for creating and compiling a model.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>name of the model</p> <code>description</code> <code>str</code> <p>description of the model</p> <code>populations</code> <code>list</code> <p>list of all populations of the model</p> <code>projections</code> <code>list</code> <p>list of all projections of the model</p> <code>attribute_df</code> <code>pandas dataframe</code> <p>dataframe containing all attributes of the model compartments</p> <code>created</code> <code>bool</code> <p>True if the model is created</p> <code>compiled</code> <code>bool</code> <p>True if the model is compiled</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>class generate_model:\n    \"\"\"\n    Class for creating and compiling a model.\n\n    Attributes:\n        name (str):\n            name of the model\n        description (str):\n            description of the model\n        populations (list):\n            list of all populations of the model\n        projections (list):\n            list of all projections of the model\n        attribute_df (pandas dataframe):\n            dataframe containing all attributes of the model compartments\n        created (bool):\n            True if the model is created\n        compiled (bool):\n            True if the model is compiled\n    \"\"\"\n\n    initialized_models = {}\n    compiled_models = {}\n\n    def __init__(\n        self,\n        model_creation_function,\n        model_kwargs=None,\n        name=\"model\",\n        description=\"\",\n        do_create=True,\n        do_compile=True,\n        compile_folder_name=\"annarchy\",\n    ):\n        \"\"\"\n        Initializes the generate_model class.\n\n        Args:\n            model_creation_function (function):\n                Function which creates the model.\n            model_kwargs (dict):\n                Keyword arguments for model_creation_function. Default: None.\n            name (str):\n                Name of the model. Default: \"model\".\n            description (str):\n                Description of the model. Default: \"\".\n            do_create (bool):\n                If True the model is created directly. Default: True.\n            do_compile (bool):\n                If True the model is compiled directly. Default: True.\n            compile_folder_name (str):\n                Name of the folder in which the model is compiled. Default: \"annarchy\".\n        \"\"\"\n        self.name = name\n        if name == \"model\":\n            self.name = name + str(self._nr_models())\n        self.description = description\n        self.model_creation_function = model_creation_function\n        self.compile_folder_name = compile_folder_name\n        self.model_kwargs = model_kwargs\n        self.populations = []\n        self.projections = []\n        self.initialized_models[self.name] = False\n        self.compiled_models[self.name] = False\n        if do_create:\n            self.create(do_compile=do_compile, compile_folder_name=compile_folder_name)\n\n    def __getattr__(self, name):\n        if name == \"created\":\n            return self.initialized_models[self.name]\n        elif name == \"compiled\":\n            return self.compiled_models[self.name]\n        else:\n            # Default behaviour\n            raise AttributeError\n\n    def compile(self, compile_folder_name=None):\n        \"\"\"\n        compiles a created model\n        \"\"\"\n        ### check if this model is created\n        if self.initialized_models[self.name]:\n            if compile_folder_name == None:\n                compile_folder_name = self.compile_folder_name\n\n            ### check if other models were initialized but not created --&gt; warn that they are not compiled\n            not_created_model_list = self._check_if_models_created()\n            if len(not_created_model_list) &gt; 0:\n                print(\n                    \"\\nWARNING during compile of model \"\n                    + self.name\n                    + \": There are initialized models which are not created, thus not compiled! models:\\n\"\n                    + \"\\n\".join(not_created_model_list)\n                    + \"\\n\"\n                )\n            mf.compile_in_folder(compile_folder_name)\n            self.compiled_models[self.name] = True\n        else:\n            print(\"\\n\")\n            assert False, (\n                \"ERROR during compile of model \"\n                + self.name\n                + \": Only compile the model after it has been created!\"\n            )\n\n    def create(self, do_compile=True, compile_folder_name=None):\n        \"\"\"\n        creates a model and optionally compiles it directly\n        \"\"\"\n        if self.initialized_models[self.name]:\n            print(\"model\", self.name, \"already created!\")\n        else:\n            initial_existing_model = mf.get_full_model()\n            ### create model populations and projections\n            if self.model_kwargs != None:\n                self.model_creation_function(**self.model_kwargs)\n            else:\n                self.model_creation_function()\n            self.initialized_models[self.name] = True\n\n            ### check which populations and projections have been added\n            post_existing_model = mf.get_full_model()\n            ### save only added not all projections/populations\n            for initial_pop in initial_existing_model[\"populations\"]:\n                post_existing_model[\"populations\"].remove(initial_pop)\n            for initial_proj in initial_existing_model[\"projections\"]:\n                post_existing_model[\"projections\"].remove(initial_proj)\n            self.populations = post_existing_model[\"populations\"]\n            self.projections = post_existing_model[\"projections\"]\n\n            self.initialized_models[self.name] = True\n\n            ### check if names of populations and projections are unique\n            self._check_double_compartments()\n\n            ### create parameter dictionary\n            self.attribute_df = self._get_attribute_df()\n\n            if do_compile:\n                self.compile(compile_folder_name)\n\n    def _check_if_models_created(self):\n        \"\"\"\n        checks which CompNeuroPy models are created\n        returns a list with all initialized CompNeuroPy models which are not created yet\n        \"\"\"\n        not_created_model_list = []\n        for key in self.initialized_models.keys():\n            if self.initialized_models[key] == False:\n                not_created_model_list.append(key)\n\n        return not_created_model_list\n\n    def _nr_models(self):\n        \"\"\"\n        returns the current number of initialized (not considering \"created\") CompNeuroPy models\n        \"\"\"\n        return len(list(self.initialized_models.keys()))\n\n    def set_param(self, compartment, parameter_name, parameter_value):\n        \"\"\"\n        sets the specified parameter of the specified compartment\n\n        args:\n            compartment: str\n                name of model compartment\n            parameter_name: str\n                name of parameter of the compartment\n            parameter_value: number or array-like with shape of compartment geometry\n                the value or values of the parameter\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR set_param: model {self.name} has to be created before setting parameters!\"\n\n        ### check if compartment is in populations or projections\n        comp_in_pop = compartment in self.populations\n        comp_in_proj = compartment in self.projections\n\n        if comp_in_pop:\n            comp_obj = get_population(compartment)\n        elif comp_in_proj:\n            comp_obj = get_projection(compartment)\n        else:\n            assert (\n                comp_in_pop or comp_in_proj\n            ), f\"ERROR set_param: setting parameter {parameter_name} of compartment {compartment}. The compartment is neither a population nor a projection of the model {self.name}!\"\n\n        ### set the parameter value\n        setattr(comp_obj, parameter_name, parameter_value)\n\n        ### update the model attribute_df\n        self._update_attribute_df(compartment, parameter_name, parameter_value)\n\n    def _update_attribute_df(self, compartment, parameter_name, parameter_value):\n        \"\"\"updates the attribute df for a specific paramter\"\"\"\n        paramter_mask = (\n            (self.attribute_df[\"compartment_name\"] == compartment).astype(int)\n            * (self.attribute_df[\"attribute_name\"] == parameter_name).astype(int)\n        ).astype(bool)\n        parameter_idx = np.arange(paramter_mask.size).astype(int)[paramter_mask][0]\n        min_val = af.get_minimum(parameter_value)\n        max_val = af.get_maximum(parameter_value)\n        if min_val != max_val:\n            self.attribute_df.at[parameter_idx, \"value\"] = f\"[{min_val}, {max_val}]\"\n        else:\n            self.attribute_df.at[parameter_idx, \"value\"] = str(min_val)\n        self.attribute_df.at[parameter_idx, \"definition\"] = \"modified\"\n\n    def _check_double_compartments(self):\n        \"\"\"\n        goes over all compartments of the model and checks if compartment is only a population or a projection\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR model {self.name}: model has to be created before checking for double compartments!\"\n        ### only have to go over populations and check if they are also projections (go over projections not neccessary)\n        pop_in_projections_list = []\n        pop_in_projections = False\n        for pop_name in self.populations:\n            if pop_name in self.projections:\n                pop_in_projections_list.append(pop_name)\n                pop_in_projections = True\n\n        assert (\n            pop_in_projections == False\n        ), f\"ERROR model {self.name}: One or multiple compartments are both population and projection ({pop_in_projections_list}). Rename them!\"\n\n    def _get_attribute_df(self):\n        \"\"\"\n        creates a dataframe containing the attributes of all model compartments\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR model {self.name}: model has to be created before creating paramteer dictionary!\"\n\n        ### create empty paramteter dict\n        attribute_dict = {\n            \"compartment_type\": [],\n            \"compartment_name\": [],\n            \"attribute_name\": [],\n            \"value\": [],\n            \"definition\": [],\n        }\n\n        ### fill paramter dict with population attributes\n        for pop in self.populations:\n            for attribute in vars(get_population(pop))[\"attributes\"]:\n                ### store min and max of attribute\n                ### create numpy array with getattr to use numpy min max function\n                values = np.array(\n                    [getattr(get_population(pop), attribute)]\n                    + [getattr(get_population(pop), attribute)]\n                )\n                attribute_dict[\"compartment_type\"].append(\"population\")\n                attribute_dict[\"compartment_name\"].append(pop)\n                attribute_dict[\"attribute_name\"].append(attribute)\n                if values.min() != values.max():\n                    attribute_dict[\"value\"].append(f\"[{values.min()}, {values.max()}]\")\n                else:\n                    attribute_dict[\"value\"].append(str(values.min()))\n                attribute_dict[\"definition\"].append(\"init\")\n\n        ### fill paramter dict with projection attributes\n        for proj in self.projections:\n            for attribute in vars(get_projection(proj))[\"attributes\"]:\n                ### store min and max of attribute\n                ### create numpy array with getattr to use numpy min max function\n                values = np.array(\n                    [getattr(get_projection(proj), attribute)]\n                    + [getattr(get_projection(proj), attribute)]\n                )\n                attribute_dict[\"compartment_type\"].append(\"projection\")\n                attribute_dict[\"compartment_name\"].append(proj)\n                attribute_dict[\"attribute_name\"].append(attribute)\n                if values.min() != values.max():\n                    attribute_dict[\"value\"].append(f\"[{values.min()}, {values.max()}]\")\n                else:\n                    attribute_dict[\"value\"].append(values.min())\n                attribute_dict[\"definition\"].append(\"init\")\n\n        ### return dataframe\n        return pd.DataFrame(attribute_dict)\n</code></pre>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.generate_model.__init__","title":"<code>__init__(model_creation_function, model_kwargs=None, name='model', description='', do_create=True, do_compile=True, compile_folder_name='annarchy')</code>","text":"<p>Initializes the generate_model class.</p> <p>Parameters:</p> Name Type Description Default <code>model_creation_function</code> <code>function</code> <p>Function which creates the model.</p> required <code>model_kwargs</code> <code>dict</code> <p>Keyword arguments for model_creation_function. Default: None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the model. Default: \"model\".</p> <code>'model'</code> <code>description</code> <code>str</code> <p>Description of the model. Default: \"\".</p> <code>''</code> <code>do_create</code> <code>bool</code> <p>If True the model is created directly. Default: True.</p> <code>True</code> <code>do_compile</code> <code>bool</code> <p>If True the model is compiled directly. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: \"annarchy\".</p> <code>'annarchy'</code> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def __init__(\n    self,\n    model_creation_function,\n    model_kwargs=None,\n    name=\"model\",\n    description=\"\",\n    do_create=True,\n    do_compile=True,\n    compile_folder_name=\"annarchy\",\n):\n    \"\"\"\n    Initializes the generate_model class.\n\n    Args:\n        model_creation_function (function):\n            Function which creates the model.\n        model_kwargs (dict):\n            Keyword arguments for model_creation_function. Default: None.\n        name (str):\n            Name of the model. Default: \"model\".\n        description (str):\n            Description of the model. Default: \"\".\n        do_create (bool):\n            If True the model is created directly. Default: True.\n        do_compile (bool):\n            If True the model is compiled directly. Default: True.\n        compile_folder_name (str):\n            Name of the folder in which the model is compiled. Default: \"annarchy\".\n    \"\"\"\n    self.name = name\n    if name == \"model\":\n        self.name = name + str(self._nr_models())\n    self.description = description\n    self.model_creation_function = model_creation_function\n    self.compile_folder_name = compile_folder_name\n    self.model_kwargs = model_kwargs\n    self.populations = []\n    self.projections = []\n    self.initialized_models[self.name] = False\n    self.compiled_models[self.name] = False\n    if do_create:\n        self.create(do_compile=do_compile, compile_folder_name=compile_folder_name)\n</code></pre>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.generate_model.compile","title":"<code>compile(compile_folder_name=None)</code>","text":"<p>compiles a created model</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def compile(self, compile_folder_name=None):\n    \"\"\"\n    compiles a created model\n    \"\"\"\n    ### check if this model is created\n    if self.initialized_models[self.name]:\n        if compile_folder_name == None:\n            compile_folder_name = self.compile_folder_name\n\n        ### check if other models were initialized but not created --&gt; warn that they are not compiled\n        not_created_model_list = self._check_if_models_created()\n        if len(not_created_model_list) &gt; 0:\n            print(\n                \"\\nWARNING during compile of model \"\n                + self.name\n                + \": There are initialized models which are not created, thus not compiled! models:\\n\"\n                + \"\\n\".join(not_created_model_list)\n                + \"\\n\"\n            )\n        mf.compile_in_folder(compile_folder_name)\n        self.compiled_models[self.name] = True\n    else:\n        print(\"\\n\")\n        assert False, (\n            \"ERROR during compile of model \"\n            + self.name\n            + \": Only compile the model after it has been created!\"\n        )\n</code></pre>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.generate_model.create","title":"<code>create(do_compile=True, compile_folder_name=None)</code>","text":"<p>creates a model and optionally compiles it directly</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def create(self, do_compile=True, compile_folder_name=None):\n    \"\"\"\n    creates a model and optionally compiles it directly\n    \"\"\"\n    if self.initialized_models[self.name]:\n        print(\"model\", self.name, \"already created!\")\n    else:\n        initial_existing_model = mf.get_full_model()\n        ### create model populations and projections\n        if self.model_kwargs != None:\n            self.model_creation_function(**self.model_kwargs)\n        else:\n            self.model_creation_function()\n        self.initialized_models[self.name] = True\n\n        ### check which populations and projections have been added\n        post_existing_model = mf.get_full_model()\n        ### save only added not all projections/populations\n        for initial_pop in initial_existing_model[\"populations\"]:\n            post_existing_model[\"populations\"].remove(initial_pop)\n        for initial_proj in initial_existing_model[\"projections\"]:\n            post_existing_model[\"projections\"].remove(initial_proj)\n        self.populations = post_existing_model[\"populations\"]\n        self.projections = post_existing_model[\"projections\"]\n\n        self.initialized_models[self.name] = True\n\n        ### check if names of populations and projections are unique\n        self._check_double_compartments()\n\n        ### create parameter dictionary\n        self.attribute_df = self._get_attribute_df()\n\n        if do_compile:\n            self.compile(compile_folder_name)\n</code></pre>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.generate_model.set_param","title":"<code>set_param(compartment, parameter_name, parameter_value)</code>","text":"<p>sets the specified parameter of the specified compartment</p> <p>Parameters:</p> Name Type Description Default <code>compartment</code> <p>str name of model compartment</p> required <code>parameter_name</code> <p>str name of parameter of the compartment</p> required <code>parameter_value</code> <p>number or array-like with shape of compartment geometry the value or values of the parameter</p> required Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def set_param(self, compartment, parameter_name, parameter_value):\n    \"\"\"\n    sets the specified parameter of the specified compartment\n\n    args:\n        compartment: str\n            name of model compartment\n        parameter_name: str\n            name of parameter of the compartment\n        parameter_value: number or array-like with shape of compartment geometry\n            the value or values of the parameter\n    \"\"\"\n    ### cach if model is not created, only if created populations and projections are available\n    assert (\n        self.initialized_models[self.name] == True\n    ), f\"ERROR set_param: model {self.name} has to be created before setting parameters!\"\n\n    ### check if compartment is in populations or projections\n    comp_in_pop = compartment in self.populations\n    comp_in_proj = compartment in self.projections\n\n    if comp_in_pop:\n        comp_obj = get_population(compartment)\n    elif comp_in_proj:\n        comp_obj = get_projection(compartment)\n    else:\n        assert (\n            comp_in_pop or comp_in_proj\n        ), f\"ERROR set_param: setting parameter {parameter_name} of compartment {compartment}. The compartment is neither a population nor a projection of the model {self.name}!\"\n\n    ### set the parameter value\n    setattr(comp_obj, parameter_name, parameter_value)\n\n    ### update the model attribute_df\n    self._update_attribute_df(compartment, parameter_name, parameter_value)\n</code></pre>"}]}