{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documentation for CompNeuroPy","text":"<p>CompNeuroPy is an assisting Python package for working with ANNarchy (GitHub, documentation, DOI). It is intended to help structure simulations with computational neuroscience models in a modular way and to make them more easily replicable. People who want to start working with ANNarchy are strongly recommended to first learn exclusively the functionality of ANNarchy. CompNeuroPy uses very few features of ANNarchy at this time. But also adds various special features.</p>"},{"location":"license/","title":"License","text":""},{"location":"license/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2022 Oliver Maith</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"additional/analysis_functions/","title":"Analysis Functions","text":""},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.my_raster_plot","title":"<code>my_raster_plot(spikes)</code>","text":"<p>Returns two vectors representing for each recorded spike 1) the spike times and 2) the ranks of the neurons. The spike times are always in simulation steps (in contrast to default ANNarchy raster_plot).</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dict</code> <p>ANNarchy spike dict of one population</p> required <p>Returns:</p> Name Type Description <code>t</code> <code>array</code> <p>spike times in simulation steps</p> <code>n</code> <code>array</code> <p>ranks of the neurons</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def my_raster_plot(spikes: dict):\n    \"\"\"\n    Returns two vectors representing for each recorded spike 1) the spike times and 2)\n    the ranks of the neurons. The spike times are always in simulation steps (in\n    contrast to default ANNarchy raster_plot).\n\n    Args:\n        spikes (dict):\n            ANNarchy spike dict of one population\n\n    Returns:\n        t (array):\n            spike times in simulation steps\n        n (array):\n            ranks of the neurons\n    \"\"\"\n    t, n = raster_plot(spikes)\n    np.zeros(10)\n    t = np.round(t / dt(), 0).astype(int)\n    return t, n\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_nanmean","title":"<code>get_nanmean(a, axis=None, dtype=None)</code>","text":"<p>Same as np.nanmean but without printing warnings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Array containing numbers whose mean is desired. If <code>a</code> is not an array, a conversion is attempted.</p> required <code>axis</code> <code>None or int or tuple of ints</code> <p>Axis or axes along which the means are computed. The default is to compute the mean of the flattened array.</p> <p>.. numpy versionadded:: 1.7.0</p> <p>If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before.</p> <code>None</code> <code>dtype</code> <code>data - type</code> <p>Type to use in computing the mean.  For integer inputs, the default is <code>float64</code>; for floating point inputs, it is the same as the input dtype.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>m</code> <code>ndarray, see dtype parameter above</code> <p>If <code>out=None</code>, returns a new array containing the mean values, otherwise a reference to the output array is returned.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_nanmean(a, axis=None, dtype=None):\n    \"\"\"\n    Same as np.nanmean but without printing warnings.\n\n    Args:\n        a (array_like):\n            Array containing numbers whose mean is desired. If `a` is not an\n            array, a conversion is attempted.\n        axis (None or int or tuple of ints, optional):\n            Axis or axes along which the means are computed. The default is to\n            compute the mean of the flattened array.\n\n            .. numpy versionadded:: 1.7.0\n\n            If this is a tuple of ints, a mean is performed over multiple axes,\n            instead of a single axis or all the axes as before.\n        dtype (data-type, optional):\n            Type to use in computing the mean.  For integer inputs, the default\n            is `float64`; for floating point inputs, it is the same as the\n            input dtype.\n\n    Returns:\n        m (ndarray, see dtype parameter above):\n            If `out=None`, returns a new array containing the mean values,\n            otherwise a reference to the output array is returned.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        ret = np.nanmean(a, axis=axis, dtype=dtype)\n    return ret\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_nanstd","title":"<code>get_nanstd(a, axis=None, dtype=None)</code>","text":"<p>Same as np.nanstd but without printing warnings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Calculate the standard deviation of these values.</p> required <code>axis</code> <code>None or int or tuple of ints</code> <p>Axis or axes along which the standard deviation is computed. The default is to compute the standard deviation of the flattened array.</p> <p>.. numpy versionadded:: 1.7.0</p> <p>If this is a tuple of ints, a standard deviation is performed over multiple axes, instead of a single axis or all the axes as before.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>Type to use in computing the standard deviation. For arrays of integer type the default is float64, for arrays of float types it is the same as the array type.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>standard_deviation</code> <code>ndarray, see dtype parameter above</code> <p>If <code>out</code> is None, return a new array containing the standard deviation, otherwise return a reference to the output array.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_nanstd(a, axis=None, dtype=None):\n    \"\"\"\n    Same as np.nanstd but without printing warnings.\n\n    Args:\n        a (array_like):\n            Calculate the standard deviation of these values.\n        axis (None or int or tuple of ints, optional):\n            Axis or axes along which the standard deviation is computed. The\n            default is to compute the standard deviation of the flattened array.\n\n            .. numpy versionadded:: 1.7.0\n\n            If this is a tuple of ints, a standard deviation is performed over\n            multiple axes, instead of a single axis or all the axes as before.\n        dtype (dtype, optional):\n            Type to use in computing the standard deviation. For arrays of\n            integer type the default is float64, for arrays of float types it is\n            the same as the array type.\n\n    Returns:\n        standard_deviation (ndarray, see dtype parameter above):\n            If `out` is None, return a new array containing the standard deviation,\n            otherwise return a reference to the output array.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        ret = np.nanstd(a, axis=axis, dtype=dtype)\n    return ret\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_population_power_spectrum","title":"<code>get_population_power_spectrum(spikes, time_step, t_start=None, t_end=None, fft_size=None)</code>","text":"<p>Generates power spectrum of population spikes, returns frequency_arr and power_spectrum_arr. Using the Welch methode from: Welch, P. (1967). The use of fast Fourier transform for the estimation of power spectra: a method based on time averaging over short, modified periodograms. IEEE Transactions on audio and electroacoustics, 15(2), 70-73.</p> <p>The spike arrays are splitted into multiple arrays and then multiple FFTs are performed and the results are averaged.</p> <p>Size of splitted signals and the time step of the simulation determine the frequency resolution and the maximum frequency:     maximum frequency [Hz] = 500 / time_step     frequency resolution [Hz] = 1000 / (time_step * fftSize)</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dicitonary</code> <p>ANNarchy spike dict of one population</p> required <code>time_step</code> <code>float</code> <p>time step of the simulation in ms</p> required <code>t_start</code> <code>float or int</code> <p>start time of analyzed data in ms. Default: time of first spike</p> <code>None</code> <code>t_end</code> <code>float or int</code> <p>end time of analyzed data in ms. Default: time of last spike</p> <code>None</code> <code>fft_size</code> <code>int</code> <p>signal size for the FFT (size of splitted arrays) has to be a power of 2. Default: maximum</p> <code>None</code> <p>Returns:</p> Name Type Description <code>frequency_arr</code> <code>array</code> <p>array with frequencies</p> <code>spectrum</code> <code>array</code> <p>array with power spectrum</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_population_power_spectrum(\n    spikes,\n    time_step,\n    t_start=None,\n    t_end=None,\n    fft_size=None,\n):\n    \"\"\"\n    Generates power spectrum of population spikes, returns frequency_arr and\n    power_spectrum_arr. Using the Welch methode from: Welch, P. (1967). The use of fast\n    Fourier transform for the estimation of power spectra: a method based on time\n    averaging over short, modified periodograms. IEEE Transactions on audio and\n    electroacoustics, 15(2), 70-73.\n\n    The spike arrays are splitted into multiple arrays and then multiple FFTs are\n    performed and the results are averaged.\n\n    Size of splitted signals and the time step of the simulation determine the frequency\n    resolution and the maximum frequency:\n        maximum frequency [Hz] = 500 / time_step\n        frequency resolution [Hz] = 1000 / (time_step * fftSize)\n\n    Args:\n        spikes (dicitonary):\n            ANNarchy spike dict of one population\n        time_step (float):\n            time step of the simulation in ms\n        t_start (float or int, optional):\n            start time of analyzed data in ms. Default: time of first spike\n        t_end (float or int, optional):\n            end time of analyzed data in ms. Default: time of last spike\n        fft_size (int, optional):\n            signal size for the FFT (size of splitted arrays)\n            has to be a power of 2. Default: maximum\n\n    Returns:\n        frequency_arr (array):\n            array with frequencies\n        spectrum (array):\n            array with power spectrum\n    \"\"\"\n\n    def ms_to_s(x):\n        return x / 1000\n\n    ### get population_size / sampling_frequency\n    populations_size = len(list(spikes.keys()))\n    sampling_frequency = 1 / ms_to_s(time_step)  # in Hz\n\n    ### check if there are spikes in data\n    t, _ = my_raster_plot(spikes)\n    if len(t) &lt; 2:\n        ### there are no 2 spikes\n        print(\"WARNING: get_population_power_spectrum: &lt;2 spikes!\")\n        ### --&gt; return None or zeros\n        if fft_size == None:\n            print(\n                \"ERROR: get_population_power_spectrum: &lt;2 spikes and no fft_size given!\"\n            )\n            quit()\n        else:\n            frequency_arr = np.fft.fftfreq(fft_size, 1.0 / sampling_frequency)\n            frequency_arr_ret = frequency_arr[2 : int(fft_size / 2)]\n            spectrum_ret = np.zeros(frequency_arr_ret.shape)\n            return [frequency_arr_ret, spectrum_ret]\n\n    ### check if t_start / t_end are None\n    if t_start == None:\n        t_start = round(t.min() * time_step, get_number_of_decimals(time_step))\n    if t_end == None:\n        t_end = round(t.max() * time_step, get_number_of_decimals(time_step))\n\n    ### calculate time\n    simulation_time = round(t_end - t_start, get_number_of_decimals(time_step))  # in ms\n\n    ### get fft_size\n    ### if None --&gt; as large as possible\n    if fft_size is None:\n        pow = 1\n        while (2 ** (pow + 1)) / sampling_frequency &lt; ms_to_s(simulation_time):\n            pow = pow + 1\n        fft_size = 2**pow\n\n    if ms_to_s(simulation_time) &lt; (fft_size / sampling_frequency):\n        ### catch a too large fft_size\n        print(\n            f\"Too large fft_size {fft_size} for duration {simulation_time} ms. FFT_size has to be smaller than {int(ms_to_s(simulation_time)*sampling_frequency)}!\"\n        )\n        return [np.zeros(int(fft_size / 2 - 2)), np.zeros(int(fft_size / 2 - 2))]\n    elif (np.log2(fft_size) - int(np.log2(fft_size))) != 0:\n        ### catch fft_size if its not power of 2\n        print(\"FFT_size hast to be power of 2!\")\n        return [np.zeros(int(fft_size / 2 - 2)), np.zeros(int(fft_size / 2 - 2))]\n    else:\n        print(\n            f\"power sepctrum, min = {1000 / (time_step * fft_size)}, max = {500 / time_step}\"\n        )\n        ### calculate frequency powers\n        spectrum = np.zeros((populations_size, fft_size))\n        for neuron in range(populations_size):\n            ### sampling steps array\n            spiketrain = np.zeros(\n                int(np.round(ms_to_s(simulation_time) * sampling_frequency))\n            )\n            ### spike times as sampling steps\n            idx = (\n                np.round(\n                    ms_to_s((np.array(spikes[neuron]) * time_step)) * sampling_frequency\n                )\n            ).astype(np.int32)\n            ### cut the spikes before t_start and after t_end\n            idx_start = ms_to_s(t_start) * sampling_frequency\n            idx_end = ms_to_s(t_end) * sampling_frequency\n            mask = ((idx &gt; idx_start).astype(int) * (idx &lt; idx_end).astype(int)).astype(\n                bool\n            )\n            idx = (idx[mask] - idx_start).astype(np.int32)\n\n            ### set spiketrain array to one if there was a spike at sampling step\n            spiketrain[idx] = 1\n\n            ### generate multiple overlapping sequences out of the spike trains\n            spiketrain_sequences = _hanning_split_overlap(\n                spiketrain, fft_size, int(fft_size / 2)\n            )\n\n            ### generate power spectrum\n            spectrum[neuron] = get_nanmean(\n                np.abs(np.fft.fft(spiketrain_sequences)) ** 2, 0\n            )\n\n        ### mean spectrum over all neurons\n        spectrum = get_nanmean(spectrum, 0)\n\n        frequency_arr = np.fft.fftfreq(fft_size, 1.0 / sampling_frequency)\n\n        return (frequency_arr[2 : int(fft_size / 2)], spectrum[2 : int(fft_size / 2)])\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_power_spektrum_from_time_array","title":"<code>get_power_spektrum_from_time_array(arr, presimulationTime, simulationTime, simulation_dt, samplingfrequency=250, fftSize=1024)</code>","text":"<p>Generates power spectrum of time signal (returns frequencies_arr and power_arr). Using the Welch methode (Welch,1967).</p> <p>amplingfrequency: to sample the arr, in Hz --&gt; max frequency = samplingfrequency / 2 fftSize: signal size for FFT, duration (in s) = fftSize / samplingfrequency --&gt; frequency resolution = samplingfrequency / fftSize</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>array</code> <p>time array, value for each timestep</p> required <code>presimulationTime</code> <code>float or int</code> <p>simulation time which will not be analyzed</p> required <code>simulationTime</code> <code>float or int</code> <p>analyzed simulation time</p> required <code>simulation_dt</code> <code>float or int</code> <p>simulation timestep</p> required <code>samplingfrequency</code> <code>float or int</code> <p>sampling frequency for sampling the time array. Default: 250</p> <code>250</code> <code>fftSize</code> <code>int</code> <p>signal size for the FFT (size of splitted arrays) has to be a power of 2. Default: 1024</p> <code>1024</code> <p>Returns:</p> Name Type Description <code>frequency_arr</code> <code>array</code> <p>array with frequencies</p> <code>spectrum</code> <code>array</code> <p>array with power spectrum</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_power_spektrum_from_time_array(\n    arr,\n    presimulationTime,\n    simulationTime,\n    simulation_dt,\n    samplingfrequency=250,\n    fftSize=1024,\n):\n    \"\"\"\n    Generates power spectrum of time signal (returns frequencies_arr and power_arr).\n    Using the Welch methode (Welch,1967).\n\n    amplingfrequency: to sample the arr, in Hz --&gt; max frequency = samplingfrequency / 2\n    fftSize: signal size for FFT, duration (in s) = fftSize / samplingfrequency\n    --&gt; frequency resolution = samplingfrequency / fftSize\n\n    Args:\n        arr (array):\n            time array, value for each timestep\n        presimulationTime (float or int):\n            simulation time which will not be analyzed\n        simulationTime (float or int):\n            analyzed simulation time\n        simulation_dt (float or int):\n            simulation timestep\n        samplingfrequency (float or int, optional):\n            sampling frequency for sampling the time array. Default: 250\n        fftSize (int, optional):\n            signal size for the FFT (size of splitted arrays)\n            has to be a power of 2. Default: 1024\n\n    Returns:\n        frequency_arr (array):\n            array with frequencies\n        spectrum (array):\n            array with power spectrum\n    \"\"\"\n\n    if (simulationTime / 1000) &lt; (fftSize / samplingfrequency):\n        print(\"Simulation time has to be &gt;=\", fftSize / samplingfrequency, \"s for FFT!\")\n        return [np.zeros(int(fftSize / 2 - 2)), np.zeros(int(fftSize / 2 - 2))]\n    else:\n        ### sampling steps array\n        sampling_arr = arr[0 :: int((1 / samplingfrequency) * 1000 / simulation_dt)]\n\n        ### generate multiple overlapping sequences\n        sampling_arr_sequences = _hanning_split_overlap(\n            sampling_arr, fftSize, int(fftSize / 2)\n        )\n\n        ### generate power spectrum\n        spektrum = get_nanmean(np.abs(np.fft.fft(sampling_arr_sequences)) ** 2, 0)\n\n        frequenzen = np.fft.fftfreq(fftSize, 1.0 / samplingfrequency)\n\n        return (frequenzen[2 : int(fftSize / 2)], spektrum[2 : int(fftSize / 2)])\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_pop_rate","title":"<code>get_pop_rate(spikes, t_start=None, t_end=None, time_step=1, t_smooth_ms=-1)</code>","text":"<p>Generates a smoothed population firing rate. Returns a time array and a firing rate array.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dictionary</code> <p>ANNarchy spike dict of one population</p> required <code>t_start</code> <code>float or int</code> <p>start time of analyzed data in ms. Default: time of first spike</p> <code>None</code> <code>t_end</code> <code>float or int</code> <p>end time of analyzed data in ms. Default: time of last spike</p> <code>None</code> <code>time_step</code> <code>float or int</code> <p>time step of the simulation in ms. Default: 1</p> <code>1</code> <code>t_smooth_ms</code> <code>float or int</code> <p>time window for firing rate calculation in ms, if -1 --&gt; time window sizes are automatically detected. Default: -1</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>array with time steps in ms</p> <code>rate</code> <code>array</code> <p>array with population rate in Hz for each time step</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_pop_rate(\n    spikes: dict,\n    t_start: float | int | None = None,\n    t_end: float | int | None = None,\n    time_step: float | int = 1,\n    t_smooth_ms: float | int = -1,\n):\n    \"\"\"\n    Generates a smoothed population firing rate. Returns a time array and a firing rate\n    array.\n\n    Args:\n        spikes (dictionary):\n            ANNarchy spike dict of one population\n        t_start (float or int, optional):\n            start time of analyzed data in ms. Default: time of first spike\n        t_end (float or int, optional):\n            end time of analyzed data in ms. Default: time of last spike\n        time_step (float or int, optional):\n            time step of the simulation in ms. Default: 1\n        t_smooth_ms (float or int, optional):\n            time window for firing rate calculation in ms, if -1 --&gt; time window sizes\n            are automatically detected. Default: -1\n\n    Returns:\n        time_arr (array):\n            array with time steps in ms\n        rate (array):\n            array with population rate in Hz for each time step\n    \"\"\"\n    dt = time_step\n\n    t, _ = my_raster_plot(spikes)\n\n    ### check if there are spikes in population at all\n    if len(t) &gt; 1:\n        if t_start == None:\n            t_start = round(t.min() * time_step, get_number_of_decimals(time_step))\n        if t_end == None:\n            t_end = round(t.max() * time_step, get_number_of_decimals(time_step))\n\n        duration = round(t_end - t_start, get_number_of_decimals(time_step))\n\n        ### if t_smooth is given --&gt; use classic time_window method\n        if t_smooth_ms &gt; 0:\n            return _get_pop_rate_old(\n                spikes, duration, dt=dt, t_start=t_start, t_smooth_ms=t_smooth_ms\n            )\n        else:\n            ### concatenate all spike times and sort them\n            spike_arr = dt * np.sort(\n                np.concatenate(\n                    [np.array(spikes[neuron]).astype(int) for neuron in spikes.keys()]\n                )\n            )\n            nr_neurons = len(list(spikes.keys()))\n            nr_spikes = spike_arr.size\n\n            ### use _recursive_rate to get firing rate\n            ### spike array is splitted in time bins\n            ### time bins widths are automatically found\n            time_population_rate, population_rate = _recursive_rate(\n                spike_arr / 1000.0,\n                t0=t_start / 1000.0,\n                t1=(t_start + duration) / 1000.0,\n                duration_init=duration / 1000.0,\n                nr_neurons=nr_neurons,\n                nr_spikes=nr_spikes,\n            )\n            ### time_population_rate was returned in s --&gt; transform it into ms\n            time_population_rate = time_population_rate * 1000\n            time_arr0 = np.arange(t_start, t_start + duration, dt)\n            if len(time_population_rate) &gt; 1:\n                ### interpolate\n                interpolate_func = interp1d(\n                    time_population_rate,\n                    population_rate,\n                    kind=\"linear\",\n                    bounds_error=False,\n                    fill_value=(population_rate[0], population_rate[-1]),\n                )\n                population_rate_arr = interpolate_func(time_arr0)\n            else:\n                population_rate_arr = np.zeros(len(time_arr0))\n                mask = time_arr0 == time_population_rate[0]\n                population_rate_arr[mask] = population_rate[0]\n\n            ret = population_rate_arr\n    else:\n        if t_start == None or t_end == None:\n            return None\n        else:\n            duration = t_end - t_start\n            ret = np.zeros(int(duration / dt))\n\n    return (np.arange(t_start, t_start + duration, dt), ret)\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.plot_recordings","title":"<code>plot_recordings(figname, recordings, recording_times, chunk, shape, plan, time_lim=[], dpi=300)</code>","text":"<p>Plots the recordings of a single chunk from recordings. Plotted variables are specified in plan.</p> <p>Parameters:</p> Name Type Description Default <code>figname</code> <code>str</code> <p>path + name of figure (e.g. \"figures/my_figure.png\")</p> required <code>recordings</code> <code>list</code> <p>a recordings list from CompNeuroPy obtained with the function get_recordings() from a CompNeuroMonitors object.</p> required <code>recording_times</code> <code>object</code> <p>recording_times object from CompNeuroPy obtained with the function get_recording_times() from a CompNeuroMonitors object.</p> required <code>chunk</code> <code>int</code> <p>which chunk of recordings should be used (the index of chunk)</p> required <code>shape</code> <code>tuple</code> <p>Defines the subplot arrangement e.g. (3,2) = 3 rows, 2 columns</p> required <code>plan</code> <code>list of strings</code> <p>Defines which recordings are plotted in which subplot and how. Entries of the list have the structure:     \"subplot_nr;model_component_name;variable_to_plot;format\",     e.g. \"1,my_pop1;v;line\".     mode: defines how the data is plotted, available modes:         - for spike data: raster, mean, hybrid         - for other data: line, mean, matrix         - only for projection data: matrix_mean</p> required <code>time_lim</code> <code>list</code> <p>Defines the x-axis for all subplots. The list contains two numbers: start and end time in ms. The times have to be within the chunk. Default: time lims of chunk</p> <code>[]</code> <code>dpi</code> <code>int</code> <p>The dpi of the saved figure. Default: 300</p> <code>300</code> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def plot_recordings(\n    figname, recordings, recording_times, chunk, shape, plan, time_lim=[], dpi=300\n):\n    \"\"\"\n    Plots the recordings of a single chunk from recordings. Plotted variables are\n    specified in plan.\n\n    Args:\n        figname (str):\n            path + name of figure (e.g. \"figures/my_figure.png\")\n        recordings (list):\n            a recordings list from CompNeuroPy obtained with the function\n            get_recordings() from a CompNeuroMonitors object.\n        recording_times (object):\n            recording_times object from CompNeuroPy obtained with the\n            function get_recording_times() from a CompNeuroMonitors object.\n        chunk (int):\n            which chunk of recordings should be used (the index of chunk)\n        shape (tuple):\n            Defines the subplot arrangement e.g. (3,2) = 3 rows, 2 columns\n        plan (list of strings):\n            Defines which recordings are plotted in which subplot and how.\n            Entries of the list have the structure:\n                \"subplot_nr;model_component_name;variable_to_plot;format\",\n                e.g. \"1,my_pop1;v;line\".\n                mode: defines how the data is plotted, available modes:\n                    - for spike data: raster, mean, hybrid\n                    - for other data: line, mean, matrix\n                    - only for projection data: matrix_mean\n        time_lim (list, optional):\n            Defines the x-axis for all subplots. The list contains two\n            numbers: start and end time in ms. The times have to be\n            within the chunk. Default: time lims of chunk\n        dpi (int, optional):\n            The dpi of the saved figure. Default: 300\n    \"\"\"\n    proc = Process(\n        target=_plot_recordings,\n        args=(figname, recordings, recording_times, chunk, shape, plan, time_lim, dpi),\n    )\n    proc.start()\n    proc.join()\n    if proc.exitcode != 0:\n        quit()\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_number_of_zero_decimals","title":"<code>get_number_of_zero_decimals(nr)</code>","text":"<p>For numbers which are smaller than zero get the number of digits after the decimal point which are zero (plus 1). For the number 0 or numbers &gt;=1 return zero, e.g.:</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>the number from which the number of digits are obtained</p> required <p>Returns:</p> Name Type Description <code>decimals</code> <code>int</code> <p>number of digits after the decimal point which are zero (plus 1)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_number_of_zero_decimals(0.12)\n1\n&gt;&gt;&gt; get_number_of_zero_decimals(0.012)\n2\n&gt;&gt;&gt; get_number_of_zero_decimals(1.012)\n0\n</code></pre> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_number_of_zero_decimals(nr):\n    \"\"\"\n    For numbers which are smaller than zero get the number of digits after the decimal\n    point which are zero (plus 1). For the number 0 or numbers &gt;=1 return zero, e.g.:\n\n    Args:\n        nr (float or int):\n            the number from which the number of digits are obtained\n\n    Returns:\n        decimals (int):\n            number of digits after the decimal point which are zero (plus 1)\n\n    Examples:\n        &gt;&gt;&gt; get_number_of_zero_decimals(0.12)\n        1\n        &gt;&gt;&gt; get_number_of_zero_decimals(0.012)\n        2\n        &gt;&gt;&gt; get_number_of_zero_decimals(1.012)\n        0\n    \"\"\"\n    decimals = 0\n    if nr != 0:\n        while abs(nr) &lt; 1:\n            nr = nr * 10\n            decimals = decimals + 1\n\n    return decimals\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_number_of_decimals","title":"<code>get_number_of_decimals(nr)</code>","text":"<p>Get number of digits after the decimal point.</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>the number from which the number of digits are obtained</p> required <p>Returns:</p> Name Type Description <code>decimals</code> <code>int</code> <p>number of digits after the decimal point</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_number_of_decimals(5)\n0\n&gt;&gt;&gt; get_number_of_decimals(5.1)\n1\n&gt;&gt;&gt; get_number_of_decimals(0.0101)\n4\n</code></pre> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_number_of_decimals(nr):\n    \"\"\"\n    Get number of digits after the decimal point.\n\n    Args:\n        nr (float or int):\n            the number from which the number of digits are obtained\n\n    Returns:\n        decimals (int):\n            number of digits after the decimal point\n\n    Examples:\n        &gt;&gt;&gt; get_number_of_decimals(5)\n        0\n        &gt;&gt;&gt; get_number_of_decimals(5.1)\n        1\n        &gt;&gt;&gt; get_number_of_decimals(0.0101)\n        4\n    \"\"\"\n\n    if nr != int(nr):\n        decimals = len(str(nr).split(\".\")[1])\n    else:\n        decimals = 0\n\n    return decimals\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.sample_data_with_timestep","title":"<code>sample_data_with_timestep(time_arr, data_arr, timestep)</code>","text":"<p>Samples a data array each timestep using interpolation</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>array</code> <p>array with data values from which will be sampled</p> required <code>timestep</code> <code>float or int</code> <p>timestep in ms for sampling</p> required <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>sampled time array</p> <code>data_arr</code> <code>array</code> <p>sampled data array</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def sample_data_with_timestep(time_arr, data_arr, timestep):\n    \"\"\"\n    Samples a data array each timestep using interpolation\n\n    Args:\n        time_arr (array):\n            times of data_arr in ms\n        data_arr (array):\n            array with data values from which will be sampled\n        timestep (float or int):\n            timestep in ms for sampling\n\n    Returns:\n        time_arr (array):\n            sampled time array\n        data_arr (array):\n            sampled data array\n    \"\"\"\n    interpolate_func = interp1d(\n        time_arr, data_arr, bounds_error=False, fill_value=\"extrapolate\"\n    )\n    min_time = round(\n        round(time_arr[0] / timestep, 0) * timestep,\n        get_number_of_decimals(timestep),\n    )\n    max_time = round(\n        round(time_arr[-1] / timestep, 0) * timestep,\n        get_number_of_decimals(timestep),\n    )\n    new_time_arr = np.arange(min_time, max_time + timestep, timestep)\n    new_data_arr = interpolate_func(new_time_arr)\n\n    return (new_time_arr, new_data_arr)\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.time_data_add_nan","title":"<code>time_data_add_nan(time_arr, data_arr, fill_time_step=None, axis=0)</code>","text":"<p>If there are gaps in time_arr --&gt; fill them with respective time values. Fill the corresponding data_arr values with nan.</p> <p>By default it is tried to fill the time array with continuously increasing times based on the smallest time difference found there can still be discontinuities after filling the arrays (because existing time values are not changed).</p> <p>But one can also give a fixed fill time step.</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>1D array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>nD array</code> <p>the size of the specified dimension of data array must have the same length as time_arr</p> required <code>fill_time_step</code> <code>number, optional, default=None</code> <p>if there are gaps they are filled with this time step</p> <code>None</code> <code>axis</code> <code>int</code> <p>which dimension of the data_arr belongs to the time_arr</p> <code>0</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>1D array</code> <p>time array with gaps filled</p> <code>data_arr</code> <code>nD array</code> <p>data array with gaps filled</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def time_data_add_nan(time_arr, data_arr, fill_time_step=None, axis=0):\n    \"\"\"\n    If there are gaps in time_arr --&gt; fill them with respective time values.\n    Fill the corresponding data_arr values with nan.\n\n    By default it is tried to fill the time array with continuously increasing times\n    based on the smallest time difference found there can still be discontinuities after\n    filling the arrays (because existing time values are not changed).\n\n    But one can also give a fixed fill time step.\n\n    Args:\n        time_arr (1D array):\n            times of data_arr in ms\n        data_arr (nD array):\n            the size of the specified dimension of data array must have the same length\n            as time_arr\n        fill_time_step (number, optional, default=None):\n            if there are gaps they are filled with this time step\n        axis (int):\n            which dimension of the data_arr belongs to the time_arr\n\n    Returns:\n        time_arr (1D array):\n            time array with gaps filled\n        data_arr (nD array):\n            data array with gaps filled\n    \"\"\"\n    time_arr = time_arr.astype(float)\n    data_arr = data_arr.astype(float)\n    data_arr_shape = data_arr.shape\n\n    if data_arr_shape[axis] != time_arr.size:\n        print(\n            \"ERROR time_data_add_nan: time_arr must have same length as specified axis (default=0) of data_arr!\"\n        )\n        quit()\n\n    ### find gaps\n    time_diff_arr = np.round(np.diff(time_arr), 6)\n    if isinstance(fill_time_step, type(None)):\n        time_diff_min = time_diff_arr.min()\n    else:\n        time_diff_min = fill_time_step\n    gaps_arr = time_diff_arr &gt; time_diff_min\n\n    ### split arrays at gaps\n    time_arr_split = np.split(\n        time_arr, indices_or_sections=np.where(gaps_arr)[0] + 1, axis=0\n    )\n    data_arr_split = np.split(\n        data_arr, indices_or_sections=np.where(gaps_arr)[0] + 1, axis=axis\n    )\n\n    ### fill gaps between splits\n    data_arr_append_shape = list(data_arr_shape)\n    for split_arr_idx in range(len(time_arr_split) - 1):\n        ### get gaps boundaries\n        current_end = time_arr_split[split_arr_idx][-1]\n        next_start = time_arr_split[split_arr_idx + 1][0]\n        ### create gap filling arrays\n        time_arr_append = np.arange(\n            current_end + time_diff_min, next_start, time_diff_min\n        )\n        data_arr_append_shape[axis] = time_arr_append.size\n        data_arr_append = np.zeros(tuple(data_arr_append_shape)) * np.nan\n        ### append gap filling arrays to splitted arrays\n        time_arr_split[split_arr_idx] = np.append(\n            arr=time_arr_split[split_arr_idx],\n            values=time_arr_append,\n            axis=0,\n        )\n        data_arr_split[split_arr_idx] = np.append(\n            arr=data_arr_split[split_arr_idx],\n            values=data_arr_append,\n            axis=axis,\n        )\n\n    ### combine splitted arrays again\n    time_arr = np.concatenate(time_arr_split, axis=0)\n    data_arr = np.concatenate(data_arr_split, axis=axis)\n\n    return (time_arr, data_arr)\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.rmse","title":"<code>rmse(a, b)</code>","text":"<p>Calculates the root-mean-square error between two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array</code> <p>first array</p> required <code>b</code> <code>array</code> <p>second array</p> required <p>Returns:</p> Name Type Description <code>rmse</code> <code>float</code> <p>root-mean-square error</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def rmse(a, b):\n    \"\"\"\n    Calculates the root-mean-square error between two arrays.\n\n    Args:\n        a (array):\n            first array\n        b (array):\n            second array\n\n    Returns:\n        rmse (float):\n            root-mean-square error\n    \"\"\"\n\n    return np.sqrt(np.mean((a - b) ** 2))\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.rsse","title":"<code>rsse(a, b)</code>","text":"<p>Calculates the root-sum-square error between two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array</code> <p>first array</p> required <code>b</code> <code>array</code> <p>second array</p> required <p>Returns:</p> Name Type Description <code>rsse</code> <code>float</code> <p>root-sum-square error</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def rsse(a, b):\n    \"\"\"\n    Calculates the root-sum-square error between two arrays.\n\n    Args:\n        a (array):\n            first array\n        b (array):\n            second array\n\n    Returns:\n        rsse (float):\n            root-sum-square error\n    \"\"\"\n\n    return np.sqrt(np.sum((a - b) ** 2))\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_minimum","title":"<code>get_minimum(input_data)</code>","text":"<p>Returns the minimum of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>list, np.ndarray, tuple, or float</code> <p>The input data from which the minimum is to be obtained.</p> required <p>Returns:</p> Name Type Description <code>minimum</code> <code>float</code> <p>The minimum of the input data.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_minimum(input_data):\n    \"\"\"\n    Returns the minimum of the input data.\n\n    Args:\n        input_data (list, np.ndarray, tuple, or float):\n            The input data from which the minimum is to be obtained.\n\n    Returns:\n        minimum (float):\n            The minimum of the input data.\n    \"\"\"\n    if isinstance(input_data, (list, np.ndarray, tuple)):\n        # If the input is a list, numpy array, or tuple, we handle them as follows\n        flattened_list = [\n            item\n            for sublist in input_data\n            for item in (\n                sublist if isinstance(sublist, (list, np.ndarray, tuple)) else [sublist]\n            )\n        ]\n        return min(flattened_list)\n    else:\n        # If the input is a single value, return it as the minimum\n        return input_data\n</code></pre>"},{"location":"additional/analysis_functions/#src.CompNeuroPy.analysis_functions.get_maximum","title":"<code>get_maximum(input_data)</code>","text":"<p>Returns the maximum of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>list, np.ndarray, tuple, or float</code> <p>The input data from which the maximum is to be obtained.</p> required <p>Returns:</p> Name Type Description <code>maximum</code> <code>float</code> <p>The maximum of the input data.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_maximum(input_data):\n    \"\"\"\n    Returns the maximum of the input data.\n\n    Args:\n        input_data (list, np.ndarray, tuple, or float):\n            The input data from which the maximum is to be obtained.\n\n    Returns:\n        maximum (float):\n            The maximum of the input data.\n    \"\"\"\n\n    if isinstance(input_data, (list, np.ndarray, tuple)):\n        # If the input is a list, numpy array, or tuple, we handle them as follows\n        flattened_list = [\n            item\n            for sublist in input_data\n            for item in (\n                sublist if isinstance(sublist, (list, np.ndarray, tuple)) else [sublist]\n            )\n        ]\n        return max(flattened_list)\n    else:\n        # If the input is a single value, return it as the maximum\n        return input_data\n</code></pre>"},{"location":"additional/extra_functions/","title":"Extra Functions","text":""},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.Cmap","title":"<code>Cmap</code>","text":"<p>Class to create a colormap with a given name and range. The colormap can be called with a value between 0 and 1 to get the corresponding rgb value.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class Cmap:\n    \"\"\"\n    Class to create a colormap with a given name and range. The colormap can be called\n    with a value between 0 and 1 to get the corresponding rgb value.\n    \"\"\"\n\n    def __init__(self, cmap_name, vmin, vmax):\n        \"\"\"\n        Args:\n            cmap_name (str):\n                Name of the colormap\n            vmin (float):\n                Lower limit of the colormap\n            vmax (float):\n                Upper limit of the colormap\n        \"\"\"\n        self.cmap_name = cmap_name\n        self.cmap = plt.get_cmap(cmap_name)\n        self.norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n        self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n\n    def __call__(self, x, alpha=1):\n        \"\"\"\n        Returns the rgba value of the colormap at the given value.\n\n        Args:\n            x (float):\n                Value between 0 and 1\n            alpha (float):\n                Alpha value of the rgba value\n\n        Returns:\n            rgba (tuple):\n                RGBA value of the colormap at the given value\n        \"\"\"\n        vals = self.get_rgb(x)\n        if isinstance(vals, tuple):\n            vals = vals[:3] + (alpha,)\n        else:\n            vals[:, -1] = alpha\n        return vals\n\n    def get_rgb(self, val):\n        \"\"\"\n        Returns the rgb value of the colormap at the given value.\n\n        Args:\n            val (float):\n                Value between 0 and 1\n\n        Returns:\n            rgb (tuple):\n                RGB value of the colormap at the given value\n        \"\"\"\n        return self.scalarMap.to_rgba(val)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.Cmap.__init__","title":"<code>__init__(cmap_name, vmin, vmax)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>cmap_name</code> <code>str</code> <p>Name of the colormap</p> required <code>vmin</code> <code>float</code> <p>Lower limit of the colormap</p> required <code>vmax</code> <code>float</code> <p>Upper limit of the colormap</p> required Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self, cmap_name, vmin, vmax):\n    \"\"\"\n    Args:\n        cmap_name (str):\n            Name of the colormap\n        vmin (float):\n            Lower limit of the colormap\n        vmax (float):\n            Upper limit of the colormap\n    \"\"\"\n    self.cmap_name = cmap_name\n    self.cmap = plt.get_cmap(cmap_name)\n    self.norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n    self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.Cmap.__call__","title":"<code>__call__(x, alpha=1)</code>","text":"<p>Returns the rgba value of the colormap at the given value.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>Value between 0 and 1</p> required <code>alpha</code> <code>float</code> <p>Alpha value of the rgba value</p> <code>1</code> <p>Returns:</p> Name Type Description <code>rgba</code> <code>tuple</code> <p>RGBA value of the colormap at the given value</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __call__(self, x, alpha=1):\n    \"\"\"\n    Returns the rgba value of the colormap at the given value.\n\n    Args:\n        x (float):\n            Value between 0 and 1\n        alpha (float):\n            Alpha value of the rgba value\n\n    Returns:\n        rgba (tuple):\n            RGBA value of the colormap at the given value\n    \"\"\"\n    vals = self.get_rgb(x)\n    if isinstance(vals, tuple):\n        vals = vals[:3] + (alpha,)\n    else:\n        vals[:, -1] = alpha\n    return vals\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.Cmap.get_rgb","title":"<code>get_rgb(val)</code>","text":"<p>Returns the rgb value of the colormap at the given value.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>float</code> <p>Value between 0 and 1</p> required <p>Returns:</p> Name Type Description <code>rgb</code> <code>tuple</code> <p>RGB value of the colormap at the given value</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_rgb(self, val):\n    \"\"\"\n    Returns the rgb value of the colormap at the given value.\n\n    Args:\n        val (float):\n            Value between 0 and 1\n\n    Returns:\n        rgb (tuple):\n            RGB value of the colormap at the given value\n    \"\"\"\n    return self.scalarMap.to_rgba(val)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.DecisionTree","title":"<code>DecisionTree</code>","text":"<p>Class to create a decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class DecisionTree:\n    \"\"\"\n    Class to create a decision tree.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Create a new empty decision tree.\n        \"\"\"\n        ### node list is a list of lists\n        ### first idx = level of tree\n        ### second idx = all nodes in the level\n        self.node_list = [[]]\n\n    def node(self, parent=None, prob=0, name=None):\n        \"\"\"\n        Create a new node in the decision tree.\n\n        Args:\n            parent (node object):\n                Parent node of the new node\n            prob (float):\n                Probability of the new node\n            name (str):\n                Name of the new node\n\n        Returns:\n            new_node (node object):\n                The new node\n        \"\"\"\n\n        ### create new node\n        new_node = DecisionTreeNode(tree=self, parent=parent, prob=prob, name=name)\n        ### add it to node_list\n        if len(self.node_list) == new_node.level:\n            self.node_list.append([])\n        self.node_list[new_node.level].append(new_node)\n        ### return the node object\n        return new_node\n\n    def get_path_prod(self, name):\n        \"\"\"\n        Get the path and path product of a node with a given name.\n\n        Args:\n            name (str):\n                Name of the node\n\n        Returns:\n            path (str):\n                Path to the node\n            path_prod (float):\n                Path product of the node\n        \"\"\"\n\n        ### search for all nodes with name\n        ### start from behind\n        search_node_list = []\n        path_list = []\n        path_prod_list = []\n        for level in range(len(self.node_list) - 1, -1, -1):\n            for node in self.node_list[level]:\n                if node.name == name:\n                    search_node_list.append(node)\n        ### get the paths and path products for the found nodes\n        for node in search_node_list:\n            path, path_prod = self._get_path_prod_rec(node)\n            path_list.append(path)\n            path_prod_list.append(path_prod)\n        ### return the paths and path products\n        return [\n            [path_list[idx], path_prod_list[idx]]\n            for idx in range(len(search_node_list))\n        ]\n\n    def _get_path_prod_rec(self, node):\n        \"\"\"\n        Recursive function to get the path and path product of a node.\n\n        Args:\n            node (node object):\n                Node to get the path and path product of\n\n        Returns:\n            path_str (str):\n                Path to the node\n            prob (float):\n                Path product of the node\n        \"\"\"\n        node: DecisionTreeNode = node\n\n        if node.parent == None:\n            return [\"/\" + node.name, node.prob]\n        else:\n            path_str, prob = self._get_path_prod_rec(node.parent)\n            return [path_str + \"/\" + node.name, prob * node.prob]\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.DecisionTree.__init__","title":"<code>__init__()</code>","text":"<p>Create a new empty decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Create a new empty decision tree.\n    \"\"\"\n    ### node list is a list of lists\n    ### first idx = level of tree\n    ### second idx = all nodes in the level\n    self.node_list = [[]]\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.DecisionTree.node","title":"<code>node(parent=None, prob=0, name=None)</code>","text":"<p>Create a new node in the decision tree.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>node object</code> <p>Parent node of the new node</p> <code>None</code> <code>prob</code> <code>float</code> <p>Probability of the new node</p> <code>0</code> <code>name</code> <code>str</code> <p>Name of the new node</p> <code>None</code> <p>Returns:</p> Name Type Description <code>new_node</code> <code>node object</code> <p>The new node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def node(self, parent=None, prob=0, name=None):\n    \"\"\"\n    Create a new node in the decision tree.\n\n    Args:\n        parent (node object):\n            Parent node of the new node\n        prob (float):\n            Probability of the new node\n        name (str):\n            Name of the new node\n\n    Returns:\n        new_node (node object):\n            The new node\n    \"\"\"\n\n    ### create new node\n    new_node = DecisionTreeNode(tree=self, parent=parent, prob=prob, name=name)\n    ### add it to node_list\n    if len(self.node_list) == new_node.level:\n        self.node_list.append([])\n    self.node_list[new_node.level].append(new_node)\n    ### return the node object\n    return new_node\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.DecisionTree.get_path_prod","title":"<code>get_path_prod(name)</code>","text":"<p>Get the path and path product of a node with a given name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the node</p> required <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>Path to the node</p> <code>path_prod</code> <code>float</code> <p>Path product of the node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_path_prod(self, name):\n    \"\"\"\n    Get the path and path product of a node with a given name.\n\n    Args:\n        name (str):\n            Name of the node\n\n    Returns:\n        path (str):\n            Path to the node\n        path_prod (float):\n            Path product of the node\n    \"\"\"\n\n    ### search for all nodes with name\n    ### start from behind\n    search_node_list = []\n    path_list = []\n    path_prod_list = []\n    for level in range(len(self.node_list) - 1, -1, -1):\n        for node in self.node_list[level]:\n            if node.name == name:\n                search_node_list.append(node)\n    ### get the paths and path products for the found nodes\n    for node in search_node_list:\n        path, path_prod = self._get_path_prod_rec(node)\n        path_list.append(path)\n        path_prod_list.append(path_prod)\n    ### return the paths and path products\n    return [\n        [path_list[idx], path_prod_list[idx]]\n        for idx in range(len(search_node_list))\n    ]\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.DecisionTreeNode","title":"<code>DecisionTreeNode</code>","text":"<p>Class to create a node in a decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class DecisionTreeNode:\n    \"\"\"\n    Class to create a node in a decision tree.\n    \"\"\"\n\n    id_counter = 0\n\n    def __init__(self, tree: DecisionTree, parent=None, prob=0, name=\"\"):\n        \"\"\"\n        Create a new node in a decision tree.\n\n        Args:\n            tree (DecisionTree object):\n                Decision tree the node belongs to\n            parent (node object):\n                Parent node of the new node\n            prob (float):\n                Probability of the new node\n            name (str):\n                Name of the new node\n        \"\"\"\n        self.tree = tree\n        parent: DecisionTreeNode = parent\n        self.parent = parent\n        self.prob = prob\n        self.name = name\n        self.id = int(self.id_counter)\n        self.id_counter += 1\n        if parent != None:\n            self.level = int(parent.level + 1)\n        else:\n            self.level = int(0)\n\n    def add(self, name, prob):\n        \"\"\"\n        Add a child node to the node.\n\n        Args:\n            name (str):\n                Name of the new node\n            prob (float):\n                Probability of the new node\n\n        Returns:\n            new_node (node object):\n                The new node\n        \"\"\"\n\n        return self.tree.node(parent=self, prob=prob, name=name)\n\n    def get_path_prod(self):\n        \"\"\"\n        Get the path and path product of the node.\n\n        Returns:\n            path (str):\n                Path to the node\n            path_prod (float):\n                Path product of the node\n        \"\"\"\n        return self.tree._get_path_prod_rec(self)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.DecisionTreeNode.__init__","title":"<code>__init__(tree, parent=None, prob=0, name='')</code>","text":"<p>Create a new node in a decision tree.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>DecisionTree object</code> <p>Decision tree the node belongs to</p> required <code>parent</code> <code>node object</code> <p>Parent node of the new node</p> <code>None</code> <code>prob</code> <code>float</code> <p>Probability of the new node</p> <code>0</code> <code>name</code> <code>str</code> <p>Name of the new node</p> <code>''</code> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self, tree: DecisionTree, parent=None, prob=0, name=\"\"):\n    \"\"\"\n    Create a new node in a decision tree.\n\n    Args:\n        tree (DecisionTree object):\n            Decision tree the node belongs to\n        parent (node object):\n            Parent node of the new node\n        prob (float):\n            Probability of the new node\n        name (str):\n            Name of the new node\n    \"\"\"\n    self.tree = tree\n    parent: DecisionTreeNode = parent\n    self.parent = parent\n    self.prob = prob\n    self.name = name\n    self.id = int(self.id_counter)\n    self.id_counter += 1\n    if parent != None:\n        self.level = int(parent.level + 1)\n    else:\n        self.level = int(0)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.DecisionTreeNode.add","title":"<code>add(name, prob)</code>","text":"<p>Add a child node to the node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the new node</p> required <code>prob</code> <code>float</code> <p>Probability of the new node</p> required <p>Returns:</p> Name Type Description <code>new_node</code> <code>node object</code> <p>The new node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def add(self, name, prob):\n    \"\"\"\n    Add a child node to the node.\n\n    Args:\n        name (str):\n            Name of the new node\n        prob (float):\n            Probability of the new node\n\n    Returns:\n        new_node (node object):\n            The new node\n    \"\"\"\n\n    return self.tree.node(parent=self, prob=prob, name=name)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.DecisionTreeNode.get_path_prod","title":"<code>get_path_prod()</code>","text":"<p>Get the path and path product of the node.</p> <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>Path to the node</p> <code>path_prod</code> <code>float</code> <p>Path product of the node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_path_prod(self):\n    \"\"\"\n    Get the path and path product of the node.\n\n    Returns:\n        path (str):\n            Path to the node\n        path_prod (float):\n            Path product of the node\n    \"\"\"\n    return self.tree._get_path_prod_rec(self)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.print_df","title":"<code>print_df(df)</code>","text":"<p>Prints the complete dataframe df</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas dataframe</code> <p>Dataframe to be printed</p> required Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def print_df(df):\n    \"\"\"\n    Prints the complete dataframe df\n\n    Args:\n        df (pandas dataframe):\n            Dataframe to be printed\n    \"\"\"\n    with pd.option_context(\n        \"display.max_rows\", None\n    ):  # more options can be specified also\n        print(df)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.flatten_list","title":"<code>flatten_list(lst)</code>","text":"<p>Retuns flattened list</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <code>list of lists or mixed</code> <p>values and lists): List to be flattened</p> required <p>Returns:</p> Name Type Description <code>new_list</code> <code>list</code> <p>Flattened list</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def flatten_list(lst):\n    \"\"\"\n    Retuns flattened list\n\n    Args:\n        lst (list of lists or mixed: values and lists):\n            List to be flattened\n\n    Returns:\n        new_list (list):\n            Flattened list\n    \"\"\"\n\n    ### if lists in lst --&gt; upack them and retunr flatten_list of new list\n    new_lst = []\n    list_in_lst = False\n    for val in lst:\n        if isinstance(val, list):\n            list_in_lst = True\n            for sub_val in val:\n                new_lst.append(sub_val)\n        else:\n            new_lst.append(val)\n\n    if list_in_lst:\n        return flatten_list(new_lst)\n    ### else return lst\n    else:\n        return lst\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.remove_key","title":"<code>remove_key(d, key)</code>","text":"<p>Removes an element from a dict, returns the new dict</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>Dict to be modified</p> required <code>key</code> <code>str</code> <p>Key to be removed</p> required <p>Returns:</p> Name Type Description <code>r</code> <code>dict</code> <p>Modified dict</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def remove_key(d, key):\n    \"\"\"\n    Removes an element from a dict, returns the new dict\n\n    Args:\n        d (dict):\n            Dict to be modified\n        key (str):\n            Key to be removed\n\n    Returns:\n        r (dict):\n            Modified dict\n    \"\"\"\n    r = dict(d)\n    del r[key]\n    return r\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.suppress_stdout","title":"<code>suppress_stdout()</code>","text":"<p>Suppresses the print output of a function</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; with suppress_stdout():\n&gt;&gt;&gt;     print(\"this will not be printed\")\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>@contextmanager\ndef suppress_stdout():\n    \"\"\"\n    Suppresses the print output of a function\n\n    Examples:\n        &gt;&gt;&gt; with suppress_stdout():\n        &gt;&gt;&gt;     print(\"this will not be printed\")\n    \"\"\"\n    with open(os.devnull, \"w\") as devnull:\n        old_stdout = sys.stdout\n        sys.stdout = devnull\n        try:\n            yield\n        finally:\n            sys.stdout = old_stdout\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.sci","title":"<code>sci(nr)</code>","text":"<p>Rounds a number to a single decimal. If number is smaller than 0 it is converted to scientific notation with 1 decimal.</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>Number to be converted</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>String of the number in scientific notation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sci(0.0001)\n'1.0e-4'\n&gt;&gt;&gt; sci(1.77)\n'1.8'\n&gt;&gt;&gt; sci(1.77e-5)\n'1.8e-5'\n&gt;&gt;&gt; sci(177.22)\n'177.2'\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def sci(nr):\n    \"\"\"\n    Rounds a number to a single decimal.\n    If number is smaller than 0 it is converted to scientific notation with 1 decimal.\n\n    Args:\n        nr (float or int):\n            Number to be converted\n\n    Returns:\n        str (str):\n            String of the number in scientific notation\n\n    Examples:\n        &gt;&gt;&gt; sci(0.0001)\n        '1.0e-4'\n        &gt;&gt;&gt; sci(1.77)\n        '1.8'\n        &gt;&gt;&gt; sci(1.77e-5)\n        '1.8e-5'\n        &gt;&gt;&gt; sci(177.22)\n        '177.2'\n    \"\"\"\n    if af.get_number_of_zero_decimals(nr) == 0:\n        return str(round(nr, 1))\n    else:\n        return f\"{nr*10**af.get_number_of_zero_decimals(nr):.1f}e-{af.get_number_of_zero_decimals(nr)}\"\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.create_cm","title":"<code>create_cm(colors, name='my_cmap', N=256, gamma=1.0, vmin=0, vmax=1)</code>","text":"<p>Create a <code>LinearSegmentedColormap</code> from a list of colors.</p> <p>Parameters:</p> Name Type Description Default <code>colors</code> <code>array-like of colors or array-like of (value, color</code> <p>If only colors are given, they are equidistantly mapped from the range :math:<code>[0, 1]</code>; i.e. 0 maps to <code>colors[0]</code> and 1 maps to <code>colors[-1]</code>. If (value, color) pairs are given, the mapping is from value to color. This can be used to divide the range unevenly.</p> required <code>name</code> <code>str</code> <p>The name of the colormap, by default 'my_cmap'.</p> <code>'my_cmap'</code> <code>N</code> <code>int</code> <p>The number of rgb quantization levels, by default 256.</p> <code>256</code> <code>gamma</code> <code>float</code> <p>Gamma correction value, by default 1.0.</p> <code>1.0</code> <code>vmin</code> <code>float</code> <p>The minimum value of the colormap, by default 0.</p> <code>0</code> <code>vmax</code> <code>float</code> <p>The maximum value of the colormap, by default 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>LinearColormap</code> <p>The colormap object</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def create_cm(colors, name=\"my_cmap\", N=256, gamma=1.0, vmin=0, vmax=1):\n    \"\"\"\n    Create a `LinearSegmentedColormap` from a list of colors.\n\n    Args:\n        colors (array-like of colors or array-like of (value, color)):\n            If only colors are given, they are equidistantly mapped from the\n            range :math:`[0, 1]`; i.e. 0 maps to ``colors[0]`` and 1 maps to\n            ``colors[-1]``.\n            If (value, color) pairs are given, the mapping is from *value*\n            to *color*. This can be used to divide the range unevenly.\n        name (str, optional):\n            The name of the colormap, by default 'my_cmap'.\n        N (int, optional):\n            The number of rgb quantization levels, by default 256.\n        gamma (float, optional):\n            Gamma correction value, by default 1.0.\n        vmin (float, optional):\n            The minimum value of the colormap, by default 0.\n        vmax (float, optional):\n            The maximum value of the colormap, by default 1.\n\n    Returns:\n        LinearColormap:\n            The colormap object\n    \"\"\"\n    if not np.iterable(colors):\n        raise ValueError(\"colors must be iterable\")\n\n    if (\n        isinstance(colors[0], Sized)\n        and len(colors[0]) == 2\n        and not isinstance(colors[0], str)\n    ):\n        # List of value, color pairs\n        vals, colors = zip(*colors)\n        vals = np.array(vals).astype(float)\n        colors = list(colors)\n        ### insert values for 0 and 1 if not given\n        ### they equal the colors of the borders of the given range\n        if vals.min() != 0.0:\n            colors = [colors[np.argmin(vals)]] + colors\n            vals = np.insert(vals, 0, 0.0)\n        if vals.max() != 1.0:\n            colors = colors + [colors[np.argmax(vals)]]\n            vals = np.insert(vals, len(vals), 1.0)\n    else:\n        vals = np.linspace(0, 1, len(colors))\n\n    ### sort values and colors, they have to increase\n    sort_idx = np.argsort(vals)\n    vals = vals[sort_idx]\n    colors = [colors[idx] for idx in sort_idx]\n\n    r_g_b_a = np.zeros((len(colors), 4))\n    for color_idx, color in enumerate(colors):\n        if isinstance(color, str):\n            ### color given by name\n            r_g_b_a[color_idx] = to_rgba_array(color)\n        else:\n            ### color given by rgb(maybe a) value\n            color = np.array(color).astype(float)\n            ### check color size\n            if len(color) != 3 and len(color) != 4:\n                raise ValueError(\n                    \"colors must be names or consist of 3 (rgb) or 4 (rgba) numbers\"\n                )\n            if color.max() &gt; 1:\n                ### assume that max value is 255\n                color[:3] = color[:3] / 255\n            if len(color) == 4:\n                ### gamma already given\n                r_g_b_a[color_idx] = color\n            else:\n                ### add gamma\n                r_g_b_a[color_idx] = np.concatenate([color, np.array([gamma])])\n    r = r_g_b_a[:, 0]\n    g = r_g_b_a[:, 1]\n    b = r_g_b_a[:, 2]\n    a = r_g_b_a[:, 3]\n\n    cdict = {\n        \"red\": np.column_stack([vals, r, r]),\n        \"green\": np.column_stack([vals, g, g]),\n        \"blue\": np.column_stack([vals, b, b]),\n        \"alpha\": np.column_stack([vals, a, a]),\n    }\n\n    return _LinearColormapClass(name, cdict, N, gamma, vmin, vmax)\n</code></pre>"},{"location":"additional/extra_functions/#src.CompNeuroPy.extra_functions.evaluate_expression_with_dict","title":"<code>evaluate_expression_with_dict(expression, value_dict)</code>","text":"<p>Evaluate a mathematical expression using values from a dictionary.</p> <p>This function takes a mathematical expression as a string and a dictionary containing variable names as keys and corresponding values as numpy arrays. It replaces the variable names in the expression with their corresponding values from the dictionary and evaluates the expression.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <code>str</code> <p>A mathematical expression to be evaluated. Variable names in the expression should match the keys in the value_dict.</p> required <code>value_dict</code> <code>dict</code> <p>A dictionary containing variable names (strings) as keys and corresponding numpy arrays or numbers as values.</p> required <p>Returns:</p> Name Type Description <code>result</code> <code>value or array</code> <p>The result of evaluating the expression using the provided values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; my_dict = {\"a\": np.ones(10), \"b\": np.arange(10)}\n&gt;&gt;&gt; my_string = \"a*2-b+10\"\n&gt;&gt;&gt; evaluate_expression_with_dict(my_string, my_dict)\narray([12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.])\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def evaluate_expression_with_dict(expression, value_dict):\n    \"\"\"\n    Evaluate a mathematical expression using values from a dictionary.\n\n    This function takes a mathematical expression as a string and a dictionary\n    containing variable names as keys and corresponding values as numpy arrays.\n    It replaces the variable names in the expression with their corresponding\n    values from the dictionary and evaluates the expression.\n\n    Args:\n        expression (str):\n            A mathematical expression to be evaluated. Variable\n            names in the expression should match the keys in the value_dict.\n        value_dict (dict):\n            A dictionary containing variable names (strings) as\n            keys and corresponding numpy arrays or numbers as values.\n\n    Returns:\n        result (value or array):\n            The result of evaluating the expression using the provided values.\n\n    Examples:\n        &gt;&gt;&gt; my_dict = {\"a\": np.ones(10), \"b\": np.arange(10)}\n        &gt;&gt;&gt; my_string = \"a*2-b+10\"\n        &gt;&gt;&gt; evaluate_expression_with_dict(my_string, my_dict)\n        array([12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.])\n    \"\"\"\n    # Replace dictionary keys in the expression with their corresponding values\n    ### replace names with dict entries\n    expression = _replace_names_with_dict(\n        expression=expression, name_of_dict=\"value_dict\", dictionary=value_dict\n    )\n\n    ### evaluate the new expression\n    try:\n        result = eval(expression)\n        return result\n    except Exception as e:\n        raise ValueError(f\"Error while evaluating expression: {str(e)}\")\n</code></pre>"},{"location":"additional/model_functions/","title":"Model Functions","text":""},{"location":"additional/model_functions/#src.CompNeuroPy.model_functions.compile_in_folder","title":"<code>compile_in_folder(folder_name, net=None, clean=False, silent=False)</code>","text":"<p>Creates the compilation folder in annarchy_folders/ or uses existing ones. Compiles the current network.</p> <p>Parameters:</p> Name Type Description Default <code>folder_name</code> <code>str</code> <p>Name of the folder within annarchy_folders/</p> required <code>net</code> <code>ANNarchy network</code> <p>ANNarchy network. Default: None.</p> <code>None</code> <code>clean</code> <code>bool</code> <p>If True, the library is recompiled entirely, else only the changes since last compilation are compiled. Default: False.</p> <code>False</code> <code>silent</code> <code>bool</code> <p>Suppress output. Defaults to False.</p> <code>False</code> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def compile_in_folder(folder_name, net=None, clean=False, silent=False):\n    \"\"\"\n    Creates the compilation folder in annarchy_folders/ or uses existing ones. Compiles\n    the current network.\n\n    Args:\n        folder_name (str):\n            Name of the folder within annarchy_folders/\n        net (ANNarchy network, optional):\n            ANNarchy network. Default: None.\n        clean (bool, optional):\n            If True, the library is recompiled entirely, else only the changes since\n            last compilation are compiled. Default: False.\n        silent (bool, optional):\n            Suppress output. Defaults to False.\n    \"\"\"\n    sf.create_dir(\"annarchy_folders/\" + folder_name, print_info=False)\n    if isinstance(net, type(None)):\n        compile(\"annarchy_folders/\" + folder_name, clean=clean, silent=silent)\n    else:\n        net.compile(\"annarchy_folders/\" + folder_name, clean=clean, silent=silent)\n    if os.getcwd().split(\"/\")[-1] == \"annarchy_folders\":\n        os.chdir(\"../\")\n</code></pre>"},{"location":"additional/model_functions/#src.CompNeuroPy.model_functions.get_full_model","title":"<code>get_full_model()</code>","text":"<p>Return all current population and projection names.</p> <p>Returns:</p> Name Type Description <code>model_dict</code> <code>dict</code> <p>Dictionary with keys \"populations\" and \"projections\" and values lists of population and projection names, respectively.</p> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def get_full_model():\n    \"\"\"\n    Return all current population and projection names.\n\n    Returns:\n        model_dict (dict):\n            Dictionary with keys \"populations\" and \"projections\" and values lists of\n            population and projection names, respectively.\n    \"\"\"\n    return {\n        \"populations\": [pop.name for pop in populations()],\n        \"projections\": [proj.name for proj in projections()],\n    }\n</code></pre>"},{"location":"additional/model_functions/#src.CompNeuroPy.model_functions.cnp_clear","title":"<code>cnp_clear(functions=True, neurons=True, synapses=True, constants=True)</code>","text":"<p>Like clear with ANNarchy, but CompNeuroModel objects are also cleared.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>bool</code> <p>If True, all functions are cleared. Default: True.</p> <code>True</code> <code>neurons</code> <code>bool</code> <p>If True, all neurons are cleared. Default: True.</p> <code>True</code> <code>synapses</code> <code>bool</code> <p>If True, all synapses are cleared. Default: True.</p> <code>True</code> <code>constants</code> <code>bool</code> <p>If True, all constants are cleared. Default: True.</p> <code>True</code> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def cnp_clear(functions=True, neurons=True, synapses=True, constants=True):\n    \"\"\"\n    Like clear with ANNarchy, but CompNeuroModel objects are also cleared.\n\n    Args:\n        functions (bool, optional):\n            If True, all functions are cleared. Default: True.\n        neurons (bool, optional):\n            If True, all neurons are cleared. Default: True.\n        synapses (bool, optional):\n            If True, all synapses are cleared. Default: True.\n        constants (bool, optional):\n            If True, all constants are cleared. Default: True.\n    \"\"\"\n    clear(functions=functions, neurons=neurons, synapses=synapses, constants=constants)\n    for model_name in CompNeuroModel.initialized_models.keys():\n        CompNeuroModel.initialized_models[model_name] = False\n    for model_name in CompNeuroModel.compiled_models.keys():\n        CompNeuroModel.compiled_models[model_name] = False\n</code></pre>"},{"location":"additional/simulation_functions/","title":"Simulation Functions","text":""},{"location":"additional/simulation_functions/#src.CompNeuroPy.simulation_functions.current_step","title":"<code>current_step(pop, t1=500, t2=500, a1=0, a2=100)</code>","text":"<p>Stimulates a given population in two periods with two input currents.</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>t1</code> <code>int</code> <p>time in ms before current step</p> <code>500</code> <code>t2</code> <code>int</code> <p>time in ms after current step</p> <code>500</code> <code>a1</code> <code>int</code> <p>current amplitude before current step</p> <code>0</code> <code>a2</code> <code>int</code> <p>current amplitude after current step</p> <code>100</code> <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>duration (int): duration of the simulation</li> </ul> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_step(pop, t1=500, t2=500, a1=0, a2=100):\n    \"\"\"\n    Stimulates a given population in two periods with two input currents.\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        t1 (int):\n            time in ms before current step\n        t2 (int):\n            time in ms after current step\n        a1 (int):\n            current amplitude before current step\n        a2 (int):\n            current amplitude after current step\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - duration (int): duration of the simulation\n    \"\"\"\n\n    ### save prev input current\n    I_prev = get_population(pop).I_app\n\n    ### first/pre current step simulation\n    get_population(pop).I_app = a1\n    simulate(t1)\n\n    ### second/post current step simulation\n    get_population(pop).I_app = a2\n    simulate(t2)\n\n    ### reset input current to previous value\n    get_population(pop).I_app = I_prev\n\n    ### return some additional information which could be usefull\n    return {\"duration\": t1 + t2}\n</code></pre>"},{"location":"additional/simulation_functions/#src.CompNeuroPy.simulation_functions.current_stim","title":"<code>current_stim(pop, t=500, a=100)</code>","text":"<p>Stimulates a given population during specified period 't' with input current with amplitude 'a', after this stimulation the current is reset to initial value (before stimulation).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>t</code> <code>int</code> <p>duration in ms</p> <code>500</code> <code>a</code> <code>int</code> <p>current amplitude</p> <code>100</code> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_stim(pop, t=500, a=100):\n    \"\"\"\n    Stimulates a given population during specified period 't' with input current with\n    amplitude 'a', after this stimulation the current is reset to initial value\n    (before stimulation).\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        t (int):\n            duration in ms\n        a (int):\n            current amplitude\n    \"\"\"\n\n    return current_step(pop, t1=t, t2=0, a1=a, a2=0)\n</code></pre>"},{"location":"additional/simulation_functions/#src.CompNeuroPy.simulation_functions.current_ramp","title":"<code>current_ramp(pop, a0, a1, dur, n)</code>","text":"<p>Conducts multiple current stimulations with constantly changing current inputs. After this current_ramp stimulation the current amplitude is reset to the initial value (before current ramp).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>a0</code> <code>int</code> <p>initial current amplitude (of first stimulation)</p> required <code>a1</code> <code>int</code> <p>final current amplitude (of last stimulation)</p> required <code>dur</code> <code>int</code> <p>duration of the complete current ramp (all stimulations)</p> required <code>n</code> <code>int</code> <p>number of stimulations</p> required <p>Warning</p> <p>dur/n should be divisible by the simulation time step without remainder</p> <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>da (int): current step size</li> <li>dur_stim (int): duration of one stimulation</li> </ul> <p>Raises:</p> Type Description <code>AssertionError</code> <p>if resulting duration of one stimulation is not divisible by the simulation time step without remainder</p> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_ramp(pop, a0, a1, dur, n):\n    \"\"\"\n    Conducts multiple current stimulations with constantly changing current inputs.\n    After this current_ramp stimulation the current amplitude is reset to the initial\n    value (before current ramp).\n\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        a0 (int):\n            initial current amplitude (of first stimulation)\n        a1 (int):\n            final current amplitude (of last stimulation)\n        dur (int):\n            duration of the complete current ramp (all stimulations)\n        n (int):\n            number of stimulations\n\n    !!! warning\n        dur/n should be divisible by the simulation time step without remainder\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - da (int): current step size\n            - dur_stim (int): duration of one stimulation\n\n    Raises:\n        AssertionError: if resulting duration of one stimulation is not divisible by the\n            simulation time step without remainder\n    \"\"\"\n\n    assert (dur / n) / dt() % 1 == 0, (\n        \"ERROR current_ramp: dur/n should result in a duration (for a single stimulation) which is divisible by the simulation time step (without remainder)\\ncurrent duration = \"\n        + str(dur / n)\n        + \", timestep = \"\n        + str(dt())\n        + \"!\\n\"\n    )\n\n    da = (a1 - a0) / (n - 1)  # for n stimulations only n-1 steps occur\n    dur_stim = dur / n\n    amp = a0\n    for _ in range(n):\n        current_stim(pop, t=dur_stim, a=amp)\n        amp = amp + da\n\n    return {\"da\": da, \"dur_stim\": dur_stim}\n</code></pre>"},{"location":"additional/simulation_functions/#src.CompNeuroPy.simulation_functions.increasing_current","title":"<code>increasing_current(pop, a0, da, nr_steps, dur_step)</code>","text":"<p>Conducts multiple current stimulations with constantly increasing current inputs. After this increasing_current stimulation the current amplitude is reset to the initial value (before increasing_current).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>a0</code> <code>int</code> <p>initial current amplitude (of first stimulation)</p> required <code>da</code> <code>int</code> <p>current step size</p> required <code>nr_steps</code> <code>int</code> <p>number of stimulations</p> required <code>dur_step</code> <code>int</code> <p>duration of one stimulation</p> required <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>current_list (list): list of current amplitudes for each stimulation</li> </ul> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def increasing_current(pop, a0, da, nr_steps, dur_step):\n    \"\"\"\n    Conducts multiple current stimulations with constantly increasing current inputs.\n    After this increasing_current stimulation the current amplitude is reset to the\n    initial value (before increasing_current).\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        a0 (int):\n            initial current amplitude (of first stimulation)\n        da (int):\n            current step size\n        nr_steps (int):\n            number of stimulations\n        dur_step (int):\n            duration of one stimulation\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - current_list (list): list of current amplitudes for each stimulation\n    \"\"\"\n    current_list = []\n    a = a0\n    for _ in range(nr_steps):\n        current_list.append(a)\n        current_stim(pop, t=dur_step, a=a)\n        a += da\n\n    return {\"current_list\": current_list}\n</code></pre>"},{"location":"main/dbs_stimulator/","title":"DBS Stimulator","text":""},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator","title":"<code>src.CompNeuroPy.dbs.DBSstimulator</code>","text":"<p>Class for stimulating a population with DBS.</p> <p>Warning</p> <p>If you use auto_implement, pointers to the populations and projections of the model are not valid anymore (new populations and projections are created)! Use a CompNeuroPy model working with names of populations and projections anyway (recommended) or use the update_pointers method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from ANNarchy import Population, Izhikevich, compile, simulate, setup\n&gt;&gt;&gt; from CompNeuroPy import DBSstimulator\n&gt;&gt;&gt;\n&gt;&gt;&gt; # setup ANNarchy\n&gt;&gt;&gt; setup(dt=0.1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # create populations\n&gt;&gt;&gt; population1 = Population(10, neuron=Izhikevich, name=\"my_pop1\")\n&gt;&gt;&gt; population2 = Population(10, neuron=Izhikevich, name=\"my_pop2\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # create DBS stimulator\n&gt;&gt;&gt; dbs = DBSstimulator(\n&gt;&gt;&gt;     stimulated_population=population1,\n&gt;&gt;&gt;     population_proportion=0.5,\n&gt;&gt;&gt;     dbs_depolarization=30,\n&gt;&gt;&gt;     auto_implement=True,\n&gt;&gt;&gt; )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # update pointers to correct populations\n&gt;&gt;&gt; population1, population2 = dbs.update_pointers(pointer_list=[population1, population2])\n&gt;&gt;&gt;\n&gt;&gt;&gt; # compile network\n&gt;&gt;&gt; compile()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # run simulation\n&gt;&gt;&gt; # 1000 ms without dbs\n&gt;&gt;&gt; simulate(1000)\n&gt;&gt;&gt; # 1000 ms with dbs\n&gt;&gt;&gt; dbs.on()\n&gt;&gt;&gt; simulate(1000)\n&gt;&gt;&gt; # 1000 ms without dbs\n&gt;&gt;&gt; dbs.off()\n&gt;&gt;&gt; simulate(1000)\n</code></pre> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>class DBSstimulator:\n    \"\"\"\n    Class for stimulating a population with DBS.\n\n    !!! warning\n        If you use auto_implement, pointers to the populations and projections of\n        the model are not valid anymore (new populations and projections are\n        created)! Use a CompNeuroPy model working with names of populations and\n        projections anyway (recommended) or use the update_pointers method.\n\n    Examples:\n        &gt;&gt;&gt; from ANNarchy import Population, Izhikevich, compile, simulate, setup\n        &gt;&gt;&gt; from CompNeuroPy import DBSstimulator\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # setup ANNarchy\n        &gt;&gt;&gt; setup(dt=0.1)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # create populations\n        &gt;&gt;&gt; population1 = Population(10, neuron=Izhikevich, name=\"my_pop1\")\n        &gt;&gt;&gt; population2 = Population(10, neuron=Izhikevich, name=\"my_pop2\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # create DBS stimulator\n        &gt;&gt;&gt; dbs = DBSstimulator(\n        &gt;&gt;&gt;     stimulated_population=population1,\n        &gt;&gt;&gt;     population_proportion=0.5,\n        &gt;&gt;&gt;     dbs_depolarization=30,\n        &gt;&gt;&gt;     auto_implement=True,\n        &gt;&gt;&gt; )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # update pointers to correct populations\n        &gt;&gt;&gt; population1, population2 = dbs.update_pointers(pointer_list=[population1, population2])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # compile network\n        &gt;&gt;&gt; compile()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # run simulation\n        &gt;&gt;&gt; # 1000 ms without dbs\n        &gt;&gt;&gt; simulate(1000)\n        &gt;&gt;&gt; # 1000 ms with dbs\n        &gt;&gt;&gt; dbs.on()\n        &gt;&gt;&gt; simulate(1000)\n        &gt;&gt;&gt; # 1000 ms without dbs\n        &gt;&gt;&gt; dbs.off()\n        &gt;&gt;&gt; simulate(1000)\n    \"\"\"\n\n    @check_types()\n    def __init__(\n        self,\n        stimulated_population: Population,\n        population_proportion: float = 1.0,\n        excluded_populations_list: list[Population] = [],\n        dbs_depolarization: float = 0.0,\n        orthodromic: bool = False,\n        antidromic: bool = False,\n        efferents: bool = False,\n        afferents: bool = False,\n        passing_fibres: bool = False,\n        passing_fibres_list: list[Projection] = [],\n        passing_fibres_strength: float | list[float] = 1.0,\n        sum_branches: bool = True,\n        dbs_pulse_frequency_Hz: float = 130.0,\n        dbs_pulse_width_us: float = 300.0,\n        axon_spikes_per_pulse: float = 1.0,\n        axon_rate_amp: float | dict[Population | str, float] = 1.0,\n        seed: int | None = None,\n        auto_implement: bool = False,\n        model: generate_model | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize DBS stimulator.\n\n        !!! warning\n            Do this before compiling the model!\n\n        Args:\n            stimulated_population (Population):\n                Population which is stimulated by DBS\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: 1.0.\n            excluded_populations_list (list, optional):\n                List of populations which are excluded from DBS effects, they are not\n                affected and their axons do not generate axon spikes. Default: [].\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: 0.0.\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically.\n                Default: False.\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: False.\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: False.\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: False.\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: False.\n            passing_fibres_list (list of Projections, optional):\n                List of projections which pass the DBS stimulated region and therefore\n                are activated by DBS. Default: [], also set passing_fibres True!\n            passing_fibres_strength (float or list of float, optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: 1.\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: True.\n            dbs_pulse_frequency_Hz (float, optional):\n                Frequency of the DBS pulse. Default: 130 Hz.\n            dbs_pulse_width_us (float, optional):\n                Width of the DBS pulse. Default: 300 us.\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: 1.\n            axon_rate_amp (float or dict of float, optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value)\n                You can specify the default value by using the key \"default\", e.g.\n                {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n                pop forward a rate of 1.0 during DBS. Default: 1.0.\n            seed (int, optional):\n                Seed for the random distribution of affected neurons based on\n                population_proportion. Default: None.\n            auto_implement (bool, optional):\n                If True, automatically implement DBS mechanisms to the model. Only\n                supported for Izhikevich spiking models and rate-coded models.\n                Default: False.\n                TODO test what happens with mixed models\n            model (generate_model, optional):\n                CompNeuroPy model which is used to automatically implement DBS\n                mechanisms, should not be compiled!. Default: None, i.e., use all\n                populations and projections of the current magic model\n        \"\"\"\n\n        if auto_implement:\n            ### recreate model with DBS mechanisms\n            ### give all variables containing Populations and Projections\n            ### and also recreate them during recreating the model\n            ### variables are:\n            ### - stimulated_population\n            ### - excluded_populations_list\n            ### - passing_fibres_list\n            ### - axon_rate_amp\n            if not isinstance(model, type(None)):\n                ### CompNeuroPy model given\n                ### recreate model with DBS mechanisms\n                create_dbs_model_obj = _CreateDBSmodelcnp(\n                    model,\n                    stimulated_population,\n                    excluded_populations_list,\n                    passing_fibres_list,\n                    axon_rate_amp,\n                )\n                ### get the new CompNeuroPy model\n                model = create_dbs_model_obj.model\n            else:\n                ### no CompNeuroPy model given --&gt; use all populations and projections of the current magic model\n                ### recreate model with DBS mechanisms\n                create_dbs_model_obj = _CreateDBSmodel(\n                    stimulated_population,\n                    excluded_populations_list,\n                    passing_fibres_list,\n                    axon_rate_amp,\n                )\n            ### get the new variables containing Populations and Projections\n            stimulated_population = create_dbs_model_obj.stimulated_population\n            excluded_populations_list = create_dbs_model_obj.excluded_populations_list\n            passing_fibres_list = create_dbs_model_obj.passing_fibres_list\n            axon_rate_amp = create_dbs_model_obj.axon_rate_amp\n\n        ### set parameters\n        self.stimulated_population = stimulated_population\n        self.population_proportion = population_proportion\n        self.excluded_populations_list = excluded_populations_list\n        self.dbs_depolarization = dbs_depolarization\n        self.orthodromic = orthodromic\n        self.antidromic = antidromic\n        self.efferents = efferents\n        self.afferents = afferents\n        self.passing_fibres = passing_fibres\n        self.passing_fibres_list = passing_fibres_list\n        self.passing_fibres_strength = passing_fibres_strength\n        self.sum_branches = sum_branches\n        self.dbs_pulse_width_us = dbs_pulse_width_us\n        self.axon_spikes_per_pulse = axon_spikes_per_pulse\n        self.axon_rate_amp = axon_rate_amp\n        self.seed = seed\n        self.model = model\n\n        ### ANNarchy constants for DBS\n        self._set_constants(dbs_pulse_frequency_Hz)\n\n        ### randomly select affected neurons i.e. create dbs_on_array\n        self.dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n\n    def _create_dbs_on_array(self, population_proportion: float, seed: int):\n        \"\"\"\n        Create an array with the shape of the stimulated population with ones and zeros\n        randomly distributed with the specified population_proportion.\n\n        Args:\n            population_proportion (float):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly\n            seed (int):\n                Seed for the random distribution of affected neurons based on\n                population_proportion\n\n        Returns:\n            dbs_on_array (np.array):\n                Array with the shape of the stimulated population with ones and zeros\n                randomly distributed with the specified population_proportion\n        \"\"\"\n        ### create random number generator\n        rng = np.random.default_rng(seed)\n        ### create an array of zeros with the shape of the population, then flatten it\n        dbs_on_array = np.zeros(self.stimulated_population.geometry).flatten()\n        ### get the number of affected neurons based on the population_proportion\n        number_of_affected_neurons = population_proportion * dbs_on_array.size\n        ### randomly ceil or floor the number of affected neurons\n        number_of_affected_neurons = int(\n            rng.choice(\n                [\n                    np.ceil(number_of_affected_neurons),\n                    np.floor(number_of_affected_neurons),\n                ]\n            )\n        )\n        ### insert ones to the dbs_on_array\n        dbs_on_array[:number_of_affected_neurons] = 1\n        ### shuffle array\n        rng.shuffle(dbs_on_array)\n        ### reshape array to the shape of the population\n        dbs_on_array = dbs_on_array.reshape(self.stimulated_population.geometry)\n        ### return array\n        return dbs_on_array\n\n    def _set_constants(self, dbs_pulse_frequency_Hz: float):\n        \"\"\"\n        Set constants for DBS.\n\n        Args:\n            dbs_pulse_frequency_Hz (float):\n                Frequency of the DBS pulse in Hz\n        \"\"\"\n        # pulse frequency:\n        Constant(\"dbs_pulse_frequency_Hz\", dbs_pulse_frequency_Hz)\n        # pulse width:\n        # Neumant et al.. 2023: 60us but Meier et al. 2022: 300us... 60us = 0.06ms is very small for ANNarchy simulations\n        Constant(\"dbs_pulse_width_us\", self.dbs_pulse_width_us)\n\n        ### add global function for DBS pulse\n        add_function(\n            \"pulse(time_ms) = ite(modulo(time_ms*1000, 1000000./dbs_pulse_frequency_Hz) &lt; dbs_pulse_width_us, 1., 0.)\"\n        )\n\n    def _axon_spikes_per_pulse_to_prob(self, axon_spikes_per_pulse: float):\n        \"\"\"\n        Convert number of axon spikes per pulse to probability of axon spikes per\n        timestep during DBS pulse\n\n        Args:\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n\n        Returns:\n            prob_axon_spike_time_step (float):\n                Probability of axon spikes per timestep during DBS pulse\n        \"\"\"\n        return np.clip(\n            (axon_spikes_per_pulse * 1000 * dt() / self.dbs_pulse_width_us), 0, 1\n        )\n\n    def _set_depolarization(self, dbs_depolarization: float | None = None):\n        \"\"\"\n        Set depolarization of population.\n\n        Args:\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: None,\n                i.e., use value from initialization\n        \"\"\"\n        ### either use given depolarization or use default value\n        if isinstance(dbs_depolarization, type(None)):\n            dbs_depolarization = self.dbs_depolarization\n\n        ### set depolarization of population\n        for pop in populations():\n            if pop == self.stimulated_population:\n                pop.dbs_depolarization = dbs_depolarization\n            else:\n                pop.dbs_depolarization = 0\n\n    def _set_axon_spikes(\n        self,\n        orthodromic: bool | None = None,\n        antidromic: bool | None = None,\n        efferents: bool | None = None,\n        afferents: bool | None = None,\n        passing_fibres: bool | None = None,\n        passing_fibres_strength: float | list[float] | None = None,\n        sum_branches: bool | None = None,\n        axon_spikes_per_pulse: float | None = None,\n        axon_rate_amp: float | dict[Population | str, float] | None = None,\n    ):\n        \"\"\"\n        Set axon spikes forwarding orthodromic\n\n        Args:\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically,\n                Default: None, i.e., use value from initialization\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: None, i.e., use value from\n                initialization\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: None, i.e., use value from initialization\n            passing_fibres_strength (float | list[float], optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: None, i.e., use value from initialization\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: None, i.e., use value from initialization\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: None, i.e., use\n                value from initialization\n            axon_rate_amp (float | dict[Population | str, float], optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value)\n                You can specify the default value by using the key \"default\", e.g.\n                {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n                pop forward a rate of 1.0 during DBS. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n\n        ### either use given orthodromic or use default value\n        if isinstance(orthodromic, type(None)):\n            orthodromic = self.orthodromic\n        ### either use given antidromic or use default value\n        if isinstance(antidromic, type(None)):\n            antidromic = self.antidromic\n        ### either use given efferents or use default value\n        if isinstance(efferents, type(None)):\n            efferents = self.efferents\n        ### either use given afferents or use default value\n        if isinstance(afferents, type(None)):\n            afferents = self.afferents\n        ### either use given afferents or use default value\n        if isinstance(passing_fibres, type(None)):\n            passing_fibres = self.passing_fibres\n        ### either use given passing_fibres_strength or use default value\n        if isinstance(passing_fibres_strength, type(None)):\n            passing_fibres_strength = self.passing_fibres_strength\n        ### either use given sum_branches or use default value\n        if isinstance(sum_branches, type(None)):\n            sum_branches = self.sum_branches\n        ### either use given axon_spikes_per_pulse or use default value\n        if isinstance(axon_spikes_per_pulse, type(None)):\n            axon_spikes_per_pulse = self.axon_spikes_per_pulse\n        ### either use given axon_rate_amp or use default value\n        if isinstance(axon_rate_amp, type(None)):\n            axon_rate_amp = self.axon_rate_amp\n\n        ### check if passing_fibres_strength is a list\n        if not isinstance(passing_fibres_strength, list):\n            passing_fibres_strength = [passing_fibres_strength] * len(\n                self.passing_fibres_list\n            )\n        ### check if axon_rate_amp is a dict or float\n        if isinstance(axon_rate_amp, dict):\n            ### check if default key is missing\n            if \"default\" not in axon_rate_amp.keys():\n                ### add the key \"default\" with the value 1.0 to the dict\n                axon_rate_amp[\"default\"] = 1.0\n        else:\n            ### create dict with default value\n            axon_rate_amp = {\"default\": axon_rate_amp}\n\n        ### deactivate DBS axon transmission\n        self._deactivate_axon_DBS()\n\n        ### activate orthodromic transmission for all projections\n        if orthodromic:\n            self._set_orthodromic(\n                efferents,\n                afferents,\n                passing_fibres,\n                passing_fibres_strength,\n                axon_spikes_per_pulse,\n                axon_rate_amp,\n            )\n\n        ### activate antidromic transmission for all populations\n        if antidromic:\n            self._set_antidromic(\n                efferents,\n                afferents,\n                passing_fibres,\n                passing_fibres_strength,\n                sum_branches,\n                axon_spikes_per_pulse,\n            )\n\n    def _deactivate_axon_DBS(self):\n        \"\"\"\n        Deactivate axon spikes forwarding for both orthodromic and antidromic.\n        \"\"\"\n        for pop in populations():\n            ### deactivate axon spike genearation for all populations\n            pop.prob_axon_spike = 0\n            pop.axon_rate_amp = 0\n            ### deactivate antidromic transmission for all populations\n            pop.antidromic = 0\n            pop.antidromic_prob = 0\n\n        ### deactivate orthodromic transmission for all projections\n        for proj in projections():\n            proj.axon_transmission = 0\n            proj.p_axon_spike_trans = 0\n\n    def _set_orthodromic(\n        self,\n        efferents: bool,\n        afferents: bool,\n        passing_fibres: bool,\n        passing_fibres_strength: list[float],\n        axon_spikes_per_pulse: float,\n        axon_rate_amp: dict[Population | str, float],\n    ):\n        \"\"\"\n        Set orthodromic axon spikes forwarding.\n\n        Args:\n            efferents (bool):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            afferents (bool):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            passing_fibres (bool):\n                If True, DBS affects the passing fibres of the stimulated population\n                (orthodromic and/or antidromic have to be True too and there have to\n                be passing fibres in the passing_fibres_list)\n            passing_fibres_strength (list[float]):\n                List of float values between 0 and 1 defining how strong the passing\n                fibres are activated by DBS (0: not activated, 1: fully activated\n                like projections in DBS stimulated region)\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n            axon_rate_amp (dict[Population | str, float]):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded\n                on axons caused by DBS. The dictionary has to contain the key\n                \"default\" with the default value for all projections and can contain\n                keys for each population with a different value for the axon_rate of\n                the efferent axons of this population.\n        \"\"\"\n        if efferents:\n            ### activate all efferent projections\n            projection_list = projections(pre=self.stimulated_population)\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.post in self.excluded_populations_list:\n                    continue\n                ### activate axon transmission\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = 1\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n        if afferents:\n            ### activate all afferent projections\n            projection_list = projections(post=self.stimulated_population)\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.pre in self.excluded_populations_list:\n                    continue\n                ### activate axon transmission\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = 1\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n        if passing_fibres:\n            ### activate all passing projections\n            for proj_idx, proj in enumerate(self.passing_fibres_list):\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = passing_fibres_strength[proj_idx]\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n    def _set_antidromic(\n        self,\n        efferents: bool,\n        afferents: bool,\n        passing_fibres: bool,\n        passing_fibres_strength: list[float],\n        sum_branches: bool,\n        axon_spikes_per_pulse: float,\n    ):\n        \"\"\"\n        Set antidromic axon spikes forwarding.\n\n        Args:\n            efferents (bool):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            afferents (bool):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            passing_fibres (bool):\n                If True, DBS affects the passing fibres of the stimulated population\n                (orthodromic and/or antidromic have to be True too and there have to\n                be passing fibres in the passing_fibres_list)\n            passing_fibres_strength (list[float]):\n                List of float values between 0 and 1 defining how strong the passing\n                fibres are activated by DBS (0: not activated, 1: fully activated\n                like projections in DBS stimulated region)\n            sum_branches (bool):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n        \"\"\"\n\n        if efferents:\n            ### activate all efferent projections, i.e. antodromic activation of stimulated population\n            pop = self.stimulated_population\n            pop.antidromic = 1\n            pop.antidromic_prob = 1\n            pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                axon_spikes_per_pulse\n            )\n        if afferents:\n            ### activate all afferent projections, i.e. all presynaptic populations of stimulated population\n            ### get presynaptic projections\n            projection_list = projections(post=self.stimulated_population)\n            ### get presynaptic populations from projections\n            presyn_pop_list = []\n            presyn_pop_name_list = []\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.pre in self.excluded_populations_list:\n                    continue\n                ### check if presynaptic population is already in list\n                if proj.pre.name not in presyn_pop_name_list:\n                    presyn_pop_name_list.append(proj.pre.name)\n                    presyn_pop_list.append(proj.pre)\n            ### set antidromic for all presynaptic populations\n            for pop in presyn_pop_list:\n                pop.antidromic = 1\n                pop.antidromic_prob = np.mean(self.stimulated_population.dbs_on)\n                pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n        if passing_fibres:\n            ### get presynaptic populations from passing fibres projections\n            presyn_pop_list = []\n            presyn_pop_name_list = []\n            for proj in self.passing_fibres_list:\n                ### check if presynaptic population is already in list\n                if proj.pre.name not in presyn_pop_name_list:\n                    presyn_pop_name_list.append(proj.pre.name)\n                    presyn_pop_list.append(proj.pre)\n            ### get antidomic_prob for each presynatic population with the passing_fibres_strength\n            antidromic_prob_list = [0] * len(presyn_pop_list)\n            for pop_idx, pop in enumerate(presyn_pop_list):\n                ### get all passing fibres and their strength of a presynaptic pop\n                passing_fibres_strength_of_pop_list = []\n                for proj_idx, proj in enumerate(self.passing_fibres_list):\n                    if proj.pre.name == pop.name:\n                        passing_fibres_strength_of_pop_list.append(\n                            passing_fibres_strength[proj_idx]\n                        )\n                ### check if the probs of the single axon branches should be summed up\n                ### if for example a presynaptic pop contributes to two passing fibres, the axons of the presynaptic pop split up into two branches\n                ### thus, if these two branches are both stimulated, they both forward APs antidromic\n                ### thus, sum up the antidromic_prob of the single branches to obtain the antidromic spikes which affect the presynaptic pop\n                ### if sum_branches is False, then this would represent that the stimulation at the axon is before it splits up into multiple branches and there should not be different passing_fibres_strengths for the same presynaptic pop\n                if sum_branches:\n                    antidromic_prob_list[pop_idx] = sum(\n                        passing_fibres_strength_of_pop_list\n                    )\n                else:\n                    if len(set(passing_fibres_strength_of_pop_list)) != 1:\n                        ### list contains different values\n                        raise ValueError(\n                            \"Different passing fibres strengths for the same presynaptic population detected. This is not possible if sum_branches is False.\"\n                        )\n                    ### all values are the same, thus take the first one\n                    antidromic_prob_list[pop_idx] = passing_fibres_strength_of_pop_list[\n                        0\n                    ]\n\n                ### TODO\n                ### if summing axon branches leads to a prob &gt; 1, then\n                ### the prob should be set to 1\n                ### the axon spike generation in this pop should be increased\n                ### and all axon spike transmissions from this pop should be decreased by the same factor\n                ### this is not implemented yet... maybe in the future\n                if antidromic_prob_list[pop_idx] &gt; 1:\n                    raise ValueError(\n                        \"Summing the passing fibres strengths of a presynaptic population leads to a antidromic spike probability &gt; 1. This is not possible yet.\"\n                    )\n\n            ### set antidromic for all presynaptic populations\n            for pop_idx, pop in enumerate(presyn_pop_list):\n                pop.antidromic = 1\n                pop.antidromic_prob = antidromic_prob_list[pop_idx]\n                pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n\n    @check_types()\n    def on(\n        self,\n        population_proportion: float | None = None,\n        dbs_depolarization: float | None = None,\n        orthodromic: bool | None = None,\n        antidromic: bool | None = None,\n        efferents: bool | None = None,\n        afferents: bool | None = None,\n        passing_fibres: bool | None = None,\n        passing_fibres_strength: float | list[float] | None = None,\n        sum_branches: bool | None = None,\n        axon_spikes_per_pulse: float | None = None,\n        axon_rate_amp: float | dict[Population | str, float] | None = None,\n        seed: int | None = None,\n    ):\n        \"\"\"\n        Activate DBS.\n\n        Args:\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: None, i.e., use value from\n                initialization\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: None,\n                i.e., use value from initialization\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically.\n                Default: None, i.e., use value from initialization\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: None, i.e., use value from\n                initialization\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: None, i.e., use value from initialization\n            passing_fibres_strength (float | list[float], optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: None, i.e., use value from initialization\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: None, i.e., use value from initialization\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: None, i.e., use\n                value from initialization\n            axon_rate_amp (float | dict[Population | str, float], optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value). You can specify the default value by using the key \"default\",\n                e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations\n                except pop forward a rate of 1.0 during DBS. Default: None, i.e., use\n                value from initialization\n            seed (int, optional):\n                Seed for the random number generator. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n\n        ### set DBS on for all populations\n        ### also sets the proportion of affected neurons, call this before set_depolarization and set_axon_spikes!\n        self._set_dbs_on(population_proportion, seed)\n\n        ### set depolarization of population\n        self._set_depolarization(dbs_depolarization)\n\n        ### set axon spikes forwarding\n        self._set_axon_spikes(\n            orthodromic,\n            antidromic,\n            efferents,\n            afferents,\n            passing_fibres,\n            passing_fibres_strength,\n            sum_branches,\n            axon_spikes_per_pulse,\n            axon_rate_amp,\n        )\n\n    def _set_dbs_on(self, population_proportion: float | None, seed: int | None):\n        \"\"\"\n        Set DBS on for all populations, for the stimulated population only the specified\n        proportion is affected by DBS.\n\n        Args:\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: None, i.e., use value from\n                initialization\n            seed (int, optional):\n                Seed for the random number generator. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n        ### set parameters for the creation of the DBS on array\n        ### either use given population_proportion or use default value\n        if isinstance(population_proportion, type(None)):\n            population_proportion = self.population_proportion\n        ### either use given seed or use default value\n        if isinstance(seed, type(None)):\n            seed = self.seed\n\n        ### if seed and population_propotion are the same as in the initialization, use the same dbs_on_array\n        if seed == self.seed and population_proportion == self.population_proportion:\n            ### use the same dbs_on_array as in the initialization\n            dbs_on_array = self.dbs_on_array\n        else:\n            ### create new dbs_on_array\n            dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n\n        ### set DBS on for all populations\n        for pop in populations():\n            ### of the stimulated population only the specified proportion is affected by DBS\n            if pop == self.stimulated_population:\n                pop.dbs_on = dbs_on_array\n            else:\n                pop.dbs_on = 1\n\n    def off(self):\n        \"\"\"\n        Deactivate DBS.\n        \"\"\"\n        ### set DBS off for all populations\n        for pop in populations():\n            pop.dbs_on = 0\n            pop.prob_axon_spike = 0\n            pop.axon_rate_amp = 0\n\n        ### deactivate DBS axon transmission\n        self._deactivate_axon_DBS()\n\n    def update_pointers(self, pointer_list):\n        \"\"\"\n        Update pointers to populations and projections after recreating the model.\n\n        Args:\n            pointer_list (list):\n                List of pointers to populations and projections\n\n        Returns:\n            pointer_list_new (list):\n                List of pointers to populations and projections of the new model\n        \"\"\"\n        ### update pointers\n        pointer_list_new: list[Population | Projection] = []\n        for pointer in pointer_list:\n            compartment_name = pointer.name\n            if isinstance(pointer, Population):\n                pointer_list_new.append(get_population(compartment_name))\n            elif isinstance(pointer, Projection):\n                pointer_list_new.append(get_projection(compartment_name))\n            else:\n                raise TypeError(\n                    f\"Pointer {pointer} is neither a Population nor a Projection\"\n                )\n        return pointer_list_new\n</code></pre>"},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator.__init__","title":"<code>__init__(stimulated_population, population_proportion=1.0, excluded_populations_list=[], dbs_depolarization=0.0, orthodromic=False, antidromic=False, efferents=False, afferents=False, passing_fibres=False, passing_fibres_list=[], passing_fibres_strength=1.0, sum_branches=True, dbs_pulse_frequency_Hz=130.0, dbs_pulse_width_us=300.0, axon_spikes_per_pulse=1.0, axon_rate_amp=1.0, seed=None, auto_implement=False, model=None)</code>","text":"<p>Initialize DBS stimulator.</p> <p>Warning</p> <p>Do this before compiling the model!</p> <p>Parameters:</p> Name Type Description Default <code>stimulated_population</code> <code>Population</code> <p>Population which is stimulated by DBS</p> required <code>population_proportion</code> <code>float</code> <p>Proportion of the stimulated population which is affected by DBS, neurons are distributed randomly. Default: 1.0.</p> <code>1.0</code> <code>excluded_populations_list</code> <code>list</code> <p>List of populations which are excluded from DBS effects, they are not affected and their axons do not generate axon spikes. Default: [].</p> <code>[]</code> <code>dbs_depolarization</code> <code>float</code> <p>Depolarization effect of the DBS pulse to local soma. Default: 0.0.</p> <code>0.0</code> <code>orthodromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded orthodromically. Default: False.</p> <code>False</code> <code>antidromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded antidromically, only available in spiking networks. Default: False.</p> <code>False</code> <code>efferents</code> <code>bool</code> <p>If True, DBS affects the efferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>afferents</code> <code>bool</code> <p>If True, DBS affects the afferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>passing_fibres</code> <code>bool</code> <p>If True, DBS affects the passing fibres of the stimulated region defined in passing_fibres_list (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>passing_fibres_list</code> <code>list of Projections</code> <p>List of projections which pass the DBS stimulated region and therefore are activated by DBS. Default: [], also set passing_fibres True!</p> <code>[]</code> <code>passing_fibres_strength</code> <code>float or list of float</code> <p>Single value or list of float values between 0 and 1 defining how strong the passing fibres are activated by DBS (0: not activated, 1: fully activated like the projections in the DBS stimulated region). Default: 1.</p> <code>1.0</code> <code>sum_branches</code> <code>bool</code> <p>If True, the antidromic_prob of a presynaptic population (defining how many axon spikes affect the pop antidromically) of passing fibres is the sum of the passing_fibres_strengths of the single axon branches. Default: True.</p> <code>True</code> <code>dbs_pulse_frequency_Hz</code> <code>float</code> <p>Frequency of the DBS pulse. Default: 130 Hz.</p> <code>130.0</code> <code>dbs_pulse_width_us</code> <code>float</code> <p>Width of the DBS pulse. Default: 300 us.</p> <code>300.0</code> <code>axon_spikes_per_pulse</code> <code>float</code> <p>Number of average axon spikes per DBS pulse. Default: 1.</p> <code>1.0</code> <code>axon_rate_amp</code> <code>float or dict of float</code> <p>Similar to prob_axon_spike in spiking model. Which rate is forwarded on axons caused by DBS. You can specify this for each population individually by using a dictionary (keys = Population instances) axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate of 1.5 during DBS (all other affected projections forward the default value) You can specify the default value by using the key \"default\", e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except pop forward a rate of 1.0 during DBS. Default: 1.0.</p> <code>1.0</code> <code>seed</code> <code>int</code> <p>Seed for the random distribution of affected neurons based on population_proportion. Default: None.</p> <code>None</code> <code>auto_implement</code> <code>bool</code> <p>If True, automatically implement DBS mechanisms to the model. Only supported for Izhikevich spiking models and rate-coded models. Default: False. TODO test what happens with mixed models</p> <code>False</code> <code>model</code> <code>generate_model</code> <p>CompNeuroPy model which is used to automatically implement DBS mechanisms, should not be compiled!. Default: None, i.e., use all populations and projections of the current magic model</p> <code>None</code> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    stimulated_population: Population,\n    population_proportion: float = 1.0,\n    excluded_populations_list: list[Population] = [],\n    dbs_depolarization: float = 0.0,\n    orthodromic: bool = False,\n    antidromic: bool = False,\n    efferents: bool = False,\n    afferents: bool = False,\n    passing_fibres: bool = False,\n    passing_fibres_list: list[Projection] = [],\n    passing_fibres_strength: float | list[float] = 1.0,\n    sum_branches: bool = True,\n    dbs_pulse_frequency_Hz: float = 130.0,\n    dbs_pulse_width_us: float = 300.0,\n    axon_spikes_per_pulse: float = 1.0,\n    axon_rate_amp: float | dict[Population | str, float] = 1.0,\n    seed: int | None = None,\n    auto_implement: bool = False,\n    model: generate_model | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize DBS stimulator.\n\n    !!! warning\n        Do this before compiling the model!\n\n    Args:\n        stimulated_population (Population):\n            Population which is stimulated by DBS\n        population_proportion (float, optional):\n            Proportion of the stimulated population which is affected by DBS,\n            neurons are distributed randomly. Default: 1.0.\n        excluded_populations_list (list, optional):\n            List of populations which are excluded from DBS effects, they are not\n            affected and their axons do not generate axon spikes. Default: [].\n        dbs_depolarization (float, optional):\n            Depolarization effect of the DBS pulse to local soma. Default: 0.0.\n        orthodromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded orthodromically.\n            Default: False.\n        antidromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded antidromically,\n            only available in spiking networks. Default: False.\n        efferents (bool, optional):\n            If True, DBS affects the efferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: False.\n        afferents (bool, optional):\n            If True, DBS affects the afferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: False.\n        passing_fibres (bool, optional):\n            If True, DBS affects the passing fibres of the stimulated region defined\n            in passing_fibres_list (orthodromic and/or antidromic have to be True\n            too). Default: False.\n        passing_fibres_list (list of Projections, optional):\n            List of projections which pass the DBS stimulated region and therefore\n            are activated by DBS. Default: [], also set passing_fibres True!\n        passing_fibres_strength (float or list of float, optional):\n            Single value or list of float values between 0 and 1 defining how strong\n            the passing fibres are activated by DBS (0: not activated, 1: fully\n            activated like the projections in the DBS stimulated region).\n            Default: 1.\n        sum_branches (bool, optional):\n            If True, the antidromic_prob of a presynaptic population (defining how\n            many axon spikes affect the pop antidromically) of passing fibres is\n            the sum of the passing_fibres_strengths of the single axon branches.\n            Default: True.\n        dbs_pulse_frequency_Hz (float, optional):\n            Frequency of the DBS pulse. Default: 130 Hz.\n        dbs_pulse_width_us (float, optional):\n            Width of the DBS pulse. Default: 300 us.\n        axon_spikes_per_pulse (float, optional):\n            Number of average axon spikes per DBS pulse. Default: 1.\n        axon_rate_amp (float or dict of float, optional):\n            Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n            axons caused by DBS. You can specify this for each population\n            individually by using a dictionary (keys = Population instances)\n            axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n            of 1.5 during DBS (all other affected projections forward the default\n            value)\n            You can specify the default value by using the key \"default\", e.g.\n            {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n            pop forward a rate of 1.0 during DBS. Default: 1.0.\n        seed (int, optional):\n            Seed for the random distribution of affected neurons based on\n            population_proportion. Default: None.\n        auto_implement (bool, optional):\n            If True, automatically implement DBS mechanisms to the model. Only\n            supported for Izhikevich spiking models and rate-coded models.\n            Default: False.\n            TODO test what happens with mixed models\n        model (generate_model, optional):\n            CompNeuroPy model which is used to automatically implement DBS\n            mechanisms, should not be compiled!. Default: None, i.e., use all\n            populations and projections of the current magic model\n    \"\"\"\n\n    if auto_implement:\n        ### recreate model with DBS mechanisms\n        ### give all variables containing Populations and Projections\n        ### and also recreate them during recreating the model\n        ### variables are:\n        ### - stimulated_population\n        ### - excluded_populations_list\n        ### - passing_fibres_list\n        ### - axon_rate_amp\n        if not isinstance(model, type(None)):\n            ### CompNeuroPy model given\n            ### recreate model with DBS mechanisms\n            create_dbs_model_obj = _CreateDBSmodelcnp(\n                model,\n                stimulated_population,\n                excluded_populations_list,\n                passing_fibres_list,\n                axon_rate_amp,\n            )\n            ### get the new CompNeuroPy model\n            model = create_dbs_model_obj.model\n        else:\n            ### no CompNeuroPy model given --&gt; use all populations and projections of the current magic model\n            ### recreate model with DBS mechanisms\n            create_dbs_model_obj = _CreateDBSmodel(\n                stimulated_population,\n                excluded_populations_list,\n                passing_fibres_list,\n                axon_rate_amp,\n            )\n        ### get the new variables containing Populations and Projections\n        stimulated_population = create_dbs_model_obj.stimulated_population\n        excluded_populations_list = create_dbs_model_obj.excluded_populations_list\n        passing_fibres_list = create_dbs_model_obj.passing_fibres_list\n        axon_rate_amp = create_dbs_model_obj.axon_rate_amp\n\n    ### set parameters\n    self.stimulated_population = stimulated_population\n    self.population_proportion = population_proportion\n    self.excluded_populations_list = excluded_populations_list\n    self.dbs_depolarization = dbs_depolarization\n    self.orthodromic = orthodromic\n    self.antidromic = antidromic\n    self.efferents = efferents\n    self.afferents = afferents\n    self.passing_fibres = passing_fibres\n    self.passing_fibres_list = passing_fibres_list\n    self.passing_fibres_strength = passing_fibres_strength\n    self.sum_branches = sum_branches\n    self.dbs_pulse_width_us = dbs_pulse_width_us\n    self.axon_spikes_per_pulse = axon_spikes_per_pulse\n    self.axon_rate_amp = axon_rate_amp\n    self.seed = seed\n    self.model = model\n\n    ### ANNarchy constants for DBS\n    self._set_constants(dbs_pulse_frequency_Hz)\n\n    ### randomly select affected neurons i.e. create dbs_on_array\n    self.dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n</code></pre>"},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator.on","title":"<code>on(population_proportion=None, dbs_depolarization=None, orthodromic=None, antidromic=None, efferents=None, afferents=None, passing_fibres=None, passing_fibres_strength=None, sum_branches=None, axon_spikes_per_pulse=None, axon_rate_amp=None, seed=None)</code>","text":"<p>Activate DBS.</p> <p>Parameters:</p> Name Type Description Default <code>population_proportion</code> <code>float</code> <p>Proportion of the stimulated population which is affected by DBS, neurons are distributed randomly. Default: None, i.e., use value from initialization</p> <code>None</code> <code>dbs_depolarization</code> <code>float</code> <p>Depolarization effect of the DBS pulse to local soma. Default: None, i.e., use value from initialization</p> <code>None</code> <code>orthodromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded orthodromically. Default: None, i.e., use value from initialization</p> <code>None</code> <code>antidromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded antidromically, only available in spiking networks. Default: None, i.e., use value from initialization</p> <code>None</code> <code>efferents</code> <code>bool</code> <p>If True, DBS affects the efferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>afferents</code> <code>bool</code> <p>If True, DBS affects the afferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>passing_fibres</code> <code>bool</code> <p>If True, DBS affects the passing fibres of the stimulated region defined in passing_fibres_list (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>passing_fibres_strength</code> <code>float | list[float]</code> <p>Single value or list of float values between 0 and 1 defining how strong the passing fibres are activated by DBS (0: not activated, 1: fully activated like the projections in the DBS stimulated region). Default: None, i.e., use value from initialization</p> <code>None</code> <code>sum_branches</code> <code>bool</code> <p>If True, the antidromic_prob of a presynaptic population (defining how many axon spikes affect the pop antidromically) of passing fibres is the sum of the passing_fibres_strengths of the single axon branches. Default: None, i.e., use value from initialization</p> <code>None</code> <code>axon_spikes_per_pulse</code> <code>float</code> <p>Number of average axon spikes per DBS pulse. Default: None, i.e., use value from initialization</p> <code>None</code> <code>axon_rate_amp</code> <code>float | dict[Population | str, float]</code> <p>Similar to prob_axon_spike in spiking model. Which rate is forwarded on axons caused by DBS. You can specify this for each population individually by using a dictionary (keys = Population instances) axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate of 1.5 during DBS (all other affected projections forward the default value). You can specify the default value by using the key \"default\", e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except pop forward a rate of 1.0 during DBS. Default: None, i.e., use value from initialization</p> <code>None</code> <code>seed</code> <code>int</code> <p>Seed for the random number generator. Default: None, i.e., use value from initialization</p> <code>None</code> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>@check_types()\ndef on(\n    self,\n    population_proportion: float | None = None,\n    dbs_depolarization: float | None = None,\n    orthodromic: bool | None = None,\n    antidromic: bool | None = None,\n    efferents: bool | None = None,\n    afferents: bool | None = None,\n    passing_fibres: bool | None = None,\n    passing_fibres_strength: float | list[float] | None = None,\n    sum_branches: bool | None = None,\n    axon_spikes_per_pulse: float | None = None,\n    axon_rate_amp: float | dict[Population | str, float] | None = None,\n    seed: int | None = None,\n):\n    \"\"\"\n    Activate DBS.\n\n    Args:\n        population_proportion (float, optional):\n            Proportion of the stimulated population which is affected by DBS,\n            neurons are distributed randomly. Default: None, i.e., use value from\n            initialization\n        dbs_depolarization (float, optional):\n            Depolarization effect of the DBS pulse to local soma. Default: None,\n            i.e., use value from initialization\n        orthodromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded orthodromically.\n            Default: None, i.e., use value from initialization\n        antidromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded antidromically,\n            only available in spiking networks. Default: None, i.e., use value from\n            initialization\n        efferents (bool, optional):\n            If True, DBS affects the efferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: None,\n            i.e., use value from initialization\n        afferents (bool, optional):\n            If True, DBS affects the afferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: None,\n            i.e., use value from initialization\n        passing_fibres (bool, optional):\n            If True, DBS affects the passing fibres of the stimulated region defined\n            in passing_fibres_list (orthodromic and/or antidromic have to be True\n            too). Default: None, i.e., use value from initialization\n        passing_fibres_strength (float | list[float], optional):\n            Single value or list of float values between 0 and 1 defining how strong\n            the passing fibres are activated by DBS (0: not activated, 1: fully\n            activated like the projections in the DBS stimulated region).\n            Default: None, i.e., use value from initialization\n        sum_branches (bool, optional):\n            If True, the antidromic_prob of a presynaptic population (defining how\n            many axon spikes affect the pop antidromically) of passing fibres is\n            the sum of the passing_fibres_strengths of the single axon branches.\n            Default: None, i.e., use value from initialization\n        axon_spikes_per_pulse (float, optional):\n            Number of average axon spikes per DBS pulse. Default: None, i.e., use\n            value from initialization\n        axon_rate_amp (float | dict[Population | str, float], optional):\n            Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n            axons caused by DBS. You can specify this for each population\n            individually by using a dictionary (keys = Population instances)\n            axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n            of 1.5 during DBS (all other affected projections forward the default\n            value). You can specify the default value by using the key \"default\",\n            e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations\n            except pop forward a rate of 1.0 during DBS. Default: None, i.e., use\n            value from initialization\n        seed (int, optional):\n            Seed for the random number generator. Default: None, i.e., use value\n            from initialization\n    \"\"\"\n\n    ### set DBS on for all populations\n    ### also sets the proportion of affected neurons, call this before set_depolarization and set_axon_spikes!\n    self._set_dbs_on(population_proportion, seed)\n\n    ### set depolarization of population\n    self._set_depolarization(dbs_depolarization)\n\n    ### set axon spikes forwarding\n    self._set_axon_spikes(\n        orthodromic,\n        antidromic,\n        efferents,\n        afferents,\n        passing_fibres,\n        passing_fibres_strength,\n        sum_branches,\n        axon_spikes_per_pulse,\n        axon_rate_amp,\n    )\n</code></pre>"},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator.off","title":"<code>off()</code>","text":"<p>Deactivate DBS.</p> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>def off(self):\n    \"\"\"\n    Deactivate DBS.\n    \"\"\"\n    ### set DBS off for all populations\n    for pop in populations():\n        pop.dbs_on = 0\n        pop.prob_axon_spike = 0\n        pop.axon_rate_amp = 0\n\n    ### deactivate DBS axon transmission\n    self._deactivate_axon_DBS()\n</code></pre>"},{"location":"main/dbs_stimulator/#src.CompNeuroPy.dbs.DBSstimulator.update_pointers","title":"<code>update_pointers(pointer_list)</code>","text":"<p>Update pointers to populations and projections after recreating the model.</p> <p>Parameters:</p> Name Type Description Default <code>pointer_list</code> <code>list</code> <p>List of pointers to populations and projections</p> required <p>Returns:</p> Name Type Description <code>pointer_list_new</code> <code>list</code> <p>List of pointers to populations and projections of the new model</p> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>def update_pointers(self, pointer_list):\n    \"\"\"\n    Update pointers to populations and projections after recreating the model.\n\n    Args:\n        pointer_list (list):\n            List of pointers to populations and projections\n\n    Returns:\n        pointer_list_new (list):\n            List of pointers to populations and projections of the new model\n    \"\"\"\n    ### update pointers\n    pointer_list_new: list[Population | Projection] = []\n    for pointer in pointer_list:\n        compartment_name = pointer.name\n        if isinstance(pointer, Population):\n            pointer_list_new.append(get_population(compartment_name))\n        elif isinstance(pointer, Projection):\n            pointer_list_new.append(get_projection(compartment_name))\n        else:\n            raise TypeError(\n                f\"Pointer {pointer} is neither a Population nor a Projection\"\n            )\n    return pointer_list_new\n</code></pre>"},{"location":"main/define_experiment/","title":"Define an Experiment","text":""},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.CompNeuroExp","title":"<code>src.CompNeuroPy.experiment.CompNeuroExp</code>","text":"<p>Experiment combining simulations and recordings.</p> <p>Use this class as a parent class for your experiment. You have to additionally implement a run function which runs the simulations and controlls the recordings. The run function should return the results of the experiment by calling the results function of the CompNeuroExp class.</p> <p>Attributes:</p> Name Type Description <code>mon</code> <code>CompNeuroMonitors</code> <p>CompNeuroMonitors object for recordings</p> <code>data</code> <code>dict</code> <p>dict for storing optional data</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from CompNeuroPy import CompNeuroExp\n&gt;&gt;&gt; from ANNarchy import simulate\n&gt;&gt;&gt;\n&gt;&gt;&gt; class MyExperiment(CompNeuroExp):\n&gt;&gt;&gt;     def run(self):\n&gt;&gt;&gt;         # run simulations and control recordings\n&gt;&gt;&gt;         self.mon.start()\n&gt;&gt;&gt;         simulate(1000)\n&gt;&gt;&gt;         self.reset()\n&gt;&gt;&gt;         simulate(1000)\n&gt;&gt;&gt;         # store optional data\n&gt;&gt;&gt;         self.data[\"duration\"] = 2000\n&gt;&gt;&gt;         # return results\n&gt;&gt;&gt;         return self.results()\n</code></pre> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>class CompNeuroExp:\n    \"\"\"\n    Experiment combining simulations and recordings.\n\n    Use this class as a parent class for your experiment. You have to additionally\n    implement a run function which runs the simulations and controlls the recordings.\n    The run function should return the results of the experiment by calling the results\n    function of the CompNeuroExp class.\n\n    Attributes:\n        mon (CompNeuroMonitors):\n            CompNeuroMonitors object for recordings\n        data (dict):\n            dict for storing optional data\n\n    Examples:\n        &gt;&gt;&gt; from CompNeuroPy import CompNeuroExp\n        &gt;&gt;&gt; from ANNarchy import simulate\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; class MyExperiment(CompNeuroExp):\n        &gt;&gt;&gt;     def run(self):\n        &gt;&gt;&gt;         # run simulations and control recordings\n        &gt;&gt;&gt;         self.mon.start()\n        &gt;&gt;&gt;         simulate(1000)\n        &gt;&gt;&gt;         self.reset()\n        &gt;&gt;&gt;         simulate(1000)\n        &gt;&gt;&gt;         # store optional data\n        &gt;&gt;&gt;         self.data[\"duration\"] = 2000\n        &gt;&gt;&gt;         # return results\n        &gt;&gt;&gt;         return self.results()\n    \"\"\"\n\n    def __init__(\n        self, monitors: CompNeuroMonitors, reset_function=None, reset_kwargs={}\n    ):\n        \"\"\"\n        Initialize the experiment.\n\n        Args:\n            monitors (CompNeuroMonitors):\n                CompNeuroMonitors object for recordings\n            reset_function (function, optional):\n                A function which resets the ANNarchy model.\n                Default: None, i.e., ANNarchys' reset function\n            reset_kwargs (dict, optional):\n                Arguments of the reset_function besides the ones which are used by\n                ANNarchys' reset function. Default: {}.\n        \"\"\"\n        self.recordings = {}  # save dict for monitor recordings\n        self.mon = monitors\n        self.data = {}  # dict for optional data\n\n        ### check function to reset network\n        if reset_function is None:\n            self.reset_function = reset\n        else:\n            self.reset_function = reset_function\n        self.reset_kwargs = reset_kwargs\n\n    def reset(self, populations=True, projections=False, synapses=False):\n        \"\"\"\n        Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the\n        experiment. The reset function of the CompNeuroExp class is used which can be\n        set during initialization and can have additional arguments besides the ones\n        which are used by ANNarchys' reset function which are also set during\n        initialization.\n\n        Args:\n            populations (bool, optional):\n                reset populations. Defaults to True.\n            projections (bool, optional):\n                reset projections. Defaults to False.\n            synapses (bool, optional):\n                reset synapses. Defaults to False.\n            monitors (bool, optional):\n                reset monitors. Defaults to True.\n        \"\"\"\n        self.reset_kwargs[\"populations\"] = populations\n        self.reset_kwargs[\"projections\"] = projections\n        self.reset_kwargs[\"synapses\"] = synapses\n        self.reset_kwargs[\"monitors\"] = True\n        ### reset monitors\n        self.mon.reset()\n        ### reset ANNarchy model\n        self.reset_function(**self.reset_kwargs)\n\n    def results(self):\n        \"\"\"\n        !!! warning\n            Call this function at the end of the run function of the CompNeuroExp class!\n\n        Returns:\n            results_obj (CompNeuroExp._ResultsCl):\n                Object with with attributes:\n                    recordings (list):\n                        list of recordings\n                    recording_times (recording_times_cl):\n                        recording times object\n                    mon_dict (dict):\n                        dict of recorded variables of the monitors\n                    data (dict):\n                        dict with optional data stored during the experiment\n        \"\"\"\n        obj = self._ResultsCl()\n        obj.recordings, obj.recording_times = self.mon.get_recordings_and_clear()\n        obj.mon_dict = self.mon.mon_dict\n        obj.data = self.data\n\n        return obj\n\n    class _ResultsCl:\n        \"\"\"\n        Class for storing the results of the experiment.\n\n        Attributes:\n            recordings (list):\n                list of recordings\n            recording_times (recording_times_cl):\n                recording times object\n            mon_dict (dict):\n                dict of recorded variables of the monitors\n            data (dict):\n                dict with optional data stored during the experiment\n        \"\"\"\n\n        def __init__(self) -&gt; None:\n            self.recordings: list\n            self.recording_times: RecordingTimes\n            self.mon_dict: dict\n            self.data: dict\n\n    def run(self) -&gt; _ResultsCl:\n        \"\"\"\n        !!! warning\n            This function has to be implemented by the user!\n        \"\"\"\n        raise NotImplementedError(\n            \"You have to implement a run function which runs the simulations and controlls the recordings. The run function should return the results of the experiment by calling the results function of the CompNeuroExp class.\"\n        )\n</code></pre>"},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.CompNeuroExp.__init__","title":"<code>__init__(monitors, reset_function=None, reset_kwargs={})</code>","text":"<p>Initialize the experiment.</p> <p>Parameters:</p> Name Type Description Default <code>monitors</code> <code>CompNeuroMonitors</code> <p>CompNeuroMonitors object for recordings</p> required <code>reset_function</code> <code>function</code> <p>A function which resets the ANNarchy model. Default: None, i.e., ANNarchys' reset function</p> <code>None</code> <code>reset_kwargs</code> <code>dict</code> <p>Arguments of the reset_function besides the ones which are used by ANNarchys' reset function. Default: {}.</p> <code>{}</code> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def __init__(\n    self, monitors: CompNeuroMonitors, reset_function=None, reset_kwargs={}\n):\n    \"\"\"\n    Initialize the experiment.\n\n    Args:\n        monitors (CompNeuroMonitors):\n            CompNeuroMonitors object for recordings\n        reset_function (function, optional):\n            A function which resets the ANNarchy model.\n            Default: None, i.e., ANNarchys' reset function\n        reset_kwargs (dict, optional):\n            Arguments of the reset_function besides the ones which are used by\n            ANNarchys' reset function. Default: {}.\n    \"\"\"\n    self.recordings = {}  # save dict for monitor recordings\n    self.mon = monitors\n    self.data = {}  # dict for optional data\n\n    ### check function to reset network\n    if reset_function is None:\n        self.reset_function = reset\n    else:\n        self.reset_function = reset_function\n    self.reset_kwargs = reset_kwargs\n</code></pre>"},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.CompNeuroExp.reset","title":"<code>reset(populations=True, projections=False, synapses=False)</code>","text":"<p>Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the experiment. The reset function of the CompNeuroExp class is used which can be set during initialization and can have additional arguments besides the ones which are used by ANNarchys' reset function which are also set during initialization.</p> <p>Parameters:</p> Name Type Description Default <code>populations</code> <code>bool</code> <p>reset populations. Defaults to True.</p> <code>True</code> <code>projections</code> <code>bool</code> <p>reset projections. Defaults to False.</p> <code>False</code> <code>synapses</code> <code>bool</code> <p>reset synapses. Defaults to False.</p> <code>False</code> <code>monitors</code> <code>bool</code> <p>reset monitors. Defaults to True.</p> required Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def reset(self, populations=True, projections=False, synapses=False):\n    \"\"\"\n    Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the\n    experiment. The reset function of the CompNeuroExp class is used which can be\n    set during initialization and can have additional arguments besides the ones\n    which are used by ANNarchys' reset function which are also set during\n    initialization.\n\n    Args:\n        populations (bool, optional):\n            reset populations. Defaults to True.\n        projections (bool, optional):\n            reset projections. Defaults to False.\n        synapses (bool, optional):\n            reset synapses. Defaults to False.\n        monitors (bool, optional):\n            reset monitors. Defaults to True.\n    \"\"\"\n    self.reset_kwargs[\"populations\"] = populations\n    self.reset_kwargs[\"projections\"] = projections\n    self.reset_kwargs[\"synapses\"] = synapses\n    self.reset_kwargs[\"monitors\"] = True\n    ### reset monitors\n    self.mon.reset()\n    ### reset ANNarchy model\n    self.reset_function(**self.reset_kwargs)\n</code></pre>"},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.CompNeuroExp.results","title":"<code>results()</code>","text":"<p>Warning</p> <p>Call this function at the end of the run function of the CompNeuroExp class!</p> <p>Returns:</p> Name Type Description <code>results_obj</code> <code>_ResultsCl</code> <p>Object with with attributes:     recordings (list):         list of recordings     recording_times (recording_times_cl):         recording times object     mon_dict (dict):         dict of recorded variables of the monitors     data (dict):         dict with optional data stored during the experiment</p> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def results(self):\n    \"\"\"\n    !!! warning\n        Call this function at the end of the run function of the CompNeuroExp class!\n\n    Returns:\n        results_obj (CompNeuroExp._ResultsCl):\n            Object with with attributes:\n                recordings (list):\n                    list of recordings\n                recording_times (recording_times_cl):\n                    recording times object\n                mon_dict (dict):\n                    dict of recorded variables of the monitors\n                data (dict):\n                    dict with optional data stored during the experiment\n    \"\"\"\n    obj = self._ResultsCl()\n    obj.recordings, obj.recording_times = self.mon.get_recordings_and_clear()\n    obj.mon_dict = self.mon.mon_dict\n    obj.data = self.data\n\n    return obj\n</code></pre>"},{"location":"main/define_experiment/#src.CompNeuroPy.experiment.CompNeuroExp.run","title":"<code>run()</code>","text":"<p>Warning</p> <p>This function has to be implemented by the user!</p> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def run(self) -&gt; _ResultsCl:\n    \"\"\"\n    !!! warning\n        This function has to be implemented by the user!\n    \"\"\"\n    raise NotImplementedError(\n        \"You have to implement a run function which runs the simulations and controlls the recordings. The run function should return the results of the experiment by calling the results function of the CompNeuroExp class.\"\n    )\n</code></pre>"},{"location":"main/generate_models/","title":"Generate Models","text":""},{"location":"main/generate_models/#introduction","title":"Introduction","text":"<p>One can create a CompNeuroPy-model using the <code>CompNeuroModel</code> class. The <code>CompNeuroModel</code> class takes as one argument the <code>model_creation_function</code>. In this function a classical ANNarchy model is created (populations, projections). The <code>CompNeuroModel</code> class only adds a framework to the model. Neccessary for a CompNeuroPy-model is to define unique names for all populations and projections. Models are created in three steps:</p> <ol> <li>model initialization: the initialization of the <code>CompNeuroModel</code> object, initializes the framework of the model without creating the ANNarchy objects (populations, projections)</li> <li>model creation: create the ANNarchy objects (populations, projections), i.e., run the <code>model_creation function</code></li> <li>model compilation: compile all created models</li> </ol>"},{"location":"main/generate_models/#example","title":"Example","text":"<pre><code>from CompNeuroPy import CompNeuroModel\nmy_model = CompNeuroModel(model_creation_function=create_model,  ### the most important part, this function creates the model (populations, projections)\n                          model_kwargs={'a':1, 'b':2},           ### define the two arguments a and b of function create_model\n                          name='my_model',                       ### you can give the model a name\n                          description='my simple example model', ### you can give the model a description\n                          do_create=True,                        ### create the model directly\n                          do_compile=True,                       ### let the model (and all models created before) compile directly\n                          compile_folder_name='my_model')        ### name of the saved compilation folder\n</code></pre> <p>The following function could be the corresponding model_creation_function:</p> <pre><code>from ANNarchy import Population, Izhikevich\ndef create_model(a, b):\n    pop = Population(geometry=a, neuron=Izhikevich, name='Izh_pop_a') ### first population, size a\n    pop.b = 0                                                         ### some parameter adjustment\n    Population(geometry=b, neuron=Izhikevich, name='Izh_pop_b')       ### second population, size b\n</code></pre> <p>Here, two populations are created (both use built-in Izhikevich neuron model of ANNarchy). The function does not require a return value. It is important that all populations and projections have unique names.</p> <p>A more detailed example is available in the Examples.</p>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.CompNeuroModel","title":"<code>src.CompNeuroPy.generate_model.CompNeuroModel</code>","text":"<p>Class for creating and compiling a model.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>name of the model</p> <code>description</code> <code>str</code> <p>description of the model</p> <code>populations</code> <code>list</code> <p>list of all populations of the model</p> <code>projections</code> <code>list</code> <p>list of all projections of the model</p> <code>attribute_df</code> <code>pandas dataframe</code> <p>dataframe containing all attributes of the model compartments</p> <code>created</code> <code>bool</code> <p>True if the model is created</p> <code>compiled</code> <code>bool</code> <p>True if the model is compiled</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>class CompNeuroModel:\n    \"\"\"\n    Class for creating and compiling a model.\n\n    Attributes:\n        name (str):\n            name of the model\n        description (str):\n            description of the model\n        populations (list):\n            list of all populations of the model\n        projections (list):\n            list of all projections of the model\n        attribute_df (pandas dataframe):\n            dataframe containing all attributes of the model compartments\n        created (bool):\n            True if the model is created\n        compiled (bool):\n            True if the model is compiled\n    \"\"\"\n\n    initialized_models = {}\n    compiled_models = {}\n\n    def __init__(\n        self,\n        model_creation_function,\n        model_kwargs=None,\n        name=\"model\",\n        description=\"\",\n        do_create=True,\n        do_compile=True,\n        compile_folder_name=\"annarchy\",\n    ):\n        \"\"\"\n        Initializes the CompNeuroModel class.\n\n        Args:\n            model_creation_function (function):\n                Function which creates the model.\n            model_kwargs (dict):\n                Keyword arguments for model_creation_function. Default: None.\n            name (str):\n                Name of the model. Default: \"model\".\n            description (str):\n                Description of the model. Default: \"\".\n            do_create (bool):\n                If True the model is created directly. Default: True.\n            do_compile (bool):\n                If True the model is compiled directly. Default: True.\n            compile_folder_name (str):\n                Name of the folder in which the model is compiled. Default: \"annarchy\".\n        \"\"\"\n        self.name = name\n        if name == \"model\":\n            self.name = name + str(self._nr_models())\n        self.description = description\n        self.model_creation_function = model_creation_function\n        self.compile_folder_name = compile_folder_name\n        self.model_kwargs = model_kwargs\n        self.populations = []\n        self.projections = []\n        self.initialized_models[self.name] = False\n        self.compiled_models[self.name] = False\n        if do_create:\n            self.create(do_compile=do_compile, compile_folder_name=compile_folder_name)\n\n    def __getattr__(self, name):\n        if name == \"created\":\n            return self.initialized_models[self.name]\n        elif name == \"compiled\":\n            return self.compiled_models[self.name]\n        else:\n            # Default behaviour\n            raise AttributeError\n\n    def compile(self, compile_folder_name=None):\n        \"\"\"\n        compiles a created model\n        \"\"\"\n        ### check if this model is created\n        if self.initialized_models[self.name]:\n            if compile_folder_name == None:\n                compile_folder_name = self.compile_folder_name\n\n            ### check if other models were initialized but not created --&gt; warn that they are not compiled\n            not_created_model_list = self._check_if_models_created()\n            if len(not_created_model_list) &gt; 0:\n                print(\n                    \"\\nWARNING during compile of model \"\n                    + self.name\n                    + \": There are initialized models which are not created, thus not compiled! models:\\n\"\n                    + \"\\n\".join(not_created_model_list)\n                    + \"\\n\"\n                )\n            mf.compile_in_folder(compile_folder_name)\n            self.compiled_models[self.name] = True\n        else:\n            print(\"\\n\")\n            assert False, (\n                \"ERROR during compile of model \"\n                + self.name\n                + \": Only compile the model after it has been created!\"\n            )\n\n    def create(self, do_compile=True, compile_folder_name=None):\n        \"\"\"\n        creates a model and optionally compiles it directly\n        \"\"\"\n        if self.initialized_models[self.name]:\n            print(\"model\", self.name, \"already created!\")\n        else:\n            initial_existing_model = mf.get_full_model()\n            ### create model populations and projections\n            if self.model_kwargs != None:\n                self.model_creation_function(**self.model_kwargs)\n            else:\n                self.model_creation_function()\n            self.initialized_models[self.name] = True\n\n            ### check which populations and projections have been added\n            post_existing_model = mf.get_full_model()\n            ### save only added not all projections/populations\n            for initial_pop in initial_existing_model[\"populations\"]:\n                post_existing_model[\"populations\"].remove(initial_pop)\n            for initial_proj in initial_existing_model[\"projections\"]:\n                post_existing_model[\"projections\"].remove(initial_proj)\n            self.populations = post_existing_model[\"populations\"]\n            self.projections = post_existing_model[\"projections\"]\n\n            self.initialized_models[self.name] = True\n\n            ### check if names of populations and projections are unique\n            self._check_double_compartments()\n\n            ### create parameter dictionary\n            self.attribute_df = self._get_attribute_df()\n\n            if do_compile:\n                self.compile(compile_folder_name)\n\n    def _check_if_models_created(self):\n        \"\"\"\n        checks which CompNeuroPy models are created\n        returns a list with all initialized CompNeuroPy models which are not created yet\n        \"\"\"\n        not_created_model_list = []\n        for key in self.initialized_models.keys():\n            if self.initialized_models[key] == False:\n                not_created_model_list.append(key)\n\n        return not_created_model_list\n\n    def _nr_models(self):\n        \"\"\"\n        returns the current number of initialized (not considering \"created\") CompNeuroPy models\n        \"\"\"\n        return len(list(self.initialized_models.keys()))\n\n    def set_param(self, compartment, parameter_name, parameter_value):\n        \"\"\"\n        sets the specified parameter of the specified compartment\n\n        args:\n            compartment: str\n                name of model compartment\n            parameter_name: str\n                name of parameter of the compartment\n            parameter_value: number or array-like with shape of compartment geometry\n                the value or values of the parameter\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR set_param: model {self.name} has to be created before setting parameters!\"\n\n        ### check if compartment is in populations or projections\n        comp_in_pop = compartment in self.populations\n        comp_in_proj = compartment in self.projections\n\n        if comp_in_pop:\n            comp_obj = get_population(compartment)\n        elif comp_in_proj:\n            comp_obj = get_projection(compartment)\n        else:\n            assert (\n                comp_in_pop or comp_in_proj\n            ), f\"ERROR set_param: setting parameter {parameter_name} of compartment {compartment}. The compartment is neither a population nor a projection of the model {self.name}!\"\n\n        ### set the parameter value\n        setattr(comp_obj, parameter_name, parameter_value)\n\n        ### update the model attribute_df\n        self._update_attribute_df(compartment, parameter_name, parameter_value)\n\n    def _update_attribute_df(self, compartment, parameter_name, parameter_value):\n        \"\"\"updates the attribute df for a specific paramter\"\"\"\n        paramter_mask = (\n            (self.attribute_df[\"compartment_name\"] == compartment).astype(int)\n            * (self.attribute_df[\"attribute_name\"] == parameter_name).astype(int)\n        ).astype(bool)\n        parameter_idx = np.arange(paramter_mask.size).astype(int)[paramter_mask][0]\n        min_val = af.get_minimum(parameter_value)\n        max_val = af.get_maximum(parameter_value)\n        if min_val != max_val:\n            self.attribute_df.at[parameter_idx, \"value\"] = f\"[{min_val}, {max_val}]\"\n        else:\n            self.attribute_df.at[parameter_idx, \"value\"] = str(min_val)\n        self.attribute_df.at[parameter_idx, \"definition\"] = \"modified\"\n\n    def _check_double_compartments(self):\n        \"\"\"\n        goes over all compartments of the model and checks if compartment is only a population or a projection\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR model {self.name}: model has to be created before checking for double compartments!\"\n        ### only have to go over populations and check if they are also projections (go over projections not neccessary)\n        pop_in_projections_list = []\n        pop_in_projections = False\n        for pop_name in self.populations:\n            if pop_name in self.projections:\n                pop_in_projections_list.append(pop_name)\n                pop_in_projections = True\n\n        assert (\n            pop_in_projections == False\n        ), f\"ERROR model {self.name}: One or multiple compartments are both population and projection ({pop_in_projections_list}). Rename them!\"\n\n    def _get_attribute_df(self):\n        \"\"\"\n        creates a dataframe containing the attributes of all model compartments\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR model {self.name}: model has to be created before creating paramteer dictionary!\"\n\n        ### create empty paramteter dict\n        attribute_dict = {\n            \"compartment_type\": [],\n            \"compartment_name\": [],\n            \"attribute_name\": [],\n            \"value\": [],\n            \"definition\": [],\n        }\n\n        ### fill paramter dict with population attributes\n        for pop in self.populations:\n            for attribute in vars(get_population(pop))[\"attributes\"]:\n                ### store min and max of attribute\n                ### create numpy array with getattr to use numpy min max function\n                values = np.array(\n                    [getattr(get_population(pop), attribute)]\n                    + [getattr(get_population(pop), attribute)]\n                )\n                attribute_dict[\"compartment_type\"].append(\"population\")\n                attribute_dict[\"compartment_name\"].append(pop)\n                attribute_dict[\"attribute_name\"].append(attribute)\n                if values.min() != values.max():\n                    attribute_dict[\"value\"].append(f\"[{values.min()}, {values.max()}]\")\n                else:\n                    attribute_dict[\"value\"].append(str(values.min()))\n                attribute_dict[\"definition\"].append(\"init\")\n\n        ### fill paramter dict with projection attributes\n        for proj in self.projections:\n            for attribute in vars(get_projection(proj))[\"attributes\"]:\n                ### store min and max of attribute\n                ### create numpy array with getattr to use numpy min max function\n                values = np.array(\n                    [getattr(get_projection(proj), attribute)]\n                    + [getattr(get_projection(proj), attribute)]\n                )\n                attribute_dict[\"compartment_type\"].append(\"projection\")\n                attribute_dict[\"compartment_name\"].append(proj)\n                attribute_dict[\"attribute_name\"].append(attribute)\n                if values.min() != values.max():\n                    attribute_dict[\"value\"].append(f\"[{values.min()}, {values.max()}]\")\n                else:\n                    attribute_dict[\"value\"].append(values.min())\n                attribute_dict[\"definition\"].append(\"init\")\n\n        ### return dataframe\n        return pd.DataFrame(attribute_dict)\n</code></pre>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.CompNeuroModel.__init__","title":"<code>__init__(model_creation_function, model_kwargs=None, name='model', description='', do_create=True, do_compile=True, compile_folder_name='annarchy')</code>","text":"<p>Initializes the CompNeuroModel class.</p> <p>Parameters:</p> Name Type Description Default <code>model_creation_function</code> <code>function</code> <p>Function which creates the model.</p> required <code>model_kwargs</code> <code>dict</code> <p>Keyword arguments for model_creation_function. Default: None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the model. Default: \"model\".</p> <code>'model'</code> <code>description</code> <code>str</code> <p>Description of the model. Default: \"\".</p> <code>''</code> <code>do_create</code> <code>bool</code> <p>If True the model is created directly. Default: True.</p> <code>True</code> <code>do_compile</code> <code>bool</code> <p>If True the model is compiled directly. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: \"annarchy\".</p> <code>'annarchy'</code> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def __init__(\n    self,\n    model_creation_function,\n    model_kwargs=None,\n    name=\"model\",\n    description=\"\",\n    do_create=True,\n    do_compile=True,\n    compile_folder_name=\"annarchy\",\n):\n    \"\"\"\n    Initializes the CompNeuroModel class.\n\n    Args:\n        model_creation_function (function):\n            Function which creates the model.\n        model_kwargs (dict):\n            Keyword arguments for model_creation_function. Default: None.\n        name (str):\n            Name of the model. Default: \"model\".\n        description (str):\n            Description of the model. Default: \"\".\n        do_create (bool):\n            If True the model is created directly. Default: True.\n        do_compile (bool):\n            If True the model is compiled directly. Default: True.\n        compile_folder_name (str):\n            Name of the folder in which the model is compiled. Default: \"annarchy\".\n    \"\"\"\n    self.name = name\n    if name == \"model\":\n        self.name = name + str(self._nr_models())\n    self.description = description\n    self.model_creation_function = model_creation_function\n    self.compile_folder_name = compile_folder_name\n    self.model_kwargs = model_kwargs\n    self.populations = []\n    self.projections = []\n    self.initialized_models[self.name] = False\n    self.compiled_models[self.name] = False\n    if do_create:\n        self.create(do_compile=do_compile, compile_folder_name=compile_folder_name)\n</code></pre>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.CompNeuroModel.compile","title":"<code>compile(compile_folder_name=None)</code>","text":"<p>compiles a created model</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def compile(self, compile_folder_name=None):\n    \"\"\"\n    compiles a created model\n    \"\"\"\n    ### check if this model is created\n    if self.initialized_models[self.name]:\n        if compile_folder_name == None:\n            compile_folder_name = self.compile_folder_name\n\n        ### check if other models were initialized but not created --&gt; warn that they are not compiled\n        not_created_model_list = self._check_if_models_created()\n        if len(not_created_model_list) &gt; 0:\n            print(\n                \"\\nWARNING during compile of model \"\n                + self.name\n                + \": There are initialized models which are not created, thus not compiled! models:\\n\"\n                + \"\\n\".join(not_created_model_list)\n                + \"\\n\"\n            )\n        mf.compile_in_folder(compile_folder_name)\n        self.compiled_models[self.name] = True\n    else:\n        print(\"\\n\")\n        assert False, (\n            \"ERROR during compile of model \"\n            + self.name\n            + \": Only compile the model after it has been created!\"\n        )\n</code></pre>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.CompNeuroModel.create","title":"<code>create(do_compile=True, compile_folder_name=None)</code>","text":"<p>creates a model and optionally compiles it directly</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def create(self, do_compile=True, compile_folder_name=None):\n    \"\"\"\n    creates a model and optionally compiles it directly\n    \"\"\"\n    if self.initialized_models[self.name]:\n        print(\"model\", self.name, \"already created!\")\n    else:\n        initial_existing_model = mf.get_full_model()\n        ### create model populations and projections\n        if self.model_kwargs != None:\n            self.model_creation_function(**self.model_kwargs)\n        else:\n            self.model_creation_function()\n        self.initialized_models[self.name] = True\n\n        ### check which populations and projections have been added\n        post_existing_model = mf.get_full_model()\n        ### save only added not all projections/populations\n        for initial_pop in initial_existing_model[\"populations\"]:\n            post_existing_model[\"populations\"].remove(initial_pop)\n        for initial_proj in initial_existing_model[\"projections\"]:\n            post_existing_model[\"projections\"].remove(initial_proj)\n        self.populations = post_existing_model[\"populations\"]\n        self.projections = post_existing_model[\"projections\"]\n\n        self.initialized_models[self.name] = True\n\n        ### check if names of populations and projections are unique\n        self._check_double_compartments()\n\n        ### create parameter dictionary\n        self.attribute_df = self._get_attribute_df()\n\n        if do_compile:\n            self.compile(compile_folder_name)\n</code></pre>"},{"location":"main/generate_models/#src.CompNeuroPy.generate_model.CompNeuroModel.set_param","title":"<code>set_param(compartment, parameter_name, parameter_value)</code>","text":"<p>sets the specified parameter of the specified compartment</p> <p>Parameters:</p> Name Type Description Default <code>compartment</code> <p>str name of model compartment</p> required <code>parameter_name</code> <p>str name of parameter of the compartment</p> required <code>parameter_value</code> <p>number or array-like with shape of compartment geometry the value or values of the parameter</p> required Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def set_param(self, compartment, parameter_name, parameter_value):\n    \"\"\"\n    sets the specified parameter of the specified compartment\n\n    args:\n        compartment: str\n            name of model compartment\n        parameter_name: str\n            name of parameter of the compartment\n        parameter_value: number or array-like with shape of compartment geometry\n            the value or values of the parameter\n    \"\"\"\n    ### cach if model is not created, only if created populations and projections are available\n    assert (\n        self.initialized_models[self.name] == True\n    ), f\"ERROR set_param: model {self.name} has to be created before setting parameters!\"\n\n    ### check if compartment is in populations or projections\n    comp_in_pop = compartment in self.populations\n    comp_in_proj = compartment in self.projections\n\n    if comp_in_pop:\n        comp_obj = get_population(compartment)\n    elif comp_in_proj:\n        comp_obj = get_projection(compartment)\n    else:\n        assert (\n            comp_in_pop or comp_in_proj\n        ), f\"ERROR set_param: setting parameter {parameter_name} of compartment {compartment}. The compartment is neither a population nor a projection of the model {self.name}!\"\n\n    ### set the parameter value\n    setattr(comp_obj, parameter_name, parameter_value)\n\n    ### update the model attribute_df\n    self._update_attribute_df(compartment, parameter_name, parameter_value)\n</code></pre>"},{"location":"main/generate_simulations/","title":"Generate Simulations","text":""},{"location":"main/generate_simulations/#src.CompNeuroPy.generate_simulation.CompNeuroSim","title":"<code>src.CompNeuroPy.generate_simulation.CompNeuroSim</code>","text":"<p>Class for generating a CompNeuroPy simulation.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>class CompNeuroSim:\n    \"\"\"\n    Class for generating a CompNeuroPy simulation.\n    \"\"\"\n\n    initialized_simulations = []\n\n    def __init__(\n        self,\n        simulation_function,\n        simulation_kwargs=None,\n        name=\"simulation\",\n        description=\"\",\n        requirements=None,\n        kwargs_warning=True,\n        monitor_object=None,\n    ):\n        \"\"\"\n        Args:\n            simulation_function (function):\n                Function which runs the simulation.\n            simulation_kwargs (dict, optional):\n                Dictionary of arguments for the simulation_function. Default: None.\n            name (str, optional):\n                Name of the simulation. Default: \"simulation\".\n            description (str, optional):\n                Description of the simulation. Default: \"\".\n            requirements (list, optional):\n                List of requirements for the simulation. Default: None.\n            kwargs_warning (bool, optional):\n                If True, a warning is printed if the simulation_kwargs are changed\n                during the simulation. Default: True.\n            monitor_object (CompNeuroMonitors object, optional):\n                CompNeuroMonitors object to automatically track the recording chunk for each\n                simulation run. Default: None.\n        \"\"\"\n        # set simulaiton function\n        self.name = name\n        if name == \"simulation\":\n            self.name = name + str(self._nr_simulations())\n        self.initialized_simulations.append(self.name)\n        self.description = description\n        self.simulation_function = simulation_function\n        self.simulation_kwargs = simulation_kwargs\n        if requirements is None:\n            self.requirements = []\n        else:\n            self.requirements = requirements\n        self.start = []\n        self.end = []\n        self.info = []\n        self.kwargs = []\n        if kwargs_warning:\n            self.warned = False\n        else:\n            self.warned = True\n        self.monitor_object = monitor_object\n        if monitor_object is not None:\n            self.monitor_chunk = []\n        else:\n            self.monitor_chunk = None\n\n        ### test initial requirements\n        self._test_req(simulation_kwargs=simulation_kwargs)\n\n    def run(self, simulation_kwargs=None):\n        \"\"\"\n        Runs the simulation function. With each run extend start, end list containing\n        start and end time of the corresponding run and the info list containing the\n        return value of the simulation function.\n\n        Args:\n            simulation_kwargs (dict, optional):\n                Temporary simulation kwargs which override the initialized simulation\n                kwargs. Default: None, i.e., use values from initialization.\n        \"\"\"\n\n        ### define the current simulation kwargs\n        if simulation_kwargs is not None:\n            if self.simulation_kwargs is not None:\n                ### not replace initialized kwargs completely but only the kwargs which are given\n                tmp_kwargs = self.simulation_kwargs.copy()\n                for key, val in simulation_kwargs.items():\n                    tmp_kwargs[key] = val\n            else:\n                ### there are no initial kwargs --&gt; only use the kwargs which are given\n                tmp_kwargs = simulation_kwargs\n            if not (self.warned) and len(self.requirements) &gt; 0:\n                print(\n                    \"\\nWARNING! run\",\n                    self.name,\n                    \"changed simulation kwargs, initial requirements may no longer be fulfilled!\\n\",\n                )\n                self.warned = True\n        else:\n            tmp_kwargs = self.simulation_kwargs\n\n        ### before each run, test requirements\n        self._test_req(simulation_kwargs=tmp_kwargs)\n\n        ### and append current simulation kwargs to the kwargs variable\n        self.kwargs.append(tmp_kwargs)\n\n        ### and append the current chunk of the monitors object to the chunk variable\n        if self.monitor_object is not None:\n            self.monitor_chunk.append(self.monitor_object.current_chunk())\n\n        ### run the simulation, store start and end simulation time\n        self.start.append(get_time())\n        if tmp_kwargs is not None:\n            self.info.append(self.simulation_function(**tmp_kwargs))\n        else:\n            self.info.append(self.simulation_function())\n        self.end.append(get_time())\n\n    def _nr_simulations(self):\n        \"\"\"\n        Returns the current number of initialized CompNeuroPy simulations.\n        \"\"\"\n        return len(self.initialized_simulations)\n\n    def _test_req(self, simulation_kwargs=None):\n        \"\"\"\n        Tests the initialized requirements with the current simulation_kwargs.\n        \"\"\"\n\n        if simulation_kwargs is None:  # --&gt; use the initial simulation_kwargs\n            simulation_kwargs = self.simulation_kwargs\n\n        for req in self.requirements:\n            if len(list(req.keys())) &gt; 1:  # --&gt; requirement and arguments\n                req_kwargs = ef.remove_key(req, \"req\")\n                ### check if req_kwargs reference to sim_kwargs, if yes, use the corresponding current sim_kwarg as req_kwarg, if not do not update the initialized requirements kwargs\n                for key, val in req_kwargs.items():\n                    if isinstance(val, str):\n                        val_split = val.split(\".\")\n                        if val_split[0] == \"simulation_kwargs\":\n                            if len(val_split) == 1:\n                                ### val is only simulation_kwargs\n                                req_kwargs = simulation_kwargs\n                            elif len(val_split) == 2:\n                                ### val is simulation_kwargs.something\n                                req_kwargs[key] = simulation_kwargs[val_split[1]]\n                            else:\n                                ### val is simulation_kwargs.something.something... e.g. key='pops' and val= 'simulation_kwargs.model.populations'\n                                req_kwargs[key] = eval(\n                                    'simulation_kwargs[\"'\n                                    + val_split[1]\n                                    + '\"].'\n                                    + \".\".join(val_split[2:])\n                                )\n\n                req[\"req\"](**req_kwargs).run()\n\n            else:  # --&gt; only requirement\n                req[\"req\"]().run()\n\n    def get_current_arr(self, dt, flat=False):\n        \"\"\"\n        Method exclusively for current_step simulation functions. Gets the current array\n        (input current value for each time step) of all runs.\n\n        !!! warning\n            This method will be removed soon. Use the get_current_arr method of the\n            SimInfo class instead.\n\n        Args:\n            dt (float):\n                Time step size of the simulation.\n            flat (bool, optional):\n                If True, returns a flattened array. Assumes that all runs are run\n                consecutively without brakes. Default: False, i.e., returns a list of\n                arrays.\n\n        Returns:\n            current_arr (list of arrays):\n                List of arrays containing the current values for each time step of each\n                run. If flat=True, returns a flattened array.\n        \"\"\"\n        assert (\n            self.simulation_function.__name__ == \"current_step\"\n        ), 'ERROR get_current_arr: Simulation has to be \"current_step\"!'\n        ### TODO: remove because deprecated\n        print(\n            \"WARNING get_current_arr function will only be available in SimInfo soon.\"\n        )\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t1 = self.kwargs[run][\"t1\"]\n            t2 = self.kwargs[run][\"t2\"]\n            a1 = self.kwargs[run][\"a1\"]\n            a2 = self.kwargs[run][\"a2\"]\n\n            if t1 &gt; 0 and t2 &gt; 0:\n                current_arr.append(\n                    np.concatenate(\n                        [\n                            np.ones(int(round(t1 / dt))) * a1,\n                            np.ones(int(round(t2 / dt))) * a2,\n                        ]\n                    )\n                )\n            elif t2 &gt; 0:\n                current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n            else:\n                current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    def simulation_info(self):\n        \"\"\"\n        Returns a SimInfo object containing the simulation information.\n\n        Returns:\n            simulation_info_obj (SimInfo):\n                Simulation information object.\n        \"\"\"\n\n        simulation_info_obj = SimInfo(\n            self.name,\n            self.description,\n            self.simulation_function.__name__,\n            self.start,\n            self.end,\n            self.info,\n            self.kwargs,\n            self.monitor_chunk,\n        )\n\n        return simulation_info_obj\n</code></pre>"},{"location":"main/generate_simulations/#src.CompNeuroPy.generate_simulation.CompNeuroSim.__init__","title":"<code>__init__(simulation_function, simulation_kwargs=None, name='simulation', description='', requirements=None, kwargs_warning=True, monitor_object=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>simulation_function</code> <code>function</code> <p>Function which runs the simulation.</p> required <code>simulation_kwargs</code> <code>dict</code> <p>Dictionary of arguments for the simulation_function. Default: None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the simulation. Default: \"simulation\".</p> <code>'simulation'</code> <code>description</code> <code>str</code> <p>Description of the simulation. Default: \"\".</p> <code>''</code> <code>requirements</code> <code>list</code> <p>List of requirements for the simulation. Default: None.</p> <code>None</code> <code>kwargs_warning</code> <code>bool</code> <p>If True, a warning is printed if the simulation_kwargs are changed during the simulation. Default: True.</p> <code>True</code> <code>monitor_object</code> <code>CompNeuroMonitors object</code> <p>CompNeuroMonitors object to automatically track the recording chunk for each simulation run. Default: None.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def __init__(\n    self,\n    simulation_function,\n    simulation_kwargs=None,\n    name=\"simulation\",\n    description=\"\",\n    requirements=None,\n    kwargs_warning=True,\n    monitor_object=None,\n):\n    \"\"\"\n    Args:\n        simulation_function (function):\n            Function which runs the simulation.\n        simulation_kwargs (dict, optional):\n            Dictionary of arguments for the simulation_function. Default: None.\n        name (str, optional):\n            Name of the simulation. Default: \"simulation\".\n        description (str, optional):\n            Description of the simulation. Default: \"\".\n        requirements (list, optional):\n            List of requirements for the simulation. Default: None.\n        kwargs_warning (bool, optional):\n            If True, a warning is printed if the simulation_kwargs are changed\n            during the simulation. Default: True.\n        monitor_object (CompNeuroMonitors object, optional):\n            CompNeuroMonitors object to automatically track the recording chunk for each\n            simulation run. Default: None.\n    \"\"\"\n    # set simulaiton function\n    self.name = name\n    if name == \"simulation\":\n        self.name = name + str(self._nr_simulations())\n    self.initialized_simulations.append(self.name)\n    self.description = description\n    self.simulation_function = simulation_function\n    self.simulation_kwargs = simulation_kwargs\n    if requirements is None:\n        self.requirements = []\n    else:\n        self.requirements = requirements\n    self.start = []\n    self.end = []\n    self.info = []\n    self.kwargs = []\n    if kwargs_warning:\n        self.warned = False\n    else:\n        self.warned = True\n    self.monitor_object = monitor_object\n    if monitor_object is not None:\n        self.monitor_chunk = []\n    else:\n        self.monitor_chunk = None\n\n    ### test initial requirements\n    self._test_req(simulation_kwargs=simulation_kwargs)\n</code></pre>"},{"location":"main/generate_simulations/#src.CompNeuroPy.generate_simulation.CompNeuroSim.run","title":"<code>run(simulation_kwargs=None)</code>","text":"<p>Runs the simulation function. With each run extend start, end list containing start and end time of the corresponding run and the info list containing the return value of the simulation function.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_kwargs</code> <code>dict</code> <p>Temporary simulation kwargs which override the initialized simulation kwargs. Default: None, i.e., use values from initialization.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def run(self, simulation_kwargs=None):\n    \"\"\"\n    Runs the simulation function. With each run extend start, end list containing\n    start and end time of the corresponding run and the info list containing the\n    return value of the simulation function.\n\n    Args:\n        simulation_kwargs (dict, optional):\n            Temporary simulation kwargs which override the initialized simulation\n            kwargs. Default: None, i.e., use values from initialization.\n    \"\"\"\n\n    ### define the current simulation kwargs\n    if simulation_kwargs is not None:\n        if self.simulation_kwargs is not None:\n            ### not replace initialized kwargs completely but only the kwargs which are given\n            tmp_kwargs = self.simulation_kwargs.copy()\n            for key, val in simulation_kwargs.items():\n                tmp_kwargs[key] = val\n        else:\n            ### there are no initial kwargs --&gt; only use the kwargs which are given\n            tmp_kwargs = simulation_kwargs\n        if not (self.warned) and len(self.requirements) &gt; 0:\n            print(\n                \"\\nWARNING! run\",\n                self.name,\n                \"changed simulation kwargs, initial requirements may no longer be fulfilled!\\n\",\n            )\n            self.warned = True\n    else:\n        tmp_kwargs = self.simulation_kwargs\n\n    ### before each run, test requirements\n    self._test_req(simulation_kwargs=tmp_kwargs)\n\n    ### and append current simulation kwargs to the kwargs variable\n    self.kwargs.append(tmp_kwargs)\n\n    ### and append the current chunk of the monitors object to the chunk variable\n    if self.monitor_object is not None:\n        self.monitor_chunk.append(self.monitor_object.current_chunk())\n\n    ### run the simulation, store start and end simulation time\n    self.start.append(get_time())\n    if tmp_kwargs is not None:\n        self.info.append(self.simulation_function(**tmp_kwargs))\n    else:\n        self.info.append(self.simulation_function())\n    self.end.append(get_time())\n</code></pre>"},{"location":"main/generate_simulations/#src.CompNeuroPy.generate_simulation.CompNeuroSim.get_current_arr","title":"<code>get_current_arr(dt, flat=False)</code>","text":"<p>Method exclusively for current_step simulation functions. Gets the current array (input current value for each time step) of all runs.</p> <p>Warning</p> <p>This method will be removed soon. Use the get_current_arr method of the SimInfo class instead.</p> <p>Parameters:</p> Name Type Description Default <code>dt</code> <code>float</code> <p>Time step size of the simulation.</p> required <code>flat</code> <code>bool</code> <p>If True, returns a flattened array. Assumes that all runs are run consecutively without brakes. Default: False, i.e., returns a list of arrays.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>current_arr</code> <code>list of arrays</code> <p>List of arrays containing the current values for each time step of each run. If flat=True, returns a flattened array.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def get_current_arr(self, dt, flat=False):\n    \"\"\"\n    Method exclusively for current_step simulation functions. Gets the current array\n    (input current value for each time step) of all runs.\n\n    !!! warning\n        This method will be removed soon. Use the get_current_arr method of the\n        SimInfo class instead.\n\n    Args:\n        dt (float):\n            Time step size of the simulation.\n        flat (bool, optional):\n            If True, returns a flattened array. Assumes that all runs are run\n            consecutively without brakes. Default: False, i.e., returns a list of\n            arrays.\n\n    Returns:\n        current_arr (list of arrays):\n            List of arrays containing the current values for each time step of each\n            run. If flat=True, returns a flattened array.\n    \"\"\"\n    assert (\n        self.simulation_function.__name__ == \"current_step\"\n    ), 'ERROR get_current_arr: Simulation has to be \"current_step\"!'\n    ### TODO: remove because deprecated\n    print(\n        \"WARNING get_current_arr function will only be available in SimInfo soon.\"\n    )\n    current_arr = []\n    for run in range(len(self.kwargs)):\n        t1 = self.kwargs[run][\"t1\"]\n        t2 = self.kwargs[run][\"t2\"]\n        a1 = self.kwargs[run][\"a1\"]\n        a2 = self.kwargs[run][\"a2\"]\n\n        if t1 &gt; 0 and t2 &gt; 0:\n            current_arr.append(\n                np.concatenate(\n                    [\n                        np.ones(int(round(t1 / dt))) * a1,\n                        np.ones(int(round(t2 / dt))) * a2,\n                    ]\n                )\n            )\n        elif t2 &gt; 0:\n            current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n        else:\n            current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n    if flat:\n        return np.concatenate(current_arr)\n    else:\n        return current_arr\n</code></pre>"},{"location":"main/generate_simulations/#src.CompNeuroPy.generate_simulation.CompNeuroSim.simulation_info","title":"<code>simulation_info()</code>","text":"<p>Returns a SimInfo object containing the simulation information.</p> <p>Returns:</p> Name Type Description <code>simulation_info_obj</code> <code>SimInfo</code> <p>Simulation information object.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def simulation_info(self):\n    \"\"\"\n    Returns a SimInfo object containing the simulation information.\n\n    Returns:\n        simulation_info_obj (SimInfo):\n            Simulation information object.\n    \"\"\"\n\n    simulation_info_obj = SimInfo(\n        self.name,\n        self.description,\n        self.simulation_function.__name__,\n        self.start,\n        self.end,\n        self.info,\n        self.kwargs,\n        self.monitor_chunk,\n    )\n\n    return simulation_info_obj\n</code></pre>"},{"location":"main/generate_simulations/#src.CompNeuroPy.generate_simulation.SimInfo","title":"<code>src.CompNeuroPy.generate_simulation.SimInfo</code>","text":"<p>Class for storing the simulation information.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the simulation.</p> <code>description</code> <code>str</code> <p>Description of the simulation.</p> <code>simulation_function</code> <code>str</code> <p>Name of the simulation function.</p> <code>start</code> <code>list</code> <p>List of start times of the simulation runs.</p> <code>end</code> <code>list</code> <p>List of end times of the simulation runs.</p> <code>info</code> <code>list</code> <p>List of return values of the simulation function of each simulation run.</p> <code>kwargs</code> <code>list</code> <p>List of simulation kwargs of the simulation function of each simulation run.</p> <code>monitor_chunk</code> <code>list</code> <p>List of recording chunks of the used CompNeuroMonitors object of each simulation run.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>class SimInfo:\n    \"\"\"\n    Class for storing the simulation information.\n\n    Attributes:\n        name (str):\n            Name of the simulation.\n        description (str):\n            Description of the simulation.\n        simulation_function (str):\n            Name of the simulation function.\n        start (list):\n            List of start times of the simulation runs.\n        end (list):\n            List of end times of the simulation runs.\n        info (list):\n            List of return values of the simulation function of each simulation run.\n        kwargs (list):\n            List of simulation kwargs of the simulation function of each simulation run.\n        monitor_chunk (list):\n            List of recording chunks of the used CompNeuroMonitors object of each simulation run.\n    \"\"\"\n\n    def __init__(\n        self,\n        name,\n        description,\n        simulation_function,\n        start,\n        end,\n        info,\n        kwargs,\n        monitor_chunk,\n    ):\n        \"\"\"\n        Initialization of the simulation information object.\n\n        Args:\n            name (str):\n                Name of the simulation.\n            description (str):\n                Description of the simulation.\n            simulation_function (str):\n                Name of the simulation function.\n            start (list):\n                List of start times of the simulation runs.\n            end (list):\n                List of end times of the simulation runs.\n            info (list):\n                List of return values of the simulation function of each simulation run.\n            kwargs (list):\n                List of simulation kwargs of the simulation function of each simulation\n                run.\n            monitor_chunk (list):\n                List of recording chunks of the used CompNeuroMonitors object of each simulation\n                run.\n        \"\"\"\n        self.name = name\n        self.description = description\n        self.simulation_function = simulation_function\n        self.start = start\n        self.end = end\n        self.info = info\n        self.kwargs = kwargs\n        self.monitor_chunk = monitor_chunk\n\n    def get_current_arr(self, dt, flat=False):\n        \"\"\"\n        Method exclusively for the following simulation functions (built-in\n        CompNeuroPy):\n            - current_step\n            - current_stim\n            - current_ramp\n        Gets the current array (input current value for each time step) of all runs.\n\n        Args:\n            dt (float):\n                Time step size of the simulation.\n            flat (bool, optional):\n                If True, returns a flattened array. Assumes that all runs are run\n                consecutively without brakes. Default: False, i.e., returns a list of\n                arrays.\n\n        Returns:\n            current_arr (list of arrays):\n                List of arrays containing the current values for each time step of each\n                run. If flat=True, returns a flattened array.\n        \"\"\"\n        assert (\n            self.simulation_function == \"current_step\"\n            or self.simulation_function == \"current_stim\"\n            or self.simulation_function == \"current_ramp\"\n        ), 'ERROR get_current_arr: Simulation has to be \"current_step\", \"current_stim\" or \"current_ramp\"!'\n\n        if self.simulation_function == \"current_step\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                t1 = self.kwargs[run][\"t1\"]\n                t2 = self.kwargs[run][\"t2\"]\n                a1 = self.kwargs[run][\"a1\"]\n                a2 = self.kwargs[run][\"a2\"]\n\n                if t1 &gt; 0 and t2 &gt; 0:\n                    current_arr.append(\n                        np.concatenate(\n                            [\n                                np.ones(int(round(t1 / dt))) * a1,\n                                np.ones(int(round(t2 / dt))) * a2,\n                            ]\n                        )\n                    )\n                elif t2 &gt; 0:\n                    current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n                else:\n                    current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n\n        elif self.simulation_function == \"current_stim\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                t = self.kwargs[run][\"t\"]\n                a = self.kwargs[run][\"a\"]\n\n                if t &gt; 0:\n                    current_arr.append(np.ones(int(round(t / dt))) * a)\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n\n        elif self.simulation_function == \"current_ramp\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                amp = self.kwargs[run][\"a0\"]\n                current_arr_ramp = []\n                for stim_idx in range(self.kwargs[run][\"n\"]):\n                    t = self.info[run][\"dur_stim\"]\n                    a = amp\n                    current_arr_ramp.append(np.ones(int(round(t / dt))) * a)\n                    amp = amp + self.info[run][\"da\"]\n                current_arr.append(list(np.concatenate(current_arr_ramp)))\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n</code></pre>"},{"location":"main/generate_simulations/#src.CompNeuroPy.generate_simulation.SimInfo.__init__","title":"<code>__init__(name, description, simulation_function, start, end, info, kwargs, monitor_chunk)</code>","text":"<p>Initialization of the simulation information object.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the simulation.</p> required <code>description</code> <code>str</code> <p>Description of the simulation.</p> required <code>simulation_function</code> <code>str</code> <p>Name of the simulation function.</p> required <code>start</code> <code>list</code> <p>List of start times of the simulation runs.</p> required <code>end</code> <code>list</code> <p>List of end times of the simulation runs.</p> required <code>info</code> <code>list</code> <p>List of return values of the simulation function of each simulation run.</p> required <code>kwargs</code> <code>list</code> <p>List of simulation kwargs of the simulation function of each simulation run.</p> required <code>monitor_chunk</code> <code>list</code> <p>List of recording chunks of the used CompNeuroMonitors object of each simulation run.</p> required Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def __init__(\n    self,\n    name,\n    description,\n    simulation_function,\n    start,\n    end,\n    info,\n    kwargs,\n    monitor_chunk,\n):\n    \"\"\"\n    Initialization of the simulation information object.\n\n    Args:\n        name (str):\n            Name of the simulation.\n        description (str):\n            Description of the simulation.\n        simulation_function (str):\n            Name of the simulation function.\n        start (list):\n            List of start times of the simulation runs.\n        end (list):\n            List of end times of the simulation runs.\n        info (list):\n            List of return values of the simulation function of each simulation run.\n        kwargs (list):\n            List of simulation kwargs of the simulation function of each simulation\n            run.\n        monitor_chunk (list):\n            List of recording chunks of the used CompNeuroMonitors object of each simulation\n            run.\n    \"\"\"\n    self.name = name\n    self.description = description\n    self.simulation_function = simulation_function\n    self.start = start\n    self.end = end\n    self.info = info\n    self.kwargs = kwargs\n    self.monitor_chunk = monitor_chunk\n</code></pre>"},{"location":"main/generate_simulations/#src.CompNeuroPy.generate_simulation.SimInfo.get_current_arr","title":"<code>get_current_arr(dt, flat=False)</code>","text":"<p>Method exclusively for the following simulation functions (built-in CompNeuroPy):     - current_step     - current_stim     - current_ramp Gets the current array (input current value for each time step) of all runs.</p> <p>Parameters:</p> Name Type Description Default <code>dt</code> <code>float</code> <p>Time step size of the simulation.</p> required <code>flat</code> <code>bool</code> <p>If True, returns a flattened array. Assumes that all runs are run consecutively without brakes. Default: False, i.e., returns a list of arrays.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>current_arr</code> <code>list of arrays</code> <p>List of arrays containing the current values for each time step of each run. If flat=True, returns a flattened array.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def get_current_arr(self, dt, flat=False):\n    \"\"\"\n    Method exclusively for the following simulation functions (built-in\n    CompNeuroPy):\n        - current_step\n        - current_stim\n        - current_ramp\n    Gets the current array (input current value for each time step) of all runs.\n\n    Args:\n        dt (float):\n            Time step size of the simulation.\n        flat (bool, optional):\n            If True, returns a flattened array. Assumes that all runs are run\n            consecutively without brakes. Default: False, i.e., returns a list of\n            arrays.\n\n    Returns:\n        current_arr (list of arrays):\n            List of arrays containing the current values for each time step of each\n            run. If flat=True, returns a flattened array.\n    \"\"\"\n    assert (\n        self.simulation_function == \"current_step\"\n        or self.simulation_function == \"current_stim\"\n        or self.simulation_function == \"current_ramp\"\n    ), 'ERROR get_current_arr: Simulation has to be \"current_step\", \"current_stim\" or \"current_ramp\"!'\n\n    if self.simulation_function == \"current_step\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t1 = self.kwargs[run][\"t1\"]\n            t2 = self.kwargs[run][\"t2\"]\n            a1 = self.kwargs[run][\"a1\"]\n            a2 = self.kwargs[run][\"a2\"]\n\n            if t1 &gt; 0 and t2 &gt; 0:\n                current_arr.append(\n                    np.concatenate(\n                        [\n                            np.ones(int(round(t1 / dt))) * a1,\n                            np.ones(int(round(t2 / dt))) * a2,\n                        ]\n                    )\n                )\n            elif t2 &gt; 0:\n                current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n            else:\n                current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    elif self.simulation_function == \"current_stim\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t = self.kwargs[run][\"t\"]\n            a = self.kwargs[run][\"a\"]\n\n            if t &gt; 0:\n                current_arr.append(np.ones(int(round(t / dt))) * a)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    elif self.simulation_function == \"current_ramp\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            amp = self.kwargs[run][\"a0\"]\n            current_arr_ramp = []\n            for stim_idx in range(self.kwargs[run][\"n\"]):\n                t = self.info[run][\"dur_stim\"]\n                a = amp\n                current_arr_ramp.append(np.ones(int(round(t / dt))) * a)\n                amp = amp + self.info[run][\"da\"]\n            current_arr.append(list(np.concatenate(current_arr_ramp)))\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n</code></pre>"},{"location":"main/monitors_recordings/","title":"Monitors / Recordings","text":""},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors","title":"<code>src.CompNeuroPy.monitors.CompNeuroMonitors</code>","text":"<p>Class to bring together ANNarchy monitors into one object.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>class CompNeuroMonitors:\n    \"\"\"\n    Class to bring together ANNarchy monitors into one object.\n    \"\"\"\n\n    def __init__(self, mon_dict={}):\n        \"\"\"\n        Initialize CompNeuroMonitors object by creating ANNarchy monitors.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"pop;pop_name\" for populations and key=\"proj;proj_name\"\n                for projections and val=list with variables to record.\n        \"\"\"\n        self.mon = self._add_monitors(mon_dict)\n        self.mon_dict = mon_dict\n        self._init_internals()\n\n    def _init_internals(self):\n        \"\"\"\n        Initialize the following internal variables:\n            - timings (dict):\n                dict with key=\"pop_name\" for populations and \"proj_name\" for projections\n                for each recorded population and projection and\n                val={\"currently_paused\": True, \"start\": [], \"stop\": []}\n            - recordings (list):\n                list with recordings of all chunks. Set to empty list.\n            - recording_times (list):\n                list with recording times of all chunks. Set to empty list.\n            - already_got_recordings (bool):\n                True if recordings were already requested, False otherwise. Set to\n                False.\n            - already_got_recording_times (bool):\n                True if recording_times were already requested, False otherwise. Set to\n                False.\n            - get_recordings_reset_call (bool):\n                True if get_recordings() and get_recording_times() are called within\n                reset(), False otherwise. Set to False.\n        \"\"\"\n        timings = {}\n        for key, val in self.mon_dict.items():\n            _, compartment, _ = self._unpack_mon_dict_keys(key)\n            timings[compartment] = {\"currently_paused\": True, \"start\": [], \"stop\": []}\n        self.timings = timings\n\n        self.recordings = []\n        self.recording_times = []\n        self.already_got_recordings = False\n        self.already_got_recording_times = False\n        self.get_recordings_reset_call = False\n\n    def start(self, compartment_list=None):\n        \"\"\"\n        Start or resume recording of all recorded compartments in compartment_list.\n\n        Args:\n            compartment_list (list, optional):\n                List with compartment names to start or resume recording. Default: None,\n                i.e., all compartments of initialized mon_dict are started or resumed.\n        \"\"\"\n        if compartment_list == None:\n            mon_dict_key_list = list(self.mon_dict.keys())\n            compartment_list = [\n                self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n            ]\n\n        self.timings = self._start_monitors(compartment_list, self.mon, self.timings)\n\n    def pause(self, compartment_list=None):\n        \"\"\"\n        Pause recording of all recorded compartments in compartment_list.\n\n        Args:\n            compartment_list (list, optional):\n                List with compartment names to pause recording. Default: None,\n                i.e., all compartments of initialized mon_dict are paused.\n        \"\"\"\n        if compartment_list == None:\n            mon_dict_key_list = list(self.mon_dict.keys())\n            compartment_list = [\n                self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n            ]\n\n        self.timings = self._pause_monitors(compartment_list, self.mon, self.timings)\n\n    def reset(\n        self,\n        populations=True,\n        projections=False,\n        synapses=False,\n        monitors=True,\n        model=True,\n        net_id=0,\n    ):\n        \"\"\"\n        Create a new recording chunk by getting recordings and recording times of the\n        current chunk and optionally resetting the model. Recordings are automatically\n        resumed in the new chunk if they are not paused.\n\n        Args:\n            populations (bool, optional):\n                If True, reset populations. Default: True.\n            projections (bool, optional):\n                If True, reset projections. Default: False.\n            synapses (bool, optional):\n                If True, reset synapses. Default: False.\n            monitors (bool, optional):\n                If True, reset ANNarchy monitors. Default: True.\n            model (bool, optional):\n                If True, reset model. Default: True.\n            net_id (int, optional):\n                Id of the network to reset. Default: 0.\n        \"\"\"\n        ### TODO rename this function to new_chunk() or something like that and let recordings and recording times be returned\n        self.get_recordings_reset_call = True\n        self.get_recordings()\n        self.get_recording_times()\n        self.get_recordings_reset_call = False\n        self.already_got_recordings = (\n            False  # after reset one can still update recordings\n        )\n        self.already_got_recording_times = (\n            False  # after reset one can still update recording_times\n        )\n        ### reset timings, after reset, add a zero to start if the monitor is still running (this is not resetted by reset())\n        ### if the model was not resetted --&gt; do add current time instead of zero\n        for key in self.timings.keys():\n            self.timings[key][\"start\"] = []\n            self.timings[key][\"stop\"] = []\n            if self.timings[key][\"currently_paused\"] == False:\n                if model:\n                    self.timings[key][\"start\"].append(0)\n                else:\n                    self.timings[key][\"start\"].append(\n                        np.round(get_time(), af.get_number_of_decimals(dt()))\n                    )\n\n        if model:\n            reset(populations, projections, synapses, monitors, net_id=net_id)\n\n    def current_chunk(self):\n        \"\"\"\n        Get the index of the current chunk.\n\n        Returns:\n            current_chunk_idx (int):\n                Index of the current chunk. If no recordings are currently active,\n                returns None.\n        \"\"\"\n        ### if recordings are currently active --&gt; return chunk in which these recordings will be saved\n        ### check if there are currently active recordings\n        active_recordings = False\n        for key, val in self.mon_dict.items():\n            _, compartment, _ = self._unpack_mon_dict_keys(key)\n            if not (self.timings[compartment][\"currently_paused\"]):\n                ### tere are currently active recordings\n                active_recordings = True\n\n        if active_recordings:\n            current_chunk_idx = len(self.recordings)\n            return current_chunk_idx\n        else:\n            ### if currently no recordings are active return None\n            return None\n\n    def get_recordings(self):\n        \"\"\"\n        Get recordings of all recorded compartments.\n\n        Returns:\n            recordings (list):\n                List with recordings of all chunks.\n        \"\"\"\n        ### only if recordings in current chunk and get_recodings was not already called add current chunk to recordings\n        if (\n            self._any_recordings_in_current_chunk()\n            and self.already_got_recordings is False\n        ):\n            ### update recordings\n            self.recordings.append(self._get_monitors(self.mon_dict, self.mon))\n            ### upade already_got_recordings --&gt; it will not update recordings again\n            self.already_got_recordings = True\n\n            if not (self.get_recordings_reset_call):\n                if len(self.recordings) == 0:\n                    print(\n                        \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                    )\n            return self.recordings\n        else:\n            if not (self.get_recordings_reset_call):\n                if len(self.recordings) == 0:\n                    print(\n                        \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                    )\n            return self.recordings\n\n    def get_recording_times(self):\n        \"\"\"\n        Get recording times of all recorded compartments.\n\n        Returns:\n            recording_times (recording_times_cl):\n                Object with recording times of all chunks.\n        \"\"\"\n\n        temp_timings = self._get_temp_timings()\n\n        ### only append temp_timings of current chunk if there are recordings in current chunk at all and if get_recordings was not already called (double call would add the same chunk again)\n        if (\n            self._any_recordings_in_current_chunk()\n            and self.already_got_recording_times is False\n        ):\n            self.recording_times.append(temp_timings)\n\n        ### upade already_got_recording_times --&gt; it will not update recording_times again\n        self.already_got_recording_times = True\n\n        ### generate a object from recording_times and return this instead of the dict\n        recording_times_ob = RecordingTimes(self.recording_times)\n\n        if not (self.get_recordings_reset_call):\n            if len(self.recording_times) == 0:\n                print(\n                    \"WARNING get_recording_times: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return recording_times_ob\n\n    def get_recordings_and_clear(self):\n        \"\"\"\n        The default get_recordings method should be called at the end of the simulation.\n        The get_recordings_and_clear method allows to get several times recordings with\n        the same monitor object and to simulate between the calls. Sets the internal\n        variables back to their initial state. Usefull if you repeat a simulation +\n        recording several times and you do not want to always create new chunks.\n\n        !!! warning\n            If you want to continue recording after calling this method, you have to\n            call start() again.\n\n        Returns:\n            recordings (list):\n                List with recordings of all chunks.\n            recording_times (recording_times_cl):\n                Object with recording times of all chunks.\n        \"\"\"\n        ret0 = self.get_recordings()\n        ret1 = self.get_recording_times()\n        self._init_internals()\n        ret = (ret0, ret1)\n        return ret\n\n    def _correct_start_stop(self, start_time_arr, stop_time_arr, period):\n        \"\"\"\n        Corrects the start and stop times of recordings to the actual start and stop\n        times of recorded values.\n\n        Args:\n            start_time_arr (np.array):\n                Array with start times of recordings, obtained with get_time() function\n                of ANNarchy.\n            stop_time_arr (np.array):\n                Array with stop times of recordings, obtained with get_time() function\n                of ANNarchy.\n            period (float):\n                Time difference between recording values specified by the user.\n\n        Returns:\n            actual_start_time (np.array):\n                Array with actual start times of recorded values.\n            actual_stop_time (np.array):\n                Array with actual stop times of recorded values.\n            nr_rec_vals (np.array):\n                Array with number of recorded values between start and stop.\n        \"\"\"\n        # actual_period = int(period / dt()) * dt()\n        actual_start_time = np.ceil(start_time_arr / period) * period\n\n        actual_stop_time = np.ceil(stop_time_arr / period - 1) * period\n\n        nr_rec_vals = 1 + (actual_stop_time - actual_start_time) / period\n\n        return (actual_start_time, actual_stop_time, nr_rec_vals)\n\n    def _get_temp_timings(self):\n        \"\"\"\n        Generates a timings dictionary with time lims and idx lims for each compartment.\n        Calculates the idx lims of the recordings based on the time lims.\n\n        Returns:\n            temp_timings (dict):\n                Dict with time lims and idx lims for each compartment.\n        \"\"\"\n        temp_timings = {}\n        for key in self.mon_dict.keys():\n            _, compartment, period = self._unpack_mon_dict_keys(key)\n            if len(self.timings[compartment][\"start\"]) &gt; len(\n                self.timings[compartment][\"stop\"]\n            ):\n                ### was started/resumed but never stoped after --&gt; use current time for stop time\n                self.timings[compartment][\"stop\"].append(get_time())\n            ### calculate the idx of the recorded arrays which correspond to the timings and remove 'currently_paused'\n            ### get for each start-stop pair the corrected start stop timings (when teh values were actually recorded, depends on period and timestep)\n            ### and also get the number of recorded values for start-stop pair\n            start_time_arr = np.array(self.timings[compartment][\"start\"])\n            stop_time_arr = np.array(self.timings[compartment][\"stop\"])\n            (\n                start_time_arr,\n                stop_time_arr,\n                nr_rec_vals_arr,\n            ) = self._correct_start_stop(start_time_arr, stop_time_arr, period)\n\n            ### with the number of recorded values -&gt; get start and end idx for each start-stop pair\n            start_idx = [\n                np.sum(nr_rec_vals_arr[0:i]).astype(int)\n                for i in range(nr_rec_vals_arr.size)\n            ]\n            stop_idx = [\n                np.sum(nr_rec_vals_arr[0 : i + 1]).astype(int) - 1\n                for i in range(nr_rec_vals_arr.size)\n            ]\n\n            ### return start-stop pair info in timings format\n            temp_timings[compartment] = {\n                \"start\": {\n                    \"ms\": np.round(\n                        start_time_arr, af.get_number_of_decimals(dt())\n                    ).tolist(),\n                    \"idx\": start_idx,\n                },\n                \"stop\": {\n                    \"ms\": np.round(\n                        stop_time_arr, af.get_number_of_decimals(dt())\n                    ).tolist(),\n                    \"idx\": stop_idx,\n                },\n            }\n        return temp_timings\n\n    def _any_recordings_in_current_chunk(self):\n        \"\"\"\n        Check if there are any recordings in the current chunk.\n\n        Returns:\n            any_recordings (bool):\n                True if there are any recordings in the current chunk, False otherwise.\n        \"\"\"\n        temp_timings = self._get_temp_timings()\n\n        ### generate a temp object of temp timings to check if there were recordings at all\n        recording_times_ob_temp = RecordingTimes([temp_timings])\n        return recording_times_ob_temp._any_recordings(chunk=0)\n\n    def _add_monitors(self, mon_dict: dict):\n        \"\"\"\n        Generate monitors defined by mon_dict.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"pop;pop_name\" for populations and key=\"proj;proj_name\"\n                for projections and val=list with variables to record.\n\n        Returns:\n            mon (dict):\n                dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n        \"\"\"\n        mon = {}\n        for key, val in mon_dict.items():\n            compartmentType, compartment, period = self._unpack_mon_dict_keys(key)\n            ### check if compartment is pop\n            if compartmentType == \"pop\":\n                mon[compartment] = Monitor(\n                    get_population(compartment), val, start=False, period=period\n                )\n            ### check if compartment is proj\n            if compartmentType == \"proj\":\n                mon[compartment] = Monitor(\n                    get_projection(compartment), val, start=False, period=period\n                )\n        return mon\n\n    def _start_monitors(self, compartment_list, mon, timings=None):\n        \"\"\"\n        Starts or resumes monitores defined by compartment_list.\n\n        Args:\n            compartment_list (list):\n                List with compartment names to start or resume recording.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n            timings (dict, optional):\n                timings variable of the CompNeuroMonitors object. Default: None.\n\n        Returns:\n            timings (dict):\n                timings variable of the CompNeuroMonitors object.\n        \"\"\"\n        ### for each compartment generate started variable (because compartments can ocure multiple times if multiple variables of them are recorded --&gt; do not start same monitor multiple times)\n        started = {}\n        for compartment_name in compartment_list:\n            started[compartment_name] = False\n\n        if timings == None:\n            ### information about pauses not available, just start\n            for compartment_name in compartment_list:\n                if started[compartment_name] == False:\n                    mon[compartment_name].start()\n                    print(\"start\", compartment_name)\n                    started[compartment_name] = True\n            return None\n        else:\n            ### information about pauses available, start if not paused, resume if paused\n            for compartment_name in compartment_list:\n                if started[compartment_name] == False:\n                    if timings[compartment_name][\"currently_paused\"]:\n                        if len(timings[compartment_name][\"start\"]) &gt; 0:\n                            ### resume\n                            mon[compartment_name].resume()\n                        else:\n                            ### initial start\n                            mon[compartment_name].start()\n                    started[compartment_name] = True\n                    ### update currently_paused\n                    timings[compartment_name][\"currently_paused\"] = False\n                    ### never make start longer than stop+1!... this can be caused if start is called multiple times without pause in between\n                    if len(timings[compartment_name][\"start\"]) &lt;= len(\n                        timings[compartment_name][\"stop\"]\n                    ):\n                        timings[compartment_name][\"start\"].append(get_time())\n            return timings\n\n    def _pause_monitors(self, compartment_list, mon, timings=None):\n        \"\"\"\n        Pause monitores defined by compartment_list.\n\n        Args:\n            compartment_list (list):\n                List with compartment names to pause recording.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n            timings (dict, optional):\n                timings variable of the CompNeuroMonitors object. Default: None.\n\n        Returns:\n            timings (dict):\n                timings variable of the CompNeuroMonitors object.\n        \"\"\"\n        ### for each compartment generate paused variable (because compartments can ocure multiple times if multiple variables of them are recorded --&gt; do not pause same monitor multiple times)\n        paused = {}\n        for compartment_name in compartment_list:\n            paused[compartment_name] = False\n\n        for compartment_name in compartment_list:\n            if paused[compartment_name] == False:\n                mon[compartment_name].pause()\n                paused[compartment_name] = True\n\n        if timings != None:\n            ### information about pauses is available, update it\n            for key, val in paused.items():\n                timings[key][\"currently_paused\"] = True\n                ### never make pause longer than start, this can be caused if pause is called multiple times without start in between\n                if len(timings[key][\"stop\"]) &lt; len(timings[key][\"start\"]):\n                    timings[key][\"stop\"].append(get_time())\n                ### if pause is directly called after start --&gt; start == stop --&gt; remove these entries, this is no actual period\n                if (\n                    len(timings[key][\"stop\"]) == len(timings[key][\"start\"])\n                    and timings[key][\"stop\"][-1] == timings[key][\"start\"][-1]\n                ):\n                    timings[key][\"stop\"] = timings[key][\"stop\"][:-1]\n                    timings[key][\"start\"] = timings[key][\"start\"][:-1]\n            return timings\n        else:\n            return None\n\n    def _get_monitors(self, mon_dict, mon):\n        \"\"\"\n        Get recorded values from ANNarchy monitors defined by mon_dict.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"pop;pop_name\" for populations and key=\"proj;proj_name\"\n                for projections and val=list with variables to record.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n\n        Returns:\n            recordings (dict):\n                Dict with key=\"compartment_name;variable\" and val=list with recorded\n                values.\n        \"\"\"\n        recordings = {}\n        for key, val in mon_dict.items():\n            compartment_type, compartment, period = self._unpack_mon_dict_keys(key)\n            recordings[f\"{compartment};period\"] = period\n            if compartment_type == \"pop\":\n                pop = get_population(compartment)\n                parameter_dict = {\n                    param_name: getattr(pop, param_name)\n                    for param_name in pop.parameters\n                }\n                recordings[f\"{compartment};parameter_dict\"] = parameter_dict\n            if compartment_type == \"proj\":\n                proj = get_projection(compartment)\n                parameter_dict = {\n                    param_name: getattr(proj, param_name)\n                    for param_name in proj.parameters\n                }\n                recordings[f\"{compartment};parameters\"] = parameter_dict\n            for val_val in val:\n                temp = mon[compartment].get(val_val)\n                recordings[f\"{compartment};{val_val}\"] = temp\n        recordings[\"dt\"] = dt()\n        return recordings\n\n    def _unpack_mon_dict_keys(self, s: str):\n        \"\"\"\n        Unpacks a string of the form \"compartment_type;compartment_name;period\" or\n        \"compartment_type;compartment_name\" into its components. If period is not provided\n        it is set to dt() for compartment_type 'pop' and dt()*1000 for compartment_type\n        'proj'.\n\n        Args:\n            s (str):\n                String to be unpacked\n\n        Returns:\n            compartment_type (str):\n                Compartment type\n            compartment_name (str):\n                Compartment name\n            period (float):\n                Period of the compartment\n        \"\"\"\n        splitted_s = s.split(\";\")\n        compartment_type = splitted_s[0]\n        if not (compartment_type in [\"pop\", \"proj\"]):\n            print(\n                f\"wrong compartment type in {compartment_type}\\nhas to be 'pop' or 'proj'\"\n            )\n            quit()\n        compartment_name = splitted_s[1]\n        if len(splitted_s) == 3:\n            period = float(splitted_s[2])\n        else:\n            period = {\"pop\": dt(), \"proj\": dt() * 1000}[compartment_type]\n\n        period = int(period / dt()) * dt()\n        return compartment_type, compartment_name, period\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors.__init__","title":"<code>__init__(mon_dict={})</code>","text":"<p>Initialize CompNeuroMonitors object by creating ANNarchy monitors.</p> <p>Parameters:</p> Name Type Description Default <code>mon_dict</code> <code>dict</code> <p>dict with key=\"pop;pop_name\" for populations and key=\"proj;proj_name\" for projections and val=list with variables to record.</p> <code>{}</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def __init__(self, mon_dict={}):\n    \"\"\"\n    Initialize CompNeuroMonitors object by creating ANNarchy monitors.\n\n    Args:\n        mon_dict (dict):\n            dict with key=\"pop;pop_name\" for populations and key=\"proj;proj_name\"\n            for projections and val=list with variables to record.\n    \"\"\"\n    self.mon = self._add_monitors(mon_dict)\n    self.mon_dict = mon_dict\n    self._init_internals()\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors.start","title":"<code>start(compartment_list=None)</code>","text":"<p>Start or resume recording of all recorded compartments in compartment_list.</p> <p>Parameters:</p> Name Type Description Default <code>compartment_list</code> <code>list</code> <p>List with compartment names to start or resume recording. Default: None, i.e., all compartments of initialized mon_dict are started or resumed.</p> <code>None</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def start(self, compartment_list=None):\n    \"\"\"\n    Start or resume recording of all recorded compartments in compartment_list.\n\n    Args:\n        compartment_list (list, optional):\n            List with compartment names to start or resume recording. Default: None,\n            i.e., all compartments of initialized mon_dict are started or resumed.\n    \"\"\"\n    if compartment_list == None:\n        mon_dict_key_list = list(self.mon_dict.keys())\n        compartment_list = [\n            self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n        ]\n\n    self.timings = self._start_monitors(compartment_list, self.mon, self.timings)\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors.pause","title":"<code>pause(compartment_list=None)</code>","text":"<p>Pause recording of all recorded compartments in compartment_list.</p> <p>Parameters:</p> Name Type Description Default <code>compartment_list</code> <code>list</code> <p>List with compartment names to pause recording. Default: None, i.e., all compartments of initialized mon_dict are paused.</p> <code>None</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def pause(self, compartment_list=None):\n    \"\"\"\n    Pause recording of all recorded compartments in compartment_list.\n\n    Args:\n        compartment_list (list, optional):\n            List with compartment names to pause recording. Default: None,\n            i.e., all compartments of initialized mon_dict are paused.\n    \"\"\"\n    if compartment_list == None:\n        mon_dict_key_list = list(self.mon_dict.keys())\n        compartment_list = [\n            self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n        ]\n\n    self.timings = self._pause_monitors(compartment_list, self.mon, self.timings)\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors.reset","title":"<code>reset(populations=True, projections=False, synapses=False, monitors=True, model=True, net_id=0)</code>","text":"<p>Create a new recording chunk by getting recordings and recording times of the current chunk and optionally resetting the model. Recordings are automatically resumed in the new chunk if they are not paused.</p> <p>Parameters:</p> Name Type Description Default <code>populations</code> <code>bool</code> <p>If True, reset populations. Default: True.</p> <code>True</code> <code>projections</code> <code>bool</code> <p>If True, reset projections. Default: False.</p> <code>False</code> <code>synapses</code> <code>bool</code> <p>If True, reset synapses. Default: False.</p> <code>False</code> <code>monitors</code> <code>bool</code> <p>If True, reset ANNarchy monitors. Default: True.</p> <code>True</code> <code>model</code> <code>bool</code> <p>If True, reset model. Default: True.</p> <code>True</code> <code>net_id</code> <code>int</code> <p>Id of the network to reset. Default: 0.</p> <code>0</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def reset(\n    self,\n    populations=True,\n    projections=False,\n    synapses=False,\n    monitors=True,\n    model=True,\n    net_id=0,\n):\n    \"\"\"\n    Create a new recording chunk by getting recordings and recording times of the\n    current chunk and optionally resetting the model. Recordings are automatically\n    resumed in the new chunk if they are not paused.\n\n    Args:\n        populations (bool, optional):\n            If True, reset populations. Default: True.\n        projections (bool, optional):\n            If True, reset projections. Default: False.\n        synapses (bool, optional):\n            If True, reset synapses. Default: False.\n        monitors (bool, optional):\n            If True, reset ANNarchy monitors. Default: True.\n        model (bool, optional):\n            If True, reset model. Default: True.\n        net_id (int, optional):\n            Id of the network to reset. Default: 0.\n    \"\"\"\n    ### TODO rename this function to new_chunk() or something like that and let recordings and recording times be returned\n    self.get_recordings_reset_call = True\n    self.get_recordings()\n    self.get_recording_times()\n    self.get_recordings_reset_call = False\n    self.already_got_recordings = (\n        False  # after reset one can still update recordings\n    )\n    self.already_got_recording_times = (\n        False  # after reset one can still update recording_times\n    )\n    ### reset timings, after reset, add a zero to start if the monitor is still running (this is not resetted by reset())\n    ### if the model was not resetted --&gt; do add current time instead of zero\n    for key in self.timings.keys():\n        self.timings[key][\"start\"] = []\n        self.timings[key][\"stop\"] = []\n        if self.timings[key][\"currently_paused\"] == False:\n            if model:\n                self.timings[key][\"start\"].append(0)\n            else:\n                self.timings[key][\"start\"].append(\n                    np.round(get_time(), af.get_number_of_decimals(dt()))\n                )\n\n    if model:\n        reset(populations, projections, synapses, monitors, net_id=net_id)\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors.current_chunk","title":"<code>current_chunk()</code>","text":"<p>Get the index of the current chunk.</p> <p>Returns:</p> Name Type Description <code>current_chunk_idx</code> <code>int</code> <p>Index of the current chunk. If no recordings are currently active, returns None.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def current_chunk(self):\n    \"\"\"\n    Get the index of the current chunk.\n\n    Returns:\n        current_chunk_idx (int):\n            Index of the current chunk. If no recordings are currently active,\n            returns None.\n    \"\"\"\n    ### if recordings are currently active --&gt; return chunk in which these recordings will be saved\n    ### check if there are currently active recordings\n    active_recordings = False\n    for key, val in self.mon_dict.items():\n        _, compartment, _ = self._unpack_mon_dict_keys(key)\n        if not (self.timings[compartment][\"currently_paused\"]):\n            ### tere are currently active recordings\n            active_recordings = True\n\n    if active_recordings:\n        current_chunk_idx = len(self.recordings)\n        return current_chunk_idx\n    else:\n        ### if currently no recordings are active return None\n        return None\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors.get_recordings","title":"<code>get_recordings()</code>","text":"<p>Get recordings of all recorded compartments.</p> <p>Returns:</p> Name Type Description <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recordings(self):\n    \"\"\"\n    Get recordings of all recorded compartments.\n\n    Returns:\n        recordings (list):\n            List with recordings of all chunks.\n    \"\"\"\n    ### only if recordings in current chunk and get_recodings was not already called add current chunk to recordings\n    if (\n        self._any_recordings_in_current_chunk()\n        and self.already_got_recordings is False\n    ):\n        ### update recordings\n        self.recordings.append(self._get_monitors(self.mon_dict, self.mon))\n        ### upade already_got_recordings --&gt; it will not update recordings again\n        self.already_got_recordings = True\n\n        if not (self.get_recordings_reset_call):\n            if len(self.recordings) == 0:\n                print(\n                    \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return self.recordings\n    else:\n        if not (self.get_recordings_reset_call):\n            if len(self.recordings) == 0:\n                print(\n                    \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return self.recordings\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors.get_recording_times","title":"<code>get_recording_times()</code>","text":"<p>Get recording times of all recorded compartments.</p> <p>Returns:</p> Name Type Description <code>recording_times</code> <code>recording_times_cl</code> <p>Object with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recording_times(self):\n    \"\"\"\n    Get recording times of all recorded compartments.\n\n    Returns:\n        recording_times (recording_times_cl):\n            Object with recording times of all chunks.\n    \"\"\"\n\n    temp_timings = self._get_temp_timings()\n\n    ### only append temp_timings of current chunk if there are recordings in current chunk at all and if get_recordings was not already called (double call would add the same chunk again)\n    if (\n        self._any_recordings_in_current_chunk()\n        and self.already_got_recording_times is False\n    ):\n        self.recording_times.append(temp_timings)\n\n    ### upade already_got_recording_times --&gt; it will not update recording_times again\n    self.already_got_recording_times = True\n\n    ### generate a object from recording_times and return this instead of the dict\n    recording_times_ob = RecordingTimes(self.recording_times)\n\n    if not (self.get_recordings_reset_call):\n        if len(self.recording_times) == 0:\n            print(\n                \"WARNING get_recording_times: no recordings available, empty list returned. Maybe forgot start()?\"\n            )\n    return recording_times_ob\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.CompNeuroMonitors.get_recordings_and_clear","title":"<code>get_recordings_and_clear()</code>","text":"<p>The default get_recordings method should be called at the end of the simulation. The get_recordings_and_clear method allows to get several times recordings with the same monitor object and to simulate between the calls. Sets the internal variables back to their initial state. Usefull if you repeat a simulation + recording several times and you do not want to always create new chunks.</p> <p>Warning</p> <p>If you want to continue recording after calling this method, you have to call start() again.</p> <p>Returns:</p> Name Type Description <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> <code>recording_times</code> <code>recording_times_cl</code> <p>Object with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recordings_and_clear(self):\n    \"\"\"\n    The default get_recordings method should be called at the end of the simulation.\n    The get_recordings_and_clear method allows to get several times recordings with\n    the same monitor object and to simulate between the calls. Sets the internal\n    variables back to their initial state. Usefull if you repeat a simulation +\n    recording several times and you do not want to always create new chunks.\n\n    !!! warning\n        If you want to continue recording after calling this method, you have to\n        call start() again.\n\n    Returns:\n        recordings (list):\n            List with recordings of all chunks.\n        recording_times (recording_times_cl):\n            Object with recording times of all chunks.\n    \"\"\"\n    ret0 = self.get_recordings()\n    ret1 = self.get_recording_times()\n    self._init_internals()\n    ret = (ret0, ret1)\n    return ret\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.RecordingTimes","title":"<code>src.CompNeuroPy.monitors.RecordingTimes</code>","text":"Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>class RecordingTimes:\n    def __init__(self, recording_times_list):\n        \"\"\"\n        Initialize RecordingTimes object.\n\n        Args:\n            recording_times_list (list):\n                List with recording times of all chunks.\n        \"\"\"\n        self.recording_times_list = recording_times_list\n\n    def time_lims(\n        self,\n        chunk: int | None = None,\n        compartment: str | None = None,\n        period: int | None = None,\n    ):\n        \"\"\"\n        Get the time limits recordings of of a specified chunk/model compartment in ms.\n\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment from\n            monitor.\n        period (int, optional):\n            Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop time of the specified chunk/model compartment.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR time_lims(): No recordings/recording_times available.\"\n        return self._lims(\"ms\", chunk, compartment, period)\n\n    def idx_lims(\n        self,\n        chunk: int | None = None,\n        compartment: str | None = None,\n        period: int | None = None,\n    ):\n        \"\"\"\n        Get the index limits of recordings of a specified chunk/model compartment.\n\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment from\n            monitor.\n        period (int, optional):\n            Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop index of the specified chunk/model\n                compartment.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR idx_lims(): No recordings/recording_times available.\"\n        return self._lims(\"idx\", chunk, compartment, period)\n\n    def all(self):\n        \"\"\"\n        Get the recording times of all chunks, compartments, periods in ms and index.\n\n        Returns:\n            recording_times_list (list):\n                List with recording times of all chunks.\n        \"\"\"\n        return self.recording_times_list\n\n    def nr_periods(self, chunk=None, compartment=None):\n        \"\"\"\n        Get the number of recording periods (start-pause) of a specified chunk/model\n        compartment.\n\n        Args:\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n            compartment (str, optional):\n                Name of the compartment. Default: None, i.e., first model compartment\n                from monitor.\n\n        Returns:\n            nr_periods (int):\n                Number of recording periods (start-pause) of a specified chunk/model\n                compartment.\n        \"\"\"\n        chunk = self._check_chunk(chunk)\n        compartment = self.__check_compartment__(compartment, chunk)\n        return self._get_nr_periods(chunk, compartment)\n\n    def combine_chunks(\n        self, recordings: list, recording_data_str: str, mode=\"sequential\"\n    ):\n        \"\"\"\n        Combines the data of all chunks of recordings, only possible if no pauses in\n        between.\n\n        Args:\n            recordings (list):\n                List with recordings of all chunks.\n            recording_data_str (str):\n                String specifying the compartment name and the variable to combine.\n                Format: \"compartment_name;variable_name\"\n            mode (str, optional):\n                How should the time array be generated. Can be \"sequential\" or\n                \"consecutive\". Default: \"sequential\".\n                - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;\n                    [0, 1, ..., 100, 0, 1, ..., 250]\n                - \"consecutive\": each chunk starts at the last stop time of the previous\n                    chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]\n\n        Returns:\n            time_arr (np.array):\n                Array with time values in ms.\n            data_arr (np.array):\n                Array with the recorded variable.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR combine_chunks(): No recordings/recording_times available.\"\n\n        compartment = recording_data_str.split(\";\")[0]\n        period_time = recordings[0][f\"{compartment};period\"]\n        time_step = recordings[0][\"dt\"]\n        nr_chunks = self._get_nr_chunks()\n        data_list = []\n        time_list = []\n        pre_chunk_start_time = 0\n\n        for chunk in range(nr_chunks):\n            ### append data list with data of all periods of this chunk\n            data_list.append(recordings[chunk][recording_data_str])\n\n            ### nr of periods in this chunk\n            nr_periods = self._get_nr_periods(chunk, compartment)\n\n            ### start time of chunk depends on mode\n            if mode == \"sequential\":\n                chunk_start_time = 0\n            elif mode == \"consecutive\":\n                if chunk == 0:\n                    chunk_start_time = 0\n                else:\n                    last_stop_time = self.recording_times_list[chunk - 1][compartment][\n                        \"stop\"\n                    ][\"ms\"][-1]\n                    chunk_start_time = (\n                        pre_chunk_start_time + last_stop_time + period_time\n                    )\n                    pre_chunk_start_time = chunk_start_time\n            else:\n                print(\"ERROR recording_times.combine_data, Wrong mode.\")\n                quit()\n\n            ### append the time list with all times of the periods\n            for period in range(nr_periods):\n                start_time = (\n                    self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                        0\n                    ]\n                    + chunk_start_time\n                )\n                end_time = (\n                    self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                        1\n                    ]\n                    + chunk_start_time\n                )\n                start_time = round(start_time, af.get_number_of_decimals(time_step))\n                end_time = round(end_time, af.get_number_of_decimals(time_step))\n                times = np.arange(start_time, end_time + period_time, period_time)\n                time_list.append(times)\n\n        ### flatten the two lists\n        data_arr = np.concatenate(data_list, 0)\n        time_arr = np.concatenate(time_list, 0)\n\n        ### check if there are gaps in the time array\n        ### fill them with the corersponding times and\n        ### the data array with nan values\n        time_arr, data_arr = af.time_data_add_nan(\n            time_arr,\n            data_arr,\n            fill_time_step=period_time,\n        )\n\n        return time_arr, data_arr\n\n    def _lims(self, string, chunk=None, compartment=None, period=None):\n        \"\"\"\n        Get the limits of recordings of a specified chunk/model compartment.\n\n        Args:\n            string (str):\n                String specifying the type of limits to return. Can be \"ms\" for time\n                limits in ms or \"idx\" for index limits.\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n            compartment (str, optional):\n                Name of the compartment. Default: None, i.e., first model compartment\n                from monitor.\n            period (int, optional):\n                Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop time/index of the specified chunk/model\n                compartment.\n        \"\"\"\n\n        chunk = self._check_chunk(chunk)\n        compartment = self.__check_compartment__(compartment, chunk)\n        period_0, period_1 = self._check_period(period, chunk, compartment)\n        lims = (\n            self.recording_times_list[chunk][compartment][\"start\"][string][period_0],\n            self.recording_times_list[chunk][compartment][\"stop\"][string][period_1],\n        )\n        return lims\n\n    def __check_compartment__(self, compartment, chunk):\n        if compartment == None:\n            ### by default just use the first compartment\n            compartment = list(self.recording_times_list[chunk].keys())[0]\n        elif compartment in list(self.recording_times_list[chunk].keys()):\n            compartment = compartment\n        else:\n            print(\n                'ERROR recording_times, given compartment \"'\n                + str(compartment)\n                + '\" not available'\n            )\n            quit()\n\n        return compartment\n\n    def _check_period(self, period, chunk, compartment):\n        \"\"\"\n        Check if period is given.\n\n        Args:\n            period (int, optional):\n                Index of the period. Default: None, i.e., all periods.\n            chunk (int):\n                Index of the chunk.\n            compartment (str):\n                Name of the compartment.\n\n        Returns:\n            period_0 (int):\n                Index of the first period.\n            period_1 (int):\n                Index of the last period. If perios is given, period_0 == period_1.\n        \"\"\"\n        if period == None:\n            ### by default use all periods\n            period_0 = 0\n            period_1 = (\n                len(self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]) - 1\n            )\n        elif period &lt; len(\n            self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]\n        ):\n            period_0 = period\n            period_1 = period\n        else:\n            print(\"ERROR recording_times, given period not available\")\n            quit()\n\n        return period_0, period_1\n\n    def _check_chunk(self, chunk):\n        \"\"\"\n        Check if chunk is given.\n\n        Args:\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n\n        Returns:\n            chunk (int):\n                Index of the chunk.\n        \"\"\"\n        if chunk is None:\n            ### by default use first chunk\n            chunk = 0\n        elif chunk &lt; self._get_nr_chunks():\n            chunk = chunk\n        else:\n            print(\"ERROR recording_times, given chunk not available\")\n            quit()\n\n        return chunk\n\n    def _get_nr_chunks(self):\n        \"\"\"\n        Get the number of chunks of the recordings.\n\n        Returns:\n            nr_chunks (int):\n                Number of chunks.\n        \"\"\"\n        return len(self.recording_times_list)\n\n    def _get_nr_periods(self, chunk, compartment):\n        \"\"\"\n        Get the number of recording periods (start-pause) of a specified chunk/model\n        compartment.\n\n        Args:\n            chunk (int):\n                Index of the chunk.\n            compartment (str):\n                Name of the compartment.\n\n        Returns:\n            nr_periods (int):\n                Number of recording periods (start-pause) of a specified chunk/model\n                compartment.\n        \"\"\"\n        return len(self.recording_times_list[chunk][compartment][\"start\"][\"idx\"])\n\n    def _any_recordings(self, chunk):\n        \"\"\"\n        Check all periods and compartments if there are any recordings.\n\n        Args:\n            chunk (int):\n                Index of the chunk.\n\n        Returns:\n            found_recordings (bool):\n                True if there are any recordings in the chunk, False otherwise.\n        \"\"\"\n        compartment_list = list(self.recording_times_list[chunk].keys())\n        found_recordings = False\n        for compartment in compartment_list:\n            nr_periods_of_compartment = len(\n                self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]\n            )\n\n            for period_idx in range(nr_periods_of_compartment):\n                idx_lims = self.idx_lims(\n                    chunk=chunk, compartment=compartment, period=period_idx\n                )\n                if np.diff(idx_lims)[0] &gt; 0:\n                    found_recordings = True\n\n        return found_recordings\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.RecordingTimes.__init__","title":"<code>__init__(recording_times_list)</code>","text":"<p>Initialize RecordingTimes object.</p> <p>Parameters:</p> Name Type Description Default <code>recording_times_list</code> <code>list</code> <p>List with recording times of all chunks.</p> required Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def __init__(self, recording_times_list):\n    \"\"\"\n    Initialize RecordingTimes object.\n\n    Args:\n        recording_times_list (list):\n            List with recording times of all chunks.\n    \"\"\"\n    self.recording_times_list = recording_times_list\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.RecordingTimes.time_lims","title":"<code>time_lims(chunk=None, compartment=None, period=None)</code>","text":"<p>Get the time limits recordings of of a specified chunk/model compartment in ms.</p> <p>chunk (int, optional):     Index of the chunk. Default: None, i.e., first chunk. compartment (str, optional):     Name of the compartment. Default: None, i.e., first model compartment from     monitor. period (int, optional):     Index of the period. Default: None, i.e., all periods.</p> <p>Returns:</p> Name Type Description <code>lims</code> <code>tuple</code> <p>Tuple with start and stop time of the specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def time_lims(\n    self,\n    chunk: int | None = None,\n    compartment: str | None = None,\n    period: int | None = None,\n):\n    \"\"\"\n    Get the time limits recordings of of a specified chunk/model compartment in ms.\n\n    chunk (int, optional):\n        Index of the chunk. Default: None, i.e., first chunk.\n    compartment (str, optional):\n        Name of the compartment. Default: None, i.e., first model compartment from\n        monitor.\n    period (int, optional):\n        Index of the period. Default: None, i.e., all periods.\n\n    Returns:\n        lims (tuple):\n            Tuple with start and stop time of the specified chunk/model compartment.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR time_lims(): No recordings/recording_times available.\"\n    return self._lims(\"ms\", chunk, compartment, period)\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.RecordingTimes.idx_lims","title":"<code>idx_lims(chunk=None, compartment=None, period=None)</code>","text":"<p>Get the index limits of recordings of a specified chunk/model compartment.</p> <p>chunk (int, optional):     Index of the chunk. Default: None, i.e., first chunk. compartment (str, optional):     Name of the compartment. Default: None, i.e., first model compartment from     monitor. period (int, optional):     Index of the period. Default: None, i.e., all periods.</p> <p>Returns:</p> Name Type Description <code>lims</code> <code>tuple</code> <p>Tuple with start and stop index of the specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def idx_lims(\n    self,\n    chunk: int | None = None,\n    compartment: str | None = None,\n    period: int | None = None,\n):\n    \"\"\"\n    Get the index limits of recordings of a specified chunk/model compartment.\n\n    chunk (int, optional):\n        Index of the chunk. Default: None, i.e., first chunk.\n    compartment (str, optional):\n        Name of the compartment. Default: None, i.e., first model compartment from\n        monitor.\n    period (int, optional):\n        Index of the period. Default: None, i.e., all periods.\n\n    Returns:\n        lims (tuple):\n            Tuple with start and stop index of the specified chunk/model\n            compartment.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR idx_lims(): No recordings/recording_times available.\"\n    return self._lims(\"idx\", chunk, compartment, period)\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.RecordingTimes.all","title":"<code>all()</code>","text":"<p>Get the recording times of all chunks, compartments, periods in ms and index.</p> <p>Returns:</p> Name Type Description <code>recording_times_list</code> <code>list</code> <p>List with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def all(self):\n    \"\"\"\n    Get the recording times of all chunks, compartments, periods in ms and index.\n\n    Returns:\n        recording_times_list (list):\n            List with recording times of all chunks.\n    \"\"\"\n    return self.recording_times_list\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.RecordingTimes.nr_periods","title":"<code>nr_periods(chunk=None, compartment=None)</code>","text":"<p>Get the number of recording periods (start-pause) of a specified chunk/model compartment.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>int</code> <p>Index of the chunk. Default: None, i.e., first chunk.</p> <code>None</code> <code>compartment</code> <code>str</code> <p>Name of the compartment. Default: None, i.e., first model compartment from monitor.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>nr_periods</code> <code>int</code> <p>Number of recording periods (start-pause) of a specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def nr_periods(self, chunk=None, compartment=None):\n    \"\"\"\n    Get the number of recording periods (start-pause) of a specified chunk/model\n    compartment.\n\n    Args:\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment\n            from monitor.\n\n    Returns:\n        nr_periods (int):\n            Number of recording periods (start-pause) of a specified chunk/model\n            compartment.\n    \"\"\"\n    chunk = self._check_chunk(chunk)\n    compartment = self.__check_compartment__(compartment, chunk)\n    return self._get_nr_periods(chunk, compartment)\n</code></pre>"},{"location":"main/monitors_recordings/#src.CompNeuroPy.monitors.RecordingTimes.combine_chunks","title":"<code>combine_chunks(recordings, recording_data_str, mode='sequential')</code>","text":"<p>Combines the data of all chunks of recordings, only possible if no pauses in between.</p> <p>Parameters:</p> Name Type Description Default <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> required <code>recording_data_str</code> <code>str</code> <p>String specifying the compartment name and the variable to combine. Format: \"compartment_name;variable_name\"</p> required <code>mode</code> <code>str</code> <p>How should the time array be generated. Can be \"sequential\" or \"consecutive\". Default: \"sequential\". - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;     [0, 1, ..., 100, 0, 1, ..., 250] - \"consecutive\": each chunk starts at the last stop time of the previous     chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]</p> <code>'sequential'</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>Array with time values in ms.</p> <code>data_arr</code> <code>array</code> <p>Array with the recorded variable.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def combine_chunks(\n    self, recordings: list, recording_data_str: str, mode=\"sequential\"\n):\n    \"\"\"\n    Combines the data of all chunks of recordings, only possible if no pauses in\n    between.\n\n    Args:\n        recordings (list):\n            List with recordings of all chunks.\n        recording_data_str (str):\n            String specifying the compartment name and the variable to combine.\n            Format: \"compartment_name;variable_name\"\n        mode (str, optional):\n            How should the time array be generated. Can be \"sequential\" or\n            \"consecutive\". Default: \"sequential\".\n            - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;\n                [0, 1, ..., 100, 0, 1, ..., 250]\n            - \"consecutive\": each chunk starts at the last stop time of the previous\n                chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]\n\n    Returns:\n        time_arr (np.array):\n            Array with time values in ms.\n        data_arr (np.array):\n            Array with the recorded variable.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR combine_chunks(): No recordings/recording_times available.\"\n\n    compartment = recording_data_str.split(\";\")[0]\n    period_time = recordings[0][f\"{compartment};period\"]\n    time_step = recordings[0][\"dt\"]\n    nr_chunks = self._get_nr_chunks()\n    data_list = []\n    time_list = []\n    pre_chunk_start_time = 0\n\n    for chunk in range(nr_chunks):\n        ### append data list with data of all periods of this chunk\n        data_list.append(recordings[chunk][recording_data_str])\n\n        ### nr of periods in this chunk\n        nr_periods = self._get_nr_periods(chunk, compartment)\n\n        ### start time of chunk depends on mode\n        if mode == \"sequential\":\n            chunk_start_time = 0\n        elif mode == \"consecutive\":\n            if chunk == 0:\n                chunk_start_time = 0\n            else:\n                last_stop_time = self.recording_times_list[chunk - 1][compartment][\n                    \"stop\"\n                ][\"ms\"][-1]\n                chunk_start_time = (\n                    pre_chunk_start_time + last_stop_time + period_time\n                )\n                pre_chunk_start_time = chunk_start_time\n        else:\n            print(\"ERROR recording_times.combine_data, Wrong mode.\")\n            quit()\n\n        ### append the time list with all times of the periods\n        for period in range(nr_periods):\n            start_time = (\n                self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                    0\n                ]\n                + chunk_start_time\n            )\n            end_time = (\n                self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                    1\n                ]\n                + chunk_start_time\n            )\n            start_time = round(start_time, af.get_number_of_decimals(time_step))\n            end_time = round(end_time, af.get_number_of_decimals(time_step))\n            times = np.arange(start_time, end_time + period_time, period_time)\n            time_list.append(times)\n\n    ### flatten the two lists\n    data_arr = np.concatenate(data_list, 0)\n    time_arr = np.concatenate(time_list, 0)\n\n    ### check if there are gaps in the time array\n    ### fill them with the corersponding times and\n    ### the data array with nan values\n    time_arr, data_arr = af.time_data_add_nan(\n        time_arr,\n        data_arr,\n        fill_time_step=period_time,\n    )\n\n    return time_arr, data_arr\n</code></pre>"},{"location":"main/optimize_neuron/","title":"Optimize a neuron model","text":""},{"location":"main/optimize_neuron/#src.CompNeuroPy.opt_neuron.OptNeuron","title":"<code>src.CompNeuroPy.opt_neuron.OptNeuron</code>","text":"<p>This class is used to optimize neuron models with ANNarchy.</p> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>class OptNeuron:\n    \"\"\"\n    This class is used to optimize neuron models with ANNarchy.\n    \"\"\"\n\n    opt_created = []\n\n    def __init__(\n        self,\n        experiment: Type[CompNeuroExp],\n        get_loss_function: Callable[[Any, Any], float | list[float]],\n        variables_bounds: dict[str, float | list[float]],\n        neuron_model: Neuron,\n        results_soll: Any | None = None,\n        target_neuron_model: Neuron | None = None,\n        time_step: float | None = 1.0,\n        compile_folder_name: str = \"annarchy_OptNeuron\",\n        num_rep_loss: int = 1,\n        method: str = \"hyperopt\",\n        prior=None,\n        fv_space: list = None,\n        record: list[str] = [],\n    ):\n        \"\"\"\n        This prepares the optimization. To run the optimization call the run function.\n\n        Args:\n            experiment (CompNeuroExp class):\n                CompNeuroExp class containing a 'run' function which defines the\n                simulations and recordings\n\n            get_loss_function (function):\n                function which takes results_ist and results_soll as arguments and\n                calculates/returns the loss\n\n            variables_bounds (dict):\n                Dictionary with parameter names (keys) and their bounds (values). If\n                single values are given as values, the parameter is constant, i.e., not\n                optimized. If a list is given as value, the parameter is optimized and\n                the list contains the lower and upper bound of the parameter (order is\n                not important).\n\n            neuron_model (ANNarchy Neuron):\n                The neuron model whose parameters should be optimized.\n\n            results_soll (Any, optional):\n                Some variable which contains the target data and can be used by the\n                get_loss_function (second argument of get_loss_function)\n                !!! warning\n                    Either provide results_soll or a target_neuron_model not both!\n                Default: None.\n\n            target_neuron_model (ANNarchy Neuron, optional):\n                The neuron model which produces the target data by running the\n                experiment.\n                !!! warning\n                    Either provide results_soll or a target_neuron_model not both!\n                Default: None.\n\n            time_step (float, optional):\n                The time step for the simulation in ms. Default: 1.\n\n            compile_folder_name (string, optional):\n                The name of the annarchy compilation folder within annarchy_folders/.\n                Default: 'annarchy_OptNeuron'.\n\n            num_rep_loss (int, optional):\n                Only interesting for noisy simulations/models. How often should the\n                simulaiton be run to calculate the loss (the defined number of losses\n                is obtained and averaged). Default: 1.\n\n            method (str, optional):\n                Either 'sbi' or 'hyperopt'. If 'sbi' is used, the optimization is\n                performed with sbi. If 'hyperopt' is used, the optimization is\n                performed with hyperopt. Default: 'hyperopt'.\n\n            prior (distribution, optional):\n                The prior distribution used by sbi. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n\n            fv_space (list, optional):\n                The search space for hyperopt. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n\n            record (list, optional):\n                List of strings which define what variables of the tuned neuron should\n                be recorded. Default: [].\n        \"\"\"\n\n        if len(self.opt_created) &gt; 0:\n            print(\n                \"OptNeuron: Error: Already another OptNeuron created. Only create one per python session!\"\n            )\n            quit()\n        else:\n            print(\n                \"OptNeuron: Initialize OptNeuron... do not create anything with ANNarchy before!\"\n            )\n\n            ### set object variables\n            self.opt_created.append(1)\n            self.record = record\n            self.results_soll = results_soll\n            self.experiment = experiment\n            self.variables_bounds = variables_bounds\n            self.fitting_variables_name_list = self._get_fitting_variables_name_list()\n            self.method = method\n            if method == \"hyperopt\":\n                if fv_space is None:\n                    self.fv_space = self._get_hyperopt_space()\n                else:\n                    self.fv_space = fv_space\n            self.const_params = self._get_const_params()\n            self.num_rep_loss = num_rep_loss\n            self.neuron_model = neuron_model\n            if method == \"sbi\":\n                self.prior = self._get_prior(prior)\n            self.target_neuron = target_neuron_model\n            self.compile_folder_name = compile_folder_name\n            self.__get_loss__ = get_loss_function\n\n            ### check target_neuron/results_soll\n            self._check_target()\n            ### check neuron models\n            self._check_neuron_models()\n\n            ### setup ANNarchy\n            setup(dt=time_step)\n\n            ### create and compile model\n            ### if neuron models and target neuron model --&gt; create both models then test,\n            ### then clear and create only model for neuron model\n            model, target_model, monitors = self._generate_models()\n\n            self.pop = model.populations[0]\n            if target_model is not None:\n                self.pop_target = target_model.populations[0]\n            else:\n                self.pop_target = None\n            self.monitors = monitors\n\n            ### check variables of model\n            self._test_variables()\n\n            ### check neuron models, experiment, get_loss\n            ### if results_soll is None -_&gt; generate results_soll\n            self._check_get_loss_function()\n\n            ### after checking neuron models, experiment, get_loss\n            ### if two models exist --&gt; clear ANNarchy and create/compile again only standard model\n            clear()\n            model, _, monitors = self._generate_models()\n            self.monitors = monitors\n\n    def _generate_models(self):\n        \"\"\"\n        Generates the tuned model and the target_model (only if results_soll is None).\n\n        Returns:\n            model (CompNeuroModel):\n                The model which is used for the optimization.\n\n            target_model (CompNeuroModel):\n                The model which is used to generate the target data. If results_soll is\n                provided, target_model is None.\n\n            monitors (CompNeuroMonitors):\n                The monitors which are used to record the data. If no variables are\n                recorded, monitors is None.\n        \"\"\"\n        with ef.suppress_stdout():\n            model = None\n            target_model = None\n            monitors = None\n            if self.results_soll is None:\n                ### create two models\n                model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\"neuron\": self.neuron_model, \"name\": \"model_neuron\"},\n                    name=\"standard_model\",\n                    do_create=True,\n                    do_compile=False,\n                    compile_folder_name=self.compile_folder_name,\n                )\n\n                target_model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\n                        \"neuron\": self.target_neuron,\n                        \"name\": \"target_model_neuron\",\n                    },\n                    name=\"target_model\",\n                    do_create=True,\n                    do_compile=True,\n                    compile_folder_name=self.compile_folder_name,\n                )\n\n                ### create monitors\n                if len(self.record) &gt; 0:\n                    monitors = CompNeuroMonitors(\n                        {\n                            f\"pop;{pop_name}\": self.record\n                            for pop_name in [\n                                model.populations[0],\n                                target_model.populations[0],\n                            ]\n                        }\n                    )\n\n            else:\n                ### create one model\n                model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\"neuron\": self.neuron_model, \"name\": \"model_neuron\"},\n                    name=\"single_model\",\n                    do_create=True,\n                    do_compile=True,\n                    compile_folder_name=self.compile_folder_name,\n                )\n                ### create monitors\n                if len(self.record) &gt; 0:\n                    monitors = CompNeuroMonitors(\n                        {f\"pop;{model.populations[0]}\": self.record}\n                    )\n\n        return model, target_model, monitors\n\n    def _check_neuron_models(self):\n        \"\"\"\n        Checks if the neuron models are ANNarchy neuron models.\n        \"\"\"\n        if not (isinstance(self.neuron_model, type(Neuron()))) or (\n            self.target_neuron is not None\n            and not (isinstance(self.target_neuron, type(Neuron())))\n        ):\n            print(\n                \"OptNeuron: Error: neuron_model and/or target_neuron_model have to be ANNarchy neuron models\"\n            )\n            quit()\n\n    def _check_target(self):\n        \"\"\"\n        Check if either results_soll or target_neuron are provided and not both.\n        \"\"\"\n        if self.target_neuron is None and self.results_soll is None:\n            print(\n                \"OptNeuron: Error: Either provide results_soll or target_neuron_model\"\n            )\n            quit()\n        elif self.target_neuron is not None and self.results_soll is not None:\n            print(\n                \"OptNeuron: Error: Either provide results_soll or target_neuron_model, not both\"\n            )\n            quit()\n\n    def _get_prior(self, prior):\n        \"\"\"\n        Get the prior distribution used by sbi. If no prior is given, uniform\n        distributions between the variable bounds are assumed. If a prior is given,\n        this prior is used.\n\n        Args:\n            prior (distribution, optional):\n                The prior distribution used by sbi. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n\n        Returns:\n            prior (distribution):\n                The prior distribution used by sbi.\n        \"\"\"\n        if prior is None:\n            prior_min = []\n            prior_max = []\n            for _, param_bounds in self.variables_bounds.items():\n                if isinstance(param_bounds, list):\n                    prior_min.append(param_bounds[0])\n                    prior_max.append(param_bounds[1])\n\n            return utils.BoxUniform(\n                low=torch.as_tensor(prior_min), high=torch.as_tensor(prior_max)\n            )\n        else:\n            return prior\n\n    def _get_fitting_variables_name_list(self):\n        \"\"\"\n        Returns a list with the names of the fitting variables.\n\n        Returns:\n            fitting_variables_name_list (list):\n                list with names of fitting variables\n        \"\"\"\n        name_list = []\n        for param_name, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                name_list.append(param_name)\n        return name_list\n\n    def _get_hyperopt_space(self):\n        \"\"\"\n        Generates the hyperopt variable space from the fitting variable bounds. The\n        variable space is a uniform distribution between the bounds.\n\n        Returns:\n            fitting_variables_space (list):\n                list with hyperopt variables\n        \"\"\"\n        fitting_variables_space = []\n        for param_name, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                fitting_variables_space.append(\n                    hp.uniform(param_name, min(param_bounds), max(param_bounds))\n                )\n        return fitting_variables_space\n\n    def _get_const_params(self):\n        \"\"\"\n        Returns:\n            const_params (dict):\n                Dictionary with constant variables. The keys are the parameter names\n                and the values are the parameter values.\n        \"\"\"\n        const_params = {}\n        for param_name, param_bounds in self.variables_bounds.items():\n            if not (isinstance(param_bounds, list)):\n                const_params[param_name] = param_bounds\n        return const_params\n\n    def _check_get_loss_function(self):\n        \"\"\"\n        Checks if the get_loss_function is compatible to the experiment and the neuron\n        model(s). To test, the experiment is run once with the tuned neuron model\n        (generating results_ist) and once with the target neuron model (if provided,\n        generating results_soll). Then, the get_loss_function is called with the\n        results_ist and results_soll.\n        \"\"\"\n        print(\"checking neuron_models, experiment, get_loss...\", end=\"\")\n\n        fitparams = []\n        for bounds in self.variables_bounds.values():\n            if isinstance(bounds, list):\n                fitparams.append(bounds[0])\n\n        if self.results_soll is not None:\n            ### only generate results_ist with standard neuron model\n            results_ist = self._run_simulator_with_results(fitparams)[\"results\"]\n        else:\n            ### run simulator with both populations (standard neuron model and target\n            ### neuron model) and generatate results_ist and results_soll\n            results_ist = self._run_simulator_with_results(fitparams)[\"results\"]\n            self.results_soll = self._run_simulator_with_results(\n                fitparams, pop=self.pop_target\n            )[\"results\"]\n\n        try:\n            self.__get_loss__(results_ist, self.results_soll)\n        except:\n            print(\n                \"\\nThe get_loss_function, experiment and neuron model(s) are not compatible:\\n\"\n            )\n            traceback.print_exc()\n            quit()\n        print(\"Done\\n\")\n\n    def _raw_neuron(self, neuron, name):\n        \"\"\"\n        Generates a population with one neuron of the given neuron model.\n\n        Args:\n            neuron (ANNarchy Neuron):\n                The neuron model.\n\n            name (str):\n                The name of the population.\n        \"\"\"\n        Population(1, neuron=neuron, name=name)\n\n    def _test_variables(self):\n        \"\"\"\n        Check if the tuned neuron model contains all parameters which are defined in\n        variables_bounds or even more.\n        \"\"\"\n        ### collect all names\n        all_vars_names = np.concatenate(\n            [\n                np.array(list(self.const_params.keys())),\n                np.array(self.fitting_variables_name_list),\n            ]\n        ).tolist()\n        ### check if pop has these parameters\n        pop_parameter_names = get_population(self.pop).attributes.copy()\n        for name in pop_parameter_names.copy():\n            if name in all_vars_names:\n                all_vars_names.remove(name)\n                pop_parameter_names.remove(name)\n        if len(pop_parameter_names) &gt; 0:\n            print(\n                \"OptNeuron: WARNING: attributes\",\n                pop_parameter_names,\n                \"are not used/initialized.\",\n            )\n        if len(all_vars_names) &gt; 0:\n            print(\n                \"OptNeuron: WARNING: The neuron_model does not contain parameters\",\n                all_vars_names,\n                \"!\",\n            )\n\n    def _run_simulator(self, fitparams):\n        \"\"\"\n        Runs the function simulator with the multiprocessing manager (if function is\n        called multiple times this saves memory, otherwise same as calling simulator\n        directly).\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters\n\n        Returns:\n            return_dict (dict):\n                dictionary needed for optimization with hyperopt, containing the loss,\n                the loss variance (in case of noisy models with multiple runs per loss\n                calculation), and the status (STATUS_OK for hyperopt).\n        \"\"\"\n\n        ### initialize manager and generate m_list = dictionary to save data\n        manager = multiprocessing.Manager()\n        m_list = manager.dict()\n\n        ### in case of noisy models, here optionally run multiple simulations, to mean the loss\n        lossAr = np.zeros(self.num_rep_loss)\n\n        return_results = False\n        for nr_run in range(self.num_rep_loss):\n            ### initialize for each run a new rng (--&gt; not always have same noise in case of noisy models/simulations)\n            rng = np.random.default_rng()\n            ### run simulator with multiprocessign manager\n            proc = Process(\n                target=self._simulator, args=(fitparams, rng, m_list, return_results)\n            )\n            proc.start()\n            proc.join()\n            ### get simulation results/loss\n            lossAr[nr_run] = m_list[0]\n\n        ### calculate mean and std of loss\n        if self.num_rep_loss &gt; 1:\n            loss = np.mean(lossAr)\n            std = np.std(lossAr)\n        else:\n            loss = lossAr[0]\n            std = None\n\n        ### return loss and other things for optimization\n        if self.num_rep_loss &gt; 1:\n            return {\"status\": STATUS_OK, \"loss\": loss, \"loss_variance\": std}\n        else:\n            return {\"status\": STATUS_OK, \"loss\": loss}\n\n    def _sbi_simulation_wrapper(self, fitparams):\n        \"\"\"\n        This function is called by sbi. It calls the simulator function and\n        returns the loss and adjusts the format of the input parameters.\n\n        Args:\n            fitparams (tensor):\n                either a batch of parameters (tensor with two dimensions) or a single\n                parameter set\n\n        Returns:\n            loss (tensor):\n                loss as tensor for sbi inference\n        \"\"\"\n        fitparams = np.asarray(fitparams)\n        if len(fitparams.shape) == 2:\n            ### batch parameters!\n            data = []\n            for idx in range(fitparams.shape[0]):\n                data.append(self._run_simulator(fitparams[idx])[\"loss\"])\n        else:\n            ### single parameter set!\n            data = [self._run_simulator(fitparams)[\"loss\"]]\n\n        return torch.as_tensor(data)\n\n    def _run_simulator_with_results(self, fitparams, pop=None):\n        \"\"\"\n        Runs the function simulator with the multiprocessing manager (if function is\n        called multiple times this saves memory, otherwise same as calling simulator\n        directly) and also returns the results.\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters\n\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n\n        Returns:\n            return_dict (dict):\n                dictionary needed for optimization with hyperopt, containing the loss,\n                the loss variance (in case of noisy models with multiple runs per loss\n                calculation), and the status (STATUS_OK for hyperopt) and the results\n                generated by the experiment.\n        \"\"\"\n        ### check if pop is given\n        if pop is None:\n            pop = self.pop\n        ### initialize manager and generate m_list = dictionary to save data\n        manager = multiprocessing.Manager()\n        m_list = manager.dict()\n\n        ### in case of noisy models, here optionally run multiple simulations, to mean the loss\n        lossAr = np.zeros(self.num_rep_loss)\n        all_loss_list = []\n        return_results = True\n        for nr_run in range(self.num_rep_loss):\n            ### initialize for each run a new rng (--&gt; not always have same noise in case of noisy models/simulations)\n            rng = np.random.default_rng()\n            ### run simulator with multiprocessign manager\n            proc = Process(\n                target=self._simulator,\n                args=(fitparams, rng, m_list, return_results, pop),\n            )\n            proc.start()\n            proc.join()\n            ### get simulation results/loss\n            lossAr[nr_run] = m_list[0]\n            results_ist = m_list[1]\n            all_loss_list.append(m_list[2])\n\n        all_loss_arr = np.array(all_loss_list)\n        ### calculate mean and std of loss\n        if self.num_rep_loss &gt; 1:\n            loss = np.mean(lossAr)\n            std = np.std(lossAr)\n            all_loss = np.mean(all_loss_arr, 0)\n        else:\n            loss = lossAr[0]\n            std = None\n            all_loss = all_loss_arr[0]\n\n        ### return loss and other things for optimization and results\n        if self.num_rep_loss &gt; 1:\n            return {\n                \"status\": STATUS_OK,\n                \"loss\": loss,\n                \"loss_variance\": std,\n                \"std\": std,\n                \"all_loss\": all_loss,\n                \"results\": results_ist,\n            }\n        else:\n            return {\n                \"status\": STATUS_OK,\n                \"loss\": loss,\n                \"std\": std,\n                \"all_loss\": all_loss,\n                \"results\": results_ist,\n            }\n\n    def _simulator(\n        self, fitparams, rng, m_list=[0, 0, 0], return_results=False, pop=None\n    ):\n        \"\"\"\n        Runs the experiment with the given parameters and 'returns' the loss and\n        optionally the results and all individual losses of the get_loss_function. The\n        'returned' values are saved in m_list.\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters\n\n            rng (numpy random generator):\n                random generator for the simulation\n\n            m_list (list, optional):\n                list with the loss, the results, and the all_loss. Default: [0, 0, 0].\n\n            return_results (bool, optional):\n                If True, the results are returned. Default: False.\n\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n        \"\"\"\n        ### TODO use rng here and add it to CompNeuroExp\n        ### check if pop is given\n        if pop is None:\n            pop = self.pop\n\n        ### reset model and set parameters which should not be optimized and parameters which should be optimized\n        self._set_fitting_parameters(fitparams, pop=pop)\n\n        ### conduct loaded experiment\n        reset_function = self._set_fitting_parameters\n        reset_kwargs = {\"fitparams\": fitparams, \"pop\": pop}\n\n        exp_obj = self.experiment(\n            monitors=self.monitors,\n            reset_function=reset_function,\n            reset_kwargs=reset_kwargs,\n        )\n        results = exp_obj.run(pop)\n\n        if self.results_soll is not None:\n            ### compute loss\n            all_loss = self.__get_loss__(results, self.results_soll)\n            if isinstance(all_loss, list) or isinstance(all_loss, type(np.zeros(1))):\n                loss = sum(all_loss)\n            else:\n                loss = all_loss\n        else:\n            all_loss = 999\n            loss = 999\n        ### \"return\" loss and other optional things\n        m_list[0] = loss\n        if return_results:\n            m_list[1] = results\n            m_list[2] = all_loss\n\n    def _set_fitting_parameters(\n        self,\n        fitparams,\n        pop=None,\n        populations=True,\n        projections=False,\n        synapses=False,\n        monitors=True,\n    ):\n        \"\"\"\n        Resets the model to compilation state and sets all given parameters for the\n        population pop.\n\n        Args:\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n\n            populations (bool, optional):\n                reset populations. Defaults to True.\n\n            projections (bool, optional):\n                reset projections. Defaults to False.\n\n            synapses (bool, optional):\n                reset synapses. Defaults to False.\n\n            monitors (bool, optional):\n                reset monitors. Defaults to True.\n        \"\"\"\n        if pop is None:\n            pop = self.pop\n\n        ### reset model to compilation state\n        reset(\n            populations=populations,\n            projections=projections,\n            synapses=synapses,\n            monitors=monitors,\n        )\n\n        ### get all variables dict (combine fitting variables and const variables)\n        all_variables_dict = self.const_params.copy()\n\n        for fitting_variable_idx, fitting_variable_name in enumerate(\n            self.fitting_variables_name_list\n        ):\n            all_variables_dict[fitting_variable_name] = fitparams[fitting_variable_idx]\n\n        ### evaluate variables defined by a str\n        for key, val in all_variables_dict.items():\n            if isinstance(val, str):\n                all_variables_dict[key] = ef.evaluate_expression_with_dict(\n                    val, all_variables_dict\n                )\n\n        ### only set parameters of the fitted neuron model (in case target neuron model is given)\n        if pop == self.pop:\n            ### set parameters\n            for param_name, param_val in all_variables_dict.items():\n                pop_parameter_names = get_population(pop).attributes\n                ### only if param_name in parameter attributes\n                if param_name in pop_parameter_names:\n                    setattr(\n                        get_population(pop),\n                        param_name,\n                        param_val,\n                    )\n\n    def _test_fit(self, fitparams_dict):\n        \"\"\"\n        Runs the experiment with the optimized parameters obtained with hyperopt and\n        returns the loss, the results and all individual losses of the\n        get_loss_function.\n\n        Args:\n            fitparams_dict (dict):\n                dictionary with parameter names (keys) and their values (values)\n\n        Returns:\n            fit (dict):\n                dictionary containing the loss, the loss variance (in case of noisy\n                models with multiple runs per loss calculation), and the status\n                (STATUS_OK for hyperopt) and the results generated by the experiment.\n        \"\"\"\n        return self._run_simulator_with_results(\n            [fitparams_dict[name] for name in self.fitting_variables_name_list]\n        )\n\n    def _run_with_sbi(self, max_evals, sbi_plot_file):\n        \"\"\"\n        Runs the optimization with sbi.\n\n        Args:\n            max_evals (int):\n                number of runs the optimization method performs\n\n            sbi_plot_file (str):\n                If you use \"sbi\": the name of the figure which will be saved and shows\n                the posterior.\n\n        Returns:\n            best (dict):\n                dictionary containing the optimized parameters and the posterior.\n        \"\"\"\n        ### get prior bounds\n        prior_min = []\n        prior_max = []\n        for _, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                prior_min.append(param_bounds[0])\n                prior_max.append(param_bounds[1])\n\n        ### run sbi\n        simulator, prior = prepare_for_sbi(\n            self._sbi_simulation_wrapper,\n            self.prior,\n            {\n                \"lower_bound\": torch.as_tensor(prior_min),\n                \"upper_bound\": torch.as_tensor(prior_max),\n            },\n        )\n        inference = SNPE(prior, density_estimator=\"mdn\")\n        theta, x = simulate_for_sbi(\n            simulator=simulator,\n            proposal=prior,\n            num_simulations=max_evals,\n            num_workers=1,\n        )\n        density_estimator = inference.append_simulations(theta, x).train()\n        posterior = inference.build_posterior(density_estimator)\n        x_o = torch.as_tensor([0])  # data which should be obtained: loss==0\n        posterior = posterior.set_default_x(x_o)\n\n        ### get best params\n        posterior_samples = posterior.sample(\n            (10000,)\n        )  # posterior = distribution P(params|data) --&gt; set data and then sample possible parameters\n        best_params = posterior_samples[\n            torch.argmax(posterior.log_prob(posterior_samples))\n        ].numpy()  # sampled parameters with highest prob in posterior\n\n        ### create best dict with best parameters\n        best = {}\n        for param_idx, param_name in enumerate(self.fitting_variables_name_list):\n            best[param_name] = best_params[param_idx]\n\n        ### also return posterior\n        best[\"posterior\"] = posterior\n\n        ### plot posterior\n        plot_limits = [\n            [prior_min[idx], prior_max[idx]] for idx in range(len(prior_max))\n        ]\n        analysis.pairplot(\n            posterior_samples,\n            limits=plot_limits,\n            ticks=plot_limits,\n            fig_size=(5, 5),\n            labels=self.fitting_variables_name_list,\n        )\n\n        ### save plot\n        sf.create_dir(\"/\".join(sbi_plot_file.split(\"/\")[:-1]))\n        plt.savefig(sbi_plot_file)\n\n        return best\n\n    @check_types()\n    def run(\n        self,\n        max_evals: int,\n        results_file_name=\"best.npy\",\n        sbi_plot_file=\"posterior.svg\",\n    ):\n        \"\"\"\n        Runs the optimization.\n\n        Args:\n            max_evals (int):\n                number of runs the optimization method performs\n\n            results_file_name (str, optional):\n                name of the file which is saved. The file contains the optimized and\n                target results, the obtained parameters, the loss, and the SD of the\n                loss (in case of noisy models with multiple runs per loss calculation)\n                Default: \"best.npy\".\n\n            sbi_plot_file (str, optional):\n                If you use \"sbi\": the name of the figure which will be saved and shows\n                the posterior. Default: \"posterior.svg\".\n\n        Returns:\n            best (dict):\n                dictionary containing:\n\n                - \"loss\": the loss\n                - \"std\": the SD of the loss (in case of noisy models with multiple\n                    runs per loss calculation)\n                - \"results\": the results generated by the experiment\n                - \"results_soll\": the target results\n        \"\"\"\n        if self.method == \"hyperopt\":\n            ### run optimization with hyperopt and return best dict\n            best = fmin(\n                fn=self._run_simulator,\n                space=self.fv_space,\n                algo=tpe.suggest,\n                max_evals=max_evals,\n            )\n        elif self.method == \"sbi\":\n            ### run optimization with sbi and return best dict\n            best = self._run_with_sbi(max_evals, sbi_plot_file)\n        else:\n            print(\"ERROR run; method should be 'hyperopt' or 'sbi'\")\n            quit()\n        fit = self._test_fit(best)\n        best[\"loss\"] = fit[\"loss\"]\n        if self.method == \"sbi\":\n            print(\"\\tbest loss:\", best[\"loss\"])\n        best[\"all_loss\"] = fit[\"all_loss\"]\n        best[\"std\"] = fit[\"std\"]\n        best[\"results\"] = fit[\"results\"]\n        best[\"results_soll\"] = self.results_soll\n        self.results = best\n\n        ### SAVE OPTIMIZED PARAMS AND LOSS\n        sf.save_data([best], [\"parameter_fit/\" + results_file_name])\n</code></pre>"},{"location":"main/optimize_neuron/#src.CompNeuroPy.opt_neuron.OptNeuron.__init__","title":"<code>__init__(experiment, get_loss_function, variables_bounds, neuron_model, results_soll=None, target_neuron_model=None, time_step=1.0, compile_folder_name='annarchy_OptNeuron', num_rep_loss=1, method='hyperopt', prior=None, fv_space=None, record=[])</code>","text":"<p>This prepares the optimization. To run the optimization call the run function.</p> <p>Parameters:</p> Name Type Description Default <code>experiment</code> <code>CompNeuroExp class</code> <p>CompNeuroExp class containing a 'run' function which defines the simulations and recordings</p> required <code>get_loss_function</code> <code>function</code> <p>function which takes results_ist and results_soll as arguments and calculates/returns the loss</p> required <code>variables_bounds</code> <code>dict</code> <p>Dictionary with parameter names (keys) and their bounds (values). If single values are given as values, the parameter is constant, i.e., not optimized. If a list is given as value, the parameter is optimized and the list contains the lower and upper bound of the parameter (order is not important).</p> required <code>neuron_model</code> <code>ANNarchy Neuron</code> <p>The neuron model whose parameters should be optimized.</p> required <code>results_soll</code> <code>Any</code> <p>Some variable which contains the target data and can be used by the get_loss_function (second argument of get_loss_function)</p> <p>Warning</p> <p>Either provide results_soll or a target_neuron_model not both!</p> <p>Default: None.</p> <code>None</code> <code>target_neuron_model</code> <code>ANNarchy Neuron</code> <p>The neuron model which produces the target data by running the experiment.</p> <p>Warning</p> <p>Either provide results_soll or a target_neuron_model not both!</p> <p>Default: None.</p> <code>None</code> <code>time_step</code> <code>float</code> <p>The time step for the simulation in ms. Default: 1.</p> <code>1.0</code> <code>compile_folder_name</code> <code>string</code> <p>The name of the annarchy compilation folder within annarchy_folders/. Default: 'annarchy_OptNeuron'.</p> <code>'annarchy_OptNeuron'</code> <code>num_rep_loss</code> <code>int</code> <p>Only interesting for noisy simulations/models. How often should the simulaiton be run to calculate the loss (the defined number of losses is obtained and averaged). Default: 1.</p> <code>1</code> <code>method</code> <code>str</code> <p>Either 'sbi' or 'hyperopt'. If 'sbi' is used, the optimization is performed with sbi. If 'hyperopt' is used, the optimization is performed with hyperopt. Default: 'hyperopt'.</p> <code>'hyperopt'</code> <code>prior</code> <code>distribution</code> <p>The prior distribution used by sbi. Default: None, i.e., uniform distributions between the variable bounds are assumed.</p> <code>None</code> <code>fv_space</code> <code>list</code> <p>The search space for hyperopt. Default: None, i.e., uniform distributions between the variable bounds are assumed.</p> <code>None</code> <code>record</code> <code>list</code> <p>List of strings which define what variables of the tuned neuron should be recorded. Default: [].</p> <code>[]</code> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>def __init__(\n    self,\n    experiment: Type[CompNeuroExp],\n    get_loss_function: Callable[[Any, Any], float | list[float]],\n    variables_bounds: dict[str, float | list[float]],\n    neuron_model: Neuron,\n    results_soll: Any | None = None,\n    target_neuron_model: Neuron | None = None,\n    time_step: float | None = 1.0,\n    compile_folder_name: str = \"annarchy_OptNeuron\",\n    num_rep_loss: int = 1,\n    method: str = \"hyperopt\",\n    prior=None,\n    fv_space: list = None,\n    record: list[str] = [],\n):\n    \"\"\"\n    This prepares the optimization. To run the optimization call the run function.\n\n    Args:\n        experiment (CompNeuroExp class):\n            CompNeuroExp class containing a 'run' function which defines the\n            simulations and recordings\n\n        get_loss_function (function):\n            function which takes results_ist and results_soll as arguments and\n            calculates/returns the loss\n\n        variables_bounds (dict):\n            Dictionary with parameter names (keys) and their bounds (values). If\n            single values are given as values, the parameter is constant, i.e., not\n            optimized. If a list is given as value, the parameter is optimized and\n            the list contains the lower and upper bound of the parameter (order is\n            not important).\n\n        neuron_model (ANNarchy Neuron):\n            The neuron model whose parameters should be optimized.\n\n        results_soll (Any, optional):\n            Some variable which contains the target data and can be used by the\n            get_loss_function (second argument of get_loss_function)\n            !!! warning\n                Either provide results_soll or a target_neuron_model not both!\n            Default: None.\n\n        target_neuron_model (ANNarchy Neuron, optional):\n            The neuron model which produces the target data by running the\n            experiment.\n            !!! warning\n                Either provide results_soll or a target_neuron_model not both!\n            Default: None.\n\n        time_step (float, optional):\n            The time step for the simulation in ms. Default: 1.\n\n        compile_folder_name (string, optional):\n            The name of the annarchy compilation folder within annarchy_folders/.\n            Default: 'annarchy_OptNeuron'.\n\n        num_rep_loss (int, optional):\n            Only interesting for noisy simulations/models. How often should the\n            simulaiton be run to calculate the loss (the defined number of losses\n            is obtained and averaged). Default: 1.\n\n        method (str, optional):\n            Either 'sbi' or 'hyperopt'. If 'sbi' is used, the optimization is\n            performed with sbi. If 'hyperopt' is used, the optimization is\n            performed with hyperopt. Default: 'hyperopt'.\n\n        prior (distribution, optional):\n            The prior distribution used by sbi. Default: None, i.e., uniform\n            distributions between the variable bounds are assumed.\n\n        fv_space (list, optional):\n            The search space for hyperopt. Default: None, i.e., uniform\n            distributions between the variable bounds are assumed.\n\n        record (list, optional):\n            List of strings which define what variables of the tuned neuron should\n            be recorded. Default: [].\n    \"\"\"\n\n    if len(self.opt_created) &gt; 0:\n        print(\n            \"OptNeuron: Error: Already another OptNeuron created. Only create one per python session!\"\n        )\n        quit()\n    else:\n        print(\n            \"OptNeuron: Initialize OptNeuron... do not create anything with ANNarchy before!\"\n        )\n\n        ### set object variables\n        self.opt_created.append(1)\n        self.record = record\n        self.results_soll = results_soll\n        self.experiment = experiment\n        self.variables_bounds = variables_bounds\n        self.fitting_variables_name_list = self._get_fitting_variables_name_list()\n        self.method = method\n        if method == \"hyperopt\":\n            if fv_space is None:\n                self.fv_space = self._get_hyperopt_space()\n            else:\n                self.fv_space = fv_space\n        self.const_params = self._get_const_params()\n        self.num_rep_loss = num_rep_loss\n        self.neuron_model = neuron_model\n        if method == \"sbi\":\n            self.prior = self._get_prior(prior)\n        self.target_neuron = target_neuron_model\n        self.compile_folder_name = compile_folder_name\n        self.__get_loss__ = get_loss_function\n\n        ### check target_neuron/results_soll\n        self._check_target()\n        ### check neuron models\n        self._check_neuron_models()\n\n        ### setup ANNarchy\n        setup(dt=time_step)\n\n        ### create and compile model\n        ### if neuron models and target neuron model --&gt; create both models then test,\n        ### then clear and create only model for neuron model\n        model, target_model, monitors = self._generate_models()\n\n        self.pop = model.populations[0]\n        if target_model is not None:\n            self.pop_target = target_model.populations[0]\n        else:\n            self.pop_target = None\n        self.monitors = monitors\n\n        ### check variables of model\n        self._test_variables()\n\n        ### check neuron models, experiment, get_loss\n        ### if results_soll is None -_&gt; generate results_soll\n        self._check_get_loss_function()\n\n        ### after checking neuron models, experiment, get_loss\n        ### if two models exist --&gt; clear ANNarchy and create/compile again only standard model\n        clear()\n        model, _, monitors = self._generate_models()\n        self.monitors = monitors\n</code></pre>"},{"location":"main/optimize_neuron/#src.CompNeuroPy.opt_neuron.OptNeuron.run","title":"<code>run(max_evals, results_file_name='best.npy', sbi_plot_file='posterior.svg')</code>","text":"<p>Runs the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>max_evals</code> <code>int</code> <p>number of runs the optimization method performs</p> required <code>results_file_name</code> <code>str</code> <p>name of the file which is saved. The file contains the optimized and target results, the obtained parameters, the loss, and the SD of the loss (in case of noisy models with multiple runs per loss calculation) Default: \"best.npy\".</p> <code>'best.npy'</code> <code>sbi_plot_file</code> <code>str</code> <p>If you use \"sbi\": the name of the figure which will be saved and shows the posterior. Default: \"posterior.svg\".</p> <code>'posterior.svg'</code> <p>Returns:</p> Name Type Description <code>best</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>\"loss\": the loss</li> <li>\"std\": the SD of the loss (in case of noisy models with multiple     runs per loss calculation)</li> <li>\"results\": the results generated by the experiment</li> <li>\"results_soll\": the target results</li> </ul> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>@check_types()\ndef run(\n    self,\n    max_evals: int,\n    results_file_name=\"best.npy\",\n    sbi_plot_file=\"posterior.svg\",\n):\n    \"\"\"\n    Runs the optimization.\n\n    Args:\n        max_evals (int):\n            number of runs the optimization method performs\n\n        results_file_name (str, optional):\n            name of the file which is saved. The file contains the optimized and\n            target results, the obtained parameters, the loss, and the SD of the\n            loss (in case of noisy models with multiple runs per loss calculation)\n            Default: \"best.npy\".\n\n        sbi_plot_file (str, optional):\n            If you use \"sbi\": the name of the figure which will be saved and shows\n            the posterior. Default: \"posterior.svg\".\n\n    Returns:\n        best (dict):\n            dictionary containing:\n\n            - \"loss\": the loss\n            - \"std\": the SD of the loss (in case of noisy models with multiple\n                runs per loss calculation)\n            - \"results\": the results generated by the experiment\n            - \"results_soll\": the target results\n    \"\"\"\n    if self.method == \"hyperopt\":\n        ### run optimization with hyperopt and return best dict\n        best = fmin(\n            fn=self._run_simulator,\n            space=self.fv_space,\n            algo=tpe.suggest,\n            max_evals=max_evals,\n        )\n    elif self.method == \"sbi\":\n        ### run optimization with sbi and return best dict\n        best = self._run_with_sbi(max_evals, sbi_plot_file)\n    else:\n        print(\"ERROR run; method should be 'hyperopt' or 'sbi'\")\n        quit()\n    fit = self._test_fit(best)\n    best[\"loss\"] = fit[\"loss\"]\n    if self.method == \"sbi\":\n        print(\"\\tbest loss:\", best[\"loss\"])\n    best[\"all_loss\"] = fit[\"all_loss\"]\n    best[\"std\"] = fit[\"std\"]\n    best[\"results\"] = fit[\"results\"]\n    best[\"results_soll\"] = self.results_soll\n    self.results = best\n\n    ### SAVE OPTIMIZED PARAMS AND LOSS\n    sf.save_data([best], [\"parameter_fit/\" + results_file_name])\n</code></pre>"}]}