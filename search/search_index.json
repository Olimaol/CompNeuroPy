{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documentation for CompNeuroPy","text":"<p>CompNeuroPy is an assisting Python package for working with ANNarchy (GitHub, documentation, DOI). It is intended to help structure simulations with computational neuroscience models in a modular way and to make them more easily replicable. People who want to start working with ANNarchy are strongly recommended to first learn exclusively the functionality of ANNarchy. CompNeuroPy uses very few features of ANNarchy at this time. But also adds various special features.</p> <ul> <li>v1.0.0: </li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>From PyPI using pip:</p> <pre><code>pip install CompNeuroPy\n</code></pre> <p>With downloaded source code; using pip in the top-level directory of the downloaded source code:</p> <pre><code>pip install .\n</code></pre> <p>or in development mode:</p> <pre><code>pip install -e .\n</code></pre> <p>You must install ANNarchy separately, best after CompNeuroPy.</p> <pre><code>git clone https://github.com/ANNarchy/ANNarchy\ncd ANNarchy\ngit checkout develop\npip install .\ncd ..\nrm -rf ANNarchy\n</code></pre> <p>Optional install torch, sbi, and hyperopt to be able to use OptNeuron <pre><code>pip install torch sbi hyperopt\n</code></pre></p>"},{"location":"license/","title":"License","text":""},{"location":"license/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2022 Oliver Maith</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"additional/analysis_functions/","title":"Analysis Functions","text":""},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.PlotRecordings","title":"<code>PlotRecordings</code>","text":"<p>Plot recordings from CompNeuroMonitors.</p> <p>TODO: CHeck if there are memory issues with large recordings or many subplots.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>class PlotRecordings:\n    \"\"\"\n    Plot recordings from CompNeuroMonitors.\n\n    TODO: CHeck if there are memory issues with large recordings or many subplots.\n    \"\"\"\n\n    @check_types()\n    def __init__(\n        self,\n        figname: str,\n        recordings: list[dict],\n        recording_times: RecordingTimes,\n        shape: tuple[int, int],\n        plan: dict,\n        chunk: int = 0,\n        time_lim: None | tuple[float, float] = None,\n        dpi: int = 300,\n    ) -&gt; None:\n        \"\"\"\n        Create and save the plot.\n\n        Args:\n            figname (str):\n                The name of the figure to be saved.\n            recordings (list):\n                A recordings list obtained from CompNeuroMonitors.\n            recording_times (RecordingTimes):\n                The RecordingTimes object containing the recording times obtained from\n                CompNeuroMonitors.\n            shape (tuple):\n                The shape of the figure. (number of rows, number of columns)\n            plan (dict):\n                Defines which recordings are plotted in which subplot and how. The plan\n                has to contain the following keys: \"position\", \"compartment\",\n                \"variable\", \"format\". The values of the keys have to be lists of the\n                same length. The values of the key \"position\" have to be integers\n                between 1 and the number of subplots (defined by shape). The values of\n                the key \"compartment\" have to be the names of the model compartments as\n                strings. The values of the key \"variable\" have to be strings containing\n                the names of the recorded variables or equations using the recorded\n                variables. The values of the key \"format\" have to be strings defining\n                how the recordings are plotted. The following formats are available for\n                spike recordings: \"raster\", \"mean\", \"hybrid\", \"interspike\". The\n                following formats are available for other recordings: \"line\",\n                \"line_mean\", \"matrix\", \"matrix_mean\".\n            chunk (int, optional):\n                The chunk of the recordings to be plotted. Default: 0.\n            time_lim (tuple, optional):\n                Defines the x-axis for all subplots. The tuple contains two\n                numbers: start and end time in ms. The times have to be\n                within the chunk. Default: None, i.e., the whole chunk is plotted.\n            dpi (int, optional):\n                The dpi of the saved figure. Default: 300.\n        \"\"\"\n        ### print start message\n        print(f\"Generate fig {figname}\", end=\"... \", flush=True)\n\n        ### set attributes\n        self.figname = figname\n        self.recordings = recordings\n        self.recording_times = recording_times\n        self.shape = shape\n        self.plan = plan\n        self.chunk = chunk\n        self.time_lim = time_lim\n        self.dpi = dpi\n\n        ### get available compartments (from recordings) and recorded variables for each\n        ### compartment\n        (\n            self._compartment_list,\n            self._compartment_recordings_dict,\n        ) = self._get_compartment_recordings()\n\n        ### check plan keys and values\n        self._check_plan()\n\n        ### get start and end time for plotting and timestep\n        self._start_time, self._end_time, self._time_step = self._get_start_end_time()\n\n        ### get compbined time array for recordings of each compartment\n        self._time_arr_list = self._get_time_arr_list()\n\n        ### get data from recordings for each subplot\n        self._raw_data_list = self._get_raw_data_list()\n\n        ### create plot\n        self._plot()\n\n        ### print end message\n        print(\"Done\\n\")\n\n    def _get_compartment_recordings(self):\n        \"\"\"\n        Get available compartment names from recordings.\n        Get recorded variables (names) for each compartment.\n\n        Returns:\n            compartment_list (list):\n                List of compartment names.\n            compartment_recordings_dict (dict):\n                Dictionary with compartment names as keys and list of recorded variables\n                as values.\n        \"\"\"\n        ### check if chunk is valid\n        if self.chunk &gt;= len(self.recordings) or self.chunk &lt; 0:\n            print(\n                f\"\\nERROR PlotRecordings: chunk {self.chunk} is not valid.\\n\"\n                f\"Number of chunks: {len(self.recordings)}\\n\"\n            )\n            quit()\n\n        ### get compartment names and recorded variables for each compartment\n        compartment_list = []\n        compartment_recordings_dict = {}\n        for recordings_key in self.recordings[self.chunk].keys():\n            if \";\" not in recordings_key:\n                continue\n\n            ### get compartment\n            compartment, recorded_variable = recordings_key.split(\";\")\n            if compartment not in compartment_list:\n                compartment_list.append(compartment)\n                compartment_recordings_dict[compartment] = []\n\n            ### get recordings for compartment\n            if recorded_variable != \"period\" and recorded_variable != \"parameter_dict\":\n                compartment_recordings_dict[compartment].append(recorded_variable)\n\n        return compartment_list, compartment_recordings_dict\n\n    def _check_plan(self):\n        \"\"\"\n        Check if plan is valid.\n        \"\"\"\n\n        ### check if plan keys are valid\n        valid_keys = [\"position\", \"compartment\", \"variable\", \"format\"]\n        for key in self.plan.keys():\n            if key not in valid_keys:\n                print(\n                    f\"\\nERROR PlotRecordings: plan key {key} is not valid.\\n\"\n                    f\"Valid keys are {valid_keys}.\\n\"\n                )\n                quit()\n\n        ### check if plan values are valid (have same length)\n        for key in self.plan.keys():\n            if len(self.plan[key]) != len(self.plan[\"position\"]):\n                print(\n                    f\"\\nERROR PlotRecordings: plan value of key '{key}' has not the same length as plan value of key 'position'.\\n\"\n                )\n                quit()\n\n        ### check if plan positions are valid\n        ### check if min and max are valid\n        if get_minimum(self.plan[\"position\"]) &lt; 1:\n            print(\n                f\"\\nERROR PlotRecordings: plan position has to be &gt;= 1.\\n\"\n                f\"plan position: {self.plan['position']}\\n\"\n            )\n            quit()\n        if get_maximum(self.plan[\"position\"]) &gt; self.shape[0] * self.shape[1]:\n            print(\n                f\"\\nERROR PlotRecordings: plan position has to be &lt;= shape[0] * shape[1].\\n\"\n                f\"plan position: {self.plan['position']}\\n\"\n                f\"shape: {self.shape}\\n\"\n            )\n            quit()\n        ### check if plan positions are unique\n        if len(np.unique(self.plan[\"position\"])) != len(self.plan[\"position\"]):\n            print(\n                f\"\\nERROR PlotRecordings: plan position has to be unique.\\n\"\n                f\"plan position: {self.plan['position']}\\n\"\n            )\n            quit()\n\n        ### check if plan compartments are valid\n        for compartment in self.plan[\"compartment\"]:\n            if compartment not in self._compartment_list:\n                print(\n                    f\"\\nERROR PlotRecordings: plan compartment {compartment} is not valid.\\n\"\n                    f\"Valid compartments are {self._compartment_list}.\\n\"\n                )\n                quit()\n\n        ### check if plan variables are valid\n        for plot_idx in range(len(self.plan[\"variable\"])):\n            compartment = self.plan[\"compartment\"][plot_idx]\n            variable: str = self.plan[\"variable\"][plot_idx]\n            ### check if variable contains a mathematical expression\n            if \"+\" in variable or \"-\" in variable or \"*\" in variable or \"/\" in variable:\n                ### separate variables\n                variable = variable.replace(\" \", \"\")\n                variable = variable.replace(\"+\", \" \")\n                variable = variable.replace(\"-\", \" \")\n                variable = variable.replace(\"*\", \" \")\n                variable = variable.replace(\"/\", \" \")\n                variables_list = variable.split(\" \")\n                ### remove numbers\n                variables_list = [var for var in variables_list if not var.isdigit()]\n                ### spike and axon_spike are not allowed in equations\n                if \"spike\" in variables_list or \"axon_spike\" in variables_list:\n                    print(\n                        f\"\\nERROR PlotRecordings: plan variable {variable} is not valid.\\n\"\n                        f\"Variables 'spike' and 'axon_spike' are not allowed in equations.\\n\"\n                    )\n                    quit()\n            else:\n                variables_list = [variable]\n            ### check if variables are valid\n            for var in variables_list:\n                if var not in self._compartment_recordings_dict[compartment]:\n                    print(\n                        f\"\\nERROR PlotRecordings: plan variable {var} is not valid for compartment {compartment}.\\n\"\n                        f\"Valid variables are {self._compartment_recordings_dict[compartment]}.\\n\"\n                    )\n                    quit()\n\n        ### check if plan formats are valid\n        valid_formats_spike = [\"raster\", \"mean\", \"hybrid\", \"interspike\", \"cv\"]\n        valid_formats_other = [\"line\", \"line_mean\", \"matrix\", \"matrix_mean\"]\n        for plot_idx in range(len(self.plan[\"format\"])):\n            variable = self.plan[\"variable\"][plot_idx]\n            format = self.plan[\"format\"][plot_idx]\n            ### check if format is valid\n            if variable == \"spike\" or variable == \"axon_spike\":\n                if format not in valid_formats_spike:\n                    print(\n                        f\"\\nERROR PlotRecordings: plan format {format} is not valid for variable {variable}.\\n\"\n                        f\"Valid formats are {valid_formats_spike}.\\n\"\n                    )\n                    quit()\n            else:\n                if format not in valid_formats_other:\n                    print(\n                        f\"\\nERROR PlotRecordings: plan format {format} is not valid for variable {variable}.\\n\"\n                        f\"Valid formats are {valid_formats_other}.\\n\"\n                    )\n                    quit()\n\n    def _get_start_end_time(self):\n        \"\"\"\n        Check if time_lim is given and valid. If it's not given get it from recordings.\n        Get timestep from recordings.\n\n        Returns:\n            start_time (float):\n                The start time of the recordings.\n            end_time (float):\n                The end time of the recordings.\n            time_step (float):\n                The timestep of the recordings.\n\n        Raises:\n            ValueError: If given time_lim is not within the chunk.\n        \"\"\"\n        ### get time limits of chunk of each compartment (use try because not all\n        ### compartments have to be recorded)\n        chunk_time_lims_list = []\n        for compartment in self._compartment_list:\n            try:\n                chunk_time_lims = self.recording_times.time_lims(\n                    chunk=self.chunk, compartment=compartment\n                )\n                chunk_time_lims_list.append(chunk_time_lims)\n            except:\n                continue\n        ### use the minimum and maximum of the time limits of the chunk as chunk time\n        ### limits\n        chunk_time_lims = (\n            get_minimum(np.array(chunk_time_lims_list)[:, 0]),\n            get_maximum(np.array(chunk_time_lims_list)[:, 1]),\n        )\n        ### check if time_lim is given\n        if isinstance(self.time_lim, type(None)):\n            ### get start and end time from recording_times\n            start_time, end_time = chunk_time_lims\n        else:\n            ### check if time_lim is within chunk\n            if (\n                self.time_lim[0] &lt; chunk_time_lims[0]\n                or self.time_lim[1] &gt; chunk_time_lims[1]\n            ):\n                raise ValueError(\n                    f\"\\nERROR PlotRecordings: time_lim {self.time_lim} is not within chunk.\\n\"\n                    f\"chunk time lims: {chunk_time_lims[0]} - {chunk_time_lims[1]}\\n\"\n                )\n            start_time, end_time = self.time_lim\n\n        ### get timestep\n        time_step = self.recordings[self.chunk][\"dt\"]\n\n        return start_time, end_time, time_step\n\n    def _get_time_arr_list(self):\n        \"\"\"\n        Get combined time array for each subplot of plan.\n\n        Returns:\n            time_arr_list (list):\n                List with time arrays for each subplot of plan.\n        \"\"\"\n        ### loop over compartments of plan\n        time_arr_dict = {}\n        for compartment in np.unique(self.plan[\"compartment\"]):\n            actual_period = self.recordings[self.chunk][f\"{compartment};period\"]\n\n            ### get time array for each recording period of the chunk\n            time_arr_period_list = []\n            nr_periods = self.recording_times._get_nr_periods(\n                chunk=self.chunk, compartment=compartment\n            )\n            for period in range(nr_periods):\n                time_lims = self.recording_times.time_lims(\n                    chunk=self.chunk, compartment=compartment, period=period\n                )\n                start_time_preiod = time_lims[0]\n                end_time_period = round(\n                    time_lims[1] + actual_period, get_number_of_decimals(actual_period)\n                )\n                time_arr_period_list.append(\n                    np.arange(start_time_preiod, end_time_period, actual_period)\n                )\n\n            ### combine time arrays of periods\n            time_arr_dict[compartment] = np.concatenate(time_arr_period_list)\n\n        ### get time array for each subplot of plan\n        time_arr_list = []\n        for plot_idx in range(len(self.plan[\"position\"])):\n            compartment = self.plan[\"compartment\"][plot_idx]\n            time_arr_list.append(time_arr_dict[compartment])\n\n        return time_arr_list\n\n    def _get_raw_data_list(self):\n        \"\"\"\n        Get raw data for each subplot of plan.\n\n        Returns:\n            data_list (dict):\n                List with data for each subplot of plan.\n        \"\"\"\n        data_list = []\n        ### loop over subplots of plan\n        for plot_idx in range(len(self.plan[\"position\"])):\n            compartment = self.plan[\"compartment\"][plot_idx]\n            variable: str = self.plan[\"variable\"][plot_idx]\n            ### check if variable is equation\n            if \"+\" in variable or \"-\" in variable or \"*\" in variable or \"/\" in variable:\n                ### get the values of the recorded variables of the compartment, store\n                ### them in dict\n                value_dict = {\n                    rec_var_name: self.recordings[self.chunk][\n                        f\"{compartment};{rec_var_name}\"\n                    ]\n                    for rec_var_name in self._compartment_recordings_dict[compartment]\n                }\n                ### evaluate equation with these values\n                variable_data = ef.evaluate_expression_with_dict(\n                    expression=variable, value_dict=value_dict\n                )\n            else:\n                ### get data from recordings\n                variable_data = self.recordings[self.chunk][f\"{compartment};{variable}\"]\n            ### append data to data_list\n            data_list.append(variable_data)\n\n        return data_list\n\n    def _plot(self):\n        \"\"\"\n        Create plot.\n        \"\"\"\n        ### create figure\n        plt.figure(figsize=([6.4 * self.shape[1], 4.8 * self.shape[0]]))\n\n        ### loop over subplots of plan\n        for plot_idx in range(len(self.plan[\"position\"])):\n            ### create subplot\n            plt.subplot(self.shape[0], self.shape[1], self.plan[\"position\"][plot_idx])\n\n            ### fill subplot\n            self._fill_subplot(plot_idx)\n\n        ### save figure\n        plt.tight_layout()\n        figname_parts = self.figname.split(\"/\")\n        if len(figname_parts) &gt; 1:\n            save_dir = \"/\".join(figname_parts[:-1])\n            sf.create_dir(save_dir)\n        plt.savefig(self.figname, dpi=self.dpi)\n        plt.close()\n\n    def _fill_subplot(self, plot_idx):\n        \"\"\"\n        Fill subplot with data.\n\n        Args:\n            plot_idx (int):\n                The index of the subplot in the plan.\n        \"\"\"\n        variable: str = self.plan[\"variable\"][plot_idx]\n\n        ### general subplot settings\n        plt.xlabel(\"time [ms]\")\n        plt.xlim(self._start_time, self._end_time)\n\n        if variable == \"spike\" or variable == \"axon_spike\":\n            ### spike recordings\n            self._fill_subplot_spike(plot_idx)\n        else:\n            ### other (array) recordings\n            self._fill_subplot_other(plot_idx)\n\n    def _fill_subplot_spike(self, plot_idx):\n        \"\"\"\n        Fill subplot with spike data.\n\n        Args:\n            plot_idx (int):\n                The index of the subplot in the plan.\n        \"\"\"\n        ### get data\n        compartment = self.plan[\"compartment\"][plot_idx]\n        format: str = self.plan[\"format\"][plot_idx]\n        data = self._raw_data_list[plot_idx]\n\n        ### get spike times and ranks\n        spike_times, spike_ranks = my_raster_plot(data)\n        spike_times = spike_times * self._time_step\n\n        ### get spikes within time_lims\n        mask: np.ndarray = (\n            (spike_times &gt;= self._start_time).astype(int)\n            * (spike_times &lt;= self._end_time).astype(int)\n        ).astype(bool)\n\n        ### check if there are no spikes\n        if mask.size == 0:\n            ### set title\n            plt.title(f\"Spikes {compartment}\")\n            ### print warning\n            print(\n                f\"\\n  WARNING PlotRecordings: {compartment} does not contain any spikes in the given time interval.\"\n            )\n            ### plot text\n            plt.text(\n                0.5,\n                0.5,\n                f\"{compartment} does not contain any spikes.\",\n                va=\"center\",\n                ha=\"center\",\n            )\n            plt.xticks([])\n            plt.yticks([])\n            plt.xlim(0, 1)\n            plt.xlabel(\"\")\n            return\n\n        ### plot raster plot\n        if format == \"raster\" or format == \"hybrid\":\n            self._raster_plot(compartment, spike_ranks, spike_times, mask)\n\n        ### plot mean firing rate\n        if format == \"mean\" or format == \"hybrid\":\n            self._mean_firing_rate_plot(compartment, data, format)\n\n        ### plot interspike interval histogram\n        if format == \"interspike\":\n            self._interspike_interval_plot(compartment, data)\n\n        ### plot coefficient of variation histogram\n        if format == \"cv\":\n            self._coefficient_of_variation_plot(compartment, data)\n\n    def _raster_plot(self, compartment, spike_ranks, spike_times, mask):\n        \"\"\"\n        Plot raster plot.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            spike_ranks (array):\n                The spike ranks.\n            spike_times (array):\n                The spike times.\n            mask (array):\n                The mask for the spike times.\n        \"\"\"\n        ### set title\n        plt.title(f\"Spikes {compartment} ({spike_ranks.max() + 1})\")\n        ### check if there is only one neuron\n        if spike_ranks.max() == 0:\n            marker, size = [\"|\", 3000]\n        else:\n            marker, size = [\".\", 3]\n        ### plot spikes\n        plt.scatter(\n            spike_times[mask],\n            spike_ranks[mask],\n            color=\"k\",\n            marker=marker,\n            s=size,\n            linewidth=0.1,\n        )\n        ### set limits\n        plt.ylim(-0.5, spike_ranks.max() + 0.5)\n        ### set ylabel\n        plt.ylabel(\"# neurons\")\n        ### set yticks\n        if spike_ranks.max() == 0:\n            plt.yticks([0])\n        else:\n            plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n\n    def _mean_firing_rate_plot(self, compartment, data, format):\n        \"\"\"\n        Plot mean firing rate.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            data (array):\n                The spike data.\n            format (str):\n                The format of the plot.\n        \"\"\"\n        ### set title\n        plt.title(f\"Activity {compartment} ({len(data)})\")\n        ### set axis\n        ax = plt.gca()\n        color = \"k\"\n        ### for hybrid format plot mean firing rate in second y-axis\n        if format == \"hybrid\":\n            ax = plt.gca().twinx()\n            color = \"r\"\n        ### get mean firing rate\n        time_arr, firing_rate = get_pop_rate(\n            spikes=data,\n            t_start=self._start_time,\n            t_end=self._end_time,\n            time_step=self._time_step,\n        )\n        ### plot mean firing rate\n        ax.plot(time_arr, firing_rate, color=color)\n        ### set limits\n        ax.set_xlim(self._start_time, self._end_time)\n        ### set ylabel\n        ax.set_ylabel(\"Mean firing rate [Hz]\", color=color)\n        ax.tick_params(axis=\"y\", colors=color)\n\n    def _interspike_interval_plot(self, compartment, data):\n        \"\"\"\n        Plot interspike interval histogram.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            data (dict):\n                The spike data.\n        \"\"\"\n        ### set title\n        plt.title(f\"Interspike interval histogram {compartment} ({len(data)})\")\n        ### get interspike intervals\n        interspike_intervals_list = inter_spike_interval(spikes=data)\n        ### plot histogram\n        plt.hist(\n            interspike_intervals_list,\n            bins=100,\n            range=(0, 200),\n            density=True,\n            color=\"k\",\n        )\n        ### set limits\n        plt.xlim(0, 200)\n        ### set ylabel\n        plt.ylabel(\"Probability\")\n        plt.xlabel(\"Interspike interval [ms]\")\n\n    def _coefficient_of_variation_plot(self, compartment, data):\n        \"\"\"\n        Plot coefficient of variation histogram.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            data (dict):\n                The spike data.\n        \"\"\"\n        ### set title\n        plt.title(f\"Coefficient of variation histogram {compartment} ({len(data)})\")\n        ### get coefficient of variation\n        coefficient_of_variation_dict = coefficient_of_variation(\n            spikes=data,\n            per_neuron=True,\n        )\n        coefficient_of_variation_list = list(coefficient_of_variation_dict.values())\n        ### plot histogram\n        plt.hist(\n            coefficient_of_variation_list,\n            bins=100,\n            range=(0, 2),\n            density=True,\n            color=\"k\",\n        )\n        ### set limits\n        plt.xlim(0, 2)\n        ### set ylabel\n        plt.ylabel(\"Probability\")\n        plt.xlabel(\"Coefficient of variation\")\n\n    def _fill_subplot_other(self, plot_idx):\n        \"\"\"\n        Fill subplot with array data.\n\n        Args:\n            plot_idx (int):\n                The index of the subplot in the plan.\n        \"\"\"\n        ### get data\n        compartment = self.plan[\"compartment\"][plot_idx]\n        variable: str = self.plan[\"variable\"][plot_idx]\n        format: str = self.plan[\"format\"][plot_idx]\n        data_arr = self._raw_data_list[plot_idx]\n        time_arr = self._time_arr_list[plot_idx]\n\n        ### get data within time_lims\n        mask: np.ndarray = (\n            (time_arr &gt;= self._start_time).astype(int)\n            * (time_arr &lt;= self._end_time).astype(int)\n        ).astype(bool)\n\n        ### fill gaps in time_arr and data_arr with nan\n        time_arr, data_arr = time_data_add_nan(\n            time_arr=time_arr[mask], data_arr=data_arr[mask], axis=0\n        )\n\n        ### plot line plot\n        if \"line\" in format:\n            self._line_plot(\n                compartment,\n                variable,\n                time_arr,\n                data_arr,\n                plot_idx,\n                mean=\"mean\" in format,\n            )\n\n        ### plot matrix plot\n        if \"matrix\" in format:\n            self._matrix_plot(\n                compartment,\n                variable,\n                time_arr,\n                data_arr,\n                plot_idx,\n                mean=\"mean\" in format,\n            )\n\n    def _line_plot(self, compartment, variable, time_arr, data_arr, plot_idx, mean):\n        \"\"\"\n        Plot line plot.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            variable (str):\n                The name of the variable.\n            time_arr (array):\n                The time array.\n            data_arr (array):\n                The data array.\n            plot_idx (int):\n                The index of the subplot in the plan.\n            mean (bool):\n                If True, plot the mean of the data. Population: average over neurons.\n                Projection: average over preneurons (results in one line for each\n                postneuron).\n        \"\"\"\n\n        ### set title\n        plt.title(f\"Variable {variable} of {compartment} ({data_arr.shape[1]})\")\n\n        ### Shape of data defines how to plot\n        ### 2D array where elements are no lists\n        ### = population data [time, neurons]\n        ### --&gt; plot line for each neuron\n        if len(data_arr.shape) == 2 and isinstance(data_arr[0, 0], list) is not True:\n            ### mean -&gt; average over neurons\n            if mean:\n                data_arr = np.mean(data_arr, 1, keepdims=True)\n            ### plot line for each neuron\n            for neuron in range(data_arr.shape[1]):\n                plt.plot(\n                    time_arr,\n                    data_arr[:, neuron],\n                    color=\"k\",\n                )\n\n        ### 2D array where elements are lists\n        ### = projection data [time, postneurons][preneurons]\n        ### 3D array\n        ### = projection data [time, postneurons, preneurons]\n        ### --&gt; plot line for each preneuron postneuron pair\n        elif len(data_arr.shape) == 3 or (\n            len(data_arr.shape) == 2 and isinstance(data_arr[0, 0], list) is True\n        ):\n            ### plot line for each preneuron postneuron pair\n            for post_neuron in range(data_arr.shape[1]):\n                ### the post_neuron has a constant number of preneurons\n                ### --&gt; create array with preneuron indices [time, preneurons]\n                post_neuron_data = np.array(data_arr[:, post_neuron])\n                ### mean -&gt; average over preneurons\n                if mean:\n                    post_neuron_data = np.mean(post_neuron_data, 1, keepdims=True)\n                for pre_neuron in range(post_neuron_data.shape[1]):\n                    plt.plot(\n                        time_arr,\n                        post_neuron_data[:, pre_neuron],\n                        color=\"k\",\n                    )\n        else:\n            print(\n                f\"\\nERROR PlotRecordings: shape of data not supported, {compartment}, {variable} in plot {plot_idx}.\\n\"\n            )\n\n    def _matrix_plot(self, compartment, variable, time_arr, data_arr, plot_idx, mean):\n        \"\"\"\n        Plot matrix plot.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            variable (str):\n                The name of the variable.\n            time_arr (array):\n                The time array.\n            data_arr (array):\n                The data array.\n            plot_idx (int):\n                The index of the subplot in the plan.\n            mean (bool):\n                If True, plot the mean of the data. Population: average over neurons.\n                Projection: average over preneurons (results in one line for each\n                postneuron).\n        \"\"\"\n        ### number of neurons i.e. postneurons\n        nr_neurons = data_arr.shape[1]\n\n        ### Shape of data defines how to plot\n        ### 2D array where elements are no lists\n        ### = population data [time, neurons]\n        ### --&gt; plot matrix row for each neuron\n        ### mean -&gt; average over neurons\n        if len(data_arr.shape) == 2 and isinstance(data_arr[0, 0], list) is not True:\n            ### mean -&gt; average over neurons\n            if mean:\n                data_arr = np.mean(data_arr, 1, keepdims=True)\n\n        ### 2D array where elements are lists\n        ### = projection data [time, postneurons][preneurons]\n        ### 3D array\n        ### = projection data [time, postneurons, preneurons]\n        ### --&gt; plot matrix row for each preneuron postneuron pair (has to reshape to 2D array [time, neuron pair])\n        ### mean -&gt; average over preneurons\n        elif len(data_arr.shape) == 3 or (\n            len(data_arr.shape) == 2 and isinstance(data_arr[0, 0], list) is True\n        ):\n            array_2D_list = []\n            ### loop over postneurons\n            for post_neuron in range(data_arr.shape[1]):\n                ### the post_neuron has a constant number of preneurons\n                ### --&gt; create array with preneuron indices [time, preneurons]\n                post_neuron_data = np.array(data_arr[:, post_neuron])\n                ### mean --&gt; average over preneurons\n                if mean:\n                    post_neuron_data = np.mean(post_neuron_data, 1, keepdims=True)\n                ### append all preneurons arrays to array_2D_list\n                for pre_neuron in range(post_neuron_data.shape[1]):\n                    array_2D_list.append(post_neuron_data[:, pre_neuron])\n                ### append a None array to array_2D_list to separate postneurons\n                array_2D_list.append(np.empty(post_neuron_data.shape[0]) * np.nan)\n\n            ### convert array_2D_list to 2D array, not use last None array\n            data_arr = np.array(array_2D_list[:-1]).T\n\n        ### some other shape not supported\n        else:\n            print(\n                f\"\\nERROR PlotRecordings: shape of data not supported, {compartment}, {variable} in plot {plot_idx}.\\n\"\n            )\n\n        ### plot matrix row for each neuron or preneuron postneuron pair\n        plt.imshow(\n            data_arr.T,\n            aspect=\"auto\",\n            vmin=np.nanmin(data_arr),\n            vmax=np.nanmax(data_arr),\n            extent=[\n                time_arr.min()\n                - self.recordings[self.chunk][f\"{compartment};period\"] / 2,\n                time_arr.max()\n                + self.recordings[self.chunk][f\"{compartment};period\"] / 2,\n                data_arr.shape[1] - 0.5,\n                -0.5,\n            ],\n            cmap=\"viridis\",\n            interpolation=\"none\",\n        )\n        if data_arr.shape[1] == 1:\n            plt.yticks([0])\n        else:\n            ### all y ticks\n            y_tick_positions_all_arr = np.arange(data_arr.shape[1])\n            ### boolean array of valid y ticks\n            valid_y_ticks = np.logical_not(np.isnan(data_arr).any(axis=0))\n            ### get y tick labels\n            if False in valid_y_ticks:\n                ### there are nan entries\n                ### split at nan entries\n                y_tick_positions_split_list = np.array_split(\n                    y_tick_positions_all_arr, np.where(np.logical_not(valid_y_ticks))[0]\n                )\n                ### decrease by 1 after each nan entry\n                y_tick_positions_split_list = [\n                    y_tick_positions_split - idx_split\n                    for idx_split, y_tick_positions_split in enumerate(\n                        y_tick_positions_split_list\n                    )\n                ]\n                ### join split arrays\n                y_tick_labels_all_arr = np.concatenate(y_tick_positions_split_list)\n            else:\n                y_tick_labels_all_arr = y_tick_positions_all_arr\n\n            valid_y_ticks_selected_idx_arr = np.linspace(\n                0,\n                np.sum(valid_y_ticks),\n                num=min([10, np.sum(valid_y_ticks)]),\n                dtype=int,\n                endpoint=False,\n            )\n            valid_y_ticks_selected_arr = y_tick_positions_all_arr[valid_y_ticks][\n                valid_y_ticks_selected_idx_arr\n            ]\n            valid_y_ticks_labels_selected_arr = y_tick_labels_all_arr[valid_y_ticks][\n                valid_y_ticks_selected_idx_arr\n            ]\n\n            plt.yticks(valid_y_ticks_selected_arr, valid_y_ticks_labels_selected_arr)\n\n        ### set title\n        plt.title(\n            f\"Variable {variable} of {compartment} ({nr_neurons}) [{ef.sci(np.nanmin(data_arr))}, {ef.sci(np.nanmax(data_arr))}]\"\n        )\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.PlotRecordings.__init__","title":"<code>__init__(figname, recordings, recording_times, shape, plan, chunk=0, time_lim=None, dpi=300)</code>","text":"<p>Create and save the plot.</p> <p>Parameters:</p> Name Type Description Default <code>figname</code> <code>str</code> <p>The name of the figure to be saved.</p> required <code>recordings</code> <code>list</code> <p>A recordings list obtained from CompNeuroMonitors.</p> required <code>recording_times</code> <code>RecordingTimes</code> <p>The RecordingTimes object containing the recording times obtained from CompNeuroMonitors.</p> required <code>shape</code> <code>tuple</code> <p>The shape of the figure. (number of rows, number of columns)</p> required <code>plan</code> <code>dict</code> <p>Defines which recordings are plotted in which subplot and how. The plan has to contain the following keys: \"position\", \"compartment\", \"variable\", \"format\". The values of the keys have to be lists of the same length. The values of the key \"position\" have to be integers between 1 and the number of subplots (defined by shape). The values of the key \"compartment\" have to be the names of the model compartments as strings. The values of the key \"variable\" have to be strings containing the names of the recorded variables or equations using the recorded variables. The values of the key \"format\" have to be strings defining how the recordings are plotted. The following formats are available for spike recordings: \"raster\", \"mean\", \"hybrid\", \"interspike\". The following formats are available for other recordings: \"line\", \"line_mean\", \"matrix\", \"matrix_mean\".</p> required <code>chunk</code> <code>int</code> <p>The chunk of the recordings to be plotted. Default: 0.</p> <code>0</code> <code>time_lim</code> <code>tuple</code> <p>Defines the x-axis for all subplots. The tuple contains two numbers: start and end time in ms. The times have to be within the chunk. Default: None, i.e., the whole chunk is plotted.</p> <code>None</code> <code>dpi</code> <code>int</code> <p>The dpi of the saved figure. Default: 300.</p> <code>300</code> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    figname: str,\n    recordings: list[dict],\n    recording_times: RecordingTimes,\n    shape: tuple[int, int],\n    plan: dict,\n    chunk: int = 0,\n    time_lim: None | tuple[float, float] = None,\n    dpi: int = 300,\n) -&gt; None:\n    \"\"\"\n    Create and save the plot.\n\n    Args:\n        figname (str):\n            The name of the figure to be saved.\n        recordings (list):\n            A recordings list obtained from CompNeuroMonitors.\n        recording_times (RecordingTimes):\n            The RecordingTimes object containing the recording times obtained from\n            CompNeuroMonitors.\n        shape (tuple):\n            The shape of the figure. (number of rows, number of columns)\n        plan (dict):\n            Defines which recordings are plotted in which subplot and how. The plan\n            has to contain the following keys: \"position\", \"compartment\",\n            \"variable\", \"format\". The values of the keys have to be lists of the\n            same length. The values of the key \"position\" have to be integers\n            between 1 and the number of subplots (defined by shape). The values of\n            the key \"compartment\" have to be the names of the model compartments as\n            strings. The values of the key \"variable\" have to be strings containing\n            the names of the recorded variables or equations using the recorded\n            variables. The values of the key \"format\" have to be strings defining\n            how the recordings are plotted. The following formats are available for\n            spike recordings: \"raster\", \"mean\", \"hybrid\", \"interspike\". The\n            following formats are available for other recordings: \"line\",\n            \"line_mean\", \"matrix\", \"matrix_mean\".\n        chunk (int, optional):\n            The chunk of the recordings to be plotted. Default: 0.\n        time_lim (tuple, optional):\n            Defines the x-axis for all subplots. The tuple contains two\n            numbers: start and end time in ms. The times have to be\n            within the chunk. Default: None, i.e., the whole chunk is plotted.\n        dpi (int, optional):\n            The dpi of the saved figure. Default: 300.\n    \"\"\"\n    ### print start message\n    print(f\"Generate fig {figname}\", end=\"... \", flush=True)\n\n    ### set attributes\n    self.figname = figname\n    self.recordings = recordings\n    self.recording_times = recording_times\n    self.shape = shape\n    self.plan = plan\n    self.chunk = chunk\n    self.time_lim = time_lim\n    self.dpi = dpi\n\n    ### get available compartments (from recordings) and recorded variables for each\n    ### compartment\n    (\n        self._compartment_list,\n        self._compartment_recordings_dict,\n    ) = self._get_compartment_recordings()\n\n    ### check plan keys and values\n    self._check_plan()\n\n    ### get start and end time for plotting and timestep\n    self._start_time, self._end_time, self._time_step = self._get_start_end_time()\n\n    ### get compbined time array for recordings of each compartment\n    self._time_arr_list = self._get_time_arr_list()\n\n    ### get data from recordings for each subplot\n    self._raw_data_list = self._get_raw_data_list()\n\n    ### create plot\n    self._plot()\n\n    ### print end message\n    print(\"Done\\n\")\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.my_raster_plot","title":"<code>my_raster_plot(spikes)</code>","text":"<p>Returns two vectors representing for each recorded spike 1) the spike times and 2) the ranks of the neurons. The spike times are always in simulation steps (in contrast to default ANNarchy raster_plot).</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dict</code> <p>ANNarchy spike dict of one population</p> required <p>Returns:</p> Name Type Description <code>t</code> <code>array</code> <p>spike times in simulation steps</p> <code>n</code> <code>array</code> <p>ranks of the neurons</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def my_raster_plot(spikes: dict):\n    \"\"\"\n    Returns two vectors representing for each recorded spike 1) the spike times and 2)\n    the ranks of the neurons. The spike times are always in simulation steps (in\n    contrast to default ANNarchy raster_plot).\n\n    Args:\n        spikes (dict):\n            ANNarchy spike dict of one population\n\n    Returns:\n        t (array):\n            spike times in simulation steps\n        n (array):\n            ranks of the neurons\n    \"\"\"\n    t, n = raster_plot(spikes)\n    np.zeros(10)\n    t = np.round(t / dt(), 0).astype(int)\n    return t, n\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_nanmean","title":"<code>get_nanmean(a, axis=None, dtype=None)</code>","text":"<p>Same as np.nanmean but without printing warnings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Array containing numbers whose mean is desired. If <code>a</code> is not an array, a conversion is attempted.</p> required <code>axis</code> <code>None or int or tuple of ints</code> <p>Axis or axes along which the means are computed. The default is to compute the mean of the flattened array.</p> <p>.. numpy versionadded:: 1.7.0</p> <p>If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before.</p> <code>None</code> <code>dtype</code> <code>data - type</code> <p>Type to use in computing the mean.  For integer inputs, the default is <code>float64</code>; for floating point inputs, it is the same as the input dtype.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>m</code> <code>ndarray, see dtype parameter above</code> <p>If <code>out=None</code>, returns a new array containing the mean values, otherwise a reference to the output array is returned.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_nanmean(a, axis=None, dtype=None):\n    \"\"\"\n    Same as np.nanmean but without printing warnings.\n\n    Args:\n        a (array_like):\n            Array containing numbers whose mean is desired. If `a` is not an\n            array, a conversion is attempted.\n        axis (None or int or tuple of ints, optional):\n            Axis or axes along which the means are computed. The default is to\n            compute the mean of the flattened array.\n\n            .. numpy versionadded:: 1.7.0\n\n            If this is a tuple of ints, a mean is performed over multiple axes,\n            instead of a single axis or all the axes as before.\n        dtype (data-type, optional):\n            Type to use in computing the mean.  For integer inputs, the default\n            is `float64`; for floating point inputs, it is the same as the\n            input dtype.\n\n    Returns:\n        m (ndarray, see dtype parameter above):\n            If `out=None`, returns a new array containing the mean values,\n            otherwise a reference to the output array is returned.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        ret = np.nanmean(a, axis=axis, dtype=dtype)\n    return ret\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_nanstd","title":"<code>get_nanstd(a, axis=None, dtype=None)</code>","text":"<p>Same as np.nanstd but without printing warnings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Calculate the standard deviation of these values.</p> required <code>axis</code> <code>None or int or tuple of ints</code> <p>Axis or axes along which the standard deviation is computed. The default is to compute the standard deviation of the flattened array.</p> <p>.. numpy versionadded:: 1.7.0</p> <p>If this is a tuple of ints, a standard deviation is performed over multiple axes, instead of a single axis or all the axes as before.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>Type to use in computing the standard deviation. For arrays of integer type the default is float64, for arrays of float types it is the same as the array type.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>standard_deviation</code> <code>ndarray, see dtype parameter above</code> <p>If <code>out</code> is None, return a new array containing the standard deviation, otherwise return a reference to the output array.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_nanstd(a, axis=None, dtype=None):\n    \"\"\"\n    Same as np.nanstd but without printing warnings.\n\n    Args:\n        a (array_like):\n            Calculate the standard deviation of these values.\n        axis (None or int or tuple of ints, optional):\n            Axis or axes along which the standard deviation is computed. The\n            default is to compute the standard deviation of the flattened array.\n\n            .. numpy versionadded:: 1.7.0\n\n            If this is a tuple of ints, a standard deviation is performed over\n            multiple axes, instead of a single axis or all the axes as before.\n        dtype (dtype, optional):\n            Type to use in computing the standard deviation. For arrays of\n            integer type the default is float64, for arrays of float types it is\n            the same as the array type.\n\n    Returns:\n        standard_deviation (ndarray, see dtype parameter above):\n            If `out` is None, return a new array containing the standard deviation,\n            otherwise return a reference to the output array.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        ret = np.nanstd(a, axis=axis, dtype=dtype)\n    return ret\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_population_power_spectrum","title":"<code>get_population_power_spectrum(spikes, time_step, t_start=None, t_end=None, fft_size=None)</code>","text":"<p>Generates power spectrum of population spikes, returns frequency_arr and power_spectrum_arr. Using the Welch methode from: Welch, P. (1967). The use of fast Fourier transform for the estimation of power spectra: a method based on time averaging over short, modified periodograms. IEEE Transactions on audio and electroacoustics, 15(2), 70-73.</p> <p>The spike arrays are splitted into multiple arrays and then multiple FFTs are performed and the results are averaged.</p> <p>Size of splitted signals and the time step of the simulation determine the frequency resolution and the maximum frequency:     maximum frequency [Hz] = 500 / time_step     frequency resolution [Hz] = 1000 / (time_step * fftSize)</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dicitonary</code> <p>ANNarchy spike dict of one population</p> required <code>time_step</code> <code>float</code> <p>time step of the simulation in ms</p> required <code>t_start</code> <code>float or int</code> <p>start time of analyzed data in ms. Default: time of first spike</p> <code>None</code> <code>t_end</code> <code>float or int</code> <p>end time of analyzed data in ms. Default: time of last spike</p> <code>None</code> <code>fft_size</code> <code>int</code> <p>signal size for the FFT (size of splitted arrays) has to be a power of 2. Default: maximum</p> <code>None</code> <p>Returns:</p> Name Type Description <code>frequency_arr</code> <code>array</code> <p>array with frequencies</p> <code>spectrum</code> <code>array</code> <p>array with power spectrum</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_population_power_spectrum(\n    spikes,\n    time_step,\n    t_start=None,\n    t_end=None,\n    fft_size=None,\n):\n    \"\"\"\n    Generates power spectrum of population spikes, returns frequency_arr and\n    power_spectrum_arr. Using the Welch methode from: Welch, P. (1967). The use of fast\n    Fourier transform for the estimation of power spectra: a method based on time\n    averaging over short, modified periodograms. IEEE Transactions on audio and\n    electroacoustics, 15(2), 70-73.\n\n    The spike arrays are splitted into multiple arrays and then multiple FFTs are\n    performed and the results are averaged.\n\n    Size of splitted signals and the time step of the simulation determine the frequency\n    resolution and the maximum frequency:\n        maximum frequency [Hz] = 500 / time_step\n        frequency resolution [Hz] = 1000 / (time_step * fftSize)\n\n    Args:\n        spikes (dicitonary):\n            ANNarchy spike dict of one population\n        time_step (float):\n            time step of the simulation in ms\n        t_start (float or int, optional):\n            start time of analyzed data in ms. Default: time of first spike\n        t_end (float or int, optional):\n            end time of analyzed data in ms. Default: time of last spike\n        fft_size (int, optional):\n            signal size for the FFT (size of splitted arrays)\n            has to be a power of 2. Default: maximum\n\n    Returns:\n        frequency_arr (array):\n            array with frequencies\n        spectrum (array):\n            array with power spectrum\n    \"\"\"\n\n    def ms_to_s(x):\n        return x / 1000\n\n    ### get population_size / sampling_frequency\n    populations_size = len(list(spikes.keys()))\n    sampling_frequency = 1 / ms_to_s(time_step)  # in Hz\n\n    ### check if there are spikes in data\n    t, _ = my_raster_plot(spikes)\n    if len(t) &lt; 2:\n        ### there are no 2 spikes\n        print(\"WARNING: get_population_power_spectrum: &lt;2 spikes!\")\n        ### --&gt; return None or zeros\n        if fft_size == None:\n            print(\n                \"ERROR: get_population_power_spectrum: &lt;2 spikes and no fft_size given!\"\n            )\n            quit()\n        else:\n            frequency_arr = np.fft.fftfreq(fft_size, 1.0 / sampling_frequency)\n            frequency_arr_ret = frequency_arr[2 : int(fft_size / 2)]\n            spectrum_ret = np.zeros(frequency_arr_ret.shape)\n            return [frequency_arr_ret, spectrum_ret]\n\n    ### check if t_start / t_end are None\n    if t_start == None:\n        t_start = round(t.min() * time_step, get_number_of_decimals(time_step))\n    if t_end == None:\n        t_end = round(t.max() * time_step, get_number_of_decimals(time_step))\n\n    ### calculate time\n    simulation_time = round(t_end - t_start, get_number_of_decimals(time_step))  # in ms\n\n    ### get fft_size\n    ### if None --&gt; as large as possible\n    if fft_size is None:\n        pow = 1\n        while (2 ** (pow + 1)) / sampling_frequency &lt; ms_to_s(simulation_time):\n            pow = pow + 1\n        fft_size = 2**pow\n\n    if ms_to_s(simulation_time) &lt; (fft_size / sampling_frequency):\n        ### catch a too large fft_size\n        print(\n            f\"Too large fft_size {fft_size} for duration {simulation_time} ms. FFT_size has to be smaller than {int(ms_to_s(simulation_time)*sampling_frequency)}!\"\n        )\n        return [np.zeros(int(fft_size / 2 - 2)), np.zeros(int(fft_size / 2 - 2))]\n    elif (np.log2(fft_size) - int(np.log2(fft_size))) != 0:\n        ### catch fft_size if its not power of 2\n        print(\"FFT_size hast to be power of 2!\")\n        return [np.zeros(int(fft_size / 2 - 2)), np.zeros(int(fft_size / 2 - 2))]\n    else:\n        print(\n            f\"power sepctrum, min = {1000 / (time_step * fft_size)}, max = {500 / time_step}\"\n        )\n        ### calculate frequency powers\n        spectrum = np.zeros((populations_size, fft_size))\n        for neuron in range(populations_size):\n            ### sampling steps array\n            spiketrain = np.zeros(\n                int(np.round(ms_to_s(simulation_time) * sampling_frequency))\n            )\n            ### spike times as sampling steps\n            idx = (\n                np.round(\n                    ms_to_s((np.array(spikes[neuron]) * time_step)) * sampling_frequency\n                )\n            ).astype(np.int32)\n            ### cut the spikes before t_start and after t_end\n            idx_start = ms_to_s(t_start) * sampling_frequency\n            idx_end = ms_to_s(t_end) * sampling_frequency\n            mask = ((idx &gt; idx_start).astype(int) * (idx &lt; idx_end).astype(int)).astype(\n                bool\n            )\n            idx = (idx[mask] - idx_start).astype(np.int32)\n\n            ### set spiketrain array to one if there was a spike at sampling step\n            spiketrain[idx] = 1\n\n            ### generate multiple overlapping sequences out of the spike trains\n            spiketrain_sequences = _hanning_split_overlap(\n                spiketrain, fft_size, int(fft_size / 2)\n            )\n\n            ### generate power spectrum\n            spectrum[neuron] = get_nanmean(\n                np.abs(np.fft.fft(spiketrain_sequences)) ** 2, 0\n            )\n\n        ### mean spectrum over all neurons\n        spectrum = get_nanmean(spectrum, 0)\n\n        frequency_arr = np.fft.fftfreq(fft_size, 1.0 / sampling_frequency)\n\n        return (frequency_arr[2 : int(fft_size / 2)], spectrum[2 : int(fft_size / 2)])\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_power_spektrum_from_time_array","title":"<code>get_power_spektrum_from_time_array(arr, presimulationTime, simulationTime, simulation_dt, samplingfrequency=250, fftSize=1024)</code>","text":"<p>Generates power spectrum of time signal (returns frequencies_arr and power_arr). Using the Welch methode (Welch,1967).</p> <p>amplingfrequency: to sample the arr, in Hz --&gt; max frequency = samplingfrequency / 2 fftSize: signal size for FFT, duration (in s) = fftSize / samplingfrequency --&gt; frequency resolution = samplingfrequency / fftSize</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>array</code> <p>time array, value for each timestep</p> required <code>presimulationTime</code> <code>float or int</code> <p>simulation time which will not be analyzed</p> required <code>simulationTime</code> <code>float or int</code> <p>analyzed simulation time</p> required <code>simulation_dt</code> <code>float or int</code> <p>simulation timestep</p> required <code>samplingfrequency</code> <code>float or int</code> <p>sampling frequency for sampling the time array. Default: 250</p> <code>250</code> <code>fftSize</code> <code>int</code> <p>signal size for the FFT (size of splitted arrays) has to be a power of 2. Default: 1024</p> <code>1024</code> <p>Returns:</p> Name Type Description <code>frequency_arr</code> <code>array</code> <p>array with frequencies</p> <code>spectrum</code> <code>array</code> <p>array with power spectrum</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_power_spektrum_from_time_array(\n    arr,\n    presimulationTime,\n    simulationTime,\n    simulation_dt,\n    samplingfrequency=250,\n    fftSize=1024,\n):\n    \"\"\"\n    Generates power spectrum of time signal (returns frequencies_arr and power_arr).\n    Using the Welch methode (Welch,1967).\n\n    amplingfrequency: to sample the arr, in Hz --&gt; max frequency = samplingfrequency / 2\n    fftSize: signal size for FFT, duration (in s) = fftSize / samplingfrequency\n    --&gt; frequency resolution = samplingfrequency / fftSize\n\n    Args:\n        arr (array):\n            time array, value for each timestep\n        presimulationTime (float or int):\n            simulation time which will not be analyzed\n        simulationTime (float or int):\n            analyzed simulation time\n        simulation_dt (float or int):\n            simulation timestep\n        samplingfrequency (float or int, optional):\n            sampling frequency for sampling the time array. Default: 250\n        fftSize (int, optional):\n            signal size for the FFT (size of splitted arrays)\n            has to be a power of 2. Default: 1024\n\n    Returns:\n        frequency_arr (array):\n            array with frequencies\n        spectrum (array):\n            array with power spectrum\n    \"\"\"\n\n    if (simulationTime / 1000) &lt; (fftSize / samplingfrequency):\n        print(\"Simulation time has to be &gt;=\", fftSize / samplingfrequency, \"s for FFT!\")\n        return [np.zeros(int(fftSize / 2 - 2)), np.zeros(int(fftSize / 2 - 2))]\n    else:\n        ### sampling steps array\n        sampling_arr = arr[0 :: int((1 / samplingfrequency) * 1000 / simulation_dt)]\n\n        ### generate multiple overlapping sequences\n        sampling_arr_sequences = _hanning_split_overlap(\n            sampling_arr, fftSize, int(fftSize / 2)\n        )\n\n        ### generate power spectrum\n        spektrum = get_nanmean(np.abs(np.fft.fft(sampling_arr_sequences)) ** 2, 0)\n\n        frequenzen = np.fft.fftfreq(fftSize, 1.0 / samplingfrequency)\n\n        return (frequenzen[2 : int(fftSize / 2)], spektrum[2 : int(fftSize / 2)])\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_pop_rate","title":"<code>get_pop_rate(spikes, t_start=None, t_end=None, time_step=1, t_smooth_ms=-1)</code>","text":"<p>Generates a smoothed population firing rate. Returns a time array and a firing rate array.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dictionary</code> <p>ANNarchy spike dict of one population</p> required <code>t_start</code> <code>float or int</code> <p>start time of analyzed data in ms. Default: time of first spike</p> <code>None</code> <code>t_end</code> <code>float or int</code> <p>end time of analyzed data in ms. Default: time of last spike</p> <code>None</code> <code>time_step</code> <code>float or int</code> <p>time step of the simulation in ms. Default: 1</p> <code>1</code> <code>t_smooth_ms</code> <code>float or int</code> <p>time window for firing rate calculation in ms, if -1 --&gt; time window sizes are automatically detected. Default: -1</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>array with time steps in ms</p> <code>rate</code> <code>array</code> <p>array with population rate in Hz for each time step</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_pop_rate(\n    spikes: dict,\n    t_start: float | int | None = None,\n    t_end: float | int | None = None,\n    time_step: float | int = 1,\n    t_smooth_ms: float | int = -1,\n):\n    \"\"\"\n    Generates a smoothed population firing rate. Returns a time array and a firing rate\n    array.\n\n    Args:\n        spikes (dictionary):\n            ANNarchy spike dict of one population\n        t_start (float or int, optional):\n            start time of analyzed data in ms. Default: time of first spike\n        t_end (float or int, optional):\n            end time of analyzed data in ms. Default: time of last spike\n        time_step (float or int, optional):\n            time step of the simulation in ms. Default: 1\n        t_smooth_ms (float or int, optional):\n            time window for firing rate calculation in ms, if -1 --&gt; time window sizes\n            are automatically detected. Default: -1\n\n    Returns:\n        time_arr (array):\n            array with time steps in ms\n        rate (array):\n            array with population rate in Hz for each time step\n    \"\"\"\n    dt = time_step\n\n    t, _ = my_raster_plot(spikes)\n\n    ### check if there are spikes in population at all\n    if len(t) &gt; 1:\n        if t_start == None:\n            t_start = round(t.min() * time_step, get_number_of_decimals(time_step))\n        if t_end == None:\n            t_end = round(t.max() * time_step, get_number_of_decimals(time_step))\n\n        duration = round(t_end - t_start, get_number_of_decimals(time_step))\n\n        ### if t_smooth is given --&gt; use classic time_window method\n        if t_smooth_ms &gt; 0:\n            return _get_pop_rate_old(\n                spikes, duration, dt=dt, t_start=t_start, t_smooth_ms=t_smooth_ms\n            )\n        else:\n            ### concatenate all spike times and sort them\n            spike_arr = dt * np.sort(\n                np.concatenate(\n                    [np.array(spikes[neuron]).astype(int) for neuron in spikes.keys()]\n                )\n            )\n            nr_neurons = len(list(spikes.keys()))\n            nr_spikes = spike_arr.size\n\n            ### use _recursive_rate to get firing rate\n            ### spike array is splitted in time bins\n            ### time bins widths are automatically found\n            time_population_rate, population_rate = _recursive_rate(\n                spike_arr / 1000.0,\n                t0=t_start / 1000.0,\n                t1=(t_start + duration) / 1000.0,\n                duration_init=duration / 1000.0,\n                nr_neurons=nr_neurons,\n                nr_spikes=nr_spikes,\n            )\n            ### time_population_rate was returned in s --&gt; transform it into ms\n            time_population_rate = time_population_rate * 1000\n            time_arr0 = np.arange(t_start, t_start + duration, dt)\n            if len(time_population_rate) &gt; 1:\n                ### interpolate\n                interpolate_func = interp1d(\n                    time_population_rate,\n                    population_rate,\n                    kind=\"linear\",\n                    bounds_error=False,\n                    fill_value=(population_rate[0], population_rate[-1]),\n                )\n                population_rate_arr = interpolate_func(time_arr0)\n            else:\n                population_rate_arr = np.zeros(len(time_arr0))\n                mask = time_arr0 == time_population_rate[0]\n                population_rate_arr[mask] = population_rate[0]\n\n            ret = population_rate_arr\n    else:\n        if t_start == None or t_end == None:\n            return None\n        else:\n            duration = t_end - t_start\n            ret = np.zeros(int(duration / dt))\n\n    return (np.arange(t_start, t_start + duration, dt), ret)\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.plot_recordings","title":"<code>plot_recordings(figname, recordings, recording_times, chunk, shape, plan, time_lim=None, dpi=300)</code>","text":"<p>Plots the recordings of a single chunk from recordings. Plotted variables are specified in plan.</p> <p>Parameters:</p> Name Type Description Default <code>figname</code> <code>str</code> <p>path + name of figure (e.g. \"figures/my_figure.png\")</p> required <code>recordings</code> <code>list</code> <p>a recordings list from CompNeuroPy obtained with the function get_recordings() from a CompNeuroMonitors object.</p> required <code>recording_times</code> <code>object</code> <p>recording_times object from CompNeuroPy obtained with the function get_recording_times() from a CompNeuroMonitors object.</p> required <code>chunk</code> <code>int</code> <p>which chunk of recordings should be used (the index of chunk)</p> required <code>shape</code> <code>tuple</code> <p>Defines the subplot arrangement e.g. (3,2) = 3 rows, 2 columns</p> required <code>plan</code> <code>list of strings</code> <p>Defines which recordings are plotted in which subplot and how. Entries of the list have the structure:     \"subplot_nr;model_component_name;variable_to_plot;format\",     e.g. \"1,my_pop1;v;line\".     mode: defines how the data is plotted, available modes:         - for spike data: raster, mean, hybrid         - for other data: line, mean, matrix         - only for projection data: matrix_mean</p> required <code>time_lim</code> <code>tuple</code> <p>Defines the x-axis for all subplots. The list contains two numbers: start and end time in ms. The times have to be within the chunk. Default: None, i.e., time lims of chunk</p> <code>None</code> <code>dpi</code> <code>int</code> <p>The dpi of the saved figure. Default: 300</p> <code>300</code> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>@check_types()\ndef plot_recordings(\n    figname: str,\n    recordings: list,\n    recording_times: RecordingTimes,\n    chunk: int,\n    shape: tuple,\n    plan: list[str],\n    time_lim: None | tuple = None,\n    dpi: int = 300,\n):\n    \"\"\"\n    Plots the recordings of a single chunk from recordings. Plotted variables are\n    specified in plan.\n\n    Args:\n        figname (str):\n            path + name of figure (e.g. \"figures/my_figure.png\")\n        recordings (list):\n            a recordings list from CompNeuroPy obtained with the function\n            get_recordings() from a CompNeuroMonitors object.\n        recording_times (object):\n            recording_times object from CompNeuroPy obtained with the\n            function get_recording_times() from a CompNeuroMonitors object.\n        chunk (int):\n            which chunk of recordings should be used (the index of chunk)\n        shape (tuple):\n            Defines the subplot arrangement e.g. (3,2) = 3 rows, 2 columns\n        plan (list of strings):\n            Defines which recordings are plotted in which subplot and how.\n            Entries of the list have the structure:\n                \"subplot_nr;model_component_name;variable_to_plot;format\",\n                e.g. \"1,my_pop1;v;line\".\n                mode: defines how the data is plotted, available modes:\n                    - for spike data: raster, mean, hybrid\n                    - for other data: line, mean, matrix\n                    - only for projection data: matrix_mean\n        time_lim (tuple, optional):\n            Defines the x-axis for all subplots. The list contains two\n            numbers: start and end time in ms. The times have to be\n            within the chunk. Default: None, i.e., time lims of chunk\n        dpi (int, optional):\n            The dpi of the saved figure. Default: 300\n    \"\"\"\n    proc = Process(\n        target=_plot_recordings,\n        args=(figname, recordings, recording_times, chunk, shape, plan, time_lim, dpi),\n    )\n    proc.start()\n    proc.join()\n    if proc.exitcode != 0:\n        quit()\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_number_of_zero_decimals","title":"<code>get_number_of_zero_decimals(nr)</code>","text":"<p>For numbers which are smaller than zero get the number of digits after the decimal point which are zero (plus 1). For the number 0 or numbers &gt;=1 return zero, e.g.:</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>the number from which the number of digits are obtained</p> required <p>Returns:</p> Name Type Description <code>decimals</code> <code>int</code> <p>number of digits after the decimal point which are zero (plus 1)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_number_of_zero_decimals(0.12)\n1\n&gt;&gt;&gt; get_number_of_zero_decimals(0.012)\n2\n&gt;&gt;&gt; get_number_of_zero_decimals(1.012)\n0\n</code></pre> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_number_of_zero_decimals(nr):\n    \"\"\"\n    For numbers which are smaller than zero get the number of digits after the decimal\n    point which are zero (plus 1). For the number 0 or numbers &gt;=1 return zero, e.g.:\n\n    Args:\n        nr (float or int):\n            the number from which the number of digits are obtained\n\n    Returns:\n        decimals (int):\n            number of digits after the decimal point which are zero (plus 1)\n\n    Examples:\n        &gt;&gt;&gt; get_number_of_zero_decimals(0.12)\n        1\n        &gt;&gt;&gt; get_number_of_zero_decimals(0.012)\n        2\n        &gt;&gt;&gt; get_number_of_zero_decimals(1.012)\n        0\n    \"\"\"\n    decimals = 0\n    if nr != 0:\n        while abs(nr) &lt; 1:\n            nr = nr * 10\n            decimals = decimals + 1\n\n    return decimals\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_number_of_decimals","title":"<code>get_number_of_decimals(nr)</code>","text":"<p>Get number of digits after the decimal point.</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>the number from which the number of digits are obtained</p> required <p>Returns:</p> Name Type Description <code>decimals</code> <code>int</code> <p>number of digits after the decimal point</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_number_of_decimals(5)\n0\n&gt;&gt;&gt; get_number_of_decimals(5.1)\n1\n&gt;&gt;&gt; get_number_of_decimals(0.0101)\n4\n</code></pre> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_number_of_decimals(nr):\n    \"\"\"\n    Get number of digits after the decimal point.\n\n    Args:\n        nr (float or int):\n            the number from which the number of digits are obtained\n\n    Returns:\n        decimals (int):\n            number of digits after the decimal point\n\n    Examples:\n        &gt;&gt;&gt; get_number_of_decimals(5)\n        0\n        &gt;&gt;&gt; get_number_of_decimals(5.1)\n        1\n        &gt;&gt;&gt; get_number_of_decimals(0.0101)\n        4\n    \"\"\"\n\n    if nr != int(nr):\n        decimals = len(str(nr).split(\".\")[1])\n    else:\n        decimals = 0\n\n    return decimals\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.sample_data_with_timestep","title":"<code>sample_data_with_timestep(time_arr, data_arr, timestep)</code>","text":"<p>Samples a data array each timestep using interpolation</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>array</code> <p>array with data values from which will be sampled</p> required <code>timestep</code> <code>float or int</code> <p>timestep in ms for sampling</p> required <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>sampled time array</p> <code>data_arr</code> <code>array</code> <p>sampled data array</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def sample_data_with_timestep(time_arr, data_arr, timestep):\n    \"\"\"\n    Samples a data array each timestep using interpolation\n\n    Args:\n        time_arr (array):\n            times of data_arr in ms\n        data_arr (array):\n            array with data values from which will be sampled\n        timestep (float or int):\n            timestep in ms for sampling\n\n    Returns:\n        time_arr (array):\n            sampled time array\n        data_arr (array):\n            sampled data array\n    \"\"\"\n    interpolate_func = interp1d(\n        time_arr, data_arr, bounds_error=False, fill_value=\"extrapolate\"\n    )\n    min_time = round(\n        round(time_arr[0] / timestep, 0) * timestep,\n        get_number_of_decimals(timestep),\n    )\n    max_time = round(\n        round(time_arr[-1] / timestep, 0) * timestep,\n        get_number_of_decimals(timestep),\n    )\n    new_time_arr = np.arange(min_time, max_time + timestep, timestep)\n    new_data_arr = interpolate_func(new_time_arr)\n\n    return (new_time_arr, new_data_arr)\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.time_data_add_nan","title":"<code>time_data_add_nan(time_arr, data_arr, fill_time_step=None, axis=0)</code>","text":"<p>If there are gaps in time_arr --&gt; fill them with respective time values. Fill the corresponding data_arr values with nan.</p> <p>By default it is tried to fill the time array with continuously increasing times based on the smallest time difference found there can still be discontinuities after filling the arrays (because existing time values are not changed).</p> <p>But one can also give a fixed fill time step.</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>1D array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>nD array</code> <p>the size of the specified dimension of data array must have the same length as time_arr</p> required <code>fill_time_step</code> <code>number, optional, default=None</code> <p>if there are gaps they are filled with this time step</p> <code>None</code> <code>axis</code> <code>int</code> <p>which dimension of the data_arr belongs to the time_arr</p> <code>0</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>1D array</code> <p>time array with gaps filled</p> <code>data_arr</code> <code>nD array</code> <p>data array with gaps filled</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def time_data_add_nan(time_arr, data_arr, fill_time_step=None, axis=0):\n    \"\"\"\n    If there are gaps in time_arr --&gt; fill them with respective time values.\n    Fill the corresponding data_arr values with nan.\n\n    By default it is tried to fill the time array with continuously increasing times\n    based on the smallest time difference found there can still be discontinuities after\n    filling the arrays (because existing time values are not changed).\n\n    But one can also give a fixed fill time step.\n\n    Args:\n        time_arr (1D array):\n            times of data_arr in ms\n        data_arr (nD array):\n            the size of the specified dimension of data array must have the same length\n            as time_arr\n        fill_time_step (number, optional, default=None):\n            if there are gaps they are filled with this time step\n        axis (int):\n            which dimension of the data_arr belongs to the time_arr\n\n    Returns:\n        time_arr (1D array):\n            time array with gaps filled\n        data_arr (nD array):\n            data array with gaps filled\n    \"\"\"\n    return time_data_fill_gaps(\n        time_arr,\n        data_arr,\n        fill_time_step=fill_time_step,\n        axis=axis,\n        fill=\"nan\",\n    )\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.time_data_fill_gaps","title":"<code>time_data_fill_gaps(time_arr, data_arr, fill_time_step=None, axis=0, fill='nan')</code>","text":"<p>If there are gaps in time_arr --&gt; fill them with respective time values. Fill the corresponding data_arr values depending on the fill argument.</p> <p>By default it is tried to fill the time array with continuously increasing times based on the smallest time difference found there can still be discontinuities after filling the arrays (because existing time values are not changed).</p> <p>But one can also give a fixed fill time step.</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>1D array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>nD array</code> <p>the size of the specified dimension of data array must have the same length as time_arr</p> required <code>fill_time_step</code> <code>number, optional, default=None</code> <p>if there are gaps they are filled with this time step</p> <code>None</code> <code>axis</code> <code>int</code> <p>which dimension of the data_arr coresponds to the time_arr</p> <code>0</code> <code>fill</code> <code>str or float</code> <p>how to fill the data array:     \"nan\" (default): fill gaps with nan     float: fill gaps with this value</p> <code>'nan'</code> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def time_data_fill_gaps(\n    time_arr, data_arr, fill_time_step=None, axis=0, fill: str | float = \"nan\"\n):\n    \"\"\"\n    If there are gaps in time_arr --&gt; fill them with respective time values.\n    Fill the corresponding data_arr values depending on the fill argument.\n\n    By default it is tried to fill the time array with continuously increasing times\n    based on the smallest time difference found there can still be discontinuities after\n    filling the arrays (because existing time values are not changed).\n\n    But one can also give a fixed fill time step.\n\n    Args:\n        time_arr (1D array):\n            times of data_arr in ms\n        data_arr (nD array):\n            the size of the specified dimension of data array must have the same length\n            as time_arr\n        fill_time_step (number, optional, default=None):\n            if there are gaps they are filled with this time step\n        axis (int):\n            which dimension of the data_arr coresponds to the time_arr\n        fill (str or float):\n            how to fill the data array:\n                \"nan\" (default): fill gaps with nan\n                float: fill gaps with this value\n    \"\"\"\n    if fill == \"nan\":\n        fill_value = np.nan\n    else:\n        fill_value = fill\n\n    time_arr = time_arr.astype(float)\n    data_arr = data_arr.astype(float)\n    data_arr_shape = data_arr.shape\n\n    if data_arr_shape[axis] != time_arr.size:\n        raise ValueError(\n            \"time_arr must have same length as specified axis (default=0) of data_arr!\"\n        )\n\n    ### find gaps\n    time_diff_arr = np.round(np.diff(time_arr), 6)\n    if isinstance(fill_time_step, type(None)):\n        time_diff_min = time_diff_arr.min()\n    else:\n        time_diff_min = fill_time_step\n    gaps_arr = time_diff_arr &gt; time_diff_min\n\n    ### split arrays at gaps\n    time_arr_split = np.split(\n        time_arr, indices_or_sections=np.where(gaps_arr)[0] + 1, axis=0\n    )\n    data_arr_split = np.split(\n        data_arr, indices_or_sections=np.where(gaps_arr)[0] + 1, axis=axis\n    )\n\n    ### fill gaps between splits\n    data_arr_append_shape = list(data_arr_shape)\n    for split_arr_idx in range(len(time_arr_split) - 1):\n        ### get gaps boundaries\n        current_end = time_arr_split[split_arr_idx][-1]\n        next_start = time_arr_split[split_arr_idx + 1][0]\n        ### create gap filling arrays\n        time_arr_append = np.arange(\n            current_end + time_diff_min, next_start, time_diff_min\n        )\n        data_arr_append_shape[axis] = time_arr_append.size\n        data_arr_append = np.ones(tuple(data_arr_append_shape)) * fill_value\n        ### append gap filling arrays to splitted arrays\n        time_arr_split[split_arr_idx] = np.append(\n            arr=time_arr_split[split_arr_idx],\n            values=time_arr_append,\n            axis=0,\n        )\n        data_arr_split[split_arr_idx] = np.append(\n            arr=data_arr_split[split_arr_idx],\n            values=data_arr_append,\n            axis=axis,\n        )\n\n    ### combine splitted arrays again\n    time_arr = np.concatenate(time_arr_split, axis=0)\n    data_arr = np.concatenate(data_arr_split, axis=axis)\n\n    return (time_arr, data_arr)\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.rmse","title":"<code>rmse(a, b)</code>","text":"<p>Calculates the root-mean-square error between two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array</code> <p>first array</p> required <code>b</code> <code>array</code> <p>second array</p> required <p>Returns:</p> Name Type Description <code>rmse</code> <code>float</code> <p>root-mean-square error</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def rmse(a, b):\n    \"\"\"\n    Calculates the root-mean-square error between two arrays.\n\n    Args:\n        a (array):\n            first array\n        b (array):\n            second array\n\n    Returns:\n        rmse (float):\n            root-mean-square error\n    \"\"\"\n\n    return np.sqrt(np.mean((a - b) ** 2))\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.rsse","title":"<code>rsse(a, b)</code>","text":"<p>Calculates the root-sum-square error between two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array</code> <p>first array</p> required <code>b</code> <code>array</code> <p>second array</p> required <p>Returns:</p> Name Type Description <code>rsse</code> <code>float</code> <p>root-sum-square error</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def rsse(a, b):\n    \"\"\"\n    Calculates the root-sum-square error between two arrays.\n\n    Args:\n        a (array):\n            first array\n        b (array):\n            second array\n\n    Returns:\n        rsse (float):\n            root-sum-square error\n    \"\"\"\n\n    return np.sqrt(np.sum((a - b) ** 2))\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_minimum","title":"<code>get_minimum(input_data)</code>","text":"<p>Returns the minimum of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>list, np.ndarray, tuple, or float</code> <p>The input data from which the minimum is to be obtained.</p> required <p>Returns:</p> Name Type Description <code>minimum</code> <code>float</code> <p>The minimum of the input data.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_minimum(input_data: list | np.ndarray | tuple | float):\n    \"\"\"\n    Returns the minimum of the input data.\n\n    Args:\n        input_data (list, np.ndarray, tuple, or float):\n            The input data from which the minimum is to be obtained.\n\n    Returns:\n        minimum (float):\n            The minimum of the input data.\n    \"\"\"\n    if isinstance(input_data, (list, np.ndarray, tuple)):\n        # If the input is a list, numpy array, or tuple, we handle them as follows\n        flattened_list = [\n            item\n            for sublist in input_data\n            for item in (\n                sublist if isinstance(sublist, (list, np.ndarray, tuple)) else [sublist]\n            )\n        ]\n        return float(np.nanmin(flattened_list))\n    else:\n        # If the input is a single value, return it as the minimum\n        return float(input_data)\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_maximum","title":"<code>get_maximum(input_data)</code>","text":"<p>Returns the maximum of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>list, np.ndarray, tuple, or float</code> <p>The input data from which the maximum is to be obtained.</p> required <p>Returns:</p> Name Type Description <code>maximum</code> <code>float</code> <p>The maximum of the input data.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_maximum(input_data: list | np.ndarray | tuple | float):\n    \"\"\"\n    Returns the maximum of the input data.\n\n    Args:\n        input_data (list, np.ndarray, tuple, or float):\n            The input data from which the maximum is to be obtained.\n\n    Returns:\n        maximum (float):\n            The maximum of the input data.\n    \"\"\"\n\n    if isinstance(input_data, (list, np.ndarray, tuple)):\n        # If the input is a list, numpy array, or tuple, we handle them as follows\n        flattened_list = [\n            item\n            for sublist in input_data\n            for item in (\n                sublist if isinstance(sublist, (list, np.ndarray, tuple)) else [sublist]\n            )\n        ]\n        return float(np.nanmax(flattened_list))\n    else:\n        # If the input is a single value, return it as the maximum\n        return float(input_data)\n</code></pre>"},{"location":"additional/extra_functions/","title":"Extra Functions","text":""},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.Cmap","title":"<code>Cmap</code>","text":"<p>Class to create a colormap with a given name and range. The colormap can be called with a value between 0 and 1 to get the corresponding rgb value.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class Cmap:\n    \"\"\"\n    Class to create a colormap with a given name and range. The colormap can be called\n    with a value between 0 and 1 to get the corresponding rgb value.\n    \"\"\"\n\n    def __init__(self, cmap_name, vmin, vmax):\n        \"\"\"\n        Args:\n            cmap_name (str):\n                Name of the colormap\n            vmin (float):\n                Lower limit of the colormap\n            vmax (float):\n                Upper limit of the colormap\n        \"\"\"\n        self.cmap_name = cmap_name\n        self.cmap = plt.get_cmap(cmap_name)\n        self.norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n        self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n\n    def __call__(self, x, alpha=1):\n        \"\"\"\n        Returns the rgba value of the colormap at the given value.\n\n        Args:\n            x (float):\n                Value between 0 and 1\n            alpha (float):\n                Alpha value of the rgba value\n\n        Returns:\n            rgba (tuple):\n                RGBA value of the colormap at the given value\n        \"\"\"\n        vals = self.get_rgb(x)\n        if isinstance(vals, tuple):\n            vals = vals[:3] + (alpha,)\n        else:\n            vals[:, -1] = alpha\n        return vals\n\n    def get_rgb(self, val):\n        \"\"\"\n        Returns the rgb value of the colormap at the given value.\n\n        Args:\n            val (float):\n                Value between 0 and 1\n\n        Returns:\n            rgb (tuple):\n                RGB value of the colormap at the given value\n        \"\"\"\n        return self.scalarMap.to_rgba(val)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.Cmap.__init__","title":"<code>__init__(cmap_name, vmin, vmax)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>cmap_name</code> <code>str</code> <p>Name of the colormap</p> required <code>vmin</code> <code>float</code> <p>Lower limit of the colormap</p> required <code>vmax</code> <code>float</code> <p>Upper limit of the colormap</p> required Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self, cmap_name, vmin, vmax):\n    \"\"\"\n    Args:\n        cmap_name (str):\n            Name of the colormap\n        vmin (float):\n            Lower limit of the colormap\n        vmax (float):\n            Upper limit of the colormap\n    \"\"\"\n    self.cmap_name = cmap_name\n    self.cmap = plt.get_cmap(cmap_name)\n    self.norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n    self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.Cmap.__call__","title":"<code>__call__(x, alpha=1)</code>","text":"<p>Returns the rgba value of the colormap at the given value.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>Value between 0 and 1</p> required <code>alpha</code> <code>float</code> <p>Alpha value of the rgba value</p> <code>1</code> <p>Returns:</p> Name Type Description <code>rgba</code> <code>tuple</code> <p>RGBA value of the colormap at the given value</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __call__(self, x, alpha=1):\n    \"\"\"\n    Returns the rgba value of the colormap at the given value.\n\n    Args:\n        x (float):\n            Value between 0 and 1\n        alpha (float):\n            Alpha value of the rgba value\n\n    Returns:\n        rgba (tuple):\n            RGBA value of the colormap at the given value\n    \"\"\"\n    vals = self.get_rgb(x)\n    if isinstance(vals, tuple):\n        vals = vals[:3] + (alpha,)\n    else:\n        vals[:, -1] = alpha\n    return vals\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.Cmap.get_rgb","title":"<code>get_rgb(val)</code>","text":"<p>Returns the rgb value of the colormap at the given value.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>float</code> <p>Value between 0 and 1</p> required <p>Returns:</p> Name Type Description <code>rgb</code> <code>tuple</code> <p>RGB value of the colormap at the given value</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_rgb(self, val):\n    \"\"\"\n    Returns the rgb value of the colormap at the given value.\n\n    Args:\n        val (float):\n            Value between 0 and 1\n\n    Returns:\n        rgb (tuple):\n            RGB value of the colormap at the given value\n    \"\"\"\n    return self.scalarMap.to_rgba(val)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTree","title":"<code>DecisionTree</code>","text":"<p>Class to create a decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class DecisionTree:\n    \"\"\"\n    Class to create a decision tree.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Create a new empty decision tree.\n        \"\"\"\n        ### node list is a list of lists\n        ### first idx = level of tree\n        ### second idx = all nodes in the level\n        self.node_list = [[]]\n\n    def node(self, parent=None, prob=0, name=None):\n        \"\"\"\n        Create a new node in the decision tree.\n\n        Args:\n            parent (node object):\n                Parent node of the new node\n            prob (float):\n                Probability of the new node\n            name (str):\n                Name of the new node\n\n        Returns:\n            new_node (node object):\n                The new node\n        \"\"\"\n\n        ### create new node\n        new_node = DecisionTreeNode(tree=self, parent=parent, prob=prob, name=name)\n        ### add it to node_list\n        if len(self.node_list) == new_node.level:\n            self.node_list.append([])\n        self.node_list[new_node.level].append(new_node)\n        ### return the node object\n        return new_node\n\n    def get_path_prod(self, name):\n        \"\"\"\n        Get the path and path product of a node with a given name.\n\n        Args:\n            name (str):\n                Name of the node\n\n        Returns:\n            path (str):\n                Path to the node\n            path_prod (float):\n                Path product of the node\n        \"\"\"\n\n        ### search for all nodes with name\n        ### start from behind\n        search_node_list = []\n        path_list = []\n        path_prod_list = []\n        for level in range(len(self.node_list) - 1, -1, -1):\n            for node in self.node_list[level]:\n                if node.name == name:\n                    search_node_list.append(node)\n        ### get the paths and path products for the found nodes\n        for node in search_node_list:\n            path, path_prod = self._get_path_prod_rec(node)\n            path_list.append(path)\n            path_prod_list.append(path_prod)\n        ### return the paths and path products\n        return [\n            [path_list[idx], path_prod_list[idx]]\n            for idx in range(len(search_node_list))\n        ]\n\n    def _get_path_prod_rec(self, node):\n        \"\"\"\n        Recursive function to get the path and path product of a node.\n\n        Args:\n            node (node object):\n                Node to get the path and path product of\n\n        Returns:\n            path_str (str):\n                Path to the node\n            prob (float):\n                Path product of the node\n        \"\"\"\n        node: DecisionTreeNode = node\n\n        if node.parent == None:\n            return [\"/\" + node.name, node.prob]\n        else:\n            path_str, prob = self._get_path_prod_rec(node.parent)\n            return [path_str + \"/\" + node.name, prob * node.prob]\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTree.__init__","title":"<code>__init__()</code>","text":"<p>Create a new empty decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Create a new empty decision tree.\n    \"\"\"\n    ### node list is a list of lists\n    ### first idx = level of tree\n    ### second idx = all nodes in the level\n    self.node_list = [[]]\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTree.node","title":"<code>node(parent=None, prob=0, name=None)</code>","text":"<p>Create a new node in the decision tree.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>node object</code> <p>Parent node of the new node</p> <code>None</code> <code>prob</code> <code>float</code> <p>Probability of the new node</p> <code>0</code> <code>name</code> <code>str</code> <p>Name of the new node</p> <code>None</code> <p>Returns:</p> Name Type Description <code>new_node</code> <code>node object</code> <p>The new node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def node(self, parent=None, prob=0, name=None):\n    \"\"\"\n    Create a new node in the decision tree.\n\n    Args:\n        parent (node object):\n            Parent node of the new node\n        prob (float):\n            Probability of the new node\n        name (str):\n            Name of the new node\n\n    Returns:\n        new_node (node object):\n            The new node\n    \"\"\"\n\n    ### create new node\n    new_node = DecisionTreeNode(tree=self, parent=parent, prob=prob, name=name)\n    ### add it to node_list\n    if len(self.node_list) == new_node.level:\n        self.node_list.append([])\n    self.node_list[new_node.level].append(new_node)\n    ### return the node object\n    return new_node\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTree.get_path_prod","title":"<code>get_path_prod(name)</code>","text":"<p>Get the path and path product of a node with a given name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the node</p> required <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>Path to the node</p> <code>path_prod</code> <code>float</code> <p>Path product of the node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_path_prod(self, name):\n    \"\"\"\n    Get the path and path product of a node with a given name.\n\n    Args:\n        name (str):\n            Name of the node\n\n    Returns:\n        path (str):\n            Path to the node\n        path_prod (float):\n            Path product of the node\n    \"\"\"\n\n    ### search for all nodes with name\n    ### start from behind\n    search_node_list = []\n    path_list = []\n    path_prod_list = []\n    for level in range(len(self.node_list) - 1, -1, -1):\n        for node in self.node_list[level]:\n            if node.name == name:\n                search_node_list.append(node)\n    ### get the paths and path products for the found nodes\n    for node in search_node_list:\n        path, path_prod = self._get_path_prod_rec(node)\n        path_list.append(path)\n        path_prod_list.append(path_prod)\n    ### return the paths and path products\n    return [\n        [path_list[idx], path_prod_list[idx]]\n        for idx in range(len(search_node_list))\n    ]\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTreeNode","title":"<code>DecisionTreeNode</code>","text":"<p>Class to create a node in a decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class DecisionTreeNode:\n    \"\"\"\n    Class to create a node in a decision tree.\n    \"\"\"\n\n    id_counter = 0\n\n    def __init__(self, tree: DecisionTree, parent=None, prob=0, name=\"\"):\n        \"\"\"\n        Create a new node in a decision tree.\n\n        Args:\n            tree (DecisionTree object):\n                Decision tree the node belongs to\n            parent (node object):\n                Parent node of the new node\n            prob (float):\n                Probability of the new node\n            name (str):\n                Name of the new node\n        \"\"\"\n        self.tree = tree\n        parent: DecisionTreeNode = parent\n        self.parent = parent\n        self.prob = prob\n        self.name = name\n        self.id = int(self.id_counter)\n        self.id_counter += 1\n        if parent != None:\n            self.level = int(parent.level + 1)\n        else:\n            self.level = int(0)\n\n    def add(self, name, prob):\n        \"\"\"\n        Add a child node to the node.\n\n        Args:\n            name (str):\n                Name of the new node\n            prob (float):\n                Probability of the new node\n\n        Returns:\n            new_node (node object):\n                The new node\n        \"\"\"\n\n        return self.tree.node(parent=self, prob=prob, name=name)\n\n    def get_path_prod(self):\n        \"\"\"\n        Get the path and path product of the node.\n\n        Returns:\n            path (str):\n                Path to the node\n            path_prod (float):\n                Path product of the node\n        \"\"\"\n        return self.tree._get_path_prod_rec(self)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTreeNode.__init__","title":"<code>__init__(tree, parent=None, prob=0, name='')</code>","text":"<p>Create a new node in a decision tree.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>DecisionTree object</code> <p>Decision tree the node belongs to</p> required <code>parent</code> <code>node object</code> <p>Parent node of the new node</p> <code>None</code> <code>prob</code> <code>float</code> <p>Probability of the new node</p> <code>0</code> <code>name</code> <code>str</code> <p>Name of the new node</p> <code>''</code> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self, tree: DecisionTree, parent=None, prob=0, name=\"\"):\n    \"\"\"\n    Create a new node in a decision tree.\n\n    Args:\n        tree (DecisionTree object):\n            Decision tree the node belongs to\n        parent (node object):\n            Parent node of the new node\n        prob (float):\n            Probability of the new node\n        name (str):\n            Name of the new node\n    \"\"\"\n    self.tree = tree\n    parent: DecisionTreeNode = parent\n    self.parent = parent\n    self.prob = prob\n    self.name = name\n    self.id = int(self.id_counter)\n    self.id_counter += 1\n    if parent != None:\n        self.level = int(parent.level + 1)\n    else:\n        self.level = int(0)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTreeNode.add","title":"<code>add(name, prob)</code>","text":"<p>Add a child node to the node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the new node</p> required <code>prob</code> <code>float</code> <p>Probability of the new node</p> required <p>Returns:</p> Name Type Description <code>new_node</code> <code>node object</code> <p>The new node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def add(self, name, prob):\n    \"\"\"\n    Add a child node to the node.\n\n    Args:\n        name (str):\n            Name of the new node\n        prob (float):\n            Probability of the new node\n\n    Returns:\n        new_node (node object):\n            The new node\n    \"\"\"\n\n    return self.tree.node(parent=self, prob=prob, name=name)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTreeNode.get_path_prod","title":"<code>get_path_prod()</code>","text":"<p>Get the path and path product of the node.</p> <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>Path to the node</p> <code>path_prod</code> <code>float</code> <p>Path product of the node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_path_prod(self):\n    \"\"\"\n    Get the path and path product of the node.\n\n    Returns:\n        path (str):\n            Path to the node\n        path_prod (float):\n            Path product of the node\n    \"\"\"\n    return self.tree._get_path_prod_rec(self)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DeapCma","title":"<code>DeapCma</code>","text":"<p>Class to run the deap Covariance Matrix Adaptation Evolution Strategy optimization.</p> <p>Attributes:</p> Name Type Description <code>deap_dict</code> <code>dict</code> <p>Dictionary containing the toolbox, the hall of fame, the statistics, the lower and upper bounds, the parameter names, the inverse scaler and the strategy.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class DeapCma:\n    \"\"\"\n    Class to run the deap Covariance Matrix Adaptation Evolution Strategy optimization.\n\n    Attributes:\n        deap_dict (dict):\n            Dictionary containing the toolbox, the hall of fame, the statistics, the\n            lower and upper bounds, the parameter names, the inverse scaler and the\n            strategy.\n    \"\"\"\n\n    def __init__(\n        self,\n        lower: np.ndarray,\n        upper: np.ndarray,\n        evaluate_function: Callable,\n        max_evals: None | int = None,\n        p0: None | np.ndarray = None,\n        param_names: None | list[str] = None,\n        learn_rate_factor: float = 1,\n        damping_factor: float = 1,\n        verbose: bool = False,\n        plot_file: None | str = \"logbook.png\",\n        cma_params_dict: dict = {},\n        source_solutions: list[tuple[np.ndarray, float]] = [],\n    ):\n        \"\"\"\n\n        Args:\n            lower (np.ndarray):\n                Lower bounds of the parameters\n            upper (np.ndarray):\n                Upper bounds of the parameters\n            evaluate_function (Callable):\n                Function evaluating the losses of a population of individuals. Return value\n                should be a list of tuples with the losses of the individuals.\n            max_evals (int, optional):\n                Maximum number of evaluations. If not given here, it has to be given in\n                the run function. By default None.\n            p0 (None | np.ndarray, optional):\n                Initial guess for the parameters. By default the mean of lower and upper\n                bounds.\n            param_names (None | list[str], optional):\n                Names of the parameters. By default None.\n            learn_rate_factor (float, optional):\n                Learning rate factor (decrease -&gt; slower). By default 1.\n            damping_factor (float, optional):\n                Damping factor (increase -&gt; slower). By default 1.\n            verbose (bool, optional):\n                Whether or not to print details. By default False.\n            plot_file (None | str, optional):\n                File to save the deap plot to. If not given here, it has to be given in\n                the run function. By default \"logbook.png\".\n            cma_params_dict (dict, optional):\n                Parameters for the deap cma strategy (deap.cma.Strategy). See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy) for more\n                details\n            source_solutions (list[tuple[np.ndarray, float]], optional):\n                List of tuples with the parameters and losses of source solutions. These\n                solutions are used to initialize the covariance matrix. By default [].\n        \"\"\"\n        ### store attributes\n        self.max_evals = max_evals\n        self.lower = lower\n        self.upper = upper\n        self.evaluate_function = evaluate_function\n        self.p0 = p0\n        self.param_names = param_names\n        self.learn_rate_factor = learn_rate_factor\n        self.damping_factor = damping_factor\n        self.verbose = verbose\n        self.plot_file = plot_file\n        self.cma_params_dict = cma_params_dict\n        self.source_solutions = source_solutions\n\n        ### prepare the optimization\n        self.deap_dict = self._prepare()\n\n    def _prepare(self):\n        \"\"\"\n        Prepares the deap Covariance Matrix Adaptation Evolution Strategy optimization.\n\n        Returns:\n            dict:\n                Dictionary containing the toolbox, the hall of fame, the statistics, the\n                lower and upper bounds, the parameter names, the inverse scaler and the\n                strategy.\n        \"\"\"\n\n        ### get attributes\n        lower = self.lower\n        upper = self.upper\n        evaluate_function = self.evaluate_function\n        p0 = self.p0\n        param_names = self.param_names\n        learn_rate_factor = self.learn_rate_factor\n        damping_factor = self.damping_factor\n        verbose = self.verbose\n        cma_params_dict = self.cma_params_dict\n\n        ### create scaler to scale parameters into range [0,1] based on lower and upper bounds\n        upper_orig = deepcopy(upper)\n        lower_orig = deepcopy(lower)\n\n        def scaler(x):\n            return (x - lower_orig) / (upper_orig - lower_orig)\n\n        ### create inverse scaler to scale parameters back into original range [lower,upper]\n        def inv_scaler(x):\n            return x * (upper_orig - lower_orig) + lower_orig\n\n        ### scale upper and lower bounds\n        lower = scaler(lower)\n        upper = scaler(upper)\n\n        ### create the individual class, since this is eventually called multiple times\n        ### deactivate warnings (it warns that the classes already exist)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n            creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n\n        ### create the toolbox\n        toolbox = base.Toolbox()\n        ### function calculating losses from individuals (from whole population)\n        toolbox.register(\"evaluate\", evaluate_function)\n        ### search strategy\n        ### warm start with initial source solutions\n        if len(self.source_solutions) &gt; 0:\n            ### scale source solutions\n            for source_solution_idx in range(len(self.source_solutions)):\n                self.source_solutions[source_solution_idx] = (\n                    scaler(self.source_solutions[source_solution_idx][0]),\n                    self.source_solutions[source_solution_idx][1],\n                )\n            centroid, sigma, cmatrix = cmaes.get_warm_start_mgd(\n                source_solutions=self.source_solutions,\n                gamma=1,\n            )\n            cma_params_dict[\"cmatrix\"] = cmatrix\n        else:\n            centroid = (lower + upper) / 2 if isinstance(p0, type(None)) else scaler(p0)\n            sigma = (upper - lower) / 4\n\n        ### create the strategy\n        strategy = cma.Strategy(\n            centroid=centroid,\n            sigma=sigma,\n            **cma_params_dict,\n        )\n\n        ### slow down the learning rate and increase the damping\n        strategy.ccov1 *= learn_rate_factor\n        strategy.ccovmu *= learn_rate_factor\n        strategy.damps *= damping_factor  # TODO what slows down?\n        if verbose:\n            print(\n                f\"lambda (The number of children to produce at each generation): {strategy.lambda_}\"\n            )\n            print(\n                f\"mu (The number of parents to keep from the lambda children): {strategy.mu}\"\n            )\n            print(f\"weights: {strategy.weights}\")\n            print(f\"mueff: {strategy.mueff}\")\n            print(f\"ccum (Cumulation constant for covariance matrix.): {strategy.cc}\")\n            print(f\"cs (Cumulation constant for step-size): {strategy.cs}\")\n            print(f\"ccov1 (Learning rate for rank-one update): {strategy.ccov1}\")\n            print(f\"ccovmu (Learning rate for rank-mu update): {strategy.ccovmu}\")\n            print(f\"damps (Damping for step-size): {strategy.damps}\")\n        ### function generating a population during optimization\n        toolbox.register(\"generate\", strategy.generate, creator.Individual)\n        ### function updating the search strategy\n        toolbox.register(\"update\", strategy.update)\n        ### hall of fame to track best individual i.e. parameters\n        hof = tools.HallOfFame(1)\n        ### statistics to track evolution of loss\n        stats = tools.Statistics(lambda ind: ind.fitness.values)\n        stats.register(\"avg\", np.mean)\n        stats.register(\"std\", np.std)\n        stats.register(\"min\", np.min)\n        stats.register(\"max\", np.max)\n\n        return {\n            \"toolbox\": toolbox,\n            \"hof\": hof,\n            \"stats\": stats,\n            \"lower\": lower,\n            \"upper\": upper,\n            \"param_names\": param_names,\n            \"inv_scaler\": inv_scaler,\n            \"strategy\": strategy,\n        }\n\n    def run(\n        self,\n        max_evals: None | int = None,\n        verbose: None | bool = None,\n        plot_file: None | str = None,\n    ):\n        \"\"\"\n        Runs the optimization with deap.\n\n        Args:\n            max_evals (int):\n                Number of runs (here generations) a single optimization performs. By\n                default None, i.e. the value from the initialization is used.\n            verbose (bool, optional):\n                Whether or not to print details. By default None, i.e. the value from\n                the initialization is used.\n            plot_file (str):\n                Path to save the logbook plot to. By default None, i.e. the value from\n                the initialization is used.\n\n        Returns:\n            best (dict):\n                Dictionary containing the best parameters, the logbook, the last population\n                of individuals and the best fitness.\n        \"\"\"\n\n        ### get attributes\n        max_evals = self.max_evals if max_evals is None else max_evals\n        verbose = self.verbose if verbose is None else verbose\n        plot_file = self.plot_file if plot_file is None else plot_file\n        deap_dict = self.deap_dict\n\n        ### run the search algorithm with the prepared deap_dict\n        pop, logbook = self._deap_ea_generate_update(\n            deap_dict,\n            ngen=max_evals,\n            verbose=verbose,\n        )\n\n        ### scale parameters of hall of fame back into original range [lower,upper]\n        hof_final = deap_dict[\"inv_scaler\"](deap_dict[\"hof\"][0])\n        best_fitness = deap_dict[\"hof\"][0].fitness.values[0]\n\n        ### get best parameters, last population of inidividuals and logbook\n        best = {}\n        for param_idx in range(len(deap_dict[\"lower\"])):\n            if deap_dict[\"param_names\"] is not None:\n                param_key = deap_dict[\"param_names\"][param_idx]\n            else:\n                param_key = f\"param{param_idx}\"\n            best[param_key] = hof_final[param_idx]\n        best[\"logbook\"] = logbook\n        best[\"deap_pop\"] = pop\n        best[\"best_fitness\"] = best_fitness\n\n        ### plot logbook with logaritmic y-axis\n        fig, ax = plt.subplots(figsize=(10, 5))\n        ax.set_yscale(\"log\")\n        ax.plot(logbook.select(\"gen\"), logbook.select(\"min\"), label=\"min\")\n        ax.plot(logbook.select(\"gen\"), logbook.select(\"avg\"), label=\"avg\")\n        ax.plot(logbook.select(\"gen\"), logbook.select(\"max\"), label=\"max\")\n        ax.legend()\n        ax.set_xlabel(\"Generation\")\n        ax.set_ylabel(\"Loss\")\n        fig.tight_layout()\n        sf.create_dir(\"/\".join(plot_file.split(\"/\")[:-1]))\n        fig.savefig(plot_file, dpi=300)\n\n        return best\n\n    def _deap_ea_generate_update(\n        self,\n        deap_dict: dict,\n        ngen: int,\n        verbose: bool = False,\n    ):\n        \"\"\"\n        This function is copied from deap.algorithms.eaGenerateUpdate and modified.\n        This is algorithm implements the ask-tell model proposed in\n        [Colette2010]_, where ask is called `generate` and tell is called `update`.\n\n        .. [Colette2010] Collette, Y., N. Hansen, G. Pujol, D. Salazar Aponte and\n        R. Le Riche (2010). On Object-Oriented Programming of Optimizers -\n        Examples in Scilab. In P. Breitkopf and R. F. Coelho, eds.:\n        Multidisciplinary Design Optimization in Computational Mechanics,\n        Wiley, pp. 527-565;\n\n        Args:\n            deap_dict (dict):\n                Dictionary containing the deap toolbox, hall of fame, statistics, lower\n                and upper bounds, parameter names, inverse scaler and strategy.\n            ngen (int):\n                number of runs (here generations) a single optimization performs\n            verbose (bool, optional):\n                Whether or not to print details. By default False.\n\n        Returns:\n            population:\n                A list of individuals.\n            logbook:\n                A Logbook() object that contains the evolution statistics.\n        \"\"\"\n\n        ### get variables from deap_dict\n        toolbox = deap_dict[\"toolbox\"]\n        lower = deap_dict[\"lower\"]\n        upper = deap_dict[\"upper\"]\n        inv_scaler = deap_dict[\"inv_scaler\"]\n        stats = deap_dict[\"stats\"]\n        halloffame = deap_dict[\"hof\"]\n        strategy = deap_dict[\"strategy\"]\n\n        ### init logbook\n        logbook = tools.Logbook()\n        logbook.header = [\"gen\", \"nevals\"] + (stats.fields if stats else [])\n\n        ### define progress bar\n        progress_bar = tqdm(range(ngen), total=ngen, unit=\"gen\")\n        early_stop = False\n\n        ### loop over generations\n        for gen in progress_bar:\n            ### Generate a new population\n            population = toolbox.generate()\n            ### clip individuals of population to variable bounds\n            ### TODO only if bounds are hard\n            for ind in population:\n                for idx, val in enumerate(ind):\n                    ind[idx] = np.clip(val, lower[idx], upper[idx])\n            ### Evaluate the individuals (here whole population at once)\n            ### scale parameters back into original range [lower,upper]\n            population_inv_scaled = [inv_scaler(ind) for ind in deepcopy(population)]\n            fitnesses = toolbox.evaluate(population_inv_scaled)\n\n            ### set fitnesses of individuals\n            for ind, fit in zip(population, fitnesses):\n                ind.fitness.values = fit\n\n            ### check if nan in population\n            for ind in population:\n                nan_in_pop = np.isnan(ind.fitness.values[0])\n\n            ### Update the hall of fame with the generated individuals\n            if halloffame is not None and not nan_in_pop:\n                halloffame.update(population)\n\n            ### Update the strategy with the evaluated individuals\n            toolbox.update(population)\n\n            ### Stop if diagD is too small\n            if np.min(strategy.diagD) &lt; 1e-5:\n                early_stop = True\n                break\n\n            ### Append the current generation statistics to the logbook\n            record = stats.compile(population) if stats is not None else {}\n            logbook.record(gen=gen, nevals=len(population), **record)\n            if verbose:\n                print(logbook.stream)\n\n            ### update progress bar with current best loss\n            progress_bar.set_postfix_str(\n                f\"best loss: {halloffame[0].fitness.values[0]:.5f}\"\n            )\n        if early_stop and verbose:\n            print(\"Stopping because convergence is reached.\")\n\n        return population, logbook\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DeapCma.__init__","title":"<code>__init__(lower, upper, evaluate_function, max_evals=None, p0=None, param_names=None, learn_rate_factor=1, damping_factor=1, verbose=False, plot_file='logbook.png', cma_params_dict={}, source_solutions=[])</code>","text":"<p>Parameters:</p> Name Type Description Default <code>lower</code> <code>ndarray</code> <p>Lower bounds of the parameters</p> required <code>upper</code> <code>ndarray</code> <p>Upper bounds of the parameters</p> required <code>evaluate_function</code> <code>Callable</code> <p>Function evaluating the losses of a population of individuals. Return value should be a list of tuples with the losses of the individuals.</p> required <code>max_evals</code> <code>int</code> <p>Maximum number of evaluations. If not given here, it has to be given in the run function. By default None.</p> <code>None</code> <code>p0</code> <code>None | ndarray</code> <p>Initial guess for the parameters. By default the mean of lower and upper bounds.</p> <code>None</code> <code>param_names</code> <code>None | list[str]</code> <p>Names of the parameters. By default None.</p> <code>None</code> <code>learn_rate_factor</code> <code>float</code> <p>Learning rate factor (decrease -&gt; slower). By default 1.</p> <code>1</code> <code>damping_factor</code> <code>float</code> <p>Damping factor (increase -&gt; slower). By default 1.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Whether or not to print details. By default False.</p> <code>False</code> <code>plot_file</code> <code>None | str</code> <p>File to save the deap plot to. If not given here, it has to be given in the run function. By default \"logbook.png\".</p> <code>'logbook.png'</code> <code>cma_params_dict</code> <code>dict</code> <p>Parameters for the deap cma strategy (deap.cma.Strategy). See here for more details</p> <code>{}</code> <code>source_solutions</code> <code>list[tuple[ndarray, float]]</code> <p>List of tuples with the parameters and losses of source solutions. These solutions are used to initialize the covariance matrix. By default [].</p> <code>[]</code> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(\n    self,\n    lower: np.ndarray,\n    upper: np.ndarray,\n    evaluate_function: Callable,\n    max_evals: None | int = None,\n    p0: None | np.ndarray = None,\n    param_names: None | list[str] = None,\n    learn_rate_factor: float = 1,\n    damping_factor: float = 1,\n    verbose: bool = False,\n    plot_file: None | str = \"logbook.png\",\n    cma_params_dict: dict = {},\n    source_solutions: list[tuple[np.ndarray, float]] = [],\n):\n    \"\"\"\n\n    Args:\n        lower (np.ndarray):\n            Lower bounds of the parameters\n        upper (np.ndarray):\n            Upper bounds of the parameters\n        evaluate_function (Callable):\n            Function evaluating the losses of a population of individuals. Return value\n            should be a list of tuples with the losses of the individuals.\n        max_evals (int, optional):\n            Maximum number of evaluations. If not given here, it has to be given in\n            the run function. By default None.\n        p0 (None | np.ndarray, optional):\n            Initial guess for the parameters. By default the mean of lower and upper\n            bounds.\n        param_names (None | list[str], optional):\n            Names of the parameters. By default None.\n        learn_rate_factor (float, optional):\n            Learning rate factor (decrease -&gt; slower). By default 1.\n        damping_factor (float, optional):\n            Damping factor (increase -&gt; slower). By default 1.\n        verbose (bool, optional):\n            Whether or not to print details. By default False.\n        plot_file (None | str, optional):\n            File to save the deap plot to. If not given here, it has to be given in\n            the run function. By default \"logbook.png\".\n        cma_params_dict (dict, optional):\n            Parameters for the deap cma strategy (deap.cma.Strategy). See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy) for more\n            details\n        source_solutions (list[tuple[np.ndarray, float]], optional):\n            List of tuples with the parameters and losses of source solutions. These\n            solutions are used to initialize the covariance matrix. By default [].\n    \"\"\"\n    ### store attributes\n    self.max_evals = max_evals\n    self.lower = lower\n    self.upper = upper\n    self.evaluate_function = evaluate_function\n    self.p0 = p0\n    self.param_names = param_names\n    self.learn_rate_factor = learn_rate_factor\n    self.damping_factor = damping_factor\n    self.verbose = verbose\n    self.plot_file = plot_file\n    self.cma_params_dict = cma_params_dict\n    self.source_solutions = source_solutions\n\n    ### prepare the optimization\n    self.deap_dict = self._prepare()\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DeapCma.run","title":"<code>run(max_evals=None, verbose=None, plot_file=None)</code>","text":"<p>Runs the optimization with deap.</p> <p>Parameters:</p> Name Type Description Default <code>max_evals</code> <code>int</code> <p>Number of runs (here generations) a single optimization performs. By default None, i.e. the value from the initialization is used.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether or not to print details. By default None, i.e. the value from the initialization is used.</p> <code>None</code> <code>plot_file</code> <code>str</code> <p>Path to save the logbook plot to. By default None, i.e. the value from the initialization is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>best</code> <code>dict</code> <p>Dictionary containing the best parameters, the logbook, the last population of individuals and the best fitness.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def run(\n    self,\n    max_evals: None | int = None,\n    verbose: None | bool = None,\n    plot_file: None | str = None,\n):\n    \"\"\"\n    Runs the optimization with deap.\n\n    Args:\n        max_evals (int):\n            Number of runs (here generations) a single optimization performs. By\n            default None, i.e. the value from the initialization is used.\n        verbose (bool, optional):\n            Whether or not to print details. By default None, i.e. the value from\n            the initialization is used.\n        plot_file (str):\n            Path to save the logbook plot to. By default None, i.e. the value from\n            the initialization is used.\n\n    Returns:\n        best (dict):\n            Dictionary containing the best parameters, the logbook, the last population\n            of individuals and the best fitness.\n    \"\"\"\n\n    ### get attributes\n    max_evals = self.max_evals if max_evals is None else max_evals\n    verbose = self.verbose if verbose is None else verbose\n    plot_file = self.plot_file if plot_file is None else plot_file\n    deap_dict = self.deap_dict\n\n    ### run the search algorithm with the prepared deap_dict\n    pop, logbook = self._deap_ea_generate_update(\n        deap_dict,\n        ngen=max_evals,\n        verbose=verbose,\n    )\n\n    ### scale parameters of hall of fame back into original range [lower,upper]\n    hof_final = deap_dict[\"inv_scaler\"](deap_dict[\"hof\"][0])\n    best_fitness = deap_dict[\"hof\"][0].fitness.values[0]\n\n    ### get best parameters, last population of inidividuals and logbook\n    best = {}\n    for param_idx in range(len(deap_dict[\"lower\"])):\n        if deap_dict[\"param_names\"] is not None:\n            param_key = deap_dict[\"param_names\"][param_idx]\n        else:\n            param_key = f\"param{param_idx}\"\n        best[param_key] = hof_final[param_idx]\n    best[\"logbook\"] = logbook\n    best[\"deap_pop\"] = pop\n    best[\"best_fitness\"] = best_fitness\n\n    ### plot logbook with logaritmic y-axis\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.set_yscale(\"log\")\n    ax.plot(logbook.select(\"gen\"), logbook.select(\"min\"), label=\"min\")\n    ax.plot(logbook.select(\"gen\"), logbook.select(\"avg\"), label=\"avg\")\n    ax.plot(logbook.select(\"gen\"), logbook.select(\"max\"), label=\"max\")\n    ax.legend()\n    ax.set_xlabel(\"Generation\")\n    ax.set_ylabel(\"Loss\")\n    fig.tight_layout()\n    sf.create_dir(\"/\".join(plot_file.split(\"/\")[:-1]))\n    fig.savefig(plot_file, dpi=300)\n\n    return best\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.VClampParamSearch","title":"<code>VClampParamSearch</code>","text":"<p>Class to obtain the parameters of some neuron model equations (describing the change of the membrane potential v) by simulating voltage steps with a given neuron_model. An voltage clamp version of the equations is used to calculate instantaneous and holding \"currents\" for specific voltage steps. The parameters are then optimized to fit the calculated \"currents\" to the measured currents from the simulated neuron model.</p> <p>Attributes:</p> Name Type Description <code>p_opt</code> <code>dict</code> <p>The optimized parameters</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class VClampParamSearch:\n    \"\"\"\n    Class to obtain the parameters of some neuron model equations (describing the change\n    of the membrane potential v) by simulating voltage steps with a given neuron_model.\n    An voltage clamp version of the equations is used to calculate instantaneous and\n    holding \"currents\" for specific voltage steps. The parameters are then optimized\n    to fit the calculated \"currents\" to the measured currents from the simulated neuron\n    model.\n\n    Attributes:\n        p_opt (dict):\n            The optimized parameters\n    \"\"\"\n\n    @check_types()\n    def __init__(\n        self,\n        neuron_model: Neuron,\n        equations: str = \"\"\"\n        C*dv/dt = k*(v - v_r)*(v - v_t) - u\n        du/dt = a*(b*(v - v_r) - u)\n        \"\"\",\n        bounds: dict[str, tuple[float, float]] = {\n            \"C\": (0.1, 100),\n            \"v_r\": (-90, -40),\n            \"v_t\": (-90, -40),\n            \"k\": (0.01, 1),\n            \"a\": (0.01, 1),\n            \"b\": (-5, 5),\n        },\n        p0: None | dict[str, float | list] = None,\n        max_evals: int = 100,\n        m: int = 20,\n        n: int = 20,\n        do_plot: bool = False,\n        results_file: str = \"v_clamp_search_results\",\n        plot_file: str = \"v_clamp_search_plot.png\",\n        cma_params_dict: dict = {\"learn_rate_factor\": 1, \"damping_factor\": 1},\n        compile_folder_name: str = \"VClampParamSearch\",\n        verbose: bool = False,\n    ):\n        \"\"\"\n        Args:\n            neuron_model (Neuron):\n                The neuron model which is simulated to obtain the parameters for the\n                equations\n            equations (str, optional):\n                The equations whose parameters should be obtained. Default: Izhikevich\n                2007 neuron model\n            bounds (dict, optional):\n                The bounds for the parameters. For each parameter a bound should be\n                given! Default: Izhikevich 2007 neuron model\n            p0 (dict, optional):\n                The initial guess for the parameters. Dict keys should be the same as\n                the keys of bounds. The values can be either a single number for each\n                parameter or a list of numbers. If lists are given, all have to have\n                the same length, which will be the number of initial guesses for the\n                parameters, i.e. how often the optimization is run. Default: None,\n                i.e. the mid of the bounds is used as a single initial guess.\n            max_evals (int, optional):\n                The maximum number of evaluations for a single optimization run.\n                Default: 100\n            m (int, optional):\n                The number of initial voltages for the voltage step simulations.\n                Default: 20\n            n (int, optional):\n                The number of voltage steps for the voltage step simulations.\n                Defaults: 20\n            do_plot (bool, optional):\n                If True, plots are created. Default: False\n            results_file (str, optional):\n                The name of the file where the results are stored, without file ending.\n                Default: \"v_clamp_search_results\"\n            plot_file (str, optional):\n                The name of the file where the plot is stored, with file ending.\n                Default: \"v_clamp_search_plot.png\"\n            cma_params_dict (dict, optional):\n                Parameters for the deap cma strategy (deap.cma.Strategy). See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy)\n                for more details. Additional parameters are learn_rate_factor and\n                damping_factor. Default: {\"learn_rate_factor\": 1, \"damping_factor\": 1}\n            compile_folder_name (str, optional):\n                The name of the folder within \"annarchy_folders\" where the ANNarchy\n                network is compiled to. Default: \"VClampParamSearch\"\n            verbose (bool, optional):\n                If True, print details. Default: False\n        \"\"\"\n        self.verbose = verbose\n        self._verbose_extreme = False\n        ### store the given neuron model and a voltage clamp version of it\n        self.neuron_model = neuron_model\n        self._neuron_model = deepcopy(neuron_model)\n        self._neuron_model_clamp = self._get_neuron_model_clamp()\n\n        ### store other attributes\n        self.m = m\n        self.n = n\n        self.equations = equations\n        self.p0 = p0\n        ### check if p0 is correct and if lists are given, create also lists single\n        ### numbers which are given\n        self._p0 = self._get_p0()\n        self.max_evals = max_evals\n        self.bounds = bounds\n        self.do_plot = do_plot\n        self.results_file = results_file\n        self.plot_file = plot_file\n        self.cma_params_dict = cma_params_dict\n        ### check if file names are correct\n        if \".\" in self.results_file or \".\" not in self.plot_file:\n            raise ValueError(\n                \"results_file should not contain file ending and plot_file should!\"\n            )\n        self.compile_folder_name = compile_folder_name\n        self._timestep = 0.001\n\n        ### create folder for plots\n        if self.do_plot:\n            sf.create_dir(\"/\".join(plot_file.split(\"/\")[:-1]))\n\n        ### create the functions for v_clamp_inst and v_clamp_hold using the given\n        ### izhikevich equations\n        self._f_inst, self._f_hold, self._f_variables = self._create_v_clamp_functions()\n\n        ### create the voltage step arrays\n        self._v_0_arr, self._v_step_arr = self._create_voltage_step_arrays()\n\n        ### for each neuron model create a population\n        if self.verbose:\n            print(\"Creating models...\")\n        mf.cnp_clear()\n        self._model_normal, self._model_clamp = self._create_model()\n\n        ### perform resting state and voltage step simulations to obtain v_clamp_inst,\n        ### v_clamp_hold and v_rest\n        self._v_clamp_inst_arr = None\n        self._v_clamp_hold_arr = None\n        if self.verbose:\n            print(\"Performing simulations...\")\n        (\n            self._v_rest,\n            self._v_clamp_inst_arr,\n            self._v_clamp_hold_arr,\n            self._v_step_unique,\n            self._v_clamp_hold_unique,\n        ) = self._simulations()\n\n        ### tune the free paramters of the functions for v_clamp_inst and v_clamp_hold\n        ### to fit the data\n        if self.verbose:\n            print(\"Tuning parameters...\")\n        self._p_opt = self._tune_v_clamp_functions()\n        self.p_opt = {\n            param_name: self._p_opt.get(param_name, None)\n            for param_name in self.bounds.keys()\n        }\n        self.p_opt[\"best_fitness\"] = self._p_opt[\"best_fitness\"]\n\n        ### print and save optimized parameters\n        if self.verbose:\n            print(f\"Optimized parameters: {self.p_opt}\")\n        ### save as pkl file\n        sf.save_variables(\n            [self.p_opt],\n            [results_file.split(\"/\")[-1]],\n            \"/\".join(results_file.split(\"/\")[:-1]) if \"/\" in results_file else \"./\",\n        )\n        ### save human readable as json file\n        json.dump(\n            self.p_opt,\n            open(\n                f\"{results_file}.json\",\n                \"w\",\n            ),\n            indent=4,\n        )\n\n        ### create a neuron model with the tuned parameters and the given equations\n        ### then run the simulations again with this neuron model\n        if self.verbose:\n            print(\"Running simulations with tuned parameters...\")\n        mf.cnp_clear()\n        self._neuron_model = self._create_neuron_model_with_tuned_parameters()\n        self._neuron_model_clamp = self._get_neuron_model_clamp()\n        self._model_normal, self._model_clamp = self._create_model()\n        self._simulations()\n\n    def _get_p0(self):\n        \"\"\"\n        Check if p0 is correct and if lists are given, create also lists single numbers\n        which are given.\n\n        Returns:\n            _p0 (dict):\n                The corrected p0\n        \"\"\"\n        _p0 = None\n        if self.p0 is not None:\n            ### collect lengths of lists\n            list_lengths = []\n            for key, val in self.p0.items():\n                if isinstance(val, list):\n                    list_lengths.append(len(val))\n            ### check if all lists have the same length\n            if len(set(list_lengths)) &gt; 1:\n                raise ValueError(\"All lists in p0 should have the same length!\")\n            ### create new p0 with lists for all parameters\n            _p0 = deepcopy(self.p0)\n            for key, val in _p0.items():\n                if not isinstance(val, list):\n                    _p0[key] = [val] * list_lengths[0] if list_lengths else [val]\n        return _p0\n\n    def _create_neuron_model_with_tuned_parameters(self):\n        \"\"\"\n        Create a neuron model with the tuned parameters and the given equations.\n\n        Returns:\n            neuron_mondel (Neuron):\n                the neuron model with the tuned parameters and the given equations\n        \"\"\"\n        ### create the neuron with the tuned parameters, if a parameter is not tuned\n        ### use the mid of the bounds (these parameters should not affect v_clamp_inst\n        ### and v_clamp_hold)\n        parameters = \"\\n\".join(\n            [\n                f\"{key} = {self._p_opt.get(key,sum(self.bounds[key])/2)}\"\n                for key in self.bounds.keys()\n            ]\n        )\n        neuron_mondel = Neuron(\n            parameters=parameters,\n            equations=self.equations + \"\\nr=0\",\n        )\n\n        return neuron_mondel\n\n    def _tune_v_clamp_functions(self):\n        \"\"\"\n        Tune the free paramters of the functions for v_clamp_inst and v_clamp_hold\n        to fit the data.\n        \"\"\"\n        ### get the names of the free parameters which will be tuned\n        sub_var_names_list = []\n        for var in self._f_variables:\n            if str(var) not in self.bounds or str(var) == \"v_r\":\n                continue\n            sub_var_names_list.append(str(var))\n\n        ### target array for the error function below\n        target_arr = np.concatenate([self._v_clamp_inst_arr, self._v_clamp_hold_unique])\n\n        ### create a function for the error\n        def error_function(x):\n            if self._verbose_extreme:\n                print(f\"Current guess: {x}\")\n            ### set the free parameters of the functions\n            p_dict = {\n                var_name: x[var_idx]\n                for var_idx, var_name in enumerate(sub_var_names_list)\n            }\n            if self._verbose_extreme:\n                print(f\"Current guess dict: {p_dict}\")\n            var_dict = {str(var): p_dict.get(str(var)) for var in self._f_variables}\n            var_dict[\"v_r\"] = self._v_rest\n            if self._verbose_extreme:\n                print(f\"var_dict: {var_dict}\")\n                print(f\"f_variables: {self._f_variables}\")\n\n            ### calculate the voltage clamp values\n            ### 1st f_inst, it depends on v_0 and v_step\n            var_dict[\"v_0\"] = self._v_0_arr\n            var_dict[\"v_step\"] = self._v_step_arr\n            f_inst_arr = self._f_inst(*list(var_dict.values()))\n            ### 2nd f_hold, it depends only on v_step\n            var_dict[\"v_0\"] = self._v_0_arr[int(len(self._v_0_arr) / 2)]\n            var_dict[\"v_step\"] = self._v_step_unique\n            f_hold_arr = self._f_hold(*list(var_dict.values()))\n\n            ### calculate the error\n            error = af.rmse(target_arr, np.concatenate([f_inst_arr, f_hold_arr]))\n            return error\n\n        def error_function_deap(population):\n            error_list = [(error_function(individual),) for individual in population]\n            return error_list\n\n        ### perform the optimization\n        ### set bounds\n        bounds = np.array([self.bounds[var_name] for var_name in sub_var_names_list])\n        ### set initial guess\n        if isinstance(self._p0, type(None)):\n            ### if no initial guess is given use the middle of the bounds\n            initial_guess = np.array(\n                [sum(self.bounds[var_name]) / 2.0 for var_name in sub_var_names_list]\n            )\n        else:\n            ### initial guess is an array 1st dimension is the number of tuned parameters\n            ### 2nd dimension is the number of initial guesses\n            initial_guess = np.array(\n                [self._p0[var_name] for var_name in sub_var_names_list]\n            )\n        if self.verbose:\n            print(f\"p0: {self.p0}\")\n            print(f\"_p0: {self._p0}\")\n            print(f\"bounds: {self.bounds}\")\n            print(f\"Initial guess: {initial_guess}\")\n            print(f\"Bounds: {bounds}\\n\")\n\n        ### run the optimization multiple times with different initial guesses\n        print_results = []\n        best_fitness = np.inf\n        for initial_guess_idx in range(initial_guess.shape[1]):\n            deap_cma = DeapCma(\n                max_evals=self.max_evals,\n                lower=bounds[:, 0],\n                upper=bounds[:, 1],\n                evaluate_function=error_function_deap,\n                p0=initial_guess[:, initial_guess_idx],\n                param_names=sub_var_names_list,\n                learn_rate_factor=self.cma_params_dict[\"learn_rate_factor\"],\n                damping_factor=self.cma_params_dict[\"damping_factor\"],\n                verbose=False,\n                plot_file=self.plot_file.split(\".\")[0]\n                + f\"_logbook_{initial_guess_idx}.\"\n                + self.plot_file.split(\".\")[-1],\n                cma_params_dict=self.cma_params_dict,\n            )\n            result = deap_cma.run()\n            print_results_dict = {\n                var_name: result[var_name] for var_name in sub_var_names_list\n            }\n            print_results_dict[\"best_fitness\"] = result[\"best_fitness\"]\n            print_results.append(print_results_dict)\n            if result[\"best_fitness\"] &lt; best_fitness:\n                best_fitness = result[\"best_fitness\"]\n                best_result = result\n        result_dict = {\n            var_name: best_result[var_name] for var_name in sub_var_names_list\n        }\n        result_dict[\"best_fitness\"] = best_result[\"best_fitness\"]\n        result_dict[\"v_r\"] = self._v_rest\n\n        if self.verbose:\n            print(\"Results:\")\n            print_df(pd.DataFrame(print_results))\n            print(f\"Result: {result_dict}\")\n\n        return result_dict\n\n    def _create_v_clamp_functions(self):\n        \"\"\"\n        Create the functions for v_clamp_inst and v_clamp_hold using the given\n        izhikevich equations.\n\n        Returns:\n            f_inst (Callable):\n                Function for v_clamp_inst\n            f_hold (Callable):\n                Function for v_clamp_hold\n            variables (list):\n                List of variables used for the functions\n        \"\"\"\n        ### obtain all variables and parameters from the equation string\n        variables_name_list = self._get_variables_from_eq(self.equations)\n\n        ### split equations into lines, remove whitespace and only keep entries with\n        ### length &gt; 0\n        eq_line_list = self.equations.splitlines()\n        eq_line_list = [line.replace(\" \", \"\") for line in eq_line_list]\n        eq_line_list = [line for line in eq_line_list if len(line) &gt; 0]\n\n        ### create a dictionary with the variables as keys and the sympy symbols as\n        ### values\n        variables_sympy_dict = {key: Symbol(key) for key in variables_name_list}\n\n        ### also create sympy symbols for v_clamp, v_0 and v_step\n        variables_sympy_dict[\"v_clamp\"] = Symbol(\"v_clamp\")\n        variables_sympy_dict[\"v_0\"] = Symbol(\"v_0\")\n        variables_sympy_dict[\"v_step\"] = Symbol(\"v_step\")\n\n        ### sympify equations\n        eq_sympy_list = []\n        variables_to_solve_for_list = []\n        instant_update_list = []\n        for line_idx, line in enumerate(eq_line_list):\n            left_side = line.split(\"=\")[0]\n            right_side = line.split(\"=\")[1]\n            ### check if line contains dv/dt, replace it with v_clamp and add v_clamp\n            ### to variables_to_solve_for_list, also set instant_update to True\n            if \"dv/dt\" in line:\n                variables_to_solve_for_list.append(\"v_clamp\")\n                left_side = left_side.replace(\"dv/dt\", \"v_clamp\")\n                instant_update_list.append(True)\n            ### check if line contains any other derivative with syntax \"d&lt;var&gt;/dt\"\n            ### using re, replace it with 0 and add the variable to\n            ### variables_to_solve_for_list, also set instant_update to False\n            elif re.search(r\"d\\w+/dt\", line):\n                variables_to_solve_for_list.append(\n                    re.search(r\"d(\\w+)/dt\", line).group(1)\n                )\n                left_side = left_side.replace(\n                    re.search(r\"d(\\w+)/dt\", line).group(0), \"0\"\n                )\n                instant_update_list.append(False)\n            ### else it is a \"normal\" equation (&lt;var&gt; = &lt;expression&gt;), not changing\n            ### anything, add the variable to variables_to_solve_for_list and set\n            ### instant_update to True\n            else:\n                variables_to_solve_for_list.append(line.split(\"=\")[0])\n                instant_update_list.append(True)\n            ### create the sympy equation, move everything on one side (other side = 0)\n            eq_sympy_list.append(Eq(0, sympify(right_side) - sympify(left_side)))\n\n        ### 1st find solution of variables for holding v_0\n        eq_sympy_list_hold_v_0 = deepcopy(eq_sympy_list)\n        for line_idx, line in enumerate(eq_sympy_list_hold_v_0):\n            eq_sympy_list_hold_v_0[line_idx] = line.subs(\n                {variables_sympy_dict[\"v\"]: variables_sympy_dict[\"v_0\"]}\n            )\n        ### solve\n        solution_hold_v_0 = self._solve_v_clamp_equations(\n            eq_sympy_list_hold_v_0, variables_to_solve_for_list, \"holding v_0\"\n        )\n\n        ### 2nd for v_clamp_inst set v to v_step only in equaitons which are\n        ### updated instantaneously  (v_clamp and all non-derivatives), for all\n        ### derivatives use the solution for holding v_0\n        eq_sympy_list_inst = deepcopy(eq_sympy_list)\n        for line_idx, line in enumerate(eq_sympy_list_inst):\n            if instant_update_list[line_idx]:\n                ### variable is updated instantaneously -&gt; set v to v_step\n                eq_sympy_list_inst[line_idx] = line.subs(\n                    {\n                        variables_sympy_dict[\"v\"]: variables_sympy_dict[\"v_step\"],\n                    }\n                )\n            else:\n                ### variable is not updated instantaneously -&gt; use solution for hold v_0\n                current_variable_name = variables_to_solve_for_list[line_idx]\n                current_variable = variables_sympy_dict[current_variable_name]\n                eq_sympy_list_inst[line_idx] = Eq(\n                    0, solution_hold_v_0[current_variable] - current_variable\n                )\n        ### solve\n        solution_inst = self._solve_v_clamp_equations(\n            eq_sympy_list_inst, variables_to_solve_for_list, \"step from v_0 to v_step\"\n        )\n\n        ### 3rd for v_clamp_hold (i.e. holding v_step) set v to v_step in all\n        ### equations\n        eq_sympy_list_hold = deepcopy(eq_sympy_list)\n        for line_idx, line in enumerate(eq_sympy_list_hold):\n            eq_sympy_list_hold[line_idx] = line.subs(\n                {variables_sympy_dict[\"v\"]: variables_sympy_dict[\"v_step\"]}\n            )\n        ### solve\n        solution_hold = self._solve_v_clamp_equations(\n            eq_sympy_list_hold, variables_to_solve_for_list, \"holding v_step\"\n        )\n\n        ### get the equations for v_clamp_inst and v_clamp_hold\n        eq_v_clamp_inst = solution_inst[variables_sympy_dict[\"v_clamp\"]]\n        eq_v_clamp_hold = solution_hold[variables_sympy_dict[\"v_clamp\"]]\n        if self.verbose:\n            print(f\"Equation for v_clamp_inst: {factor(eq_v_clamp_inst)}\")\n            print(f\"Equation for v_clamp_hold: {factor(eq_v_clamp_hold)}\")\n\n        ### create functions for v_clamp_inst and v_clamp_hold\n        ### 1st obtain all variables from the equations for v_clamp_inst and v_clamp_hold\n        f_variables = list(\n            set(list(eq_v_clamp_inst.free_symbols) + list(eq_v_clamp_hold.free_symbols))\n        )\n        ### 2nd create a function for each equation\n        f_inst = lambdify(f_variables, eq_v_clamp_inst)\n        f_hold = lambdify(f_variables, eq_v_clamp_hold)\n\n        return f_inst, f_hold, f_variables\n\n    def _solve_v_clamp_equations(\n        self, eq_sympy_list, variables_to_solve_for_list, name\n    ):\n        solution = solve(\n            eq_sympy_list,\n            variables_to_solve_for_list,\n            dict=True,\n        )\n        if len(solution) == 1:\n            solution = solution[0]\n        elif len(solution) &gt; 1:\n            print(f\"Warning: Multiple solutions for {name}!\")\n        else:\n            raise ValueError(f\"Could not solve equations for {name}!\")\n\n        return solution\n\n    def _get_variables_from_eq(self, eq: str):\n        \"\"\"\n        Get a list of all variable names from the given equation string.\n\n        Args:\n            eq (str):\n                the equation string\n        \"\"\"\n        ### split equations into lines\n        eq_line_list = eq.splitlines()\n\n        ### loop over lines\n        variables_name_list = []\n        for line in eq_line_list:\n            if \"=\" not in line:\n                continue\n            ### split line at = and only take right side (e.g. not use dv/dt)\n            line = line.split(\"=\")[1]\n            ### remove whitespaces\n            line = line.replace(\" \", \"\")\n            ### replace all kind of special characters with a space\n            special_characters = [\"+\", \"-\", \"*\", \"/\", \"(\", \")\", \"[\", \"]\", \"=\"]\n            for special_character in special_characters:\n                line = line.replace(special_character, \" \")\n            ### split line at spaces\n            line_split = line.split()\n            ### append to list\n            variables_name_list += line_split\n\n        ### remove duplicates\n        variables_name_list = list(set(variables_name_list))\n\n        return variables_name_list\n\n    def _simulations(self):\n        \"\"\"\n        Perform the resting state and voltage step simulations to obtain v_clamp_inst,\n        v_clamp_hold and v_rest.\n\n        Returns:\n            v_rest (float):\n                resting state voltage\n            v_clamp_inst (np.array):\n                array of the voltage clamp values directly after the voltage step\n            v_clamp_hold (np.array):\n                array of the voltage clamp values after the holding period\n\n        \"\"\"\n        duration = 200\n        ### simulate both models at the same time\n        ### for pop_normal nothing happens (resting state)\n        ### for pop_clamp the voltage is set to v_0 and then to v_step for each neuron\n        get_population(\"pop_clamp\").v = self._v_0_arr\n        simulate(duration)\n        get_population(\"pop_clamp\").v = self._v_step_arr\n        simulate(self._timestep)\n        v_clamp_inst_arr = get_population(\"pop_clamp\").v_clamp\n        simulate(duration - self._timestep)\n        v_clamp_hold_arr = get_population(\"pop_clamp\").v_clamp\n        v_rest = get_population(\"pop_normal\").v[0]\n\n        ### get unique values of v_step and their indices\n        v_step_unique, v_step_unique_idx = np.unique(\n            self._v_step_arr, return_index=True\n        )\n        ### get the corresponding values of v_clamp_hold (because it does only depend om\n        ### v_step)\n        v_clamp_hold_unique = v_clamp_hold_arr[v_step_unique_idx]\n\n        if self.do_plot and not isinstance(self._v_clamp_inst_arr, type(None)):\n            plt.figure(figsize=(6.4 * 3, 4.8 * 2))\n            ### create a 2D color-coded plot of the data for v_clamp_inst and v_clamp_hold\n            x = self._v_0_arr\n            y = self._v_step_arr\n\n            ### create 2 subplots for original v_clamp_inst and v_clamp_hold\n            plt.subplot(231)\n            self._plot_v_clamp_subplot(\n                x,\n                y,\n                self._v_clamp_inst_arr,\n                \"v_clamp_inst original\",\n            )\n            plt.subplot(234)\n            self._plot_v_clamp_subplot(\n                x,\n                y,\n                self._v_clamp_hold_arr,\n                \"v_clamp_hold original\",\n            )\n\n            ### create 2 subplots for tuned v_clamp_inst and v_clamp_hold\n            plt.subplot(232)\n            self._plot_v_clamp_subplot(\n                x,\n                y,\n                v_clamp_inst_arr,\n                \"v_clamp_inst tuned\",\n            )\n            plt.subplot(235)\n            self._plot_v_clamp_subplot(\n                x,\n                y,\n                v_clamp_hold_arr,\n                \"v_clamp_hold tuned\",\n            )\n\n            ### create 2 subplots for differences\n            plt.subplot(233)\n            self._plot_v_clamp_subplot(\n                x,\n                y,\n                self._v_clamp_inst_arr - v_clamp_inst_arr,\n                \"v_clamp_inst diff\",\n            )\n            plt.subplot(236)\n            self._plot_v_clamp_subplot(\n                x,\n                y,\n                self._v_clamp_hold_arr - v_clamp_hold_arr,\n                \"v_clamp_hold diff\",\n            )\n\n            plt.tight_layout()\n\n            plt.savefig(\n                self.plot_file.split(\".\")[0] + \"_data.\" + self.plot_file.split(\".\")[1],\n                dpi=300,\n            )\n            plt.close()\n\n        return (\n            v_rest,\n            v_clamp_inst_arr,\n            v_clamp_hold_arr,\n            v_step_unique,\n            v_clamp_hold_unique,\n        )\n\n    def _plot_v_clamp_subplot(self, x, y, c, label):\n        plt.title(label)\n\n        ci = c\n        if len(c) &gt;= 4:\n            # Define the grid for interpolation\n            xi, yi = np.meshgrid(\n                np.linspace(min(x), max(x), 100), np.linspace(min(y), max(y), 100)\n            )\n\n            # Perform the interpolation\n            ci = griddata((x, y), c, (xi, yi), method=\"linear\")\n\n            # Plot the interpolated surface\n            plt.contourf(\n                xi,\n                yi,\n                ci,\n                levels=100,\n                cmap=\"bwr\",\n                vmin=-af.get_maximum(np.absolute(ci)),\n                vmax=af.get_maximum(np.absolute(ci)),\n            )\n\n        # Plot also the original data points\n        plt.scatter(\n            x,\n            y,\n            c=c,\n            cmap=\"bwr\",\n            vmin=-af.get_maximum(np.absolute(ci)),\n            vmax=af.get_maximum(np.absolute(ci)),\n            s=5,\n        )\n\n        plt.colorbar(label=label)\n        plt.xlabel(\"v_0\")\n        plt.ylabel(\"v_step\")\n\n    def _create_voltage_step_arrays(self):\n        \"\"\"\n        Create the arrays for the initial voltages and the voltage steps.\n\n        Returns:\n            v_0_arr (np.array):\n                array of the initial voltages\n            v_step_arr (np.array):\n                array of the voltage steps\n\n        \"\"\"\n        ### create the unique values of v_step and v_0\n        v_0_arr_unique = np.linspace(-90, -40, self.m)\n        v_step_arr_unique = np.linspace(-90, -40, self.n)\n\n        ### create a 2D array of all combinations of v_0 and v_step\n        v_0_arr = np.repeat(v_0_arr_unique, self.n)\n        v_step_arr = np.tile(v_step_arr_unique, self.m)\n\n        return v_0_arr, v_step_arr\n\n    def _create_model(self):\n        \"\"\"\n        Create a population (single neuron) for each neuron model.\n\n        Returns:\n            model_normal (CompNeuroModel):\n                model containing the population with the normal neuron model\n            model_clamp (CompNeuroModel):\n                model containing the population with the voltage clamped neuron model\n        \"\"\"\n        ### setup ANNarchy\n        setup(dt=self._timestep, seed=1234)\n        ### create a population with the normal neuron model\n        model_normal = CompNeuroModel(\n            model_creation_function=lambda: Population(\n                1, self._neuron_model, name=\"pop_normal\"\n            ),\n            name=\"model_normal\",\n            do_compile=False,\n        )\n        ### create a population with the voltage clamped neuron model\n        model_clamp = CompNeuroModel(\n            model_creation_function=lambda: Population(\n                len(self._v_0_arr), self._neuron_model_clamp, name=\"pop_clamp\"\n            ),\n            name=\"model_clamp\",\n            compile_folder_name=self.compile_folder_name,\n        )\n\n        return model_normal, model_clamp\n\n    def _get_neuron_model_attributes(self, neuron_model: Neuron):\n        \"\"\"\n        Get a list of the attributes (parameters and variables) of the given neuron\n        model.\n\n        Returns:\n            attributes (list):\n                list of the attributes of the given neuron model\n        \"\"\"\n        neuron_model._analyse()\n        attributes = []\n        for param in neuron_model.description[\"parameters\"]:\n            attributes.append(param[\"name\"])\n        for var in neuron_model.description[\"variables\"]:\n            attributes.append(var[\"name\"])\n        return attributes\n\n    def _get_neuron_model_arguments(self, neuron_model: Neuron):\n        \"\"\"\n        Get a dictionary of the initial arguments of the given neuron model.\n\n        Args:\n            neuron_model (Neuron):\n                the neuron model which should be analyzed\n\n        Returns:\n            init_arguments_dict (dict):\n                dictionary of the initial arguments of the given neuron model\n        \"\"\"\n        ### get the names of the arguments of a Neuron class\n        init_arguments_name_list = list(Neuron.__init__.__code__.co_varnames)\n        init_arguments_name_list.remove(\"self\")\n        init_arguments_name_list.remove(\"name\")\n        init_arguments_name_list.remove(\"description\")\n        ### get these attributes from the given neuron model\n        init_arguments_dict = {\n            init_arguments_name: getattr(neuron_model, init_arguments_name)\n            for init_arguments_name in init_arguments_name_list\n        }\n\n        return init_arguments_dict\n\n    def _get_neuron_model_clamp(self):\n        \"\"\"\n        Create a neuron model with voltage clamp equations.\n\n        Returns:\n            neuron_model_clamp (Neuron):\n                the neuron model with voltage clamped equation\n        \"\"\"\n        ### get these attributes from the given neuron model\n        init_arguments_dict = self._get_neuron_model_arguments(self._neuron_model)\n        ### split the equations string\n        equations_line_split_list = str(init_arguments_dict[\"equations\"]).splitlines()\n        ### adjust the equations for voltage clamp\n        equations_line_split_list = self._adjust_equations_for_voltage_clamp(\n            equations_line_split_list\n        )\n\n        ### combine string lines to multiline strings again\n        init_arguments_dict[\"equations\"] = \"\\n\".join(equations_line_split_list)\n\n        ### create neuron model with new equations\n        neuron_model_clamp = Neuron(**init_arguments_dict)\n\n        if self.verbose:\n            print(f\"Neuron model with voltage clamp equations:\\n{neuron_model_clamp}\")\n\n        return neuron_model_clamp\n\n    def _adjust_equations_for_voltage_clamp(self, eq_line_list: list):\n        \"\"\"\n        Replaces the 'dv/dt' or 'v+=' equation with a voltage clamp version in which the\n        new variable 'v_clamp' is calculated from the right side of the 'dv/dt' or 'v+='\n        equation.\n\n        Args:\n            eq_line_list (list):\n                list of the lines of the equations of the neuron model\n\n        Returns:\n            eq_line_list (list):\n                list of the lines of the equations of the neuron model with voltage clamp\n        \"\"\"\n        ### check in which lines v is updated\n        line_is_v_list = [False] * len(eq_line_list)\n        for line_idx, line in enumerate(eq_line_list):\n            line_is_v_list[line_idx] = self._get_line_is_v(line)\n        ### raise error if in no line v is updated or in multiple lines\n        if sum(line_is_v_list) == 0 or sum(line_is_v_list) &gt; 1:\n            raise ValueError(\n                \"Could not find one line with dv/dt or v+= in equations of neuronmodel!\"\n            )\n\n        ### obtain the line containing v update\n        eq_v = eq_line_list[line_is_v_list.index(True)]\n\n        ### remove whitespaces\n        eq_v = eq_v.replace(\" \", \"\")\n\n        ### split eqatuion at \":\" to separate flags\n        eq_v_split = eq_v.split(\":\")\n        eq_v = eq_v_split[0]\n        ### check if flags are present\n        if len(eq_v_split) == 1:\n            flags = \"\"\n        else:\n            flags = \":\" + eq_v_split[1]\n        ### adjust the equation for voltage clamp\n        if \"+=\" in eq_v:\n            eq_v, eq_v_clamp = self._adjust_equation_for_voltage_clamp_plus(eq_v, flags)\n        else:\n            eq_v, eq_v_clamp = self._adjust_equation_for_voltage_clamp_dvdt(eq_v, flags)\n        ### delete old equation from equation list using the index of the equation\n        eq_line_list.pop(line_is_v_list.index(True))\n        ### insert new equation at the same position\n        eq_line_list.insert(line_is_v_list.index(True), eq_v)\n        ### insert new equation for \"v_clamp\" at the same position\n        eq_line_list.insert(line_is_v_list.index(True), eq_v_clamp)\n\n        return eq_line_list\n\n    def _adjust_equation_for_voltage_clamp_plus(self, eq_v: str, flags: str):\n        \"\"\"\n        Convert the v-update equation using \"v+=\" into a voltage clamp version.\n\n        Args:\n            eq_v (str):\n                the equation string for updating v (without flags)\n            flags (str):\n                the flags of the equation string\n\n        Returns:\n            eq_v (str):\n                the adjusted equation string for updating v (without flags)\n            eq_v_clamp (str):\n                the equation string for \"v_clamp\" (with flags)\n        \"\"\"\n        ### split equations at \"=\" to separate left and right side\n        eq_v_left, eq_v_right = eq_v.split(\"=\")\n        ### set right side to zero and combine equation again with \"=\"\n        eq_v = eq_v_left + \"=\" + \"0\"\n        ### create new equation for \"v_clamp\" with right side of original equation\n        eq_v_clamp = \"v_clamp=\" + eq_v_right + flags\n\n        return eq_v, eq_v_clamp\n\n    def _adjust_equation_for_voltage_clamp_dvdt(self, eq_v: str, flags: str):\n        \"\"\"\n        Convert the v-update equation using \"dv/dt\" into a voltage clamp version.\n\n        Args:\n            eq_v (str):\n                the equation string for updating v (without flags)\n            flags (str):\n                the flags of the equation string\n\n        Returns:\n            eq_v (str):\n                the adjusted equation string for updating v (without flags)\n            eq_v_clamp (str):\n                the equation string for \"v_clamp\" (with flags)\n        \"\"\"\n        ### if equation starts with \"dv/dt=\" do the same as for \"v+=\"\n        if eq_v.startswith(\"dv/dt=\"):\n            return self._adjust_equation_for_voltage_clamp_plus(eq_v, flags)\n\n        ### if equation doesn't start with \"dv/dt=\" --&gt; need to rearrange equation\n        ### i.e. solve the equation for dv/dt\n        eq_v = eq_v.replace(\"dv/dt\", \"delta_v\")\n\n        ### split the equation at \"=\" and move everything on one side (other side = 0)\n        ### replace the whole right side with \"right_side\" making solving easier\n        left_side, right_side = eq_v.split(\"=\")\n        eq_v_one_side = f\"(right_side) - {left_side}\"\n\n        ### prepare the sympy equation generation\n        attributes_name_list = self._get_neuron_model_attributes(self._neuron_model)\n        ### create a sympy symbol for each attribute of the neuron\n        attributes_tuple = symbols(\",\".join(attributes_name_list))\n        ### create a dict with the names as keys and the sympy symbols as values\n        attributes_sympy_dict = {\n            key: attributes_tuple[attributes_name_list.index(key)]\n            for key in attributes_name_list\n        }\n        ### further create symbols for delta_v and right_side\n        attributes_sympy_dict[\"delta_v\"] = Symbol(\"delta_v\")\n        attributes_sympy_dict[\"right_side\"] = Symbol(\"right_side\")\n\n        ### now creating the sympy equation\n        eq_sympy = sympify(eq_v_one_side)\n\n        ### solve the equation for delta_v\n        result = solve(eq_sympy, attributes_sympy_dict[\"delta_v\"], dict=True)\n        if len(result) != 1:\n            raise ValueError(\"Could not solve equation of neuronmodel for dv/dt!\")\n\n        ### convert result to string\n        result = str(result[0][attributes_sympy_dict[\"delta_v\"]])\n\n        ### replace \"right_side\" by the actual right side in brackets\n        result = result.replace(\"right_side\", f\"({right_side})\")\n\n        ### create new equation for dv/dt\n        eq_v = \"dv/dt = 0\"\n        ### create new equation for \"v_clamp\" with the equation solved for dv/dt\n        eq_v_clamp = \"v_clamp=\" + result + flags\n\n        return eq_v, eq_v_clamp\n\n    def _get_line_is_v(self, line: str):\n        \"\"\"\n        Check if a equation string contains dv/dt or v+=\n\n        Args:\n            line (str):\n                the equation string\n\n        Returns:\n            line_is_v (bool):\n                True if the equation string contains dv/dt or v+=, False otherwise\n        \"\"\"\n        if \"v\" not in line:\n            return False\n\n        ### remove whitespaces\n        line = line.replace(\" \", \"\")\n\n        ### check for dv/dt\n        if \"dv/dt\" in line:\n            return True\n\n        ### check for v update\n        if \"v+=\" in line and line.startswith(\"v\"):\n            return True\n\n        return False\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.VClampParamSearch.__init__","title":"<code>__init__(neuron_model, equations='\\n        C*dv/dt = k*(v - v_r)*(v - v_t) - u\\n        du/dt = a*(b*(v - v_r) - u)\\n        ', bounds={'C': (0.1, 100), 'v_r': (-90, -40), 'v_t': (-90, -40), 'k': (0.01, 1), 'a': (0.01, 1), 'b': (-5, 5)}, p0=None, max_evals=100, m=20, n=20, do_plot=False, results_file='v_clamp_search_results', plot_file='v_clamp_search_plot.png', cma_params_dict={'learn_rate_factor': 1, 'damping_factor': 1}, compile_folder_name='VClampParamSearch', verbose=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>neuron_model</code> <code>Neuron</code> <p>The neuron model which is simulated to obtain the parameters for the equations</p> required <code>equations</code> <code>str</code> <p>The equations whose parameters should be obtained. Default: Izhikevich 2007 neuron model</p> <code>'\\n        C*dv/dt = k*(v - v_r)*(v - v_t) - u\\n        du/dt = a*(b*(v - v_r) - u)\\n        '</code> <code>bounds</code> <code>dict</code> <p>The bounds for the parameters. For each parameter a bound should be given! Default: Izhikevich 2007 neuron model</p> <code>{'C': (0.1, 100), 'v_r': (-90, -40), 'v_t': (-90, -40), 'k': (0.01, 1), 'a': (0.01, 1), 'b': (-5, 5)}</code> <code>p0</code> <code>dict</code> <p>The initial guess for the parameters. Dict keys should be the same as the keys of bounds. The values can be either a single number for each parameter or a list of numbers. If lists are given, all have to have the same length, which will be the number of initial guesses for the parameters, i.e. how often the optimization is run. Default: None, i.e. the mid of the bounds is used as a single initial guess.</p> <code>None</code> <code>max_evals</code> <code>int</code> <p>The maximum number of evaluations for a single optimization run. Default: 100</p> <code>100</code> <code>m</code> <code>int</code> <p>The number of initial voltages for the voltage step simulations. Default: 20</p> <code>20</code> <code>n</code> <code>int</code> <p>The number of voltage steps for the voltage step simulations. Defaults: 20</p> <code>20</code> <code>do_plot</code> <code>bool</code> <p>If True, plots are created. Default: False</p> <code>False</code> <code>results_file</code> <code>str</code> <p>The name of the file where the results are stored, without file ending. Default: \"v_clamp_search_results\"</p> <code>'v_clamp_search_results'</code> <code>plot_file</code> <code>str</code> <p>The name of the file where the plot is stored, with file ending. Default: \"v_clamp_search_plot.png\"</p> <code>'v_clamp_search_plot.png'</code> <code>cma_params_dict</code> <code>dict</code> <p>Parameters for the deap cma strategy (deap.cma.Strategy). See here for more details. Additional parameters are learn_rate_factor and damping_factor. Default: {\"learn_rate_factor\": 1, \"damping_factor\": 1}</p> <code>{'learn_rate_factor': 1, 'damping_factor': 1}</code> <code>compile_folder_name</code> <code>str</code> <p>The name of the folder within \"annarchy_folders\" where the ANNarchy network is compiled to. Default: \"VClampParamSearch\"</p> <code>'VClampParamSearch'</code> <code>verbose</code> <code>bool</code> <p>If True, print details. Default: False</p> <code>False</code> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    neuron_model: Neuron,\n    equations: str = \"\"\"\n    C*dv/dt = k*(v - v_r)*(v - v_t) - u\n    du/dt = a*(b*(v - v_r) - u)\n    \"\"\",\n    bounds: dict[str, tuple[float, float]] = {\n        \"C\": (0.1, 100),\n        \"v_r\": (-90, -40),\n        \"v_t\": (-90, -40),\n        \"k\": (0.01, 1),\n        \"a\": (0.01, 1),\n        \"b\": (-5, 5),\n    },\n    p0: None | dict[str, float | list] = None,\n    max_evals: int = 100,\n    m: int = 20,\n    n: int = 20,\n    do_plot: bool = False,\n    results_file: str = \"v_clamp_search_results\",\n    plot_file: str = \"v_clamp_search_plot.png\",\n    cma_params_dict: dict = {\"learn_rate_factor\": 1, \"damping_factor\": 1},\n    compile_folder_name: str = \"VClampParamSearch\",\n    verbose: bool = False,\n):\n    \"\"\"\n    Args:\n        neuron_model (Neuron):\n            The neuron model which is simulated to obtain the parameters for the\n            equations\n        equations (str, optional):\n            The equations whose parameters should be obtained. Default: Izhikevich\n            2007 neuron model\n        bounds (dict, optional):\n            The bounds for the parameters. For each parameter a bound should be\n            given! Default: Izhikevich 2007 neuron model\n        p0 (dict, optional):\n            The initial guess for the parameters. Dict keys should be the same as\n            the keys of bounds. The values can be either a single number for each\n            parameter or a list of numbers. If lists are given, all have to have\n            the same length, which will be the number of initial guesses for the\n            parameters, i.e. how often the optimization is run. Default: None,\n            i.e. the mid of the bounds is used as a single initial guess.\n        max_evals (int, optional):\n            The maximum number of evaluations for a single optimization run.\n            Default: 100\n        m (int, optional):\n            The number of initial voltages for the voltage step simulations.\n            Default: 20\n        n (int, optional):\n            The number of voltage steps for the voltage step simulations.\n            Defaults: 20\n        do_plot (bool, optional):\n            If True, plots are created. Default: False\n        results_file (str, optional):\n            The name of the file where the results are stored, without file ending.\n            Default: \"v_clamp_search_results\"\n        plot_file (str, optional):\n            The name of the file where the plot is stored, with file ending.\n            Default: \"v_clamp_search_plot.png\"\n        cma_params_dict (dict, optional):\n            Parameters for the deap cma strategy (deap.cma.Strategy). See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy)\n            for more details. Additional parameters are learn_rate_factor and\n            damping_factor. Default: {\"learn_rate_factor\": 1, \"damping_factor\": 1}\n        compile_folder_name (str, optional):\n            The name of the folder within \"annarchy_folders\" where the ANNarchy\n            network is compiled to. Default: \"VClampParamSearch\"\n        verbose (bool, optional):\n            If True, print details. Default: False\n    \"\"\"\n    self.verbose = verbose\n    self._verbose_extreme = False\n    ### store the given neuron model and a voltage clamp version of it\n    self.neuron_model = neuron_model\n    self._neuron_model = deepcopy(neuron_model)\n    self._neuron_model_clamp = self._get_neuron_model_clamp()\n\n    ### store other attributes\n    self.m = m\n    self.n = n\n    self.equations = equations\n    self.p0 = p0\n    ### check if p0 is correct and if lists are given, create also lists single\n    ### numbers which are given\n    self._p0 = self._get_p0()\n    self.max_evals = max_evals\n    self.bounds = bounds\n    self.do_plot = do_plot\n    self.results_file = results_file\n    self.plot_file = plot_file\n    self.cma_params_dict = cma_params_dict\n    ### check if file names are correct\n    if \".\" in self.results_file or \".\" not in self.plot_file:\n        raise ValueError(\n            \"results_file should not contain file ending and plot_file should!\"\n        )\n    self.compile_folder_name = compile_folder_name\n    self._timestep = 0.001\n\n    ### create folder for plots\n    if self.do_plot:\n        sf.create_dir(\"/\".join(plot_file.split(\"/\")[:-1]))\n\n    ### create the functions for v_clamp_inst and v_clamp_hold using the given\n    ### izhikevich equations\n    self._f_inst, self._f_hold, self._f_variables = self._create_v_clamp_functions()\n\n    ### create the voltage step arrays\n    self._v_0_arr, self._v_step_arr = self._create_voltage_step_arrays()\n\n    ### for each neuron model create a population\n    if self.verbose:\n        print(\"Creating models...\")\n    mf.cnp_clear()\n    self._model_normal, self._model_clamp = self._create_model()\n\n    ### perform resting state and voltage step simulations to obtain v_clamp_inst,\n    ### v_clamp_hold and v_rest\n    self._v_clamp_inst_arr = None\n    self._v_clamp_hold_arr = None\n    if self.verbose:\n        print(\"Performing simulations...\")\n    (\n        self._v_rest,\n        self._v_clamp_inst_arr,\n        self._v_clamp_hold_arr,\n        self._v_step_unique,\n        self._v_clamp_hold_unique,\n    ) = self._simulations()\n\n    ### tune the free paramters of the functions for v_clamp_inst and v_clamp_hold\n    ### to fit the data\n    if self.verbose:\n        print(\"Tuning parameters...\")\n    self._p_opt = self._tune_v_clamp_functions()\n    self.p_opt = {\n        param_name: self._p_opt.get(param_name, None)\n        for param_name in self.bounds.keys()\n    }\n    self.p_opt[\"best_fitness\"] = self._p_opt[\"best_fitness\"]\n\n    ### print and save optimized parameters\n    if self.verbose:\n        print(f\"Optimized parameters: {self.p_opt}\")\n    ### save as pkl file\n    sf.save_variables(\n        [self.p_opt],\n        [results_file.split(\"/\")[-1]],\n        \"/\".join(results_file.split(\"/\")[:-1]) if \"/\" in results_file else \"./\",\n    )\n    ### save human readable as json file\n    json.dump(\n        self.p_opt,\n        open(\n            f\"{results_file}.json\",\n            \"w\",\n        ),\n        indent=4,\n    )\n\n    ### create a neuron model with the tuned parameters and the given equations\n    ### then run the simulations again with this neuron model\n    if self.verbose:\n        print(\"Running simulations with tuned parameters...\")\n    mf.cnp_clear()\n    self._neuron_model = self._create_neuron_model_with_tuned_parameters()\n    self._neuron_model_clamp = self._get_neuron_model_clamp()\n    self._model_normal, self._model_clamp = self._create_model()\n    self._simulations()\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.print_df","title":"<code>print_df(df, **kwargs)</code>","text":"<p>Prints the complete dataframe df</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas dataframe or dict</code> <p>Dataframe to be printed</p> required Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def print_df(df: pd.DataFrame | dict, **kwargs):\n    \"\"\"\n    Prints the complete dataframe df\n\n    Args:\n        df (pandas dataframe or dict):\n            Dataframe to be printed\n    \"\"\"\n    if isinstance(df, dict):\n        df = pd.DataFrame.from_dict(df)\n    with pd.option_context(\n        \"display.max_rows\", None\n    ):  # more options can be specified also\n        print(df, **kwargs)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.flatten_list","title":"<code>flatten_list(lst)</code>","text":"<p>Retuns flattened list</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <code>list of lists or mixed</code> <p>values and lists): List to be flattened</p> required <p>Returns:</p> Name Type Description <code>new_list</code> <code>list</code> <p>Flattened list</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def flatten_list(lst):\n    \"\"\"\n    Retuns flattened list\n\n    Args:\n        lst (list of lists or mixed: values and lists):\n            List to be flattened\n\n    Returns:\n        new_list (list):\n            Flattened list\n    \"\"\"\n\n    ### if lists in lst --&gt; upack them and retunr flatten_list of new list\n    new_lst = []\n    list_in_lst = False\n    for val in lst:\n        if isinstance(val, list):\n            list_in_lst = True\n            for sub_val in val:\n                new_lst.append(sub_val)\n        else:\n            new_lst.append(val)\n\n    if list_in_lst:\n        return flatten_list(new_lst)\n    ### else return lst\n    else:\n        return lst\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.remove_key","title":"<code>remove_key(d, key)</code>","text":"<p>Removes an element from a dict, returns the new dict</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>Dict to be modified</p> required <code>key</code> <code>str</code> <p>Key to be removed</p> required <p>Returns:</p> Name Type Description <code>r</code> <code>dict</code> <p>Modified dict</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def remove_key(d, key):\n    \"\"\"\n    Removes an element from a dict, returns the new dict\n\n    Args:\n        d (dict):\n            Dict to be modified\n        key (str):\n            Key to be removed\n\n    Returns:\n        r (dict):\n            Modified dict\n    \"\"\"\n    r = dict(d)\n    del r[key]\n    return r\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.suppress_stdout","title":"<code>suppress_stdout()</code>","text":"<p>Suppresses the print output of a function</p> <p>Examples:</p> <pre><code>with suppress_stdout():\n    print(\"this will not be printed\")\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>@contextmanager\ndef suppress_stdout():\n    \"\"\"\n    Suppresses the print output of a function\n\n    Examples:\n        ```python\n        with suppress_stdout():\n            print(\"this will not be printed\")\n        ```\n    \"\"\"\n    with open(os.devnull, \"w\") as devnull:\n        old_stdout = sys.stdout\n        sys.stdout = devnull\n        try:\n            yield\n        finally:\n            sys.stdout = old_stdout\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.sci","title":"<code>sci(nr)</code>","text":"<p>Rounds a number to a single decimal. If number is smaller than 0 it is converted to scientific notation with 1 decimal.</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>Number to be converted</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>String of the number in scientific notation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sci(0.0001)\n'1.0e-4'\n&gt;&gt;&gt; sci(1.77)\n'1.8'\n&gt;&gt;&gt; sci(1.77e-5)\n'1.8e-5'\n&gt;&gt;&gt; sci(177.22)\n'177.2'\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def sci(nr):\n    \"\"\"\n    Rounds a number to a single decimal.\n    If number is smaller than 0 it is converted to scientific notation with 1 decimal.\n\n    Args:\n        nr (float or int):\n            Number to be converted\n\n    Returns:\n        str (str):\n            String of the number in scientific notation\n\n    Examples:\n        &gt;&gt;&gt; sci(0.0001)\n        '1.0e-4'\n        &gt;&gt;&gt; sci(1.77)\n        '1.8'\n        &gt;&gt;&gt; sci(1.77e-5)\n        '1.8e-5'\n        &gt;&gt;&gt; sci(177.22)\n        '177.2'\n    \"\"\"\n    if af.get_number_of_zero_decimals(nr) == 0:\n        return str(round(nr, 1))\n    else:\n        return f\"{nr*10**af.get_number_of_zero_decimals(nr):.1f}e-{af.get_number_of_zero_decimals(nr)}\"\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.create_cm","title":"<code>create_cm(colors, name='my_cmap', N=256, gamma=1.0, vmin=0, vmax=1)</code>","text":"<p>Create a <code>LinearSegmentedColormap</code> from a list of colors.</p> <p>Parameters:</p> Name Type Description Default <code>colors</code> <code>array-like of colors or array-like of (value, color</code> <p>If only colors are given, they are equidistantly mapped from the range :math:<code>[0, 1]</code>; i.e. 0 maps to <code>colors[0]</code> and 1 maps to <code>colors[-1]</code>. If (value, color) pairs are given, the mapping is from value to color. This can be used to divide the range unevenly.</p> required <code>name</code> <code>str</code> <p>The name of the colormap, by default 'my_cmap'.</p> <code>'my_cmap'</code> <code>N</code> <code>int</code> <p>The number of rgb quantization levels, by default 256.</p> <code>256</code> <code>gamma</code> <code>float</code> <p>Gamma correction value, by default 1.0.</p> <code>1.0</code> <code>vmin</code> <code>float</code> <p>The minimum value of the colormap, by default 0.</p> <code>0</code> <code>vmax</code> <code>float</code> <p>The maximum value of the colormap, by default 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>linear_colormap</code> <code>_LinearColormapClass</code> <p>The colormap object</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def create_cm(colors, name=\"my_cmap\", N=256, gamma=1.0, vmin=0, vmax=1):\n    \"\"\"\n    Create a `LinearSegmentedColormap` from a list of colors.\n\n    Args:\n        colors (array-like of colors or array-like of (value, color)):\n            If only colors are given, they are equidistantly mapped from the\n            range :math:`[0, 1]`; i.e. 0 maps to ``colors[0]`` and 1 maps to\n            ``colors[-1]``.\n            If (value, color) pairs are given, the mapping is from *value*\n            to *color*. This can be used to divide the range unevenly.\n        name (str, optional):\n            The name of the colormap, by default 'my_cmap'.\n        N (int, optional):\n            The number of rgb quantization levels, by default 256.\n        gamma (float, optional):\n            Gamma correction value, by default 1.0.\n        vmin (float, optional):\n            The minimum value of the colormap, by default 0.\n        vmax (float, optional):\n            The maximum value of the colormap, by default 1.\n\n    Returns:\n        linear_colormap (_LinearColormapClass):\n            The colormap object\n    \"\"\"\n    if not np.iterable(colors):\n        raise ValueError(\"colors must be iterable\")\n\n    if (\n        isinstance(colors[0], Sized)\n        and len(colors[0]) == 2\n        and not isinstance(colors[0], str)\n    ):\n        # List of value, color pairs\n        vals, colors = zip(*colors)\n        vals = np.array(vals).astype(float)\n        colors = list(colors)\n        ### insert values for 0 and 1 if not given\n        ### they equal the colors of the borders of the given range\n        if vals.min() != 0.0:\n            colors = [colors[np.argmin(vals)]] + colors\n            vals = np.insert(vals, 0, 0.0)\n        if vals.max() != 1.0:\n            colors = colors + [colors[np.argmax(vals)]]\n            vals = np.insert(vals, len(vals), 1.0)\n    else:\n        vals = np.linspace(0, 1, len(colors))\n\n    ### sort values and colors, they have to increase\n    sort_idx = np.argsort(vals)\n    vals = vals[sort_idx]\n    colors = [colors[idx] for idx in sort_idx]\n\n    r_g_b_a = np.zeros((len(colors), 4))\n    for color_idx, color in enumerate(colors):\n        if isinstance(color, str):\n            ### color given by name\n            r_g_b_a[color_idx] = to_rgba_array(color)\n        else:\n            ### color given by rgb(maybe a) value\n            color = np.array(color).astype(float)\n            ### check color size\n            if len(color) != 3 and len(color) != 4:\n                raise ValueError(\n                    \"colors must be names or consist of 3 (rgb) or 4 (rgba) numbers\"\n                )\n            if color.max() &gt; 1:\n                ### assume that max value is 255\n                color[:3] = color[:3] / 255\n            if len(color) == 4:\n                ### gamma already given\n                r_g_b_a[color_idx] = color\n            else:\n                ### add gamma\n                r_g_b_a[color_idx] = np.concatenate([color, np.array([gamma])])\n    r = r_g_b_a[:, 0]\n    g = r_g_b_a[:, 1]\n    b = r_g_b_a[:, 2]\n    a = r_g_b_a[:, 3]\n\n    cdict = {\n        \"red\": np.column_stack([vals, r, r]),\n        \"green\": np.column_stack([vals, g, g]),\n        \"blue\": np.column_stack([vals, b, b]),\n        \"alpha\": np.column_stack([vals, a, a]),\n    }\n\n    return _LinearColormapClass(name, cdict, N, gamma, vmin, vmax)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.evaluate_expression_with_dict","title":"<code>evaluate_expression_with_dict(expression, value_dict)</code>","text":"<p>Evaluate a mathematical expression using values from a dictionary.</p> <p>This function takes a mathematical expression as a string and a dictionary containing variable names as keys and corresponding values as numpy arrays. It replaces the variable names in the expression with their corresponding values from the dictionary and evaluates the expression.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <code>str</code> <p>A mathematical expression to be evaluated. Variable names in the expression should match the keys in the value_dict.</p> required <code>value_dict</code> <code>dict</code> <p>A dictionary containing variable names (strings) as keys and corresponding numpy arrays or numbers as values.</p> required <p>Returns:</p> Name Type Description <code>result</code> <code>value or array</code> <p>The result of evaluating the expression using the provided values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; my_dict = {\"a\": np.ones(10), \"b\": np.arange(10)}\n&gt;&gt;&gt; my_string = \"a*2-b+10\"\n&gt;&gt;&gt; evaluate_expression_with_dict(my_string, my_dict)\narray([12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.])\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def evaluate_expression_with_dict(expression, value_dict):\n    \"\"\"\n    Evaluate a mathematical expression using values from a dictionary.\n\n    This function takes a mathematical expression as a string and a dictionary\n    containing variable names as keys and corresponding values as numpy arrays.\n    It replaces the variable names in the expression with their corresponding\n    values from the dictionary and evaluates the expression.\n\n    Args:\n        expression (str):\n            A mathematical expression to be evaluated. Variable\n            names in the expression should match the keys in the value_dict.\n        value_dict (dict):\n            A dictionary containing variable names (strings) as\n            keys and corresponding numpy arrays or numbers as values.\n\n    Returns:\n        result (value or array):\n            The result of evaluating the expression using the provided values.\n\n    Examples:\n        &gt;&gt;&gt; my_dict = {\"a\": np.ones(10), \"b\": np.arange(10)}\n        &gt;&gt;&gt; my_string = \"a*2-b+10\"\n        &gt;&gt;&gt; evaluate_expression_with_dict(my_string, my_dict)\n        array([12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.])\n    \"\"\"\n    # Replace dictionary keys in the expression with their corresponding values\n    ### replace names with dict entries\n    expression = _replace_names_with_dict(\n        expression=expression, name_of_dict=\"value_dict\", dictionary=value_dict\n    )\n\n    ### evaluate the new expression\n    try:\n        result = eval(expression)\n        return result\n    except Exception as e:\n        raise ValueError(f\"Error while evaluating expression: {str(e)}\")\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.interactive_plot","title":"<code>interactive_plot(nrows, ncols, sliders, create_plot)</code>","text":"<p>Create an interactive plot with sliders.</p> <p>Parameters:</p> Name Type Description Default <code>nrows</code> <code>int</code> <p>number of rows of subplots</p> required <code>ncols</code> <code>int</code> <p>number of columns of subplots</p> required <code>sliders</code> <code>list</code> <p>list of dictionaries with slider kwargs (see matplotlib.widgets.Slider), at least the following keys have to be present:     - label (str):         label of the slider     - valmin (float):         minimum value of the slider     - valmax (float):         maximum value of the slider</p> required <code>create_plot</code> <code>Callable</code> <p>function which fills the subplots, has to have the signature create_plot(axs, sliders), where axs is a list of axes (for each subplot) and sliders is the given sliders list with newly added keys \"ax\" (axes of the slider) and \"slider\" (the Slider object itself, so that you can access the slider values in the create_plot function using the .val attribute)</p> required <p>Examples:</p> <pre><code>def create_plot(axs, sliders):\n    axs[0].axhline(sliders[0][\"slider\"].val, color=\"r\")\n    axs[1].axvline(sliders[1][\"slider\"].val, color=\"r\")\n\ninteractive_plot(\n    nrows=2,\n    ncols=1,\n    sliders=[\n        {\"label\": \"a\", \"valmin\": 0.0, \"valmax\": 1.0, \"valinit\": 0.3},\n        {\"label\": \"b\", \"valmin\": 0.0, \"valmax\": 1.0, \"valinit\": 0.7},\n    ],\n    create_plot=create_plot,\n)\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def interactive_plot(\n    nrows: int,\n    ncols: int,\n    sliders: list[dict],\n    create_plot: Callable,\n):\n    \"\"\"\n    Create an interactive plot with sliders.\n\n    Args:\n        nrows (int):\n            number of rows of subplots\n        ncols (int):\n            number of columns of subplots\n        sliders (list):\n            list of dictionaries with slider kwargs (see matplotlib.widgets.Slider), at\n            least the following keys have to be present:\n                - label (str):\n                    label of the slider\n                - valmin (float):\n                    minimum value of the slider\n                - valmax (float):\n                    maximum value of the slider\n        create_plot (Callable):\n            function which fills the subplots, has to have the signature\n            create_plot(axs, sliders), where axs is a list of axes (for each subplot)\n            and sliders is the given sliders list with newly added keys \"ax\" (axes of\n            the slider) and \"slider\" (the Slider object itself, so that you can access\n            the slider values in the create_plot function using the .val attribute)\n\n    Examples:\n        ```python\n        def create_plot(axs, sliders):\n            axs[0].axhline(sliders[0][\"slider\"].val, color=\"r\")\n            axs[1].axvline(sliders[1][\"slider\"].val, color=\"r\")\n\n        interactive_plot(\n            nrows=2,\n            ncols=1,\n            sliders=[\n                {\"label\": \"a\", \"valmin\": 0.0, \"valmax\": 1.0, \"valinit\": 0.3},\n                {\"label\": \"b\", \"valmin\": 0.0, \"valmax\": 1.0, \"valinit\": 0.7},\n            ],\n            create_plot=create_plot,\n        )\n        ```\n    \"\"\"\n\n    def update(axs, sliders):\n        ### remove everything from all axes except the sliders axes\n        for ax in axs:\n            if ax not in [slider[\"ax\"] for slider in sliders]:\n                ax.cla()\n        ### recreate the plot\n        create_plot(axs, sliders)\n        ### redraw the canvas\n        fig.canvas.draw_idle()\n\n    ### create the figure as large as the screen\n    screen_width, screen_height = get_monitors()[0].width, get_monitors()[0].height\n    figsize = (screen_width / 100, screen_height / 100)\n    fig = plt.figure(figsize=figsize)\n\n    ### create the axes filled with the create_plot function\n    grid = GridSpec((nrows + 1) * len(sliders), ncols * len(sliders), figure=fig)\n    axs = []\n    for row_idx in range(nrows):\n        for col_idx in range(ncols):\n            ax = fig.add_subplot(\n                grid[\n                    row_idx * len(sliders) : (row_idx + 1) * len(sliders),\n                    col_idx * len(sliders) : (col_idx + 1) * len(sliders),\n                ]\n            )\n            axs.append(ax)\n\n    ### create the sliders axes\n    for slider_idx, slider_kwargs in enumerate(sliders):\n        sliders[slider_idx][\"ax\"] = fig.add_subplot(\n            grid[nrows * len(sliders) + slider_idx, :]\n        )\n\n    ### initialize the sliders to their axes\n    for slider_idx, slider_kwargs in enumerate(sliders):\n        ### if init out of min max, change min max\n        if \"valinit\" in slider_kwargs:\n            if slider_kwargs[\"valinit\"] &lt; slider_kwargs[\"valmin\"]:\n                slider_kwargs[\"valmin\"] = slider_kwargs[\"valinit\"]\n            elif slider_kwargs[\"valinit\"] &gt; slider_kwargs[\"valmax\"]:\n                slider_kwargs[\"valmax\"] = slider_kwargs[\"valinit\"]\n        slider = Slider(**slider_kwargs)\n        slider.on_changed(lambda val: update(axs, sliders))\n        sliders[slider_idx][\"slider\"] = slider\n\n    ### create the plot\n    create_plot(axs, sliders)\n    ### arange subplots\n    plt.tight_layout()\n    new_right_border = 0.85\n    new_left_border = 0.15\n    for slider_idx, slider_kwargs in enumerate(sliders):\n        ax = sliders[slider_idx][\"ax\"]\n        ### set new borders\n        ax.set_position(\n            [\n                new_left_border,\n                ax.get_position().y0,\n                new_right_border - new_left_border,\n                ax.get_position().height,\n            ]\n        )\n\n    ### show the plot\n    plt.show()\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.efel_loss","title":"<code>efel_loss(trace1, trace2, feature_list)</code>","text":"<p>Calculate the loss between two traces using the features from the feature_list.</p> <p>Parameters:</p> Name Type Description Default <code>trace1</code> <code>dict</code> <p>dictionary with the keys \"T\" (time), \"V\" (voltage), \"stim_start\" (start of the stimulus), \"stim_end\" (end of the stimulus)</p> required <code>trace2</code> <code>dict</code> <p>dictionary with the keys \"T\" (time), \"V\" (voltage), \"stim_start\" (start of the stimulus), \"stim_end\" (end of the stimulus)</p> required <code>feature_list</code> <code>list</code> <p>list of feature names which should be used to calculate the loss (see https://efel.readthedocs.io/en/latest/eFeatures.html, some of them are available)</p> required <p>Returns:</p> Name Type Description <code>loss</code> <code>array</code> <p>array with the loss</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def efel_loss(trace1, trace2, feature_list):\n    \"\"\"\n    Calculate the loss between two traces using the features from the feature_list.\n\n    Args:\n        trace1 (dict):\n            dictionary with the keys \"T\" (time), \"V\" (voltage), \"stim_start\" (start of\n            the stimulus), \"stim_end\" (end of the stimulus)\n        trace2 (dict):\n            dictionary with the keys \"T\" (time), \"V\" (voltage), \"stim_start\" (start of\n            the stimulus), \"stim_end\" (end of the stimulus)\n        feature_list (list):\n            list of feature names which should be used to calculate the loss (see\n            https://efel.readthedocs.io/en/latest/eFeatures.html, some of them are\n            available)\n\n    Returns:\n        loss (np.array):\n            array with the loss\n    \"\"\"\n    verbose = False\n    ### set a plausible \"maximum\" absolute difference for each feature\n    diff_max = {\n        \"steady_state_voltage_stimend\": 200,\n        \"steady_state_voltage\": 200,\n        \"voltage_base\": 200,\n        \"voltage_after_stim\": 200,\n        \"minimum_voltage\": 200,\n        \"time_to_first_spike\": trace1[\"T\"][-1] - trace1[\"stim_start\"][0],\n        \"time_to_second_spike\": trace1[\"T\"][-1] - trace1[\"stim_start\"][0],\n        \"time_to_last_spike\": trace1[\"T\"][-1] - trace1[\"stim_start\"][0],\n        \"spike_count\": len(trace1[\"T\"]),\n        \"spike_count_stimint\": len(\n            trace1[\"T\"][\n                (\n                    (trace1[\"T\"] &gt;= trace1[\"stim_start\"][0]).astype(int)\n                    * (trace1[\"T\"] &lt; trace1[\"stim_end\"][0]).astype(int)\n                ).astype(bool)\n            ]\n        ),\n        \"ISI_CV\": 1,\n    }\n    if verbose:\n        print(f\"\\ndiff_max: {diff_max}\")\n\n    ### set a plausible \"close\" absolute difference for each feature\n    diff_close = {\n        \"steady_state_voltage_stimend\": 10,\n        \"steady_state_voltage\": 10,\n        \"voltage_base\": 10,\n        \"voltage_after_stim\": 10,\n        \"minimum_voltage\": 10,\n        \"time_to_first_spike\": np.clip(\n            (trace1[\"T\"][-1] - trace1[\"stim_start\"][0]) * 0.1, 5, 50\n        ),\n        \"time_to_second_spike\": np.clip(\n            (trace1[\"T\"][-1] - trace1[\"stim_start\"][0]) * 0.1, 5, 50\n        ),\n        \"time_to_last_spike\": np.clip(\n            (trace1[\"T\"][-1] - trace1[\"stim_start\"][0]) * 0.1, 5, 50\n        ),\n        \"spike_count\": np.ceil((trace1[\"T\"][-1] - trace1[\"T\"][0]) / 200),\n        \"spike_count_stimint\": np.ceil((trace1[\"T\"][-1] - trace1[\"T\"][0]) / 200),\n        \"ISI_CV\": 0.1,\n    }\n    if verbose:\n        print(f\"\\ndiff_close: {diff_close}\\n\")\n\n    ### catch if features from feature_list are not supported\n    features_not_supported = [\n        feature for feature in feature_list if feature not in diff_max\n    ]\n    if features_not_supported:\n        raise ValueError(f\"Features not supported: {features_not_supported}\")\n\n    ### catch \"exploding\" neurons by returning max loss of features\n    if (\n        np.any(trace1[\"V\"] &lt; -200)\n        or np.any(trace1[\"V\"] &gt; 100)\n        or np.any(trace2[\"V\"] &lt; -200)\n        or np.any(trace2[\"V\"] &gt; 100)\n    ):\n        loss = 0\n        for feature in feature_list:\n            loss += diff_max[feature] / diff_close[feature]\n        loss /= len(feature_list)\n        loss = np.array([loss])\n        if verbose:\n            print(f\"loss: {loss}\")\n        return loss\n\n    ### calculate and return the mean of the differences of the features\n    features_1, features_2 = efel.getFeatureValues(\n        [trace1, trace2],\n        feature_list,\n        raise_warnings=False,\n    )\n    if verbose:\n        print(f\"\\nfeatures_1: {features_1}\\n\")\n        print(f\"features_2: {features_2}\\n\")\n    loss = 0\n    for feature in feature_list:\n        ### if both features are None use 0\n        if features_1[feature] is None and features_2[feature] is None:\n            diff = 0\n        ### if single feature is None use diff_max\n        elif features_1[feature] is None or features_2[feature] is None:\n            diff = diff_max[feature]\n        ### if features contain multiple values use the mean TODO not tested yet\n        elif len(features_1[feature]) &gt; 1 or len(features_2[feature]) &gt; 1:\n            if verbose:\n                print(\"features with multiple values not tested yet!\")\n            diff = np.mean(\n                np.absolute(features_1[feature] - features_2[feature]), keepdims=True\n            )\n        else:\n            diff = np.absolute(features_1[feature] - features_2[feature])\n        ### scale the difference by diff_close and add to loss\n        loss += diff / diff_close[feature]\n    loss /= len(feature_list)\n\n    if verbose:\n        print(f\"loss: {loss}\")\n    return loss\n</code></pre>"},{"location":"additional/model_functions/","title":"Model Functions","text":""},{"location":"additional/model_functions/#CompNeuroPy.model_functions.compile_in_folder","title":"<code>compile_in_folder(folder_name, net=None, clean=False, silent=False)</code>","text":"<p>Creates the compilation folder in annarchy_folders/ or uses existing ones. Compiles the current network.</p> <p>Parameters:</p> Name Type Description Default <code>folder_name</code> <code>str</code> <p>Name of the folder within annarchy_folders/</p> required <code>net</code> <code>ANNarchy network</code> <p>ANNarchy network. Default: None.</p> <code>None</code> <code>clean</code> <code>bool</code> <p>If True, the library is recompiled entirely, else only the changes since last compilation are compiled. Default: False.</p> <code>False</code> <code>silent</code> <code>bool</code> <p>Suppress output. Defaults to False.</p> <code>False</code> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def compile_in_folder(folder_name, net=None, clean=False, silent=False):\n    \"\"\"\n    Creates the compilation folder in annarchy_folders/ or uses existing ones. Compiles\n    the current network.\n\n    Args:\n        folder_name (str):\n            Name of the folder within annarchy_folders/\n        net (ANNarchy network, optional):\n            ANNarchy network. Default: None.\n        clean (bool, optional):\n            If True, the library is recompiled entirely, else only the changes since\n            last compilation are compiled. Default: False.\n        silent (bool, optional):\n            Suppress output. Defaults to False.\n    \"\"\"\n    sf.create_dir(\"annarchy_folders/\" + folder_name, print_info=False)\n    if isinstance(net, type(None)):\n        compile(\"annarchy_folders/\" + folder_name, clean=clean, silent=silent)\n    else:\n        net.compile(\"annarchy_folders/\" + folder_name, clean=clean, silent=silent)\n    if os.getcwd().split(\"/\")[-1] == \"annarchy_folders\":\n        os.chdir(\"../\")\n</code></pre>"},{"location":"additional/model_functions/#CompNeuroPy.model_functions.annarchy_compiled","title":"<code>annarchy_compiled(net_id=0)</code>","text":"<p>Check if ANNarchy network was compiled.</p> <p>Parameters:</p> Name Type Description Default <code>net_id</code> <code>int</code> <p>Network ID. Default: 0.</p> <code>0</code> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def annarchy_compiled(net_id=0):\n    \"\"\"\n    Check if ANNarchy network was compiled.\n\n    Args:\n        net_id (int, optional):\n            Network ID. Default: 0.\n    \"\"\"\n    return Global._network[net_id][\"compiled\"]\n</code></pre>"},{"location":"additional/model_functions/#CompNeuroPy.model_functions.get_full_model","title":"<code>get_full_model()</code>","text":"<p>Return all current population and projection names.</p> <p>Returns:</p> Name Type Description <code>model_dict</code> <code>dict</code> <p>Dictionary with keys \"populations\" and \"projections\" and values lists of population and projection names, respectively.</p> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def get_full_model():\n    \"\"\"\n    Return all current population and projection names.\n\n    Returns:\n        model_dict (dict):\n            Dictionary with keys \"populations\" and \"projections\" and values lists of\n            population and projection names, respectively.\n    \"\"\"\n    return {\n        \"populations\": [pop.name for pop in populations()],\n        \"projections\": [proj.name for proj in projections()],\n    }\n</code></pre>"},{"location":"additional/model_functions/#CompNeuroPy.model_functions.cnp_clear","title":"<code>cnp_clear(functions=True, neurons=True, synapses=True, constants=True)</code>","text":"<p>Like clear with ANNarchy, but CompNeuroModel objects are also cleared.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>bool</code> <p>If True, all functions are cleared. Default: True.</p> <code>True</code> <code>neurons</code> <code>bool</code> <p>If True, all neurons are cleared. Default: True.</p> <code>True</code> <code>synapses</code> <code>bool</code> <p>If True, all synapses are cleared. Default: True.</p> <code>True</code> <code>constants</code> <code>bool</code> <p>If True, all constants are cleared. Default: True.</p> <code>True</code> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def cnp_clear(functions=True, neurons=True, synapses=True, constants=True):\n    \"\"\"\n    Like clear with ANNarchy, but CompNeuroModel objects are also cleared.\n\n    Args:\n        functions (bool, optional):\n            If True, all functions are cleared. Default: True.\n        neurons (bool, optional):\n            If True, all neurons are cleared. Default: True.\n        synapses (bool, optional):\n            If True, all synapses are cleared. Default: True.\n        constants (bool, optional):\n            If True, all constants are cleared. Default: True.\n    \"\"\"\n    clear(functions=functions, neurons=neurons, synapses=synapses, constants=constants)\n    for model_name in CompNeuroModel._initialized_models.keys():\n        CompNeuroModel._initialized_models[model_name] = False\n    for model_name in CompNeuroModel._compiled_models.keys():\n        CompNeuroModel._compiled_models[model_name] = False\n</code></pre>"},{"location":"additional/simulation_functions/","title":"Simulation Functions","text":""},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.attr_sim","title":"<code>attr_sim(pop, attr_dict, t=500)</code>","text":"<p>Simulates a period 't' setting the attributes of a given population to the values specified in 'attr_list', after this simulation the attributes are reset to initial values (before simulation).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population whose attributes should be set</p> required <code>attr_dict</code> <code>dict</code> <p>dictionary containing the attributes and their values</p> required <code>t</code> <code>int</code> <p>duration in ms</p> <code>500</code> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def attr_sim(pop: str, attr_dict, t=500):\n    \"\"\"\n    Simulates a period 't' setting the attributes of a given population to the values\n    specified in 'attr_list', after this simulation the attributes are reset to initial\n    values (before simulation).\n\n    Args:\n        pop (str):\n            population name of population whose attributes should be set\n        attr_dict (dict):\n            dictionary containing the attributes and their values\n        t (int):\n            duration in ms\n    \"\"\"\n\n    ### save prev attr\n    v_prev_dict = {\n        attr: getattr(get_population(pop), attr) for attr in attr_dict.keys()\n    }\n\n    ### set attributes\n    for attr, v in attr_dict.items():\n        setattr(get_population(pop), attr, v)\n\n    ### simulate\n    simulate(t)\n\n    ### reset attributes to previous values\n    for attr, v in v_prev_dict.items():\n        setattr(get_population(pop), attr, v)\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.attribute_step","title":"<code>attribute_step(pop, attr, t1=500, t2=500, v1=0, v2=100)</code>","text":"<p>Simulates an attribute step for a given population.</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population whose attribute should be changed</p> required <code>attr</code> <code>str</code> <p>name of attribute which should be changed</p> required <code>t1</code> <code>int</code> <p>time in ms before step</p> <code>500</code> <code>t2</code> <code>int</code> <p>time in ms after step</p> <code>500</code> <code>v1</code> <code>int</code> <p>value of attribute for t1</p> <code>0</code> <code>v2</code> <code>int</code> <p>value of attribute for t2</p> <code>100</code> <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>duration (int): duration of the simulation</li> </ul> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def attribute_step(pop: str, attr, t1=500, t2=500, v1=0, v2=100):\n    \"\"\"\n    Simulates an attribute step for a given population.\n\n    Args:\n        pop (str):\n            population name of population whose attribute should be changed\n        attr (str):\n            name of attribute which should be changed\n        t1 (int):\n            time in ms before step\n        t2 (int):\n            time in ms after step\n        v1 (int):\n            value of attribute for t1\n        v2 (int):\n            value of attribute for t2\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - duration (int): duration of the simulation\n    \"\"\"\n\n    ### first/pre step simulation\n    attr_sim(pop, {attr: v1}, t=t1)\n\n    ### second/post step simulation\n    attr_sim(pop, {attr: v2}, t=t2)\n\n    ### return duration of the simulation\n    return {\"duration\": t1 + t2}\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.attr_ramp","title":"<code>attr_ramp(pop, attr, v0, v1, dur, n)</code>","text":"<p>Simulating while constantly changing the attribute of a given population. After this attr_ramp simulation the attribute value is reset to the initial value (before simulation).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population whose attribute should be changed</p> required <code>attr</code> <code>str</code> <p>name of attribute which should be changed</p> required <code>v0</code> <code>int</code> <p>initial value of attribute (of first stimulation)</p> required <code>v1</code> <code>int</code> <p>final value of attribute (of last stimulation)</p> required <code>dur</code> <code>int</code> <p>duration of the complete ramp simulation</p> required <code>n</code> <code>int</code> <p>number of steps for changing the attribute</p> required <p>Warning</p> <p>dur/n should be divisible by the simulation time step without remainder</p> <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>dv (int): step size of attribute</li> <li>dur_stim (int): duration of single steps</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>if resulting duration of one stimulation is not divisible by the simulation time step without remainder</p> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def attr_ramp(pop: str, attr, v0, v1, dur, n):\n    \"\"\"\n    Simulating while constantly changing the attribute of a given population.\n    After this attr_ramp simulation the attribute value is reset to the initial\n    value (before simulation).\n\n    Args:\n        pop (str):\n            population name of population whose attribute should be changed\n        attr (str):\n            name of attribute which should be changed\n        v0 (int):\n            initial value of attribute (of first stimulation)\n        v1 (int):\n            final value of attribute (of last stimulation)\n        dur (int):\n            duration of the complete ramp simulation\n        n (int):\n            number of steps for changing the attribute\n\n    !!! warning\n        dur/n should be divisible by the simulation time step without remainder\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - dv (int): step size of attribute\n            - dur_stim (int): duration of single steps\n\n    Raises:\n        ValueError: if resulting duration of one stimulation is not divisible by the\n            simulation time step without remainder\n    \"\"\"\n\n    if (dur / n) / dt() % 1 != 0:\n        raise ValueError(\n            \"ERROR current_ramp: dur/n should result in a duration (for a single stimulation) which is divisible by the simulation time step (without remainder)\\ncurrent duration = \"\n            + str(dur / n)\n            + \", timestep = \"\n            + str(dt())\n            + \"!\\n\"\n        )\n\n    dv = (v1 - v0) / (n - 1)  # for n stimulations only n-1 steps occur\n    dur_stim = dur / n\n    v = v0\n    for _ in range(n):\n        attr_sim(pop, attr_dict={attr: v}, t=dur_stim)\n        v = v + dv\n\n    return {\"dv\": dv, \"dur_stim\": dur_stim}\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.increasing_attr","title":"<code>increasing_attr(pop, attr, v0, dv, nr_steps, dur_step)</code>","text":"<p>Conducts multiple simulations while constantly increasing the attribute of a given population. After this simulation the attribute value is reset to the initial value (before simulation).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population whose attribute should be changed</p> required <code>v0</code> <code>int</code> <p>initial attribute value (of first stimulation)</p> required <code>dv</code> <code>int</code> <p>attribute step size</p> required <code>nr_steps</code> <code>int</code> <p>number of simulations with different attribute values</p> required <code>dur_step</code> <code>int</code> <p>duration of one step simulation</p> required <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>attr_list (list): list of attribute values for each step simulation</li> </ul> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def increasing_attr(pop: str, attr, v0, dv, nr_steps, dur_step):\n    \"\"\"\n    Conducts multiple simulations while constantly increasing the attribute of a given\n    population. After this simulation the attribute value is reset to the initial value\n    (before simulation).\n\n    Args:\n        pop (str):\n            population name of population whose attribute should be changed\n        v0 (int):\n            initial attribute value (of first stimulation)\n        dv (int):\n            attribute step size\n        nr_steps (int):\n            number of simulations with different attribute values\n        dur_step (int):\n            duration of one step simulation\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - attr_list (list): list of attribute values for each step simulation\n    \"\"\"\n    attr_list = []\n    v = v0\n    for _ in range(nr_steps):\n        attr_list.append(v)\n        attr_sim(pop, {attr: v}, t=dur_step)\n        v += dv\n\n    return {\"attr_list\": attr_list}\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.current_step","title":"<code>current_step(pop, t1=500, t2=500, a1=0, a2=100)</code>","text":"<p>Stimulates a given population in two periods with two input currents.</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>t1</code> <code>int</code> <p>time in ms before current step</p> <code>500</code> <code>t2</code> <code>int</code> <p>time in ms after current step</p> <code>500</code> <code>a1</code> <code>int</code> <p>current amplitude before current step</p> <code>0</code> <code>a2</code> <code>int</code> <p>current amplitude after current step</p> <code>100</code> <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>duration (int): duration of the simulation</li> </ul> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_step(pop: str, t1=500, t2=500, a1=0, a2=100):\n    \"\"\"\n    Stimulates a given population in two periods with two input currents.\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        t1 (int):\n            time in ms before current step\n        t2 (int):\n            time in ms after current step\n        a1 (int):\n            current amplitude before current step\n        a2 (int):\n            current amplitude after current step\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - duration (int): duration of the simulation\n    \"\"\"\n    return attribute_step(pop, \"I_app\", t1=t1, t2=t2, v1=a1, v2=a2)\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.current_stim","title":"<code>current_stim(pop, t=500, a=100)</code>","text":"<p>Stimulates a given population during specified period 't' with input current with amplitude 'a', after this stimulation the current is reset to initial value (before stimulation).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>t</code> <code>int</code> <p>duration in ms</p> <code>500</code> <code>a</code> <code>int</code> <p>current amplitude</p> <code>100</code> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_stim(pop: str, t=500, a=100):\n    \"\"\"\n    Stimulates a given population during specified period 't' with input current with\n    amplitude 'a', after this stimulation the current is reset to initial value\n    (before stimulation).\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        t (int):\n            duration in ms\n        a (int):\n            current amplitude\n    \"\"\"\n    attr_sim(pop, {\"I_app\": a}, t=t)\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.current_ramp","title":"<code>current_ramp(pop, a0, a1, dur, n)</code>","text":"<p>Conducts multiple current stimulations with constantly changing current inputs. After this current_ramp stimulation the current amplitude is reset to the initial value (before current ramp).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>a0</code> <code>int</code> <p>initial current amplitude (of first stimulation)</p> required <code>a1</code> <code>int</code> <p>final current amplitude (of last stimulation)</p> required <code>dur</code> <code>int</code> <p>duration of the complete current ramp (all stimulations)</p> required <code>n</code> <code>int</code> <p>number of stimulations</p> required <p>Warning</p> <p>dur/n should be divisible by the simulation time step without remainder</p> <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>da (int): current step size</li> <li>dur_stim (int): duration of one stimulation</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>if resulting duration of one stimulation is not divisible by the simulation time step without remainder</p> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_ramp(pop: str, a0, a1, dur, n):\n    \"\"\"\n    Conducts multiple current stimulations with constantly changing current inputs.\n    After this current_ramp stimulation the current amplitude is reset to the initial\n    value (before current ramp).\n\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        a0 (int):\n            initial current amplitude (of first stimulation)\n        a1 (int):\n            final current amplitude (of last stimulation)\n        dur (int):\n            duration of the complete current ramp (all stimulations)\n        n (int):\n            number of stimulations\n\n    !!! warning\n        dur/n should be divisible by the simulation time step without remainder\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - da (int): current step size\n            - dur_stim (int): duration of one stimulation\n\n    Raises:\n        ValueError: if resulting duration of one stimulation is not divisible by the\n            simulation time step without remainder\n    \"\"\"\n    attr_ramp_return = attr_ramp(pop, \"I_app\", a0, a1, dur, n)\n    return {\"da\": attr_ramp_return[\"dv\"], \"dur_stim\": attr_ramp_return[\"dur_stim\"]}\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.increasing_current","title":"<code>increasing_current(pop, a0, da, nr_steps, dur_step)</code>","text":"<p>Conducts multiple current stimulations with constantly increasing current inputs. After this increasing_current stimulation the current amplitude is reset to the initial value (before increasing_current).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>a0</code> <code>int</code> <p>initial current amplitude (of first stimulation)</p> required <code>da</code> <code>int</code> <p>current step size</p> required <code>nr_steps</code> <code>int</code> <p>number of stimulations</p> required <code>dur_step</code> <code>int</code> <p>duration of one stimulation</p> required <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>current_list (list): list of current amplitudes for each stimulation</li> </ul> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def increasing_current(pop: str, a0, da, nr_steps, dur_step):\n    \"\"\"\n    Conducts multiple current stimulations with constantly increasing current inputs.\n    After this increasing_current stimulation the current amplitude is reset to the\n    initial value (before increasing_current).\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        a0 (int):\n            initial current amplitude (of first stimulation)\n        da (int):\n            current step size\n        nr_steps (int):\n            number of stimulations\n        dur_step (int):\n            duration of one stimulation\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - current_list (list): list of current amplitudes for each stimulation\n    \"\"\"\n    increasing_attr_return = increasing_attr(pop, \"I_app\", a0, da, nr_steps, dur_step)\n    return {\"current_list\": increasing_attr_return[\"attr_list\"]}\n</code></pre>"},{"location":"additional/simulation_requirements/","title":"Simulation Requirements","text":""},{"location":"additional/simulation_requirements/#CompNeuroPy.simulation_requirements.ReqPopHasAttr","title":"<code>ReqPopHasAttr</code>","text":"<p>Checks if population(s) contains the attribute(s) (parameters or variables)</p> Source code in <code>src/CompNeuroPy/simulation_requirements.py</code> <pre><code>class ReqPopHasAttr:\n    \"\"\"\n    Checks if population(s) contains the attribute(s) (parameters or variables)\n    \"\"\"\n\n    def __init__(self, pop, attr):\n        \"\"\"\n        Args:\n            pop (str or list of strings):\n                population name(s)\n            attr (str or list of strings):\n                attribute name(s)\n        \"\"\"\n        self.pop_name_list = pop\n        self.attr_name_list = attr\n        ### convert single strings into list\n        if not (isinstance(pop, list)):\n            self.pop_name_list = [pop]\n        if not (isinstance(attr, list)):\n            self.attr_name_list = [attr]\n\n    def run(self):\n        \"\"\"\n        Checks if population(s) contains the attribute(s) (parameters or variables)\n\n        Raises:\n            ValueError: if population(s) does not contain the attribute(s)\n        \"\"\"\n        for attr_name in self.attr_name_list:\n            for pop_name in self.pop_name_list:\n                pop: Population = get_population(pop_name)\n                if not (attr_name in pop.attributes):\n                    raise ValueError(\n                        \"Population \"\n                        + pop_name\n                        + \" does not contain attribute \"\n                        + attr_name\n                        + \"!\\n\"\n                    )\n</code></pre>"},{"location":"additional/simulation_requirements/#CompNeuroPy.simulation_requirements.ReqPopHasAttr.__init__","title":"<code>__init__(pop, attr)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str or list of strings</code> <p>population name(s)</p> required <code>attr</code> <code>str or list of strings</code> <p>attribute name(s)</p> required Source code in <code>src/CompNeuroPy/simulation_requirements.py</code> <pre><code>def __init__(self, pop, attr):\n    \"\"\"\n    Args:\n        pop (str or list of strings):\n            population name(s)\n        attr (str or list of strings):\n            attribute name(s)\n    \"\"\"\n    self.pop_name_list = pop\n    self.attr_name_list = attr\n    ### convert single strings into list\n    if not (isinstance(pop, list)):\n        self.pop_name_list = [pop]\n    if not (isinstance(attr, list)):\n        self.attr_name_list = [attr]\n</code></pre>"},{"location":"additional/simulation_requirements/#CompNeuroPy.simulation_requirements.ReqPopHasAttr.run","title":"<code>run()</code>","text":"<p>Checks if population(s) contains the attribute(s) (parameters or variables)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if population(s) does not contain the attribute(s)</p> Source code in <code>src/CompNeuroPy/simulation_requirements.py</code> <pre><code>def run(self):\n    \"\"\"\n    Checks if population(s) contains the attribute(s) (parameters or variables)\n\n    Raises:\n        ValueError: if population(s) does not contain the attribute(s)\n    \"\"\"\n    for attr_name in self.attr_name_list:\n        for pop_name in self.pop_name_list:\n            pop: Population = get_population(pop_name)\n            if not (attr_name in pop.attributes):\n                raise ValueError(\n                    \"Population \"\n                    + pop_name\n                    + \" does not contain attribute \"\n                    + attr_name\n                    + \"!\\n\"\n                )\n</code></pre>"},{"location":"additional/statistic_functions/","title":"Statistic Functions","text":""},{"location":"additional/statistic_functions/#CompNeuroPy.statistic_functions.anova_between_groups","title":"<code>anova_between_groups(df, dv, group_list, print_file='./anova_between_groups.txt', fig_path='./boxplot.png')</code>","text":"<p>Perform a N-way ANOVA with post-hoc tests. Besides creating the print_file, it also saves the ANOVA table and the post-hoc tests in the same folder as the print_file. (names: anova_between_groups_equal_var_group_name.pkl, anova_between_groups_anova.pkl, and anova_between_groups_post_hoc.pkl)</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>dataframe with the data</p> required <code>dv</code> <code>str</code> <p>dependent variable</p> required <code>group_list</code> <code>list[str]</code> <p>list of independent variables</p> required <code>print_file</code> <code>str</code> <p>path to save the ANOVA table</p> <code>'./anova_between_groups.txt'</code> <code>fig_path</code> <code>str</code> <p>path to save the box plot figure</p> <code>'./boxplot.png'</code> Source code in <code>src/CompNeuroPy/statistic_functions.py</code> <pre><code>def anova_between_groups(\n    df: pd.DataFrame,\n    dv: str,\n    group_list: list[str],\n    print_file: str = \"./anova_between_groups.txt\",\n    fig_path: str = \"./boxplot.png\",\n):\n    \"\"\"\n    Perform a N-way ANOVA with post-hoc tests.\n    Besides creating the print_file, it also saves the ANOVA table and the post-hoc tests\n    in the same folder as the print_file. (names:\n    anova_between_groups_equal_var_*group_name*.pkl, anova_between_groups_anova.pkl, and\n    anova_between_groups_post_hoc.pkl)\n\n    Args:\n        df (pd.DataFrame):\n            dataframe with the data\n        dv (str):\n            dependent variable\n        group_list (list[str]):\n            list of independent variables\n        print_file (str):\n            path to save the ANOVA table\n        fig_path (str):\n            path to save the box plot figure\n    \"\"\"\n    ### print the dataframe\n    if \"/\" in print_file:\n        sf.create_dir(\"/\".join(print_file.split(\"/\")[:-1]))\n    with open(print_file, \"w\") as file:\n        ef.print_df(df, file=file)\n        print(\"\\n\", file=file)\n\n    ### This is a between subject design, so the first step is to test for equality of\n    ### variances\n    equal_var_list = []\n    for group in group_list:\n        equal_var = pg.homoscedasticity(data=df, dv=dv, group=group)\n        ### print the dataframe equal_var\n        with open(print_file, \"a\") as file:\n            print(f\"equal_var {group}:\", file=file)\n            ef.print_df(equal_var, file=file)\n            print(\"\\n\", file=file)\n        ### save the dataframe equal_var\n        sf.save_variables(\n            [equal_var],\n            [f\"anova_between_groups_equal_var_{group}\"],\n            path=\"/\".join(print_file.split(\"/\")[:-1]) if \"/\" in print_file else \"./\",\n        )\n        ### store if equal_var is True in equal_var_list\n        equal_var_list.append(equal_var[\"equal_var\"].iloc[0])\n\n    if all(equal_var_list):\n        ### If the groups have equal variances, we can use a regular N-way ANOVA\n        anova = pg.anova(data=df, dv=dv, between=group_list)\n    elif len(group_list) == 1:\n        ### If one group has unequal variances, we can use a Welch's ANOVA\n        anova = pg.welch_anova(data=df, dv=dv, between=group_list)\n    else:\n        ### If more than one group has unequal variances, fall back to regular N-way ANOVA\n        anova = pg.anova(data=df, dv=dv, between=group_list)\n    ### print the dataframe anova\n    with open(print_file, \"a\") as file:\n        print(\"ANOVA table:\", file=file)\n        ef.print_df(anova, file=file)\n        print(\"\\n\", file=file)\n    ### save the dataframe anova\n    sf.save_variables(\n        [anova],\n        [\"anova_between_groups_anova\"],\n        path=\"/\".join(print_file.split(\"/\")[:-1]) if \"/\" in print_file else \"./\",\n    )\n\n    ### post-hoc tests\n    post_hoc = pg.pairwise_tests(\n        data=df, dv=dv, between=group_list, padjust=\"fdr_bh\", return_desc=True\n    )\n    ### print the dataframe post_hoc\n    with open(print_file, \"a\") as file:\n        print(\"Post-hoc tests:\", file=file)\n        ef.print_df(post_hoc, file=file)\n        print(\"\\n\", file=file)\n    ### save the dataframe post_hoc\n    sf.save_variables(\n        [post_hoc],\n        [\"anova_between_groups_post_hoc\"],\n        path=\"/\".join(print_file.split(\"/\")[:-1]) if \"/\" in print_file else \"./\",\n    )\n\n    # create boxplot for each group\n    df.boxplot(column=dv, by=group_list, figsize=(12, 8))\n    plt.tight_layout()\n    if \"/\" in fig_path:\n        sf.create_dir(\"/\".join(fig_path.split(\"/\")[:-1]))\n    plt.savefig(fig_path, dpi=300)\n    plt.close(\"all\")\n</code></pre>"},{"location":"additional/system_functions/","title":"System Functions","text":""},{"location":"additional/system_functions/#CompNeuroPy.system_functions.clear_dir","title":"<code>clear_dir(path)</code>","text":"<p>Deletes all files and subdirectories in the specified folder.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the folder to clear.</p> required Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def clear_dir(path):\n    \"\"\"\n    Deletes all files and subdirectories in the specified folder.\n\n    Args:\n        path (str):\n            Path to the folder to clear.\n    \"\"\"\n    try:\n        if not os.path.exists(path):\n            print(f\"The folder '{path}' does not exist.\")\n            return\n\n        for filename in os.listdir(path):\n            file_path = os.path.join(path, filename)\n            try:\n                if os.path.isfile(file_path) or os.path.islink(file_path):\n                    os.unlink(file_path)\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n            except Exception:\n                print(traceback.format_exc())\n                print(f\"Failed to delete {file_path}\")\n    except Exception:\n        print(traceback.format_exc())\n        print(f\"Failed to clear {path}\")\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.create_dir","title":"<code>create_dir(path, print_info=False, clear=False)</code>","text":"<p>Creates a directory.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the directory to create.</p> required <code>print_info</code> <code>bool</code> <p>Whether to print information about the directory creation. Default: False.</p> <code>False</code> <code>clear</code> <code>bool</code> <p>Whether to clear the directory if it already exists. Default: False.</p> <code>False</code> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def create_dir(path, print_info=False, clear=False):\n    \"\"\"\n    Creates a directory.\n\n    Args:\n        path (str):\n            Path to the directory to create.\n\n        print_info (bool, optional):\n            Whether to print information about the directory creation. Default: False.\n\n        clear (bool, optional):\n            Whether to clear the directory if it already exists. Default: False.\n    \"\"\"\n    try:\n        if isinstance(path, str):\n            if len(path) &gt; 0:\n                os.makedirs(path)\n        else:\n            print(\"create_dir, ERROR: path is no str\")\n    except Exception:\n        if os.path.isdir(path):\n            if print_info:\n                print(path + \" already exists\")\n            if clear:\n                ### clear folder\n                ### do you really want?\n                answer = input(f\"Do you really want to clear {path} (y/n):\")\n                while answer != \"y\" and answer != \"n\":\n                    print(\"please enter y or n\")\n                    answer = input(f\"Do you really want to clear {path} (y/n):\")\n                ### clear or not depending on answer\n                if answer == \"y\":\n                    clear_dir(path)\n                    if print_info:\n                        print(path + \" already exists and was cleared.\")\n                else:\n                    if print_info:\n                        print(path + \" already exists and was not cleared.\")\n        else:\n            print(traceback.format_exc())\n            print(\"could not create \" + path + \" folder\")\n            quit()\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.save_variables","title":"<code>save_variables(variable_list, name_list, path='./')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>variable_list</code> <code>list</code> <p>variables to save</p> required <code>name_list</code> <code>list</code> <p>names of the save files of the variables</p> required <code>path</code> <code>str or list</code> <p>save path for all variables, or save path for each variable of the variable_list. Default: \"./\"</p> <code>'./'</code> <p>Examples:</p> <pre><code>import numpy as np\nfrom CompNeuroPy import save_variables, load_variables\n\n### create variables\nvar1 = np.random.rand(10)\nvar2 = np.random.rand(10)\n\n### save variables\nsave_variables([var1, var2], [\"var1_file\", \"var2_file\"], \"my_variables_folder\")\n\n### load variables\nloaded_variables = load_variables([\"var1\", \"var2\"], \"my_variables_folder\")\n\n### use loaded variables\nprint(loaded_variables[\"var1_file\"])\nprint(loaded_variables[\"var2_file\"])\n</code></pre> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def save_variables(variable_list: list, name_list: list, path: str | list = \"./\"):\n    \"\"\"\n    Args:\n        variable_list (list):\n            variables to save\n        name_list (list):\n            names of the save files of the variables\n        path (str or list):\n            save path for all variables, or save path for each variable of the\n            variable_list. Default: \"./\"\n\n    Examples:\n        ```python\n        import numpy as np\n        from CompNeuroPy import save_variables, load_variables\n\n        ### create variables\n        var1 = np.random.rand(10)\n        var2 = np.random.rand(10)\n\n        ### save variables\n        save_variables([var1, var2], [\"var1_file\", \"var2_file\"], \"my_variables_folder\")\n\n        ### load variables\n        loaded_variables = load_variables([\"var1\", \"var2\"], \"my_variables_folder\")\n\n        ### use loaded variables\n        print(loaded_variables[\"var1_file\"])\n        print(loaded_variables[\"var2_file\"])\n        ```\n    \"\"\"\n    for idx in range(len(variable_list)):\n        ### set save path\n        if isinstance(path, str):\n            save_path = path\n        else:\n            save_path = path[idx]\n        if save_path.endswith(\"/\"):\n            save_path = save_path[:-1]\n        ### set file name\n        file_name = f\"{name_list[idx]}.pkl\"\n        ### set variable\n        variable = variable_list[idx]\n        ### generate save folder\n        create_dir(save_path)\n        ### Saving a variable to a file\n        with open(f\"{save_path}/{file_name}\", \"wb\") as file:\n            pickle.dump(variable, file)\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.load_variables","title":"<code>load_variables(name_list, path='./')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name_list</code> <code>list</code> <p>names of the save files of the variables</p> required <code>path</code> <code>str or list</code> <p>save path for all variables, or save path for each variable of the variable_list. Default: \"./\"</p> <code>'./'</code> <p>Returns:</p> Name Type Description <code>variable_dict</code> <code>dict</code> <p>dictionary with the loaded variables, keys are the names of the files, values are the loaded variables</p> <p>Examples:</p> <pre><code>import numpy as np\nfrom CompNeuroPy import save_variables, load_variables\n\n### create variables\nvar1 = np.random.rand(10)\nvar2 = np.random.rand(10)\n\n### save variables\nsave_variables([var1, var2], [\"var1_file\", \"var2_file\"], \"my_variables_folder\")\n\n### load variables\nloaded_variables = load_variables([\"var1\", \"var2\"], \"my_variables_folder\")\n\n### use loaded variables\nprint(loaded_variables[\"var1_file\"])\nprint(loaded_variables[\"var2_file\"])\n</code></pre> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def load_variables(name_list: list, path: str | list = \"./\"):\n    \"\"\"\n    Args:\n        name_list (list):\n            names of the save files of the variables\n        path (str or list, optional):\n            save path for all variables, or save path for each variable of the\n            variable_list. Default: \"./\"\n\n    Returns:\n        variable_dict (dict):\n            dictionary with the loaded variables, keys are the names of the\n            files, values are the loaded variables\n\n    Examples:\n        ```python\n        import numpy as np\n        from CompNeuroPy import save_variables, load_variables\n\n        ### create variables\n        var1 = np.random.rand(10)\n        var2 = np.random.rand(10)\n\n        ### save variables\n        save_variables([var1, var2], [\"var1_file\", \"var2_file\"], \"my_variables_folder\")\n\n        ### load variables\n        loaded_variables = load_variables([\"var1\", \"var2\"], \"my_variables_folder\")\n\n        ### use loaded variables\n        print(loaded_variables[\"var1_file\"])\n        print(loaded_variables[\"var2_file\"])\n        ```\n    \"\"\"\n    variable_dict = {}\n    for idx in range(len(name_list)):\n        ### set save path\n        if isinstance(path, str):\n            save_path = path\n        else:\n            save_path = path[idx]\n        if save_path.endswith(\"/\"):\n            save_path = save_path[:-1]\n        ### set file name\n        file_name = f\"{name_list[idx]}.pkl\"\n        ### Loading the variable from the file\n        with open(f\"{save_path}/{file_name}\", \"rb\") as file:\n            loaded_variable = pickle.load(file)\n        ### store variable in variable_dict\n        variable_dict[name_list[idx]] = loaded_variable\n\n    return variable_dict\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.timing_decorator","title":"<code>timing_decorator(threshold=0.1)</code>","text":"<p>Decorator to measure the execution time of a function.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>Threshold in seconds. If the execution time of the function is larger than this threshold, the execution time is printed. Default: 0.1.</p> <code>0.1</code> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def timing_decorator(threshold=0.1):\n    \"\"\"\n    Decorator to measure the execution time of a function.\n\n    Args:\n        threshold (float, optional):\n            Threshold in seconds. If the execution time of the function is\n            larger than this threshold, the execution time is printed. Default: 0.1.\n    \"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            start_time = time()\n            result = func(*args, **kwargs)\n            end_time = time()\n            execution_time = end_time - start_time\n            if execution_time &gt;= threshold:\n                print(f\"{func.__name__} took {execution_time:.4f} seconds\")\n            return result\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.run_script_parallel","title":"<code>run_script_parallel(script_path, n_jobs, args_list=[''], n_total=1)</code>","text":"<p>Run a script in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>script_path</code> <code>str</code> <p>Path to the script to run.</p> required <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs.</p> required <code>args_list</code> <code>list</code> <p>List of lists containing the arguments (string values) of each run to pass to the script. Length of the list is the number of total runs. If a list of strings is passed these arguments are passed to the script and it is run n_total times. Default: [\"\"], i.e. no arguments are passed to the script.</p> <code>['']</code> <code>n_total</code> <code>int</code> <p>Number of total runs, only used if args_list is not a list of lists. Default: 1.</p> <code>1</code> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def run_script_parallel(\n    script_path: str, n_jobs: int, args_list: list = [\"\"], n_total: int = 1\n):\n    \"\"\"\n    Run a script in parallel.\n\n    Args:\n        script_path (str):\n            Path to the script to run.\n        n_jobs (int):\n            Number of parallel jobs.\n        args_list (list, optional):\n            List of lists containing the arguments (string values) of each run to pass\n            to the script. Length of the list is the number of total runs. If a list\n            of strings is passed these arguments are passed to the script and it is run\n            n_total times. Default: [\"\"], i.e. no arguments are passed to the script.\n        n_total (int, optional):\n            Number of total runs, only used if args_list is not a list of lists.\n            Default: 1.\n    \"\"\"\n    ### check if args_list is a list of lists\n    if not isinstance(args_list[0], list):\n        args_list = [args_list] * n_total\n    elif n_total != 1:\n        print(\n            \"run_script_parallel; Warning: n_total is ignored because args_list is a list of lists\"\n        )\n\n    ### do not use more jobs than necessary\n    n_jobs = min(n_jobs, len(args_list))\n\n    ### run the script in parallel\n    Parallel(n_jobs=n_jobs)(\n        delayed(os.system)(f\"python {script_path} {' '.join(args)}\")\n        for args in args_list\n    )\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.create_data_raw_folder","title":"<code>create_data_raw_folder(folder_name, **kwargs)</code>","text":"<p>Create a folder for raw data of some kind of experiments/study etc. All data raw should be created by RUNNING A SINGLE PYTHON script. This data should be stored in the folder created here. If the created raw data depends on some parameters, these parameters should also be stored. They should be global in the corresponding python script to be able to easily set them again (replicate the data raw creation process). Best practice for the python script: define global parameters at the beginning, then call this function. This function stores the following information in a file called \"data_raw_meta\" in the created folder:     - the name of the python script which created the data raw     - the global variables of the python script given as kwargs     - the conda environment     - the pip requirements     - the git log of ANNarchy and CompNeuroPy if they are installed locally</p> <p>Warning</p> <p>Only works in a conda environment.</p> <p>Parameters:</p> Name Type Description Default <code>folder_name</code> <code>str</code> <p>Name of the folder to create.</p> required <code>**kwargs</code> <code>Any</code> <p>Global variables of the caller script.</p> <code>{}</code> <p>Examples:</p> <pre><code>from CompNeuroPy import create_data_raw_folder\n\n### define global variables\nvar1 = 1\nvar2 = \"test\"\nvar3 = [1, 2, 3]\n\n### call the function\ncreate_data_raw_folder(\n    \"my_data_raw_folder\",\n    var1=var1,\n    var2=var2,\n    var3=var3,\n)\n</code></pre> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def create_data_raw_folder(\n    folder_name: str,\n    **kwargs,\n):\n    \"\"\"\n    Create a folder for raw data of some kind of experiments/study etc.\n    All data raw should be created by RUNNING A SINGLE PYTHON script. This data should\n    be stored in the folder created here.\n    If the created raw data depends on some parameters, these parameters should also be\n    stored. They should be global in the corresponding python script to be able to easily\n    set them again (replicate the data raw creation process).\n    Best practice for the python script: define global parameters at the beginning, then\n    call this function.\n    This function stores the following information in a file called \"__data_raw_meta__\"\n    in the created folder:\n        - the name of the python script which created the data raw\n        - the global variables of the python script given as kwargs\n        - the conda environment\n        - the pip requirements\n        - the git log of ANNarchy and CompNeuroPy if they are installed locally\n\n    !!! warning\n        Only works in a conda environment.\n\n    Args:\n        folder_name (str):\n            Name of the folder to create.\n\n        **kwargs (Any, optional):\n            Global variables of the caller script.\n\n    Examples:\n        ```python\n        from CompNeuroPy import create_data_raw_folder\n\n        ### define global variables\n        var1 = 1\n        var2 = \"test\"\n        var3 = [1, 2, 3]\n\n        ### call the function\n        create_data_raw_folder(\n            \"my_data_raw_folder\",\n            var1=var1,\n            var2=var2,\n            var3=var3,\n        )\n        ```\n    \"\"\"\n    ### check if folder already exists\n    if os.path.isdir(folder_name):\n        raise FileExistsError(f\"{folder_name} already exists\")\n    ### create folder\n    create_dir(folder_name)\n\n    ### get caller script\n    caller_frame = inspect.stack()[1]\n    caller_script = caller_frame.filename\n    current_path = os.getcwd()\n\n    ### check if in current path there is a git repository, if yes, get the current\n    ### commit\n    if _is_git_repo():\n        ### get git log\n        os.system(\"git log &gt; __git_log__.txt\")\n        with open(\"__git_log__.txt\", \"r\") as f:\n            git_log = f.readlines()\n        os.remove(\"__git_log__.txt\")\n        if len(git_log) == 0:\n            git_log = None\n        ### get git top level\n        os.system(\"basename $(git rev-parse --show-toplevel) &gt; __git_top__.txt\")\n        with open(\"__git_top__.txt\", \"r\") as f:\n            git_top = f.readlines()\n        os.remove(\"__git_top__.txt\")\n        if len(git_top) == 0:\n            git_top = None\n        ### get git remote\n        os.system(\"git remote get-url origin &gt; __git_remote__.txt\")\n        with open(\"__git_remote__.txt\", \"r\") as f:\n            git_remote = f.readlines()\n        os.remove(\"__git_remote__.txt\")\n        if len(git_remote) == 0:\n            git_remote = None\n    else:\n        git_log = None\n        git_top = None\n        git_remote = None\n\n    ### now get info for annarchy and compneuropy\n    ### check with pip list if annarchy and compneuropy are editable (i.e. installed\n    ### from local path with \"pip install -e .\")\n    os.system(\"pip list &gt; __pip_list__.txt\")\n    with open(\"__pip_list__.txt\", \"r\") as f:\n        pip_list = f.readlines()\n    os.remove(\"__pip_list__.txt\")\n    annarchy_found = False\n    compneuropy_found = False\n    annarchy_found_path = \"\"\n    compneuropy_found_path = \"\"\n    for line in pip_list:\n        if \"ANNarchy\" in line:\n            if \"/\" in line:\n                annarchy_found = True\n                annarchy_found_path = line.split(\" \")[-1]\n        if \"CompNeuroPy\" in line:\n            if \"/\" in line:\n                compneuropy_found = True\n                compneuropy_found_path = line.split(\" \")[-1]\n\n    ### if both are editable we have the paths, else check pip freeze for \"@ file\" (i.e.\n    ### installed from local path with \"pip install .\")\n    if not annarchy_found or not compneuropy_found:\n        os.system(\"pip freeze &gt; __pip_freeze__.txt\")\n        with open(\"__pip_freeze__.txt\", \"r\") as f:\n            pip_freeze = f.readlines()\n        os.remove(\"__pip_freeze__.txt\")\n        for line in pip_freeze:\n            if \"ANNarchy\" in line and \"@ file://\" in line and not annarchy_found:\n                annarchy_found = True\n                annarchy_found_path = line.split(\"@ file://\")[-1]\n            if \"CompNeuroPy\" in line and \"@ file://\" in line and not compneuropy_found:\n                compneuropy_found = True\n                compneuropy_found_path = line.split(\"@ file://\")[-1]\n\n    ### remove \"\\n\" from paths\n    annarchy_found_path = annarchy_found_path.replace(\"\\n\", \"\")\n    compneuropy_found_path = compneuropy_found_path.replace(\"\\n\", \"\")\n\n    ### if they were found get the git log of the found path\n    if annarchy_found:\n        ### run the following commands in the terminal, wait between the commands\n        command_list = [\n            \"git log &gt; __annarchy_git_log__.txt\",\n            f\"mv __annarchy_git_log__.txt {current_path}\",\n        ]\n        os.chdir(annarchy_found_path)\n        for command in command_list:\n            process = subprocess.Popen(\n                command,\n                shell=True,\n            )\n            process.wait()\n        os.chdir(current_path)\n        ### read the git log\n        with open(\"__annarchy_git_log__.txt\", \"r\") as f:\n            annarchy_git_log = f.readlines()\n        os.remove(\"__annarchy_git_log__.txt\")\n    if compneuropy_found:\n        ### run the following commands in the terminal, wait between the commands\n        command_list = [\n            \"git log &gt; __compneuropy_git_log__.txt\",\n            f\"mv __compneuropy_git_log__.txt {current_path}\",\n        ]\n        os.chdir(compneuropy_found_path)\n        for command in command_list:\n            process = subprocess.Popen(\n                command,\n                shell=True,\n            )\n            process.wait()\n        os.chdir(current_path)\n        ### read the git log\n        with open(\"__compneuropy_git_log__.txt\", \"r\") as f:\n            compneuropy_git_log = f.readlines()\n        os.remove(\"__compneuropy_git_log__.txt\")\n\n    ### now get conda env file and pip requirements file to be able to replicate the\n    ### environment\n    ### run \"conda list --explicit &gt; conda_env.txt\"\n    os.system(\"conda list --explicit &gt; __conda_env__.txt\")\n    ### run \"pip-chill --no-chill &gt; requirements.txt\"\n    os.system(\"pip-chill --no-chill &gt; __requirements__.txt\")\n\n    ### read conda env and requirements\n    with open(\"__conda_env__.txt\", \"r\") as f:\n        conda_env = f.readlines()\n    os.remove(\"__conda_env__.txt\")\n    with open(\"__requirements__.txt\", \"r\") as f:\n        requirements = f.readlines()\n    os.remove(\"__requirements__.txt\")\n\n    ### remove the line for annarchy and compneuropy from requirements if found earlier\n    ### in requirements they are written with small letters\n    if annarchy_found:\n        requirements = [line for line in requirements if \"annarchy\" not in line]\n    if compneuropy_found:\n        requirements = [line for line in requirements if \"compneuropy\" not in line]\n\n    ### store everything in a meta file\n    with open(f\"{folder_name}/__data_raw_meta__\", \"w\") as f:\n        git_strings = []\n        if git_top:\n            git_strings.append(\"#  \" + git_top[0])\n        if git_remote:\n            git_strings.append(\"#  \" + git_remote[0])\n        if git_log:\n            git_strings.append(\"#  \" + git_log[0])\n        f.write(\n            f\"# Data created by runnning\\n\"\n            f\"#  {caller_script}\\n\"\n            f\"# part of git repo:\\n\"\n            f\"{''.join(git_strings)}\"\n            f\"# with the following global variables:\\n\"\n        )\n        for key, value in kwargs.items():\n            if isinstance(value, str):\n                f.write(f\"{key} = '{value}'\\n\")\n            else:\n                f.write(f\"{key} = {value}\\n\")\n        f.write(\"\\n\")\n        f.write(\n            \"# ##########################################################################\\n\"\n        )\n        f.write(\n            \"# START OF CONDA ENV FILE ##################################################\\n\"\n        )\n        f.write(\n            \"# COPY AND STORE IT AS TXT FILE ############################################\\n\"\n        )\n        for line in conda_env:\n            f.write(line)\n        f.write(\"\\n\")\n        f.write(\n            \"# ##########################################################################\\n\"\n        )\n        f.write(\n            \"# START OF PIP REQUIREMENTS FILE ###########################################\\n\"\n        )\n        f.write(\n            \"# COPY AND STORE IT AS TXT FILE ############################################\\n\"\n        )\n        f.write(\"# This file may be used to install the python packages:\\n\")\n        f.write(\"# $ pip install -r &lt;this file&gt;\\n\")\n        for line in requirements:\n            f.write(line)\n        if annarchy_found:\n            f.write(\"\\n\")\n            f.write(\"# ANNarchy was installed locally with commit:\\n\")\n            annarchy_commit = annarchy_git_log[0].replace(\"\\n\", \"\")\n            f.write(f\"# {annarchy_commit}\")\n        if compneuropy_found:\n            f.write(\"\\n\")\n            f.write(\"# CompNeuroPy was installed locally with commit:\\n\")\n            compneuropy_commit = compneuropy_git_log[0].replace(\"\\n\", \"\")\n            f.write(f\"# {compneuropy_commit}\")\n</code></pre>"},{"location":"built_in/models/","title":"Full Models","text":""},{"location":"built_in/models/#CompNeuroPy.full_models.BGM","title":"<code>CompNeuroPy.full_models.BGM</code>","text":"<p>             Bases: <code>CompNeuroModel</code></p> <p>The basal ganglia model based on the model from Goenner et al. (2021).</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>name of the model</p> <code>description</code> <code>str</code> <p>description of the model</p> <code>model_creation_function</code> <code>function</code> <p>function which creates the model</p> <code>compile_folder_name</code> <code>str</code> <p>name of the folder in which the model is compiled</p> <code>model_kwargs</code> <code>dict</code> <p>keyword arguments for model_creation_function</p> <code>populations</code> <code>list</code> <p>list of names of all populations of the model</p> <code>projections</code> <code>list</code> <p>list of names of all projections of the model</p> <code>created</code> <code>bool</code> <p>True if the model is created</p> <code>compiled</code> <code>bool</code> <p>True if the model is compiled</p> <code>attribute_df</code> <code>pandas dataframe</code> <p>dataframe containing all attributes of the model compartments</p> <code>params</code> <code>dict</code> <p>dictionary containing all parameters of the model</p> <code>name_appendix</code> <code>str</code> <p>string which is appended to all model compartments and parameters</p> Source code in <code>src/CompNeuroPy/full_models/bgm_22/bgm.py</code> <pre><code>class BGM(CompNeuroModel):\n    \"\"\"\n    The basal ganglia model based on the model from [Goenner et al. (2021)](https://doi.org/10.1111/ejn.15082).\n\n    Attributes:\n        name (str):\n            name of the model\n        description (str):\n            description of the model\n        model_creation_function (function):\n            function which creates the model\n        compile_folder_name (str):\n            name of the folder in which the model is compiled\n        model_kwargs (dict):\n            keyword arguments for model_creation_function\n        populations (list):\n            list of names of all populations of the model\n        projections (list):\n            list of names of all projections of the model\n        created (bool):\n            True if the model is created\n        compiled (bool):\n            True if the model is compiled\n        attribute_df (pandas dataframe):\n            dataframe containing all attributes of the model compartments\n        params (dict):\n            dictionary containing all parameters of the model\n        name_appendix (str):\n            string which is appended to all model compartments and parameters\n    \"\"\"\n\n    @check_types()\n    def __init__(\n        self,\n        name: str = \"BGM_v01_p01\",\n        do_create: bool = True,\n        do_compile: bool = True,\n        compile_folder_name: str | None = None,\n        seed: int | None = None,\n        name_appendix: str = \"\",\n    ):\n        \"\"\"\n        Args:\n            name (str, optional):\n                name of the model, syntax: \"BGM_v&lt;model_version&gt;_p&lt;parameters_version&gt;\"\n                replace &lt;model_version&gt; and &lt;parameters_version&gt; with the versions you\n                want to use, see CompNeuroPy.full_models.BGM_22.parameters for available\n                versions. Default: \"BGM_v01_p01\"\n            do_create (bool, optional):\n                if True, the model is created after initialization. Default: True\n            do_compile (bool, optional):\n                if True, the model is compiled after creation. Default: True\n            compile_folder_name (str, optional):\n                name of the folder in which the compiled model is saved. Default: None,\n                i.e. \"annarchy_BGM_v&lt;model_version&gt;\" is used\n            seed (int, optional):\n                the seed for the random number generator used during model creation.\n                Default: None, i.e. random seed is used\n            name_appendix (str, optional):\n                string which is appended to all model compartments and parameters.\n                Allows to create multiple models with the same name and keep names of\n                compartments and parameters unique. Default: \"\"\n        \"\"\"\n        ### check if name is correct, otherwise raise ValueError\n        if not (\n            len(name.split(\"_\")) == 3\n            and name.split(\"_\")[0] == \"BGM\"\n            and name.split(\"_\")[1][0] == \"v\"\n            and name.split(\"_\")[2][0] == \"p\"\n        ):\n            raise ValueError(\n                \"name has to be of the form 'BGM_v&lt;model_version&gt;_p&lt;parameters_version&gt;'\"\n            )\n\n        ### set attributes (except the ones which are set in the super().__init__())\n        self.name_appendix = name_appendix\n        self.seed = seed\n        if len(self.name_appendix) &gt; 0:\n            self._name_appendix_to_add = \":\" + name_appendix\n        else:\n            self._name_appendix_to_add = \"\"\n\n        ### set model_version_name\n        self._model_version_name = \"_\".join(name.split(\"_\")[:2])\n\n        ### update name with name_appendix\n        name = name + self._name_appendix_to_add\n\n        ### init default compile_folder_name\n        if compile_folder_name == None:\n            compile_folder_name = \"annarchy_\" + self._model_version_name\n\n        ### set description\n        description = (\n            \"The basal ganglia model based on the model from Goenner et al. (2021)\"\n        )\n\n        ### init random number generator\n        self._rng = np.random.default_rng(seed)\n\n        ### get model parameters before init, ignore name_appendix\n        self.params = self._get_params(name.split(\":\")[0])\n\n        ### init\n        super().__init__(\n            model_creation_function=self._model_creation_function,\n            name=name,\n            description=description,\n            do_create=do_create,\n            do_compile=do_compile,\n            compile_folder_name=compile_folder_name,\n        )\n\n    def _add_name_appendix(self):\n        \"\"\"\n        Rename all model compartments, keys (except general) in params dict and\n        names in attribute_df by appending the name_appendix to the original name.\n        \"\"\"\n\n        ### update the attribute_df of the model object (it still contains the original\n        ### names of the model creation)\n        self.attribute_df[\"compartment_name\"] = (\n            self.attribute_df[\"compartment_name\"] + self._name_appendix_to_add\n        )\n        ### rename populations and projections\n        populations_new = []\n        for pop_name in self.populations:\n            populations_new.append(pop_name + self._name_appendix_to_add)\n            get_population(pop_name).name = pop_name + self._name_appendix_to_add\n        self.populations = populations_new\n        projections_new = []\n        for proj_name in self.projections:\n            projections_new.append(proj_name + self._name_appendix_to_add)\n            get_projection(proj_name).name = proj_name + self._name_appendix_to_add\n        self.projections = projections_new\n        ### rename parameter keys except general\n        params_new = {}\n        for key, param_val in self.params.items():\n            param_object = key.split(\".\")[0]\n            param_name = key.split(\".\")[1]\n\n            if param_object == \"general\":\n                params_new[key] = param_val\n                continue\n\n            param_object = param_object + self._name_appendix_to_add\n            key_new = param_object + \".\" + param_name\n            params_new[key_new] = param_val\n        self.params = params_new\n\n    def _model_creation_function(self):\n        \"\"\"\n        Creates the model using the model_creation_function from the\n        model_creation_functions.py file. The function is defined by the\n        model_version_name.\n        \"\"\"\n        model_creation_function = eval(\n            \"importlib.import_module('CompNeuroPy.full_models.bgm_22.model_creation_functions').\"\n            + self._model_version_name\n        )\n        model_creation_function(self)\n\n    def create(self, do_compile=True, compile_folder_name=None):\n        \"\"\"\n        Creates the model and optionally compiles it directly.\n\n        Args:\n            do_compile (bool, optional):\n                If True the model is compiled directly. Default: True.\n            compile_folder_name (str, optional):\n                Name of the folder in which the model is compiled. Default: value from\n                initialization.\n        \"\"\"\n        ### create the model, but do not compile to set parameters before compilation\n        super().create(do_compile=False, compile_folder_name=compile_folder_name)\n\n        ### update names of compartments and parameters\n        self._add_name_appendix()\n\n        ### set parameters and connectivity of projections\n        ### for each projection the connectivity has to be defined in the params\n        self._set_params()\n        self._set_noise_values()\n        self._set_connections()\n\n        ### compile the model, after setting all parameters (included in compile state)\n        if do_compile:\n            self.compile(compile_folder_name)\n\n    def _set_params(self):\n        \"\"\"\n        sets params of all populations\n        \"\"\"\n\n        ### loop over all params\n        for key, param_val in self.params.items():\n            ### split key in param object and param name\n            param_object = key.split(\".\")[0]\n            param_name = key.split(\".\")[1]\n\n            ### if param is a noise param --&gt; skip (separate function)\n            if param_name.split(\"_\")[-1] == \"noise\":\n                continue\n\n            ### if param name ends with init --&gt; actual param_name (in pop) is without init\n            if param_name.split(\"_\")[-1] == \"init\":\n                param_name = \"_\".join(param_name.split(\"_\")[:-1])\n\n            ### if param_object is a pop in network\n            if param_object in self.populations:\n                ### and the param_name is an attribute of the pop --&gt; set param of pop\n                if param_name in vars(get_population(param_object))[\"attributes\"]:\n                    ### if parameter values are given as distribution --&gt; get numpy array\n                    if isinstance(param_val, str):\n                        if (\n                            \"Uniform\" in param_val\n                            or \"DiscreteUniform\" in param_val\n                            or \"Normal\" in param_val\n                            or \"LogNormal\" in param_val\n                            or \"Exponential\" in param_val\n                            or \"Gamma\" in param_val\n                        ):\n                            distribution = eval(param_val)\n                            param_val = distribution.get_values(\n                                shape=get_population(param_object).geometry\n                            )\n                    self.set_param(\n                        compartment=param_object,\n                        parameter_name=param_name,\n                        parameter_value=param_val,\n                    )\n                    ### if parameter base_mean --&gt; also set I_base\n                    if param_name == \"base_mean\":\n                        self.set_param(\n                            compartment=param_object,\n                            parameter_name=\"I_base\",\n                            parameter_value=param_val,\n                        )\n\n    def _set_noise_values(self):\n        \"\"\"\n        sets noise params of all populations\n        \"\"\"\n\n        ### loop over all params\n        for key, param_val in self.params.items():\n            ### split key in param object and param name\n            param_object = key.split(\".\")[0]\n            param_name = key.split(\".\")[1]\n\n            ### if param_object is a pop in network and param_name ends with noise --&gt; set noise param of pop\n            if (\n                param_object in self.populations\n                and param_name.split(\"_\")[-1] == \"noise\"\n            ):\n                if param_name == \"mean_rate_noise\":\n                    ### for mean and sd the actual parameter of the pop has to be calculated\n                    mean = param_val\n                    try:\n                        ### noise values defined by mean and sd\n                        sd = self.params[param_object + \".rate_sd_noise\"]\n                    except:\n                        ### if only mean is available, only set mean\n                        sd = 0\n                    if sd != 0:\n                        self.set_param(\n                            compartment=param_object,\n                            parameter_name=\"rates_noise\",\n                            parameter_value=self._rng.normal(\n                                mean, sd, get_population(param_object).size\n                            ),\n                        )\n                    else:\n                        self.set_param(\n                            compartment=param_object,\n                            parameter_name=\"rates_noise\",\n                            parameter_value=mean,\n                        )\n                elif param_name in vars(get_population(param_object))[\"attributes\"]:\n                    ### noise parameters which are actual attributes of the pop are simply set\n                    self.set_param(\n                        compartment=param_object,\n                        parameter_name=param_name,\n                        parameter_value=param_val,\n                    )\n                else:\n                    continue\n\n    def _set_connections(self):\n        \"\"\"\n        sets the connectivity and parameters of all projections\n        \"\"\"\n\n        ### dict for each projection, which params were already set during connectivity definition\n        already_set_params = {}\n\n        ### set connectivity\n        ### loop over all projections\n        set_con_failed = False\n        error_message_list = []\n        for proj_name in self.projections:\n            ### get the type of connectivity for projection\n            try:\n                connectivity = self.params[proj_name + \".connectivity\"]\n            except:\n                print(\n                    \"\\nERROR: missing connectivity parameter for\",\n                    proj_name,\n                    \"\\n\",\n                    proj_name + \".connectivity\",\n                    \"needed!\\n\",\n                    \"parameters id:\",\n                    self.params[\"general.id\"],\n                    \"\\n\",\n                )\n                quit()\n\n            possible_con_list = [\n                \"connect_fixed_number_pre\",\n                \"connect_all_to_all\",\n                \"connect_one_to_one\",\n                \"connect_fixed_probability\",\n            ]\n            if connectivity in possible_con_list:\n                try:\n                    # get all possible parameters of the connectivity function\n                    con_func = eval(f\"get_projection(proj_name).{connectivity}\")\n                    possible_con_params_list = list(\n                        inspect.signature(con_func).parameters.keys()\n                    )\n                    # check if paramters are given in the params dict and create the kwargs for the connectivity function\n                    con_kwargs = {}\n                    for con_param_key in possible_con_params_list:\n                        if proj_name + \".\" + con_param_key in self.params:\n                            con_kwargs[con_param_key] = eval(\n                                str(self.params[proj_name + \".\" + con_param_key])\n                            )\n                    # call the connectivity function with the obtained kwargs\n                    con_func(**con_kwargs)\n                    # store which parameters have been set\n                    already_set_params[proj_name] = list(con_kwargs.keys())\n                except:\n                    exc_type, exc_value, exc_traceback = sys.exc_info()\n                    error_message = traceback.format_exception_only(exc_type, exc_value)\n                    error_message_list.append([f\"ERROR: {proj_name}\"] + error_message)\n                    set_con_failed = True\n            else:\n                print(\n                    \"\\nERROR: wrong connectivity parameter for\",\n                    proj_name + \".connectivity!\\n\",\n                    \"parameters id:\",\n                    self.params[\"general.id\"],\n                    \"possible:\",\n                    possible_con_list,\n                    \"\\n\",\n                )\n                quit()\n        if set_con_failed:\n            print(\"\\n\")\n            for error_message in error_message_list:\n                print(\" \".join(error_message))\n            raise TypeError(\"Setting connectivities failed\")\n\n        ### set parameters\n        ### loop over all params\n        for key, param_val in self.params.items():\n            ### split key in param object and param name\n            param_object = key.split(\".\")[0]\n            param_name = key.split(\".\")[1]\n\n            if param_object == \"general\":\n                continue\n\n            ### if param_object is proj in network and param not already used and param is an attribute of proj --&gt; set param of proj\n            if (\n                param_object in self.projections\n                and not (param_name in already_set_params[param_object])\n                and param_name in vars(get_projection(param_object))[\"attributes\"]\n            ):\n                self.set_param(\n                    compartment=param_object,\n                    parameter_name=param_name,\n                    parameter_value=param_val,\n                )\n\n    def _get_params(self, name):\n        \"\"\"\n        read all parameters for specified model name\n\n        Args:\n            name (str):\n                name of the model, specifies which column in the csv file is used\n        \"\"\"\n\n        csvPath = os.path.dirname(os.path.realpath(__file__)) + \"/parameters.csv\"\n        csvfile = open(csvPath, newline=\"\")\n\n        params = {}\n        reader = csv.reader(csvfile, delimiter=\",\")\n        fileRows = []\n        idx = -1\n        ### check if name is in the .csv file\n        for row in reader:\n            if row[0] == \"\":\n                continue\n            fileRows.append(row)\n            if \"general.id\" == row[0] and True in [\n                name == row[i] for i in range(1, len(row))\n            ]:\n                idx = [name == row[i] for i in range(1, len(row))].index(True) + 1\n            elif \"general.id\" == row[0]:\n                print(\n                    \"No Parameters available for given model name \"\n                    + name\n                    + \"! (file \"\n                    + csvPath\n                    + \")\"\n                )\n                quit()\n        if idx == -1:\n            print(\"No general.id in parameter csv file!\")\n            quit()\n        ### read the column corresponding to name\n        for row in fileRows:\n            if \"###\" in row[0]:\n                continue\n            if row[idx] == \"\":\n                continue\n\n            value = row[idx]\n            try:\n                ### if float(value) works value is a number --&gt; check if it is int\n                if float(value) - int(float(value)) == 0:\n                    params[row[0]] = int(float(value))\n                else:\n                    params[row[0]] = float(value)\n            except:\n                ### value is a string\n                if value[0] == \"$\" and value[-1] == \"$\":\n                    ### value is a formula\n                    params[row[0]] = float(eval(value[1:-1]))\n                else:\n                    ### value is some other string\n                    params[row[0]] = value\n        csvfile.close()\n\n        return params\n\n    def _needed_imports(self):\n        for import_val in [\n            Uniform,\n            DiscreteUniform,\n            Normal,\n            LogNormal,\n            Exponential,\n            Gamma,\n            importlib,\n        ]:\n            print(import_val)\n</code></pre>"},{"location":"built_in/models/#CompNeuroPy.full_models.BGM.__init__","title":"<code>__init__(name='BGM_v01_p01', do_create=True, do_compile=True, compile_folder_name=None, seed=None, name_appendix='')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the model, syntax: \"BGM_v_p\" replace  and  with the versions you want to use, see CompNeuroPy.full_models.BGM_22.parameters for available versions. Default: \"BGM_v01_p01\" <code>'BGM_v01_p01'</code> <code>do_create</code> <code>bool</code> <p>if True, the model is created after initialization. Default: True</p> <code>True</code> <code>do_compile</code> <code>bool</code> <p>if True, the model is compiled after creation. Default: True</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>name of the folder in which the compiled model is saved. Default: None, i.e. \"annarchy_BGM_v\" is used <code>None</code> <code>seed</code> <code>int</code> <p>the seed for the random number generator used during model creation. Default: None, i.e. random seed is used</p> <code>None</code> <code>name_appendix</code> <code>str</code> <p>string which is appended to all model compartments and parameters. Allows to create multiple models with the same name and keep names of compartments and parameters unique. Default: \"\"</p> <code>''</code> Source code in <code>src/CompNeuroPy/full_models/bgm_22/bgm.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    name: str = \"BGM_v01_p01\",\n    do_create: bool = True,\n    do_compile: bool = True,\n    compile_folder_name: str | None = None,\n    seed: int | None = None,\n    name_appendix: str = \"\",\n):\n    \"\"\"\n    Args:\n        name (str, optional):\n            name of the model, syntax: \"BGM_v&lt;model_version&gt;_p&lt;parameters_version&gt;\"\n            replace &lt;model_version&gt; and &lt;parameters_version&gt; with the versions you\n            want to use, see CompNeuroPy.full_models.BGM_22.parameters for available\n            versions. Default: \"BGM_v01_p01\"\n        do_create (bool, optional):\n            if True, the model is created after initialization. Default: True\n        do_compile (bool, optional):\n            if True, the model is compiled after creation. Default: True\n        compile_folder_name (str, optional):\n            name of the folder in which the compiled model is saved. Default: None,\n            i.e. \"annarchy_BGM_v&lt;model_version&gt;\" is used\n        seed (int, optional):\n            the seed for the random number generator used during model creation.\n            Default: None, i.e. random seed is used\n        name_appendix (str, optional):\n            string which is appended to all model compartments and parameters.\n            Allows to create multiple models with the same name and keep names of\n            compartments and parameters unique. Default: \"\"\n    \"\"\"\n    ### check if name is correct, otherwise raise ValueError\n    if not (\n        len(name.split(\"_\")) == 3\n        and name.split(\"_\")[0] == \"BGM\"\n        and name.split(\"_\")[1][0] == \"v\"\n        and name.split(\"_\")[2][0] == \"p\"\n    ):\n        raise ValueError(\n            \"name has to be of the form 'BGM_v&lt;model_version&gt;_p&lt;parameters_version&gt;'\"\n        )\n\n    ### set attributes (except the ones which are set in the super().__init__())\n    self.name_appendix = name_appendix\n    self.seed = seed\n    if len(self.name_appendix) &gt; 0:\n        self._name_appendix_to_add = \":\" + name_appendix\n    else:\n        self._name_appendix_to_add = \"\"\n\n    ### set model_version_name\n    self._model_version_name = \"_\".join(name.split(\"_\")[:2])\n\n    ### update name with name_appendix\n    name = name + self._name_appendix_to_add\n\n    ### init default compile_folder_name\n    if compile_folder_name == None:\n        compile_folder_name = \"annarchy_\" + self._model_version_name\n\n    ### set description\n    description = (\n        \"The basal ganglia model based on the model from Goenner et al. (2021)\"\n    )\n\n    ### init random number generator\n    self._rng = np.random.default_rng(seed)\n\n    ### get model parameters before init, ignore name_appendix\n    self.params = self._get_params(name.split(\":\")[0])\n\n    ### init\n    super().__init__(\n        model_creation_function=self._model_creation_function,\n        name=name,\n        description=description,\n        do_create=do_create,\n        do_compile=do_compile,\n        compile_folder_name=compile_folder_name,\n    )\n</code></pre>"},{"location":"built_in/models/#CompNeuroPy.full_models.BGM.create","title":"<code>create(do_compile=True, compile_folder_name=None)</code>","text":"<p>Creates the model and optionally compiles it directly.</p> <p>Parameters:</p> Name Type Description Default <code>do_compile</code> <code>bool</code> <p>If True the model is compiled directly. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: value from initialization.</p> <code>None</code> Source code in <code>src/CompNeuroPy/full_models/bgm_22/bgm.py</code> <pre><code>def create(self, do_compile=True, compile_folder_name=None):\n    \"\"\"\n    Creates the model and optionally compiles it directly.\n\n    Args:\n        do_compile (bool, optional):\n            If True the model is compiled directly. Default: True.\n        compile_folder_name (str, optional):\n            Name of the folder in which the model is compiled. Default: value from\n            initialization.\n    \"\"\"\n    ### create the model, but do not compile to set parameters before compilation\n    super().create(do_compile=False, compile_folder_name=compile_folder_name)\n\n    ### update names of compartments and parameters\n    self._add_name_appendix()\n\n    ### set parameters and connectivity of projections\n    ### for each projection the connectivity has to be defined in the params\n    self._set_params()\n    self._set_noise_values()\n    self._set_connections()\n\n    ### compile the model, after setting all parameters (included in compile state)\n    if do_compile:\n        self.compile(compile_folder_name)\n</code></pre>"},{"location":"built_in/models/#CompNeuroPy.full_models.HHmodelBischop","title":"<code>CompNeuroPy.full_models.HHmodelBischop</code>","text":"<p>             Bases: <code>CompNeuroModel</code></p> <p>Generates a single population of the Hodgkin &amp; Huxley neuron model of Bischop et al. (2012) and optionally creates/compiles the network.</p> Source code in <code>src/CompNeuroPy/full_models/hodgkin_huxley_single_pop.py</code> <pre><code>class HHmodelBischop(CompNeuroModel):\n    \"\"\"\n    Generates a single population of the Hodgkin &amp; Huxley neuron model of\n    [Bischop et al. (2012)](https://doi.org/10.3389/fnmol.2012.00078) and optionally\n    creates/compiles the network.\n    \"\"\"\n\n    def __init__(\n        self,\n        pop_size=1,\n        conductance_based_synapses=False,\n        name=\"single_HH_Bischop\",\n        do_create=True,\n        do_compile=True,\n        compile_folder_name=\"annarchy_single_HH_Bischop\",\n    ):\n        \"\"\"\n        Args:\n            pop_size (int, optional):\n                Number of neurons in the population. Default: 1.\n            conductance_based_synapses (bool, optional):\n                Whether the equations contain conductance based synapses for AMPA and\n                GABA. Default: False.\n            name (str, optional):\n                Name of the model. Default: \"single_HH_Bischop\".\n            do_create (bool, optional):\n                Whether to create the model. Default: True.\n            do_compile (bool, optional):\n                Whether to compile the model. Default: True.\n            compile_folder_name (str, optional):\n                Name of the folder for the compiled model.\n                Default: \"annarchy_single_HH_Bischop\".\n        \"\"\"\n        ### set attributes\n        self.pop_size = pop_size\n        self.conductance_based_synapses = conductance_based_synapses\n        # define description\n        description = \"\"\"\n            One population \"HH_Bischop\" with a single neuron of the Hodgkin\n            &amp; Huxley neuron model of Bischop et al. (2012).\n        \"\"\"\n        # initialize CompNeuroModel\n        super().__init__(\n            model_creation_function=self._bischop_2012_creation_function,\n            name=name,\n            description=description,\n            do_create=do_create,\n            do_compile=do_compile,\n            compile_folder_name=compile_folder_name,\n        )\n\n    def _bischop_2012_creation_function(self):\n        if self.conductance_based_synapses:\n            Population(self.pop_size, neuron=HHneuronBischopSyn, name=\"HH_Bischop_syn\")\n        else:\n            Population(self.pop_size, neuron=HHneuronBischop, name=\"HH_Bischop\")\n</code></pre>"},{"location":"built_in/models/#CompNeuroPy.full_models.HHmodelBischop.__init__","title":"<code>__init__(pop_size=1, conductance_based_synapses=False, name='single_HH_Bischop', do_create=True, do_compile=True, compile_folder_name='annarchy_single_HH_Bischop')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>pop_size</code> <code>int</code> <p>Number of neurons in the population. Default: 1.</p> <code>1</code> <code>conductance_based_synapses</code> <code>bool</code> <p>Whether the equations contain conductance based synapses for AMPA and GABA. Default: False.</p> <code>False</code> <code>name</code> <code>str</code> <p>Name of the model. Default: \"single_HH_Bischop\".</p> <code>'single_HH_Bischop'</code> <code>do_create</code> <code>bool</code> <p>Whether to create the model. Default: True.</p> <code>True</code> <code>do_compile</code> <code>bool</code> <p>Whether to compile the model. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder for the compiled model. Default: \"annarchy_single_HH_Bischop\".</p> <code>'annarchy_single_HH_Bischop'</code> Source code in <code>src/CompNeuroPy/full_models/hodgkin_huxley_single_pop.py</code> <pre><code>def __init__(\n    self,\n    pop_size=1,\n    conductance_based_synapses=False,\n    name=\"single_HH_Bischop\",\n    do_create=True,\n    do_compile=True,\n    compile_folder_name=\"annarchy_single_HH_Bischop\",\n):\n    \"\"\"\n    Args:\n        pop_size (int, optional):\n            Number of neurons in the population. Default: 1.\n        conductance_based_synapses (bool, optional):\n            Whether the equations contain conductance based synapses for AMPA and\n            GABA. Default: False.\n        name (str, optional):\n            Name of the model. Default: \"single_HH_Bischop\".\n        do_create (bool, optional):\n            Whether to create the model. Default: True.\n        do_compile (bool, optional):\n            Whether to compile the model. Default: True.\n        compile_folder_name (str, optional):\n            Name of the folder for the compiled model.\n            Default: \"annarchy_single_HH_Bischop\".\n    \"\"\"\n    ### set attributes\n    self.pop_size = pop_size\n    self.conductance_based_synapses = conductance_based_synapses\n    # define description\n    description = \"\"\"\n        One population \"HH_Bischop\" with a single neuron of the Hodgkin\n        &amp; Huxley neuron model of Bischop et al. (2012).\n    \"\"\"\n    # initialize CompNeuroModel\n    super().__init__(\n        model_creation_function=self._bischop_2012_creation_function,\n        name=name,\n        description=description,\n        do_create=do_create,\n        do_compile=do_compile,\n        compile_folder_name=compile_folder_name,\n    )\n</code></pre>"},{"location":"built_in/models/#CompNeuroPy.full_models.HHmodelCorbit","title":"<code>CompNeuroPy.full_models.HHmodelCorbit</code>","text":"<p>             Bases: <code>CompNeuroModel</code></p> <p>Generates a single population of the Hodgkin &amp; Huxley neuron model of Corbit et al. (2016) and optionally creates/compiles the network.</p> Source code in <code>src/CompNeuroPy/full_models/hodgkin_huxley_single_pop.py</code> <pre><code>class HHmodelCorbit(CompNeuroModel):\n    \"\"\"\n    Generates a single population of the Hodgkin &amp; Huxley neuron model of\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016) and\n    optionally creates/compiles the network.\n    \"\"\"\n\n    def __init__(\n        self,\n        pop_size=1,\n        conductance_based_synapses=False,\n        name=\"single_HH_Corbit\",\n        do_create=True,\n        do_compile=True,\n        compile_folder_name=\"annarchy_single_HH_Corbit\",\n    ):\n        \"\"\"\n        Args:\n            pop_size (int, optional):\n                Number of neurons in the population. Default: 1.\n            conductance_based_synapses (bool, optional):\n                Whether the equations contain conductance based synapses for AMPA and\n                GABA. Default: False.\n            name (str, optional):\n                Name of the model. Default: \"single_HH_Corbit\".\n            do_create (bool, optional):\n                Whether to create the model. Default: True.\n            do_compile (bool, optional):\n                Whether to compile the model. Default: True.\n            compile_folder_name (str, optional):\n                Name of the folder for the compiled model.\n                Default: \"annarchy_single_HH_Corbit\".\n        \"\"\"\n        ### set attributes\n        self.pop_size = pop_size\n        self.conductance_based_synapses = conductance_based_synapses\n        # define description\n        description = \"\"\"\n            One population \"HH_Bischop\" with a single neuron of the Hodgkin\n            &amp; Huxley neuron model of Bischop et al. (2012).\n        \"\"\"\n        # initialize CompNeuroModel\n        super().__init__(\n            model_creation_function=self._model_creation_function,\n            name=name,\n            description=description,\n            do_create=do_create,\n            do_compile=do_compile,\n            compile_folder_name=compile_folder_name,\n        )\n\n    def _model_creation_function(self):\n        if self.conductance_based_synapses:\n            Population(self.pop_size, neuron=HHneuronCorbitSyn, name=\"HH_Corbit_syn\")\n        else:\n            Population(self.pop_size, neuron=HHneuronCorbit, name=\"HH_Corbit\")\n</code></pre>"},{"location":"built_in/models/#CompNeuroPy.full_models.HHmodelCorbit.__init__","title":"<code>__init__(pop_size=1, conductance_based_synapses=False, name='single_HH_Corbit', do_create=True, do_compile=True, compile_folder_name='annarchy_single_HH_Corbit')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>pop_size</code> <code>int</code> <p>Number of neurons in the population. Default: 1.</p> <code>1</code> <code>conductance_based_synapses</code> <code>bool</code> <p>Whether the equations contain conductance based synapses for AMPA and GABA. Default: False.</p> <code>False</code> <code>name</code> <code>str</code> <p>Name of the model. Default: \"single_HH_Corbit\".</p> <code>'single_HH_Corbit'</code> <code>do_create</code> <code>bool</code> <p>Whether to create the model. Default: True.</p> <code>True</code> <code>do_compile</code> <code>bool</code> <p>Whether to compile the model. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder for the compiled model. Default: \"annarchy_single_HH_Corbit\".</p> <code>'annarchy_single_HH_Corbit'</code> Source code in <code>src/CompNeuroPy/full_models/hodgkin_huxley_single_pop.py</code> <pre><code>def __init__(\n    self,\n    pop_size=1,\n    conductance_based_synapses=False,\n    name=\"single_HH_Corbit\",\n    do_create=True,\n    do_compile=True,\n    compile_folder_name=\"annarchy_single_HH_Corbit\",\n):\n    \"\"\"\n    Args:\n        pop_size (int, optional):\n            Number of neurons in the population. Default: 1.\n        conductance_based_synapses (bool, optional):\n            Whether the equations contain conductance based synapses for AMPA and\n            GABA. Default: False.\n        name (str, optional):\n            Name of the model. Default: \"single_HH_Corbit\".\n        do_create (bool, optional):\n            Whether to create the model. Default: True.\n        do_compile (bool, optional):\n            Whether to compile the model. Default: True.\n        compile_folder_name (str, optional):\n            Name of the folder for the compiled model.\n            Default: \"annarchy_single_HH_Corbit\".\n    \"\"\"\n    ### set attributes\n    self.pop_size = pop_size\n    self.conductance_based_synapses = conductance_based_synapses\n    # define description\n    description = \"\"\"\n        One population \"HH_Bischop\" with a single neuron of the Hodgkin\n        &amp; Huxley neuron model of Bischop et al. (2012).\n    \"\"\"\n    # initialize CompNeuroModel\n    super().__init__(\n        model_creation_function=self._model_creation_function,\n        name=name,\n        description=description,\n        do_create=do_create,\n        do_compile=do_compile,\n        compile_folder_name=compile_folder_name,\n    )\n</code></pre>"},{"location":"built_in/neuron_models/","title":"Neuron Models","text":""},{"location":"built_in/neuron_models/#artificial-neurons","title":"Artificial Neurons","text":""},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.IntegratorNeuron","title":"<code>IntegratorNeuron</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Integrator Neuron for stop_condition in spiking models.</p> <p>The variable g_ampa increases for incoming spikes (target ampa) and decreases exponentially with time constant tau. If g_ampa reaches a threshold, the neuron's variable decision, which is by default -1, changes to the neuron_id. This can be used to cause the stop_condition of ANNarchy's simulate_until() function (stop_codnition=\"decision&gt;=0 : any\"). In case of multiple integrator neurons, the neuron_id can be used to identify the neuron that reached the threshold.</p> <p>Warning</p> <p>You have to define the variable neuron_id for each neuron in the Integrator population.</p> <p>Parameters:</p> Name Type Description Default <code>tau</code> <code>float</code> <p>Time constant in ms of the neuron. Default: 1.</p> <code>1</code> <code>threshold</code> <code>float</code> <p>Threshold for the decision g_ampa has to reach. Default: 1.</p> <code>1</code> <p>Examples:</p> <pre><code>from ANNarchy import Population, simulate_until\nfrom CompNeuroPy.neuron_models import Integrator\n\n# Create a population of 10 integrator neurons\nintegrator_neurons = Population(\n    geometry=10,\n    neuron=IntegratorNeuron(tau=1, threshold=1),\n    stop_condition=\"decision&gt;=0 : any\",\n    name=\"integrator_neurons\",)\n\n# set the neuron_id for each neuron\nintegrator_neurons.neuron_id = range(10)\n\n# simulate until one neuron reaches the threshold\nsimulate_until(max_duration=1000, population=integrator_neurons)\n\n# check if simulation stop due to stop_codnition and which neuron reached the\n# threshold\nif (integrator_neurons.decision &gt;= 0).any():\n    neurons_reached_thresh = integrator_neurons.neuron_id[\n        integrator_neurons.decision &gt;= 0\n    ]\n    print(f\"Neuron(s) {neurons_reached_thresh} reached threshold.\")\nelse:\n    print(\"No neuron reached threshold.\")\n</code></pre> Variables to record <ul> <li>g_ampa</li> <li>decision</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class IntegratorNeuron(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    Integrator Neuron for stop_condition in spiking models.\n\n    The variable g_ampa increases for incoming spikes (target ampa) and decreases\n    exponentially with time constant tau. If g_ampa reaches a threshold, the neuron's\n    variable decision, which is by default -1, changes to the neuron_id. This can be\n    used to cause the stop_condition of ANNarchy's simulate_until() function\n    (stop_codnition=\"decision&gt;=0 : any\"). In case of multiple integrator neurons,\n    the neuron_id can be used to identify the neuron that reached the threshold.\n\n    !!! warning\n        You have to define the variable neuron_id for each neuron in the Integrator\n        population.\n\n    Parameters:\n        tau (float, optional):\n            Time constant in ms of the neuron. Default: 1.\n        threshold (float, optional):\n            Threshold for the decision g_ampa has to reach. Default: 1.\n\n    Examples:\n        ```python\n        from ANNarchy import Population, simulate_until\n        from CompNeuroPy.neuron_models import Integrator\n\n        # Create a population of 10 integrator neurons\n        integrator_neurons = Population(\n            geometry=10,\n            neuron=IntegratorNeuron(tau=1, threshold=1),\n            stop_condition=\"decision&gt;=0 : any\",\n            name=\"integrator_neurons\",)\n\n        # set the neuron_id for each neuron\n        integrator_neurons.neuron_id = range(10)\n\n        # simulate until one neuron reaches the threshold\n        simulate_until(max_duration=1000, population=integrator_neurons)\n\n        # check if simulation stop due to stop_codnition and which neuron reached the\n        # threshold\n        if (integrator_neurons.decision &gt;= 0).any():\n            neurons_reached_thresh = integrator_neurons.neuron_id[\n                integrator_neurons.decision &gt;= 0\n            ]\n            print(f\"Neuron(s) {neurons_reached_thresh} reached threshold.\")\n        else:\n            print(\"No neuron reached threshold.\")\n        ```\n\n    Variables to record:\n        - g_ampa\n        - decision\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(self, tau: float = 1, threshold: float = 1):\n        # Create the arguments\n        parameters = f\"\"\"\n            tau = {tau} : population\n            threshold = {threshold} : population\n            neuron_id = 0\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = - g_ampa / tau\n                ddecision/dt = 0 : init = -1\n            \"\"\",\n            spike=\"\"\"\n                g_ampa &gt;= threshold\n            \"\"\",\n            reset=\"\"\"\n                decision = neuron_id\n            \"\"\",\n            name=\"integrator_neuron\",\n            description=\"\"\"\n                Integrator Neuron, which integrates incoming spikes with value g_ampa\n                and emits a spike when reaching a threshold. After spike decision\n                changes, which can be used as for stop condition\"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.IntegratorNeuronSimple","title":"<code>IntegratorNeuronSimple</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Integrator Neuron for stop_condition in spiking models.</p> <p>The variable g_ampa increases for incoming spikes (target ampa) and decreases exponentially with time constant tau. You can check g_ampa and use it for the stop_condition of ANNarchy's simulate_until() function (stop_codnition=\"g_ampa&gt;=some_value : any\"). In case of multiple integrator neurons, the neuron_id can be used to identify the neuron that reached the threshold.</p> <p>Warning</p> <p>You have to define the variable neuron_id for each neuron in the Integrator population.</p> <p>Parameters:</p> Name Type Description Default <code>tau</code> <code>float</code> <p>Time constant in ms of the neuron. Default: 1.</p> <code>1</code> <p>Examples:</p> <pre><code>from ANNarchy import Population, simulate_until\nfrom CompNeuroPy.neuron_models import Integrator\n\n# Create a population of 10 integrator neurons\nintegrator_neurons = Population(\n    geometry=10,\n    neuron=IntegratorNeuronSimple(tau=1),\n    stop_condition=\"g_ampa&gt;=5 : any\",\n    name=\"integrator_neurons\",)\n\n# set the neuron_id for each neuron\nintegrator_neurons.neuron_id = range(10)\n\n# simulate until one neuron reaches the threshold\nsimulate_until(max_duration=1000, population=integrator_neurons)\n\n# check if simulation stop due to stop_codnition and which neuron reached the\n# threshold\nif (integrator_neurons.g_ampa &gt;= 5).any():\n    neurons_reached_thresh = integrator_neurons.neuron_id[\n        integrator_neurons.g_ampa &gt;= 5\n    ]\n    print(f\"Neuron(s) {neurons_reached_thresh} reached threshold.\")\nelse:\n    print(\"No neuron reached threshold.\")\n</code></pre> Variables to record <ul> <li>g_ampa</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class IntegratorNeuronSimple(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    Integrator Neuron for stop_condition in spiking models.\n\n    The variable g_ampa increases for incoming spikes (target ampa) and decreases\n    exponentially with time constant tau. You can check g_ampa and use it for the\n    stop_condition of ANNarchy's simulate_until() function\n    (stop_codnition=\"g_ampa&gt;=some_value : any\"). In case of multiple integrator neurons,\n    the neuron_id can be used to identify the neuron that reached the threshold.\n\n    !!! warning\n        You have to define the variable neuron_id for each neuron in the Integrator\n        population.\n\n    Parameters:\n        tau (float, optional):\n            Time constant in ms of the neuron. Default: 1.\n\n    Examples:\n        ```python\n        from ANNarchy import Population, simulate_until\n        from CompNeuroPy.neuron_models import Integrator\n\n        # Create a population of 10 integrator neurons\n        integrator_neurons = Population(\n            geometry=10,\n            neuron=IntegratorNeuronSimple(tau=1),\n            stop_condition=\"g_ampa&gt;=5 : any\",\n            name=\"integrator_neurons\",)\n\n        # set the neuron_id for each neuron\n        integrator_neurons.neuron_id = range(10)\n\n        # simulate until one neuron reaches the threshold\n        simulate_until(max_duration=1000, population=integrator_neurons)\n\n        # check if simulation stop due to stop_codnition and which neuron reached the\n        # threshold\n        if (integrator_neurons.g_ampa &gt;= 5).any():\n            neurons_reached_thresh = integrator_neurons.neuron_id[\n                integrator_neurons.g_ampa &gt;= 5\n            ]\n            print(f\"Neuron(s) {neurons_reached_thresh} reached threshold.\")\n        else:\n            print(\"No neuron reached threshold.\")\n        ```\n\n    Variables to record:\n        - g_ampa\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(self, tau: float = 1):\n        # Create the arguments\n        parameters = f\"\"\"\n            tau = {tau} : population\n            neuron_id = 0\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = - g_ampa / tau\n                r = 0\n            \"\"\",\n            name=\"integrator_neuron_simple\",\n            description=\"\"\"\n                Integrator Neuron, which integrates incoming spikes with value g_ampa,\n                which can be used as a stop condition\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.PoissonNeuron","title":"<code>PoissonNeuron</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Poisson neuron whose rate can be specified and is reached instantaneous. The neuron emits spikes following a Poisson distribution, the average firing rate is given by the parameter rates.</p> <p>Parameters:</p> Name Type Description Default <code>rates</code> <code>float</code> <p>The average firing rate of the neuron in Hz. Default: 0.</p> <code>0</code> Variables to record <ul> <li>p</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class PoissonNeuron(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    Poisson neuron whose rate can be specified and is reached instantaneous. The\n    neuron emits spikes following a Poisson distribution, the average firing rate\n    is given by the parameter rates.\n\n    Parameters:\n        rates (float, optional):\n            The average firing rate of the neuron in Hz. Default: 0.\n\n    Variables to record:\n        - p\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(self, rates: float = 0):\n        # Create the arguments\n        parameters = f\"\"\"\n            rates = {rates}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                p = Uniform(0.0, 1.0) * 1000.0 / dt\n            \"\"\",\n            spike=\"\"\"\n                p &lt;= rates\n            \"\"\",\n            reset=\"\"\"\n                p = 0.0\n            \"\"\",\n            name=\"poisson_neuron\",\n            description=\"\"\"\n                Poisson neuron whose rate can be specified and is reached instantaneous.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.PoissonNeuronUpDown","title":"<code>PoissonNeuronUpDown</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>The neuron emits spikes following a Poisson distribution, the average firing rate is given by the parameter rates and is reached with time constants tau_up and tau_down.</p> <p>Attributes:</p> Name Type Description <code>rates</code> <code>float</code> <p>The average firing rate of the neuron in Hz. Default: 0.</p> <code>tau_up</code> <code>float</code> <p>Time constant in ms for increasing the firing rate. Default: 1.</p> <code>tau_down</code> <code>float</code> <p>Time constant in ms for decreasing the firing rate. Default: 1.</p> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class PoissonNeuronUpDown(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    The neuron emits spikes following a Poisson distribution, the average firing rate is\n    given by the parameter rates and is reached with time constants tau_up and tau_down.\n\n    Attributes:\n        rates (float, optional):\n            The average firing rate of the neuron in Hz. Default: 0.\n        tau_up (float, optional):\n            Time constant in ms for increasing the firing rate. Default: 1.\n        tau_down (float, optional):\n            Time constant in ms for decreasing the firing rate. Default: 1.\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(self, rates: float = 0, tau_up: float = 1, tau_down: float = 1):\n        # Create the arguments\n        parameters = f\"\"\"\n            rates = {rates}\n            tau_up = {tau_up}\n            tau_down = {tau_down}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                p = Uniform(0.0, 1.0) * 1000.0 / dt\n                dact/dt = if (rates - act) &gt; 0:\n                              (rates - act) / tau_up\n                          else:\n                              (rates - act) / tau_down\n            \"\"\",\n            spike=\"\"\"\n                p &lt;= act\n            \"\"\",\n            reset=\"\"\"\n                p = 0.0\n            \"\"\",\n            name=\"poisson_neuron_up_down\",\n            description=\"\"\"Poisson neuron whose rate can be specified and is reached\n                with time constants tau_up and tau_down.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.PoissonNeuronSin","title":"<code>PoissonNeuronSin</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Neuron emitting spikes following a Poisson distribution, the average firing rate is given by a sinus function.</p> <p>Parameters:</p> Name Type Description Default <code>amplitude</code> <code>float</code> <p>Amplitude of the sinus function. Default: 0.</p> <code>0</code> <code>base</code> <code>float</code> <p>Base (offset) of the sinus function. Default: 0.</p> <code>0</code> <code>frequency</code> <code>float</code> <p>Frequency of the sinus function. Default: 0.</p> <code>0</code> <code>phase</code> <code>float</code> <p>Phase of the sinus function. Default: 0.</p> <code>0</code> Variables to record <ul> <li>rates</li> <li>p</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class PoissonNeuronSin(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    Neuron emitting spikes following a Poisson distribution, the average firing rate\n    is given by a sinus function.\n\n    Parameters:\n        amplitude (float, optional):\n            Amplitude of the sinus function. Default: 0.\n        base (float, optional):\n            Base (offset) of the sinus function. Default: 0.\n        frequency (float, optional):\n            Frequency of the sinus function. Default: 0.\n        phase (float, optional):\n            Phase of the sinus function. Default: 0.\n\n    Variables to record:\n        - rates\n        - p\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        amplitude: float = 0,\n        base: float = 0,\n        frequency: float = 0,\n        phase: float = 0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            amplitude = {amplitude}\n            base = {base}\n            frequency = {frequency}\n            phase = {phase}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                rates = amplitude * sin((2*pi*frequency)*(t/1000-phase)) + base\n                p     = Uniform(0.0, 1.0) * 1000.0 / dt\n            \"\"\",\n            spike=\"\"\"\n                p &lt;= rates\n            \"\"\",\n            reset=\"\"\"\n                p = 0.0\n            \"\"\",\n            name=\"poisson_neuron_sin\",\n            description=\"Poisson neuron whose rate varies with a sinus function.\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#hodgkin-huxley-neurons","title":"Hodgkin Huxley Neurons","text":""},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronBischop","title":"<code>HHneuronBischop</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Bischop et al. (2012).</p> Variables to record <ul> <li>prev_v</li> <li>I_L</li> <li>alpha_h</li> <li>beta_h</li> <li>h_inf</li> <li>tau_h</li> <li>h</li> <li>alpha_m</li> <li>beta_m</li> <li>m_inf</li> <li>m</li> <li>I_Na</li> <li>alpha_n1</li> <li>beta_n1</li> <li>n1_inf</li> <li>tau_n1</li> <li>n1</li> <li>I_Kv1</li> <li>alpha_n3</li> <li>beta_n3</li> <li>n3_inf</li> <li>tau_n3</li> <li>n3</li> <li>I_Kv3</li> <li>PV</li> <li>PV_Mg</li> <li>dPV_Ca_dt</li> <li>PV_Ca</li> <li>Ca</li> <li>k_inf</li> <li>tau_k</li> <li>k</li> <li>I_SK</li> <li>a_inf</li> <li>a</li> <li>I_Ca</li> <li>v</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronBischop(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Bischop et al. (2012)](https://doi.org/10.3389/fnmol.2012.00078).\n\n    Variables to record:\n        - prev_v\n        - I_L\n        - alpha_h\n        - beta_h\n        - h_inf\n        - tau_h\n        - h\n        - alpha_m\n        - beta_m\n        - m_inf\n        - m\n        - I_Na\n        - alpha_n1\n        - beta_n1\n        - n1_inf\n        - tau_n1\n        - n1\n        - I_Kv1\n        - alpha_n3\n        - beta_n3\n        - n3_inf\n        - tau_n3\n        - n3\n        - I_Kv3\n        - PV\n        - PV_Mg\n        - dPV_Ca_dt\n        - PV_Ca\n        - Ca\n        - k_inf\n        - tau_k\n        - k\n        - I_SK\n        - a_inf\n        - a\n        - I_Ca\n        - v\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.bischop = _BischopStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.bischop.parameters_base\n\n    def _get_equations(self):\n        return self.bischop.equations_base + self.bischop.membrane_base\n\n    def _get_name(self):\n        return \"H_and_H_Bischop\"\n\n    def _get_description(self):\n        return (\n            \"Hodgkin Huxley neuron model for striatal FSI from Bischop et al. (2012).\"\n        )\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronBischopSyn","title":"<code>HHneuronBischopSyn</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Bischop et al. (2012) with conductance-based synapses/currents for AMPA and GABA.</p> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>prev_v</li> <li>I_L</li> <li>alpha_h</li> <li>beta_h</li> <li>h_inf</li> <li>tau_h</li> <li>h</li> <li>alpha_m</li> <li>beta_m</li> <li>m_inf</li> <li>m</li> <li>I_Na</li> <li>alpha_n1</li> <li>beta_n1</li> <li>n1_inf</li> <li>tau_n1</li> <li>n1</li> <li>I_Kv1</li> <li>alpha_n3</li> <li>beta_n3</li> <li>n3_inf</li> <li>tau_n3</li> <li>n3</li> <li>I_Kv3</li> <li>PV</li> <li>PV_Mg</li> <li>dPV_Ca_dt</li> <li>PV_Ca</li> <li>Ca</li> <li>k_inf</li> <li>tau_k</li> <li>k</li> <li>I_SK</li> <li>a_inf</li> <li>a</li> <li>I_Ca</li> <li>v</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronBischopSyn(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Bischop et al. (2012)](https://doi.org/10.3389/fnmol.2012.00078) with\n    conductance-based synapses/currents for AMPA and GABA.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - prev_v\n        - I_L\n        - alpha_h\n        - beta_h\n        - h_inf\n        - tau_h\n        - h\n        - alpha_m\n        - beta_m\n        - m_inf\n        - m\n        - I_Na\n        - alpha_n1\n        - beta_n1\n        - n1_inf\n        - tau_n1\n        - n1\n        - I_Kv1\n        - alpha_n3\n        - beta_n3\n        - n3_inf\n        - tau_n3\n        - n3\n        - I_Kv3\n        - PV\n        - PV_Mg\n        - dPV_Ca_dt\n        - PV_Ca\n        - Ca\n        - k_inf\n        - tau_k\n        - k\n        - I_SK\n        - a_inf\n        - a\n        - I_Ca\n        - v\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.bischop = _BischopStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.bischop.parameters_conductance\n\n    def _get_equations(self):\n        return self.bischop.equations_conductance + self.bischop.membrane_conductance\n\n    def _get_name(self):\n        return \"H_and_H_Bischop_syn\"\n\n    def _get_description(self):\n        return \"\"\"\n                Hodgkin Huxley neuron model for striatal FSI from Bischop et al. (2012)\n                with conductance-based synapses/currents for AMPA and GABA.\n            \"\"\"\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronCorbit","title":"<code>HHneuronCorbit</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016).</p> Variables to record <ul> <li>prev_v</li> <li>I_L</li> <li>m_Na</li> <li>h_Na</li> <li>I_Na</li> <li>n_Kv3_inf</li> <li>tau_n_Kv3_inf</li> <li>n_Kv3</li> <li>I_Kv3</li> <li>m_Kv1</li> <li>h_Kv1</li> <li>I_Kv1</li> <li>v</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronCorbit(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016).\n\n    Variables to record:\n        - prev_v\n        - I_L\n        - m_Na\n        - h_Na\n        - I_Na\n        - n_Kv3_inf\n        - tau_n_Kv3_inf\n        - n_Kv3\n        - I_Kv3\n        - m_Kv1\n        - h_Kv1\n        - I_Kv1\n        - v\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.corbit = _CorbitStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.corbit.parameters_base\n\n    def _get_equations(self):\n        return self.corbit.equations_base + self.corbit.membrane_base\n\n    def _get_name(self):\n        return \"H_and_H_Corbit\"\n\n    def _get_description(self):\n        return \"Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016).\"\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronCorbitSyn","title":"<code>HHneuronCorbitSyn</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016) with conductance-based synapses/currents for AMPA and GABA.</p> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>prev_v</li> <li>I_L</li> <li>m_Na</li> <li>h_Na</li> <li>I_Na</li> <li>n_Kv3_inf</li> <li>tau_n_Kv3_inf</li> <li>n_Kv3</li> <li>I_Kv3</li> <li>m_Kv1</li> <li>h_Kv1</li> <li>I_Kv1</li> <li>v</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronCorbitSyn(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016) with\n    conductance-based synapses/currents for AMPA and GABA.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - prev_v\n        - I_L\n        - m_Na\n        - h_Na\n        - I_Na\n        - n_Kv3_inf\n        - tau_n_Kv3_inf\n        - n_Kv3\n        - I_Kv3\n        - m_Kv1\n        - h_Kv1\n        - I_Kv1\n        - v\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.corbit = _CorbitStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.corbit.parameters_conductance\n\n    def _get_equations(self):\n        return self.corbit.equations_conductance + self.corbit.membrane_conductance\n\n    def _get_name(self):\n        return \"H_and_H_Corbit_syn\"\n\n    def _get_description(self):\n        return \"\"\"\n                Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016)\n                with conductance-based synapses/currents for AMPA and GABA.\n            \"\"\"\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronCorbitVoltageClamp","title":"<code>HHneuronCorbitVoltageClamp</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016) with voltage clamp. Membrane potential v is clamped and I_inf can be recorded.</p> Variables to record <ul> <li>prev_v</li> <li>I_L</li> <li>m_Na</li> <li>h_Na</li> <li>I_Na</li> <li>n_Kv3_inf</li> <li>tau_n_Kv3_inf</li> <li>n_Kv3</li> <li>I_Kv3</li> <li>m_Kv1</li> <li>h_Kv1</li> <li>I_Kv1</li> <li>v</li> <li>I_inf</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronCorbitVoltageClamp(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016) with\n    voltage clamp. Membrane potential v is clamped and I_inf can be recorded.\n\n    Variables to record:\n        - prev_v\n        - I_L\n        - m_Na\n        - h_Na\n        - I_Na\n        - n_Kv3_inf\n        - tau_n_Kv3_inf\n        - n_Kv3\n        - I_Kv3\n        - m_Kv1\n        - h_Kv1\n        - I_Kv1\n        - v\n        - I_inf\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.corbit = _CorbitStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.corbit.parameters_base\n\n    def _get_equations(self):\n        return self.corbit.equations_base + self.corbit.membrane_voltage_clamp\n\n    def _get_name(self):\n        return \"H_and_H_Corbit_voltage_clamp\"\n\n    def _get_description(self):\n        return \"\"\"\n                Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016)\n                with voltage clamp.\n            \"\"\"\n</code></pre>"},{"location":"built_in/neuron_models/#izhikevich-2003-like-neurons","title":"Izhikevich (2003)-like Neurons","text":""},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003FixedNoisyAmpa","title":"<code>Izhikevich2003FixedNoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents with noise in AMPA conductance. Fixed means, the 3 factors of the quadratic equation cannot be changed.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>increase_noise</code> <code>float</code> <p>Increase of the Poisson distributed (equivalent to a Poisson distributed spike train as input) noise in the AMPA conductance.</p> <code>0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the AMPA conductance.</p> <code>0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003FixedNoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents with noise in AMPA\n    conductance. Fixed means, the 3 factors of the quadratic equation cannot be changed.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        increase_noise (float, optional):\n            Increase of the Poisson distributed (equivalent to a Poisson distributed\n            spike train as input) noise in the AMPA conductance.\n        rates_noise (float, optional):\n            Rate of the Poisson distributed noise in the AMPA conductance.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        increase_noise: float = 0,\n        rates_noise: float = 0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app}\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rates_noise, -g_ampa/tau_ampa, -g_ampa/tau_ampa + increase_noise/dt)\n                dg_gaba/dt = -g_gaba / tau_gaba\n                dv/dt      = 0.04 * v * v + 5 * v + 140 - u + I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba))\n                du/dt      = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2003_fixed_noisy_AMPA\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2003) with additional\n                conductance-based synapses for AMPA and GABA currents with noise in AMPA\n                conductance.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyAmpa","title":"<code>Izhikevich2003NoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents with noise in AMPA conductance.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>increase_noise</code> <code>float</code> <p>Increase of the Poisson distributed (equivalent to a Poisson distributed spike train as input) noise in the AMPA conductance.</p> <code>0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the AMPA conductance.</p> <code>0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents with noise in AMPA\n    conductance.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        increase_noise (float, optional):\n            Increase of the Poisson distributed (equivalent to a Poisson distributed\n            spike train as input) noise in the AMPA conductance.\n        rates_noise (float, optional):\n            Rate of the Poisson distributed noise in the AMPA conductance.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        increase_noise: float = 0,\n        rates_noise: float = 0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            n2             = {n2} : population\n            n1             = {n1} : population\n            n0             = {n0} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app}\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rates_noise, -g_ampa/tau_ampa, -g_ampa/tau_ampa + increase_noise/dt)\n                dg_gaba/dt = -g_gaba / tau_gaba\n                dv/dt      = n2 * v * v + n1 * v + n0 - u + I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba))\n                du/dt      = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2003_noisy_AMPA\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents with noise in AMPA conductance.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyAmpaNonlin","title":"<code>Izhikevich2003NoisyAmpaNonlin</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents with noise in AMPA conductance. With nonlinear function for external current.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>increase_noise</code> <code>float</code> <p>Increase of the Poisson distributed (equivalent to a Poisson distributed spike train as input) noise in the AMPA conductance.</p> <code>0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the AMPA conductance.</p> <code>0</code> <code>nonlin</code> <code>float</code> <p>Exponent of the nonlinear function for the external current.</p> <code>1</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyAmpaNonlin(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents with noise in AMPA\n    conductance. With nonlinear function for external current.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        increase_noise (float, optional):\n            Increase of the Poisson distributed (equivalent to a Poisson distributed\n            spike train as input) noise in the AMPA conductance.\n        rates_noise (float, optional):\n            Rate of the Poisson distributed noise in the AMPA conductance.\n        nonlin (float, optional):\n            Exponent of the nonlinear function for the external current.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        increase_noise: float = 0,\n        rates_noise: float = 0,\n        nonlin: float = 1,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            n2             = {n2} : population\n            n1             = {n1} : population\n            n0             = {n0} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app}\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n            nonlin         = {nonlin} : population\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rates_noise, -g_ampa/tau_ampa, -g_ampa/tau_ampa + increase_noise/dt)\n                dg_gaba/dt = -g_gaba / tau_gaba\n                I = I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba))\n                dv/dt      = n2 * v * v + n1 * v + n0 - u + f(I,nonlin)\n                du/dt      = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            functions=\"\"\"\n                f(x,y)=((abs(x))**(1/y))/((x+1e-20)/(abs(x)+ 1e-20))\n            \"\"\",\n            name=\"Izhikevich2003_noisy_AMPA_nonlin\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents with noise in AMPA conductance.\n                With nonlinear function for external current.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyAmpaOscillating","title":"<code>Izhikevich2003NoisyAmpaOscillating</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents with noise in AMPA conductance. With additional oscillation term.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>increase_noise</code> <code>float</code> <p>Increase of the Poisson distributed (equivalent to a Poisson distributed spike train as input) noise in the AMPA conductance.</p> <code>0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the AMPA conductance.</p> <code>0</code> <code>freq</code> <code>float</code> <p>Frequency of the oscillation term.</p> <code>0</code> <code>amp</code> <code>float</code> <p>Amplitude of the oscillation term.</p> <code>6</code> Variables to record <ul> <li>osc</li> <li>g_ampa</li> <li>g_gaba</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyAmpaOscillating(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents with noise in AMPA\n    conductance. With additional oscillation term.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        increase_noise (float, optional):\n            Increase of the Poisson distributed (equivalent to a Poisson distributed\n            spike train as input) noise in the AMPA conductance.\n        rates_noise (float, optional):\n            Rate of the Poisson distributed noise in the AMPA conductance.\n        freq (float, optional):\n            Frequency of the oscillation term.\n        amp (float, optional):\n            Amplitude of the oscillation term.\n\n    Variables to record:\n        - osc\n        - g_ampa\n        - g_gaba\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        increase_noise: float = 0,\n        rates_noise: float = 0,\n        freq: float = 0,\n        amp: float = 6,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            n2             = {n2} : population\n            n1             = {n1} : population\n            n0             = {n0} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app}\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n            freq           = {freq}\n            amp            = {amp}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                osc        = amp * sin(t * 2 * pi * (freq / 1000))\n                dg_ampa/dt = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rates_noise, -g_ampa/tau_ampa, -g_ampa/tau_ampa + increase_noise/dt)\n                dg_gaba/dt = -g_gaba / tau_gaba\n                dv/dt      = n2 * v * v + n1 * v + n0 - u + I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba)) + osc\n                du/dt      = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2003_noisy_AMPA_oscillating\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents with noise in AMPA conductance.\n                With additional oscillation term.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyBase","title":"<code>Izhikevich2003NoisyBase</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents and a noisy baseline current.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>base_mean</code> <code>float</code> <p>Mean of the baseline current.</p> <code>0</code> <code>base_noise</code> <code>float</code> <p>Standard deviation of the baseline current.</p> <code>0</code> <code>rate_base_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the baseline current, i.e. how often the baseline current is changed randomly.</p> <code>0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>offset_base</li> <li>I_base</li> <li>I</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyBase(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents and a noisy baseline\n    current.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        base_mean (float, optional):\n            Mean of the baseline current.\n        base_noise (float, optional):\n            Standard deviation of the baseline current.\n        rate_base_noise (float, optional):\n            Rate of the Poisson distributed noise in the baseline current, i.e. how\n            often the baseline current is changed randomly.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - offset_base\n        - I_base\n        - I\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        base_mean: float = 0,\n        base_noise: float = 0,\n        rate_base_noise: float = 0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a               = {a} : population\n            b               = {b} : population\n            c               = {c} : population\n            d               = {d} : population\n            n2              = {n2} : population\n            n1              = {n1} : population\n            n0              = {n0} : population\n            tau_ampa        = {tau_ampa} : population\n            tau_gaba        = {tau_gaba} : population\n            E_ampa          = {E_ampa} : population\n            E_gaba          = {E_gaba} : population\n            I_app           = {I_app}\n            base_mean       = {base_mean}\n            base_noise      = {base_noise}\n            rate_base_noise = {rate_base_noise}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt  = -g_ampa/tau_ampa\n                dg_gaba/dt  = -g_gaba / tau_gaba\n                offset_base = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rate_base_noise, offset_base, Normal(0, 1) * base_noise)\n                I_base      = base_mean + offset_base\n                I           = I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba)) + I_base\n                dv/dt       = n2 * v * v + n1 * v + n0 - u + I\n                du/dt       = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2003_noisy_I\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents and a noisy baseline current.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyBaseNonlin","title":"<code>Izhikevich2003NoisyBaseNonlin</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents and a noisy baseline current. With nonlinear function for external current.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>base_mean</code> <code>float</code> <p>Mean of the baseline current.</p> <code>0</code> <code>base_noise</code> <code>float</code> <p>Standard deviation of the baseline current.</p> <code>0</code> <code>rate_base_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the baseline current, i.e. how often the baseline current is changed randomly.</p> <code>0</code> <code>nonlin</code> <code>float</code> <p>Exponent of the nonlinear function for the external current.</p> <code>1</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>offset_base</li> <li>I_base</li> <li>I</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyBaseNonlin(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents and a noisy baseline\n    current. With nonlinear function for external current.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        base_mean (float, optional):\n            Mean of the baseline current.\n        base_noise (float, optional):\n            Standard deviation of the baseline current.\n        rate_base_noise (float, optional):\n            Rate of the Poisson distributed noise in the baseline current, i.e. how\n            often the baseline current is changed randomly.\n        nonlin (float, optional):\n            Exponent of the nonlinear function for the external current.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - offset_base\n        - I_base\n        - I\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        base_mean: float = 0,\n        base_noise: float = 0,\n        rate_base_noise: float = 0,\n        nonlin: float = 1,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a               = {a} : population\n            b               = {b} : population\n            c               = {c} : population\n            d               = {d} : population\n            n2              = {n2} : population\n            n1              = {n1} : population\n            n0              = {n0} : population\n            tau_ampa        = {tau_ampa} : population\n            tau_gaba        = {tau_gaba} : population\n            E_ampa          = {E_ampa} : population\n            E_gaba          = {E_gaba} : population\n            I_app           = {I_app}\n            base_mean       = {base_mean}\n            base_noise      = {base_noise}\n            rate_base_noise = {rate_base_noise}\n            nonlin          = {nonlin} : population\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt  = -g_ampa/tau_ampa\n                dg_gaba/dt  = -g_gaba / tau_gaba\n                offset_base = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rate_base_noise, offset_base, Normal(0, 1) * base_noise)\n                I_base      = base_mean + offset_base\n                I           = I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba))\n                dv/dt       = n2 * v * v + n1 * v + n0 - u + f(I,nonlin) + I_base\n                du/dt       = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            functions=\"\"\"\n                f(x,y)=((abs(x))**(1/y))/((x+1e-20)/(abs(x)+ 1e-20))\n            \"\"\",\n            name=\"Izhikevich2003_noisy_I_nonlin\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents and a noisy baseline current.\n                With nonlinear function for external current.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#izhikevich-2007-like-neurons","title":"Izhikevich (2007)-like Neurons","text":""},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007","title":"<code>Izhikevich2007</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C      = {C} {': population' if params_for_pop else ''} # pF\n            k      = {k} {': population' if params_for_pop else ''} # pS * mV**-1\n            v_r    = {v_r} {': population' if params_for_pop else ''} # mV\n            v_t    = {v_t} {': population' if params_for_pop else ''} # mV\n            a      = {a} {': population' if params_for_pop else ''} # ms**-1\n            b      = {b} {': population' if params_for_pop else ''} # nS\n            c      = {c} {': population' if params_for_pop else ''} # mV\n            d      = {d} {': population' if params_for_pop else ''} # pA\n            v_peak = {v_peak} {': population' if params_for_pop else ''} # mV\n            I_app  = {I_app} # pA\n        \"\"\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007()\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        # create the neuron\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007\",\n            description=\"Neuron model equations from Izhikevich (2007).\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007RecCur","title":"<code>Izhikevich2007RecCur</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with separate currents to record.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>I_v</li> <li>v</li> <li>u</li> <li>I_u</li> <li>I_k</li> <li>I_a</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007RecCur(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with separate currents to record.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - I_v\n        - v\n        - u\n        - I_u\n        - I_k\n        - I_a\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C      = {C} {': population' if params_for_pop else ''} # pF\n            k      = {k} {': population' if params_for_pop else ''} # pS * mV**-1\n            v_r    = {v_r} {': population' if params_for_pop else ''} # mV\n            v_t    = {v_t} {': population' if params_for_pop else ''} # mV\n            a      = {a} {': population' if params_for_pop else ''} # ms**-1\n            b      = {b} {': population' if params_for_pop else ''} # nS\n            c      = {c} {': population' if params_for_pop else ''} # mV\n            d      = {d} {': population' if params_for_pop else ''} # pA\n            v_peak = {v_peak} {': population' if params_for_pop else ''} # mV\n            I_app  = {I_app} # pA\n        \"\"\"\n\n        affix = \"\"\"\n            I_u = -u\n            I_k = k*(v - v_r)*(v - v_t)\n            I_a = I_app\n        \"\"\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(affix=affix)\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_record_currents\",\n            description=\"\"\"\n                Neuron model equations from Izhikevich (2007) with separate\n                currents to record.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007VoltageClamp","title":"<code>Izhikevich2007VoltageClamp</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with voltage clamp to record I_inf.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>I_v</li> <li>v</li> <li>u</li> <li>I_inf</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007VoltageClamp(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with voltage clamp to record I_inf.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - I_v\n        - v\n        - u\n        - I_inf\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C      = {C} {': population' if params_for_pop else ''} # pF\n            k      = {k} {': population' if params_for_pop else ''} # pS * mV**-1\n            v_r    = {v_r} {': population' if params_for_pop else ''} # mV\n            v_t    = {v_t} {': population' if params_for_pop else ''} # mV\n            a      = {a} {': population' if params_for_pop else ''} # ms**-1\n            b      = {b} {': population' if params_for_pop else ''} # nS\n            c      = {c} {': population' if params_for_pop else ''} # mV\n            d      = {d} {': population' if params_for_pop else ''} # pA\n            v_peak = {v_peak} {': population' if params_for_pop else ''} # mV\n            I_app  = {I_app} # pA\n        \"\"\"\n\n        dv = \"0\"\n        affix = f\"I_inf = {_dv_default}\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(dv=dv, affix=affix)\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_voltage_clamp\",\n            description=\"\"\"\n                Neuron model equations from Izhikevich (2007) with voltage clamp\n                to record I_inf.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007Syn","title":"<code>Izhikevich2007Syn</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based synapses.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>10.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>10.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-90.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007Syn(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based synapses.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 10.0,\n        tau_gaba: float = 10.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -90.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C      = {C} {': population' if params_for_pop else ''}\n            k      = {k} {': population' if params_for_pop else ''}\n            v_r    = {v_r} {': population' if params_for_pop else ''}\n            v_t    = {v_t} {': population' if params_for_pop else ''}\n            a      = {a} {': population' if params_for_pop else ''}\n            b      = {b} {': population' if params_for_pop else ''}\n            c      = {c} {': population' if params_for_pop else ''}\n            d      = {d} {': population' if params_for_pop else ''}\n            v_peak = {v_peak} {': population' if params_for_pop else ''}\n            I_app  = {I_app} # pA\n            tau_ampa = {tau_ampa} {': population' if params_for_pop else ''}\n            tau_gaba = {tau_gaba} {': population' if params_for_pop else ''}\n            E_ampa   = {E_ampa} {': population' if params_for_pop else ''}\n            E_gaba   = {E_gaba} {': population' if params_for_pop else ''}\n        \"\"\"\n\n        syn = _syn_default\n        i_v = f\"I_app {_I_syn}\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(syn=syn, i_v=i_v)\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_syn\",\n            description=\"\"\"\n                Neuron model equations from Izhikevich (2007) with conductance-based\n                AMPA and GABA synapses/currents.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007NoisyAmpa","title":"<code>Izhikevich2007NoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>10.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>10.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-90.0</code> <code>increase_noise</code> <code>float</code> <p>Increase of AMPA conductance due to noise (equal to a Poisson distributed spike train as input).</p> <code>0.0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the noise in the AMPA conductance.</p> <code>0.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007NoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        increase_noise (float, optional):\n            Increase of AMPA conductance due to noise (equal to a Poisson distributed\n            spike train as input).\n        rates_noise (float, optional):\n            Rate of the noise in the AMPA conductance.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 10.0,\n        tau_gaba: float = 10.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -90.0,\n        increase_noise: float = 0.0,\n        rates_noise: float = 0.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} {': population' if params_for_pop else ''}\n            k              = {k} {': population' if params_for_pop else ''}\n            v_r            = {v_r} {': population' if params_for_pop else ''}\n            v_t            = {v_t} {': population' if params_for_pop else ''}\n            a              = {a} {': population' if params_for_pop else ''}\n            b              = {b} {': population' if params_for_pop else ''}\n            c              = {c} {': population' if params_for_pop else ''}\n            d              = {d} {': population' if params_for_pop else ''}\n            v_peak         = {v_peak} {': population' if params_for_pop else ''}\n            tau_ampa       = {tau_ampa} {': population' if params_for_pop else ''}\n            tau_gaba       = {tau_gaba} {': population' if params_for_pop else ''}\n            E_ampa         = {E_ampa} {': population' if params_for_pop else ''}\n            E_gaba         = {E_gaba} {': population' if params_for_pop else ''}\n            I_app          = {I_app} # pA\n            increase_noise = {increase_noise} {': population' if params_for_pop else ''}\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        syn = _syn_noisy\n        i_v = f\"I_app {_I_syn}\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(syn=syn, i_v=i_v)\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_noisy_AMPA\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in AMPA conductance.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007NoisyBase","title":"<code>Izhikevich2007NoisyBase</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the baseline current.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>10.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>10.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-90.0</code> <code>base_mean</code> <code>float</code> <p>Mean of the baseline current.</p> <code>0.0</code> <code>base_noise</code> <code>float</code> <p>Standard deviation of the baseline current noise.</p> <code>0.0</code> <code>rate_base_noise</code> <code>float</code> <p>Rate of the noise update (Poisson distributed) in the baseline current.</p> <code>0.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>offset_base</li> <li>I_base</li> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007NoisyBase(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the baseline current.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        base_mean (float, optional):\n            Mean of the baseline current.\n        base_noise (float, optional):\n            Standard deviation of the baseline current noise.\n        rate_base_noise (float, optional):\n            Rate of the noise update (Poisson distributed) in the baseline current.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - offset_base\n        - I_base\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 10.0,\n        tau_gaba: float = 10.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -90.0,\n        base_mean: float = 0.0,\n        base_noise: float = 0.0,\n        rate_base_noise: float = 0.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} {': population' if params_for_pop else ''}\n            k              = {k} {': population' if params_for_pop else ''}\n            v_r            = {v_r} {': population' if params_for_pop else ''}\n            v_t            = {v_t} {': population' if params_for_pop else ''}\n            a              = {a} {': population' if params_for_pop else ''}\n            b              = {b} {': population' if params_for_pop else ''}\n            c              = {c} {': population' if params_for_pop else ''}\n            d              = {d} {': population' if params_for_pop else ''}\n            v_peak         = {v_peak} {': population' if params_for_pop else ''}\n            tau_ampa       = {tau_ampa} {': population' if params_for_pop else ''}\n            tau_gaba       = {tau_gaba} {': population' if params_for_pop else ''}\n            E_ampa         = {E_ampa} {': population' if params_for_pop else ''}\n            E_gaba         = {E_gaba} {': population' if params_for_pop else ''}\n            I_app          = {I_app} # pA\n            base_mean      = {base_mean}\n            base_noise     = {base_noise}\n            rate_base_noise = {rate_base_noise}\n        \"\"\"\n\n        syn = _syn_default\n        i_v = f\"I_app {_I_syn} + I_base\"\n        prefix = _I_base_noise\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(syn=syn, i_v=i_v, prefix=prefix)\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_noisy_base\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents and noisy\n                baseline current.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007FsiNoisyAmpa","title":"<code>Izhikevich2007FsiNoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model for fast-spiking neurons, with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>20.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>1.0</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-55.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>v_b</code> <code>float</code> <p>Instantaneous activation threshold potential for the recovery variable u.</p> <code>-55.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.1</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>2.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>25.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>2.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>5.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-80.0</code> <code>increase_noise</code> <code>float</code> <p>Increase of AMPA conductance due to noise (equal to a Poisson distributed spike train as input).</p> <code>0.0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the noise in the AMPA conductance.</p> <code>0.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007FsiNoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    for fast-spiking neurons, with conductance-based AMPA and GABA synapses with noise\n    in the AMPA conductance.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        v_b (float, optional):\n            Instantaneous activation threshold potential for the recovery variable u.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        increase_noise (float, optional):\n            Increase of AMPA conductance due to noise (equal to a Poisson distributed\n            spike train as input).\n        rates_noise (float, optional):\n            Rate of the noise in the AMPA conductance.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 20.0,\n        k: float = 1.0,\n        v_r: float = -55.0,\n        v_t: float = -40.0,\n        v_b: float = -55.0,\n        a: float = 0.1,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 2.0,\n        v_peak: float = 25.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 2.0,\n        tau_gaba: float = 5.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -80.0,\n        increase_noise: float = 0.0,\n        rates_noise: float = 0.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} {': population' if params_for_pop else ''}\n            k              = {k} {': population' if params_for_pop else ''}\n            v_r            = {v_r} {': population' if params_for_pop else ''}\n            v_t            = {v_t} {': population' if params_for_pop else ''}\n            v_b            = {v_b} {': population' if params_for_pop else ''}\n            a              = {a} {': population' if params_for_pop else ''}\n            b              = {b} {': population' if params_for_pop else ''}\n            c              = {c} {': population' if params_for_pop else ''}\n            d              = {d} {': population' if params_for_pop else ''}\n            v_peak         = {v_peak} {': population' if params_for_pop else ''}\n            tau_ampa       = {tau_ampa} {': population' if params_for_pop else ''}\n            tau_gaba       = {tau_gaba} {': population' if params_for_pop else ''}\n            E_ampa         = {E_ampa} {': population' if params_for_pop else ''}\n            E_gaba         = {E_gaba} {': population' if params_for_pop else ''}\n            I_app          = {I_app} # pA\n            increase_noise = {increase_noise} {': population' if params_for_pop else ''}\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        syn = _syn_noisy\n        i_v = f\"I_app {_I_syn}\"\n        du = \"if v&lt;v_b: -a * u else: a * (b * (v - v_b)**3 - u)\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(syn=syn, i_v=i_v, du=du)\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_FSI_noisy_AMPA\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in AMPA conductance.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007CorbitFsiNoisyAmpa","title":"<code>Izhikevich2007CorbitFsiNoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the AMPA conductance. Additional slow currents were added to fit the striatal FSI neuron model from Corbit et al. (2016). The additional currents should allow the neuron to produce late spiking.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>20.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>1.0</code> <code>b_n</code> <code>float</code> <p>Sensitivity of the slow current n to the difference between the slow current s and the recovery variable u.</p> <code>0.1</code> <code>a_s</code> <code>float</code> <p>Time scale of the slow current s.</p> <code>0.1</code> <code>a_n</code> <code>float</code> <p>Time scale of the slow current n.</p> <code>0.1</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-55.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.1</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>2.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>25.0</code> <code>nonlin</code> <code>float</code> <p>Nonlinearity of the input current. (1.0 = linear, 2.0 = square, etc.)</p> <code>0.1</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>2.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>5.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-80.0</code> <code>increase_noise</code> <code>float</code> <p>Increase of AMPA conductance due to noise (equal to a Poisson distributed spike train as input).</p> <code>0.0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the noise in the AMPA conductance.</p> <code>0.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>s</li> <li>n</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007CorbitFsiNoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.\n    Additional slow currents were added to fit the striatal FSI neuron model from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016). The\n    additional currents should allow the neuron to produce late spiking.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        b_n (float, optional):\n            Sensitivity of the slow current n to the difference between the slow current\n            s and the recovery variable u.\n        a_s (float, optional):\n            Time scale of the slow current s.\n        a_n (float, optional):\n            Time scale of the slow current n.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        nonlin (float, optional):\n            Nonlinearity of the input current. (1.0 = linear, 2.0 = square, etc.)\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        increase_noise (float, optional):\n            Increase of AMPA conductance due to noise (equal to a Poisson distributed\n            spike train as input).\n        rates_noise (float, optional):\n            Rate of the noise in the AMPA conductance.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - s\n        - n\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 20.0,\n        k: float = 1.0,\n        b_n: float = 0.1,\n        a_s: float = 0.1,\n        a_n: float = 0.1,\n        v_r: float = -55.0,\n        v_t: float = -40.0,\n        a: float = 0.1,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 2.0,\n        v_peak: float = 25.0,\n        nonlin: float = 0.1,\n        I_app: float = 0.0,\n        tau_ampa: float = 2.0,\n        tau_gaba: float = 5.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -80.0,\n        increase_noise: float = 0.0,\n        rates_noise: float = 0.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} {': population' if params_for_pop else ''}\n            k              = {k} {': population' if params_for_pop else ''}\n            b_n            = {b_n} {': population' if params_for_pop else ''}\n            a_s            = {a_s} {': population' if params_for_pop else ''}\n            a_n            = {a_n} {': population' if params_for_pop else ''}\n            v_r            = {v_r} {': population' if params_for_pop else ''}\n            v_t            = {v_t} {': population' if params_for_pop else ''}\n            a              = {a} {': population' if params_for_pop else ''}\n            b              = {b} {': population' if params_for_pop else ''}\n            c              = {c} {': population' if params_for_pop else ''}\n            d              = {d} {': population' if params_for_pop else ''}\n            v_peak         = {v_peak} {': population' if params_for_pop else ''}\n            nonlin         = {nonlin} {': population' if params_for_pop else ''}\n            tau_ampa       = {tau_ampa} {': population' if params_for_pop else ''}\n            tau_gaba       = {tau_gaba} {': population' if params_for_pop else ''}\n            E_ampa         = {E_ampa} {': population' if params_for_pop else ''}\n            E_gaba         = {E_gaba} {': population' if params_for_pop else ''}\n            I_app          = {I_app} # pA\n            increase_noise = {increase_noise} {': population' if params_for_pop else ''}\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        syn = _syn_noisy\n        i_v = f\"root_func(I_app {_I_syn}, nonlin) - n\"\n        affix = \"\"\"\n            ds/dt     = a_s*(pos(u)**0.1 - s)\n            dn/dt     = a_n*(b_n*(pos(u)**0.1-s) - n)\n        \"\"\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(syn=syn, i_v=i_v, affix=affix)\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            functions=\"\"\"\n                root_func(x,y)=((abs(x))**(1/y))/((x+1e-20)/(abs(x)+ 1e-20))\n            \"\"\",\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_Corbit_FSI_noisy_AMPA\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in AMPA conductance. Additional slow currents were added to fit\n                the striatal FSI neuron model from Corbit et al. (2016).\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007CorbitFsiNoisyBase","title":"<code>Izhikevich2007CorbitFsiNoisyBase</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the baseline current. Additional slow currents were added to fit the striatal FSI neuron model from Corbit et al. (2016). The additional currents should allow the neuron to produce late spiking.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>20.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>1.0</code> <code>b_n</code> <code>float</code> <p>Sensitivity of the slow current n to the difference between the slow current s and the recovery variable u.</p> <code>0.1</code> <code>a_s</code> <code>float</code> <p>Time scale of the slow current s.</p> <code>0.1</code> <code>a_n</code> <code>float</code> <p>Time scale of the slow current n.</p> <code>0.1</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-55.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.1</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>2.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>25.0</code> <code>nonlin</code> <code>float</code> <p>Nonlinearity of the input current. (1.0 = linear, 2.0 = square, etc.)</p> <code>0.1</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>2.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>5.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-80.0</code> <code>base_mean</code> <code>float</code> <p>Mean of the baseline current.</p> <code>0.0</code> <code>base_noise</code> <code>float</code> <p>Standard deviation of the baseline current noise.</p> <code>0.0</code> <code>rate_base_noise</code> <code>float</code> <p>Rate of the noise update (Poisson distributed) in the baseline current.</p> <code>0.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>offset_base</li> <li>I_base</li> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>s</li> <li>n</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007CorbitFsiNoisyBase(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the baseline current.\n    Additional slow currents were added to fit the striatal FSI neuron model from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016). The\n    additional currents should allow the neuron to produce late spiking.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        b_n (float, optional):\n            Sensitivity of the slow current n to the difference between the slow current\n            s and the recovery variable u.\n        a_s (float, optional):\n            Time scale of the slow current s.\n        a_n (float, optional):\n            Time scale of the slow current n.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        nonlin (float, optional):\n            Nonlinearity of the input current. (1.0 = linear, 2.0 = square, etc.)\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        base_mean (float, optional):\n            Mean of the baseline current.\n        base_noise (float, optional):\n            Standard deviation of the baseline current noise.\n        rate_base_noise (float, optional):\n            Rate of the noise update (Poisson distributed) in the baseline current.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - offset_base\n        - I_base\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - s\n        - n\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 20.0,\n        k: float = 1.0,\n        b_n: float = 0.1,\n        a_s: float = 0.1,\n        a_n: float = 0.1,\n        v_r: float = -55.0,\n        v_t: float = -40.0,\n        a: float = 0.1,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 2.0,\n        v_peak: float = 25.0,\n        nonlin: float = 0.1,\n        I_app: float = 0.0,\n        tau_ampa: float = 2.0,\n        tau_gaba: float = 5.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -80.0,\n        base_mean: float = 0.0,\n        base_noise: float = 0.0,\n        rate_base_noise: float = 0.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} {': population' if params_for_pop else ''}\n            k              = {k} {': population' if params_for_pop else ''}\n            b_n            = {b_n} {': population' if params_for_pop else ''}\n            a_s            = {a_s} {': population' if params_for_pop else ''}\n            a_n            = {a_n} {': population' if params_for_pop else ''}\n            v_r            = {v_r} {': population' if params_for_pop else ''}\n            v_t            = {v_t} {': population' if params_for_pop else ''}\n            a              = {a} {': population' if params_for_pop else ''}\n            b              = {b} {': population' if params_for_pop else ''}\n            c              = {c} {': population' if params_for_pop else ''}\n            d              = {d} {': population' if params_for_pop else ''}\n            v_peak         = {v_peak} {': population' if params_for_pop else ''}\n            nonlin         = {nonlin} {': population' if params_for_pop else ''}\n            tau_ampa       = {tau_ampa} {': population' if params_for_pop else ''}\n            tau_gaba       = {tau_gaba} {': population' if params_for_pop else ''}\n            E_ampa         = {E_ampa} {': population' if params_for_pop else ''}\n            E_gaba         = {E_gaba} {': population' if params_for_pop else ''}\n            I_app          = {I_app} # pA\n            base_mean      = {base_mean}\n            base_noise     = {base_noise}\n            rate_base_noise = {rate_base_noise}\n        \"\"\"\n\n        syn = _syn_default\n        i_v = f\"root_func(I_app {_I_syn}, nonlin) - n + I_base\"\n        prefix = _I_base_noise\n        affix = \"\"\"\n            ds/dt     = a_s*(pos(u)**0.1 - s)\n            dn/dt     = a_n*(b_n*(pos(u)**0.1-s) - n)\n        \"\"\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(\n            syn=syn, i_v=i_v, prefix=prefix, affix=affix\n        )\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            functions=\"\"\"\n                root_func(x,y)=((abs(x))**(1/y))/((x+1e-20)/(abs(x)+ 1e-20))\n            \"\"\",\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_Corbit_FSI_noisy_base\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in the baseline current. Additional slow currents were added to fit\n                the striatal FSI neuron model from Corbit et al. (2016).\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007NoisyAmpaOscillating","title":"<code>Izhikevich2007NoisyAmpaOscillating</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the AMPA conductance. An additional oscillating current was added to the model.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>20.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>1.0</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-55.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.1</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>2.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>25.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>2.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>5.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-80.0</code> <code>increase_noise</code> <code>float</code> <p>Increase of AMPA conductance due to noise (equal to a Poisson distributed spike train as input).</p> <code>0.0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the noise in the AMPA conductance.</p> <code>0.0</code> <code>freq</code> <code>float</code> <p>Frequency of the oscillating current.</p> <code>0.0</code> <code>amp</code> <code>float</code> <p>Amplitude of the oscillating current.</p> <code>300.0</code> <code>params_for_pop</code> <code>bool</code> <p>If True, the parameters are population-wide and not neuron-specific.</p> <code>False</code> <code>init</code> <code>dict</code> <p>Initial values for the variables.</p> <code>{}</code> Variables to record <ul> <li>osc</li> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007NoisyAmpaOscillating(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.\n    An additional oscillating current was added to the model.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        increase_noise (float, optional):\n            Increase of AMPA conductance due to noise (equal to a Poisson distributed\n            spike train as input).\n        rates_noise (float, optional):\n            Rate of the noise in the AMPA conductance.\n        freq (float, optional):\n            Frequency of the oscillating current.\n        amp (float, optional):\n            Amplitude of the oscillating current.\n        params_for_pop (bool, optional):\n            If True, the parameters are population-wide and not neuron-specific.\n        init (dict, optional):\n            Initial values for the variables.\n\n    Variables to record:\n        - osc\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 20.0,\n        k: float = 1.0,\n        v_r: float = -55.0,\n        v_t: float = -40.0,\n        a: float = 0.1,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 2.0,\n        v_peak: float = 25.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 2.0,\n        tau_gaba: float = 5.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -80.0,\n        increase_noise: float = 0.0,\n        rates_noise: float = 0.0,\n        freq: float = 0.0,\n        amp: float = 300.0,\n        params_for_pop: bool = False,\n        init: dict = {},\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} {': population' if params_for_pop else ''}\n            k              = {k} {': population' if params_for_pop else ''}\n            v_r            = {v_r} {': population' if params_for_pop else ''}\n            v_t            = {v_t} {': population' if params_for_pop else ''}\n            a              = {a} {': population' if params_for_pop else ''}\n            b              = {b} {': population' if params_for_pop else ''}\n            c              = {c} {': population' if params_for_pop else ''}\n            d              = {d} {': population' if params_for_pop else ''}\n            v_peak         = {v_peak} {': population' if params_for_pop else ''}\n            tau_ampa       = {tau_ampa} {': population' if params_for_pop else ''}\n            tau_gaba       = {tau_gaba} {': population' if params_for_pop else ''}\n            E_ampa         = {E_ampa} {': population' if params_for_pop else ''}\n            E_gaba         = {E_gaba} {': population' if params_for_pop else ''}\n            I_app          = {I_app} # pA\n            increase_noise = {increase_noise} {': population' if params_for_pop else ''}\n            rates_noise    = {rates_noise}\n            freq           = {freq}\n            amp            = {amp}\n        \"\"\"\n\n        syn = _syn_noisy\n        i_v = f\"I_app {_I_syn} + osc\"\n        prefix = \"osc = amp * sin(t * 2 * pi * (freq  /1000))\"\n\n        # get equations\n        equations = _get_equation_izhikevich_2007(syn=syn, i_v=i_v, prefix=prefix)\n\n        # set initial values\n        equations = _set_init(equations, init)\n\n        super().__init__(\n            parameters=parameters,\n            equations=equations,\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_noisy_AMPA_oscillating\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in AMPA conductance. An additional oscillating current was added\n                to the model.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/synapse_models/","title":"Synapse Models","text":""},{"location":"built_in/synapse_models/#CompNeuroPy.synapse_models.synapse_models.FactorSynapse","title":"<code>FactorSynapse</code>","text":"<p>             Bases: <code>Synapse</code></p> <p>Synapse which scales the transmitted value by a specified factor. Factor is equivalent to the connection weight if weight==1.</p> <p>Parameters:</p> Name Type Description Default <code>max_trans</code> <code>float</code> <p>Maximum value that can be transmitted. Default: None.</p> <code>None</code> <code>mod_factor</code> <code>float</code> <p>Factor by which the weight value is multiplied. Default: 0.</p> <code>0</code> Source code in <code>src/CompNeuroPy/synapse_models/synapse_models.py</code> <pre><code>class FactorSynapse(Synapse):\n    \"\"\"\n    Synapse which scales the transmitted value by a specified factor. Factor is\n    equivalent to the connection weight if weight==1.\n\n    Parameters:\n        max_trans (float, optional):\n            Maximum value that can be transmitted. Default: None.\n        mod_factor (float, optional):\n            Factor by which the weight value is multiplied. Default: 0.\n    \"\"\"\n\n    def __init__(self, max_trans: None | float = None, mod_factor: float = 0):\n        super().__init__(\n            parameters=f\"\"\"\n            {f\"max_trans  = {max_trans}\" if max_trans is not None else \"\"}\n            mod_factor = {mod_factor}\n        \"\"\",\n            equations=\"\",\n            pre_spike=f\"\"\"\n            g_target += w * mod_factor {\": max = max_trans\" if max_trans is not None else \"\"}\n        \"\"\",\n            name=\"factor_synapse\",\n            description=\"\"\"\n            Synapse which scales the transmitted value by a specified factor. Factor is\n            equivalent to the connection weight if weight==1.\n        \"\"\",\n        )\n</code></pre>"},{"location":"examples/dbs/","title":"DBS Simulator","text":""},{"location":"examples/dbs/#simple-example","title":"Simple example","text":""},{"location":"examples/dbs/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the DBSstimulator class to implement DBS in a network. It is shown how to create a DBSstimulator, how to use it and how to update pointers. In this simple example only the depolarization of the stimulated population is demostrated. All other possible DBS mechanisms are demonstrated in the other example dbs_stimulator.py.</p>"},{"location":"examples/dbs/#code","title":"Code","text":"<pre><code>from ANNarchy import Population, Izhikevich, compile, simulate\nfrom CompNeuroPy import DBSstimulator\n\nfrom ANNarchy import setup\nfrom CompNeuroPy import CompNeuroMonitors, PlotRecordings\n\nsetup(dt=0.1)\n\n# create populations\npopulation1 = Population(10, neuron=Izhikevich, name=\"my_pop1\")\npopulation2 = Population(10, neuron=Izhikevich, name=\"my_pop2\")\n\n# create DBS stimulator\ndbs = DBSstimulator(\n    stimulated_population=population1,\n    population_proportion=0.5,\n    dbs_depolarization=30,\n    auto_implement=True,\n)\n\n# if you work with names of populations/projections everything will work, but if you\n# want to work with pointers you have to update them after calling the DBSstimulator\npopulation1, population2 = dbs.update_pointers(pointer_list=[population1, population2])\n\n# compile network\ncompile()\n\n# create monitors\nmonitors = CompNeuroMonitors({\"my_pop1\": \"v\", \"my_pop2\": \"v\"})\nmonitors.start()\n\n# run simulation\n# 1000 ms without dbs\nsimulate(1000)\n# 1000 ms with dbs\ndbs.on()\nsimulate(1000)\n# 1000 ms without dbs\ndbs.off()\nsimulate(1000)\n\n# plot recordings\nPlotRecordings(\n    figname=\"dbs_stimulator_simple.png\",\n    recordings=monitors.get_recordings(),\n    recording_times=monitors.get_recording_times(),\n    chunk=0,\n    shape=(2, 1),\n    plan={\n        \"position\": [1, 2],\n        \"compartment\": [\"my_pop1\", \"my_pop2\"],\n        \"variable\": [\"v\", \"v\"],\n        \"format\": [\"matrix\", \"matrix\"],\n    },\n)\n</code></pre>"},{"location":"examples/dbs/#console-output","title":"Console Output","text":"<pre><code>$ python dbs_stimulator_simple.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nCompiling ...  OK \nGenerate fig dbs_stimulator_simple.png... Done\n</code></pre>"},{"location":"examples/dbs/#complex-example","title":"Complex Example","text":""},{"location":"examples/dbs/#introduction_1","title":"Introduction","text":"<p>In this example, the DBS stimulator is tested with a simple spiking and rate-coded model. The spiking model is based on the Izhikevich model with conductance-based synapses. The rate-coded model is based on neurons including membrane potential and a resulting firing rate. The DBS stimulator is tested with different stimulation parameters. The resulting activity of the populations is compared to the expected activity (not part of example, included for testing purposes only). The resulting activity of the populations is plotted. The figures are saved in the DBS_spiking_figure and DBS_rate_figure folders. The different DBS conditions are:     - no stimulation     - orthodromic stimulation of efferents     - orthodromic stimulation of afferents     - orthodromic stimulation of efferents and afferents     - orthodromic stimulation of passing fibres     - depolarization of the stimulated population     - antidromic stimulation of efferents     - antidromic stimulation of afferents     - antidromic stimulation of efferents and afferents     - antidromic stimulation of passing fibres     - antidromic stimulation of passing fibres with lower strength     - full dbs stimulation     - full dbs stimulation without axon spikes (only effective for spiking model)     - full dbs stimulation without axon_rate_amp (only effective for rate-coded model)</p> <p>Warning</p> <p>For rate-coded models, antidromic stimulation of projections is not available.</p>"},{"location":"examples/dbs/#code_1","title":"Code","text":"<pre><code>from ANNarchy import (\n    Neuron,\n    Population,\n    setup,\n    simulate,\n    Projection,\n    get_population,\n    get_projection,\n    DefaultRateCodedSynapse,\n    DefaultSpikingSynapse,\n    dt,\n    Constant,\n)\nfrom CompNeuroPy import (\n    CompNeuroMonitors,\n    PlotRecordings,\n    CompNeuroModel,\n    cnp_clear,\n    DBSstimulator,\n)\nfrom CompNeuroPy.monitors import RecordingTimes\nimport numpy as np\n\n### setup ANNarchy\nsetup(dt=0.1, seed=12345)\n\n\n### create dbs test model\nclass dbs_test_model_class:\n    \"\"\"\n    Class to create dbs test model.\n\n    The used neuron models have the following constraints:\n        The neuron model has to contain the following parameters:\n        - base_mean: mean of the base current\n        - base_noise: standard deviation of the base current noise\n        Spiking neuron models have to contain conductance based synapses using the\n        following conductance variables:\n        - g_ampa: excitatory synapse\n        - g_gaba: inhibitory synapse\n        Rate neuron models have to contain the following input variables:\n        - sum(ampa): excitatory input\n        - sum(gaba): inhibitory input\n        For DBS rate-coded models have to contain a membrane potential variable mp\n        and spiking models have to be Izhihkevich models.\n\n    Model structure:\n    -------------------------\n            POP1       POP2\n            |          |\n            o          v\n    DBS---&gt;POP3------oPOP4\n                .----.\n                |    |\n            POP5   '--&gt;POP6\n\n    -o = inhibitory synapse\n    -&gt; = excitatory synapse\n    .-&gt; = passing fibre excitatory synapse\n\n    Attributes:\n        model (CompNeuroModel):\n            dbs test model\n    \"\"\"\n\n    def __init__(self, mode) -&gt; None:\n        \"\"\"\n        Initialize dbs test model\n\n        Args:\n            mode (str):\n                Mode of the dbs test model, either \"spiking\" or \"rate-coded\"\n        \"\"\"\n        ### constants should still be available after DBSstimulator recreates the model\n        ### test this by creating this constant\n        Constant(\"my_important_const\", 0.0)\n\n        ### check if model to create is spiking or rate-coded\n        if mode == \"spiking\":\n            self.model = CompNeuroModel(\n                model_creation_function=self.create_model,\n                model_kwargs={\n                    \"neuron_model\": self.get_neuron_model_spiking(),\n                    \"base_current_list\": [40, 100, 200, 50, 40, 40],\n                    \"base_current_noise\": 40,\n                },\n                name=\"dbs_test_spiking\",\n                description=\"Simple spiking model to test dbs\",\n                do_compile=False,\n            )\n        elif mode == \"rate-coded\":\n            self.model = CompNeuroModel(\n                model_creation_function=self.create_model,\n                model_kwargs={\n                    \"neuron_model\": self.get_neuron_model_rate_coded(),\n                    \"base_current_list\": [0.35, 0.7, 1.1, 0.85, 0.35, 0.35],\n                    \"base_current_noise\": 0.01,\n                    \"weight_list\": [0.3, 0.4, 0.3, 0.1],\n                    \"prob_list\": [0.5, 0.7, 0.7, 0.5],\n                },\n                name=\"dbs_test_rate-coded\",\n                description=\"Simple rate-coded model to test dbs\",\n                do_compile=False,\n            )\n        else:\n            raise ValueError(\"Neuron model not recognized\")\n\n    def create_model(\n        self,\n        neuron_model: Neuron,\n        pop_size: int = 10,\n        base_current_list: list = [0, 0, 0, 0, 0, 0],\n        base_current_noise: float = 0.0,\n        prob_list: list = [0.5, 0.5, 0.5, 0.5],\n        weight_list: list = [1.0, 1.0, 1.0, 1.0],\n    ):\n        \"\"\"\n        Create dbs test model\n\n        Args:\n            neuron_model (Neuron):\n                Neuron model to use for the dbs test model\n            pop_size (int, optional):\n                Number of neurons in each population. Default: 10\n            base_current_list (list, optional):\n                List of base currents for the four populations.\n                Default: [0, 0, 0, 0, 0, 0]\n            base_current_noise (float, optional):\n                Standard deviation of the base current noise. Default: 0\n            prob_list (list, optional):\n                List of connection probabilities for the inhibitory and excitatory path.\n                Default: [0.5, 0.5, 0.5, 0.5]\n            weight_list (list, optional):\n                List of connection weights for the inhibitory and excitatory path.\n                Default: [0.1, 0.1, 0.1, 0.1]\n        \"\"\"\n        ### create populations\n        pop1 = Population(pop_size, neuron_model, name=f\"pop1_{neuron_model.name}\")\n        pop2 = Population(pop_size, neuron_model, name=f\"pop2_{neuron_model.name}\")\n        pop3 = Population(pop_size, neuron_model, name=f\"pop3_{neuron_model.name}\")\n        pop4 = Population(pop_size, neuron_model, name=f\"pop4_{neuron_model.name}\")\n        pop5 = Population(pop_size, neuron_model, name=f\"pop5_{neuron_model.name}\")\n        pop6 = Population(pop_size, neuron_model, name=f\"pop6_{neuron_model.name}\")\n\n        ### create projections of inhhibitory path\n        proj_1_3 = Projection(\n            pre=pop1,\n            post=pop3,\n            target=\"gaba\",\n            name=f\"proj_1_3_{neuron_model.name}\",\n            synapse=self.get_synapse(neuron_model.name),\n        )\n        proj_1_3.connect_fixed_probability(\n            probability=prob_list[0],\n            weights=weight_list[0],\n        )\n        proj_3_4 = Projection(\n            pre=pop3,\n            post=pop4,\n            target=\"gaba\",\n            name=f\"proj_3_4_{neuron_model.name}\",\n            synapse=self.get_synapse(neuron_model.name),\n        )\n        proj_3_4.connect_fixed_probability(\n            probability=prob_list[1],\n            weights=weight_list[1],\n        )\n        ### create projections of excitatory path\n        proj_2_4 = Projection(\n            pre=pop2,\n            post=pop4,\n            target=\"ampa\",\n            name=f\"proj_2_4_{neuron_model.name}\",\n            synapse=self.get_synapse(neuron_model.name),\n        )\n        proj_2_4.connect_fixed_probability(\n            probability=prob_list[2],\n            weights=weight_list[2],\n        )\n        ### create projection of passing fibres\n        proj_5_6 = Projection(\n            pre=pop5,\n            post=pop6,\n            target=\"ampa\",\n            name=f\"proj_5_6_{neuron_model.name}\",\n            synapse=self.get_synapse(neuron_model.name),\n        )\n        proj_5_6.connect_fixed_probability(\n            probability=prob_list[3],\n            weights=weight_list[3],\n        )\n\n        ### set baseline activity parameters\n        pop1.base_mean = base_current_list[0]\n        pop2.base_mean = base_current_list[1]\n        pop3.base_mean = base_current_list[2]\n        pop4.base_mean = base_current_list[3]\n        pop5.base_mean = base_current_list[4]\n        pop6.base_mean = base_current_list[5]\n        pop1.base_noise = base_current_noise\n        pop2.base_noise = base_current_noise\n        pop3.base_noise = base_current_noise\n        pop4.base_noise = base_current_noise\n        pop5.base_noise = base_current_noise\n        pop6.base_noise = base_current_noise\n\n    def get_neuron_model_spiking(self):\n        \"\"\"\n        Get neuron model with spiking dynamics\n\n        Returns\n            neuron_model (Neuron):\n                Neuron model with spiking dynamics\n        \"\"\"\n        neuron_model = Neuron(\n            parameters=\"\"\"\n                C      = 100     : population # pF\n                k      = 0.7     : population # pS * mV**-1\n                v_r    = -60     : population # mV\n                v_t    = -40     : population # mV\n                a      = 0.03     : population # ms**-1\n                b      = -2     : population # nS\n                c      = -50     : population # mV\n                d      = 100     : population # pA\n                v_peak = 35     : population # mV\n                I_app  = 0     # pA\n                tau_ampa = 10  : population # ms\n                tau_gaba = 10  : population # ms\n                E_ampa   = 0   : population # mV\n                E_gaba   = -90 : population # mV\n                base_mean       = 0 # pA\n                base_noise      = 0 # pA\n                rate_base_noise = 100 # Hz\n            \"\"\",\n            equations=\"\"\"\n                ### noisy base input\n                offset_base = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rate_base_noise, offset_base, Normal(0., 1.) * base_noise)\n                I_base      = base_mean + offset_base + my_important_const\n                ### input conductances\n                dg_ampa/dt = -g_ampa/tau_ampa\n                dg_gaba/dt = -g_gaba/tau_gaba\n                ### input currents\n                I = I_app - g_ampa*neg(v - E_ampa) - g_gaba*pos(v - E_gaba) + I_base\n                ### membrane potential and recovery variable\n                C * dv/dt  = k*(v - v_r)*(v - v_t) - u + I\n                du/dt      = a*(b*(v - v_r) - u)\n            \"\"\",\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"spiking\",\n            description=\"\"\"\n                Simple neuron model equations from Izhikevich (2007) using regular-spiking parameters\n                with conductance-based AMPA and GABA synapses/currents.\n            \"\"\",\n        )\n        return neuron_model\n\n    def get_neuron_model_rate_coded(self):\n        \"\"\"\n        Get neuron model with rate-coded dynamics\n\n        Returns:\n            neuron_model (Neuron):\n                Neuron model with rate-coded dynamics\n        \"\"\"\n        neuron_model = Neuron(\n            parameters=\"\"\"\n                tau = 10.0 : population\n                sigma = 0.6 : population\n                I_0 = 0.2 : population\n                I_app = 0.\n                base_mean       = 0\n                base_noise      = 0\n                rate_base_noise = 100 # Hz\n                # = (sigma*I_0 + I_0)/(sigma - sigma*I_0) : population\n                c = (0.6*0.2 + 0.2)/(0.6 - 0.6*0.2) : population\n            \"\"\",\n            equations=\"\"\"\n                ### noisy base input\n                offset_base = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rate_base_noise, offset_base, Normal(0., 1.) * base_noise)\n                I_base      = base_mean + offset_base + my_important_const\n                ### input currents\n                I = sum(ampa) - sum(gaba) + I_base + I_app\n                ### membrane potential\n                tau * dmp/dt = -mp + I\n                mp_r = mp: min=-0.99*sigma\n                ### activation function\n                r = activation(mp_r,sigma,c) : max=1., min=0.\n            \"\"\",\n            name=\"rate-coded\",\n            functions=\"\"\"\n                activation(x,sigma,c) = ((sigma*x + x)/(sigma + x)) * (1 + c) - c\n            \"\"\",\n            description=\"Rate-coded neuron with excitatory (ampa) and inhibitory (gaba) inputs plus baseline and noise.\",\n        )\n        return neuron_model\n\n    def get_synapse(self, mode):\n        \"\"\"\n        Create a synapse.\n\n        Args:\n            mode (str):\n                Mode of the dbs test model, either \"spiking\" or \"rate-coded\"\n\n        Returns:\n            synapse (DefaultRateCodedSynapse or DefaultSpikingSynapse):\n                Synapse object\n        \"\"\"\n        if mode == \"rate-coded\":\n            return DefaultRateCodedSynapse()\n        elif mode == \"spiking\":\n            return DefaultSpikingSynapse()\n        else:\n            raise ValueError(\"Neuron model not recognized\")\n\n\ndef do_simulation(\n    mon: CompNeuroMonitors,\n    dbs: DBSstimulator,\n    dbs_val_list: list[list],\n    dbs_key_list: list[str],\n):\n    \"\"\"\n    Do the simulation\n\n    Args:\n        mon (CompNeuroMonitors):\n            CompNeuroMonitors object\n        dbs (DBSstimulator):\n            DBS stimulator object\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        dbs_key_list (list[str]):\n            List of DBS stimulation keys used by the dbs.on() function\n\n    Returns:\n        recordings (list):\n            List of recordings from the monitors\n        recording_times (RecordingTimes):\n            Recording times object\n    \"\"\"\n    ### run initial ramp up simulation\n    simulate(2000.0)\n\n    ### start monitors\n    mon.start()\n\n    ### loop over trials\n    for trial in range(len(dbs_val_list)):\n        ### 1000 ms with DBS off\n        simulate(1000.0)\n        ### 500 ms with DBS on\n        dbs.on(\n            **{\n                dbs_key_list[i]: dbs_val_list[trial][i]\n                for i in range(len(dbs_key_list))\n            }\n        )\n        simulate(500.0)\n        ### 1000 ms with DBS off\n        dbs.off()\n        simulate(1000.0)\n        mon.reset(model=False)\n\n    ### get data from monitors\n    recordings = mon.get_recordings()\n    recording_times = mon.get_recording_times()\n\n    return recordings, recording_times\n\n\ndef check_dbs_effects_spiking(\n    dbs_val_list: list[list],\n    recordings: list,\n    model: CompNeuroModel,\n    recording_times: RecordingTimes,\n):\n    \"\"\"\n    Check if the dbs effects are as expecteds.\n\n    Args:\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        recordings (list):\n            List of recordings from the monitors\n        model (CompNeuroModel):\n            Model used for the simulation\n        recording_times (RecordingTimes):\n            Recording times object\n    \"\"\"\n    ### effects_on_activity_list contains the expected effects of dbs on the activity of the populations for each trial\n    ### 0 means no effect, 1 means increase, -1 means decrease\n    effects_on_activity = [\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, -1, 0, 0],\n        [0, 0, -1, 1, 0, 0],\n        [0, 0, -1, -1, 0, 0],\n        [0, 0, 0, 0, 0, 1],\n        [0, 0, -1, 1, 0, 0],\n        [0, 0, -1, 1, 0, 0],\n        [-1, 0, 0, 0, 0, 0],\n        [-1, 0, -1, 1, 0, 0],\n        [0, 0, 0, 0, -1, 0],\n        [0, 0, 0, 0, 0, 0],\n        [-1, 0, -1, -1, -1, 1],\n        [0, 0, -1, 1, 0, 0],\n        [-1, 0, -1, -1, -1, 1],\n    ]\n    ### check if the expected effects are present in the data\n    effect_list = []\n    high_effect_list = []\n    low_effect_list = []\n    for trial_idx, trial in enumerate(range(len(dbs_val_list))):\n        effect_list.append([])\n        for pop_name_idx, pop_name in enumerate(model.populations):\n            v_arr = recordings[trial][f\"{pop_name};v\"]\n            ### mean over neurons\n            v_arr = np.mean(v_arr, axis=1)\n            ### mean of first period\n            v_mean_1 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt()))\n                ]\n            )\n            v_std_1 = np.std(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt()))\n                ]\n            )\n            ### mean of second period\n            v_mean_2 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt()))\n                ]\n            )\n            ### mean of third period\n            v_mean_3 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(2000 / dt()))\n                ]\n            )\n            v_std_3 = np.std(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(2000 / dt()))\n                ]\n            )\n            ### get meand depending on dbs\n            mean_on = v_mean_2\n            mean_off = (v_mean_1 + v_mean_3) / 2\n            std_off = (v_std_1 + v_std_3) / 2\n            ### calculate effect\n            effect = (mean_on - mean_off) / std_off\n            if effect &gt; 1:\n                high_effect_list.append(abs(effect))\n                effect = 1\n            elif effect &lt; -1:\n                high_effect_list.append(abs(effect))\n                effect = -1\n            else:\n                low_effect_list.append(abs(effect))\n                effect = 0\n\n            effect_list[trial_idx].append(effect)\n\n    assert (\n        np.array(effects_on_activity).astype(int) == np.array(effect_list).astype(int)\n    ).all(), \"Effects on activity not as expected for spiking model\"\n\n\ndef check_dbs_effects_rate_coded(\n    dbs_val_list: list[list],\n    recordings: list,\n    model: CompNeuroModel,\n    recording_times: RecordingTimes,\n):\n    \"\"\"\n    Check if the dbs effects are as expected.\n\n    Args:\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        recordings (list):\n            List of recordings from the monitors\n        model (CompNeuroModel):\n            Model used for the simulation\n        recording_times (RecordingTimes):\n            Recording times object\n    \"\"\"\n    ### effects_on_activity_list contains the expected effects of dbs on the activity of the populations for each trial\n    ### 0 means no effect, 1 means increase, -1 means decrease\n    effects_on_activity = [\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, -1, 0, 0],\n        [0, 0, -1, 1, 0, 0],\n        [0, 0, -1, -1, 0, 0],\n        [0, 0, 0, 0, 0, 1],\n        [0, 0, -1, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, -1, -1, 0, 1],\n        [0, 0, -1, -1, 0, 1],\n        [0, 0, -1, 1, 0, 0],\n    ]\n    ### check if the expected effects are present in the data\n    effect_list = []\n    high_effect_list = []\n    low_effect_list = []\n    for trial_idx, trial in enumerate(range(len(dbs_val_list))):\n        effect_list.append([])\n        for pop_name_idx, pop_name in enumerate(model.populations):\n            v_arr = recordings[trial][f\"{pop_name};r\"]\n            ### mean over neurons\n            v_arr = np.mean(v_arr, axis=1)\n            ### mean of first period\n            v_mean_1 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt()))\n                ]\n            )\n            v_std_1 = np.std(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt()))\n                ]\n            )\n            ### mean of second period\n            v_mean_2 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt()))\n                ]\n            )\n            ### mean of third period\n            v_mean_3 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(2000 / dt()))\n                ]\n            )\n            v_std_3 = np.std(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(2000 / dt()))\n                ]\n            )\n            ### get meand depending on dbs\n            mean_on = v_mean_2\n            mean_off = (v_mean_1 + v_mean_3) / 2\n            std_off = (v_std_1 + v_std_3) / 2\n            ### calculate effect\n            effect = (mean_on - mean_off) / std_off\n            if effect &gt; 2.5:\n                high_effect_list.append(abs(effect))\n                effect = 1\n            elif effect &lt; -2.5:\n                high_effect_list.append(abs(effect))\n                effect = -1\n            else:\n                low_effect_list.append(abs(effect))\n                effect = 0\n\n            effect_list[trial_idx].append(effect)\n    assert (\n        np.array(effects_on_activity).astype(int) == np.array(effect_list).astype(int)\n    ).all(), \"Effects on activity not as expected for rate-coded model\"\n\n\ndef plot_spiking(\n    dbs_val_list: list[list],\n    recordings: list,\n    recording_times: RecordingTimes,\n    model: CompNeuroModel,\n    plotting: bool,\n):\n    \"\"\"\n    Plot spiking data.\n\n    Args:\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        recordings (list):\n            List of recordings from the monitors\n        recording_times (RecordingTimes):\n            Recording times object\n        model (CompNeuroModel):\n            Model used for the simulation\n        plotting (bool):\n            If True, plots are created\n    \"\"\"\n    if not plotting:\n        return\n\n    ### plot data\n    for trial in range(len(dbs_val_list)):\n        PlotRecordings(\n            figname=f\"DBS_spiking_figure/membrane_trial_{trial}.png\",\n            recordings=recordings,\n            recording_times=recording_times,\n            chunk=trial,\n            shape=(3, 2),\n            plan={\n                \"position\": np.arange(len(model.populations), dtype=int) + 1,\n                \"compartment\": model.populations,\n                \"variable\": [\"v\"] * len(model.populations),\n                \"format\": [\"matrix\"] * len(model.populations),\n            },\n            time_lim=(\n                recording_times.time_lims(chunk=trial)[0] + 500,\n                recording_times.time_lims(chunk=trial)[1] - 500,\n            ),\n        )\n        PlotRecordings(\n            figname=f\"DBS_spiking_figure/axon_spikes_{trial}.png\",\n            recordings=recordings,\n            recording_times=recording_times,\n            chunk=trial,\n            shape=(3, 2),\n            plan={\n                \"position\": np.arange(len(model.populations), dtype=int) + 1,\n                \"compartment\": model.populations,\n                \"variable\": [\"axon_spike\"] * len(model.populations),\n                \"format\": [\"raster\"] * len(model.populations),\n            },\n            time_lim=(\n                recording_times.time_lims(chunk=trial)[0] + 1000,\n                recording_times.time_lims(chunk=trial)[0] + 1030,\n            ),\n        )\n\n\ndef plot_rate_coded(\n    dbs_val_list: list[list],\n    recordings: list,\n    recording_times: RecordingTimes,\n    model: CompNeuroModel,\n    plotting: bool,\n):\n    \"\"\"\n    Plot rate-coded data.\n\n    Args:\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        recordings (list):\n            List of recordings from the monitors\n        recording_times (RecordingTimes):\n            Recording times object\n        model (CompNeuroModel):\n            Model used for the simulation\n        plotting (bool):\n            If True, plots are created\n    \"\"\"\n    if not plotting:\n        return\n\n    ### plot data\n    for trial in range(len(dbs_val_list)):\n        PlotRecordings(\n            figname=f\"DBS_rate_figure/activity_trial_{trial}.png\",\n            recordings=recordings,\n            recording_times=recording_times,\n            chunk=trial,\n            shape=(3, 2),\n            plan={\n                \"position\": np.arange(len(model.populations), dtype=int) + 1,\n                \"compartment\": model.populations,\n                \"variable\": [\"r\"] * len(model.populations),\n                \"format\": [\"matrix\"] * len(model.populations),\n            },\n            time_lim=(\n                recording_times.time_lims(chunk=trial)[0] + 500,\n                recording_times.time_lims(chunk=trial)[1] - 500,\n            ),\n        )\n\n\ndef main(plotting: bool = False):\n    \"\"\"\n    Main function\n\n    Args:\n        plotting (bool, optional):\n            If True, plots are created. Default: False\n    \"\"\"\n    ### define simulations\n    ### i.e. the parameters for the dbs stimulator on function\n    ### do simulate calls repeatedly dbs.on() and dbs.off() with different parameters\n    ### specified in dbs_val_list\n    dbs_key_list = [\n        \"population_proportion\",\n        \"dbs_depolarization\",\n        \"orthodromic\",\n        \"antidromic\",\n        \"efferents\",\n        \"afferents\",\n        \"passing_fibres\",\n        \"passing_fibres_strength\",\n        \"axon_spikes_per_pulse\",\n        \"axon_rate_amp\",\n    ]\n    dbs_val_list = [\n        # 0 - nothing\n        [None, 0, False, False, False, False, False, 0.2, 1, 1],\n        # 1 - orthodromic efferents\n        [None, 0, True, False, True, False, False, 0.2, 1, 1],\n        # 2 - orthodromic afferents\n        [None, 0, True, False, False, True, False, 0.2, 1, 1],\n        # 3 - orthodromic efferents and afferents\n        [None, 0, True, False, True, True, False, 0.2, 1, 1],\n        # 4 - orthodromic passing fibres\n        [None, 0, True, False, False, False, True, 0.2, 1, 1],\n        # 5 - depolarization\n        [None, 100, False, False, False, False, False, 0.2, 1, 1],\n        # 6 - antidromic efferents\n        [None, 0, False, True, True, False, False, 0.2, 1, 1],\n        # 7 - antidromic afferents\n        [None, 0, False, True, False, True, False, 0.2, 1, 1],\n        # 8 - antidromic efferents and afferents\n        [None, 0, False, True, True, True, False, 0.2, 1, 1],\n        # 9 - antidromic passing fibres\n        [None, 0, False, True, False, False, True, 0.2, 1, 1],\n        # 10 - antidromic passing fibres lower strength\n        [None, 0, False, True, False, False, True, 0.01, 1, 1],\n        # 11 - all\n        [None, 100, True, True, True, True, True, 0.2, 1, 1],\n        # 12 - all without axon spikes, should not affect rate-coded model\n        [None, 100, True, True, True, True, True, 0.2, 0, 1],\n        # 13 - all without axon_rate_amp, should not affect spiking model\n        [None, 100, True, True, True, True, True, 0.2, 1, 0],\n    ]\n\n    spiking_model = True\n    rate_coded_model = True\n\n    if spiking_model:\n        ### create the spiking network\n        model = dbs_test_model_class(\"spiking\").model\n        dbs = DBSstimulator(\n            stimulated_population=get_population(\"pop3_spiking\"),\n            passing_fibres_list=[get_projection(\"proj_5_6_spiking\")],\n            passing_fibres_strength=0.2,\n            auto_implement=True,\n            model=model,\n        )\n        model = dbs.model\n\n        ### compile model\n        model.compile(compile_folder_name=\"DBS_test_spiking\")\n\n        ### create monitors\n        mon_dict = {}\n        for pop_name in model.populations:\n            mon_dict[pop_name] = [\"v\", \"spike\", \"axon_spike\"]\n        mon = CompNeuroMonitors(mon_dict)\n\n        ### run simulation and get data from monitors\n        recordings, recording_times = do_simulation(\n            mon, dbs, dbs_val_list, dbs_key_list\n        )\n\n        ### plot data\n        plot_spiking(\n            dbs_val_list=dbs_val_list,\n            recordings=recordings,\n            recording_times=recording_times,\n            model=model,\n            plotting=plotting,\n        )\n\n        ### check dbs effects\n        check_dbs_effects_spiking(\n            dbs_val_list,\n            recordings,\n            model,\n            recording_times,\n        )\n\n    if rate_coded_model:\n        ### create the rate-coded network\n        cnp_clear()\n        model = dbs_test_model_class(\"rate-coded\").model\n        dbs = DBSstimulator(\n            stimulated_population=get_population(\"pop3_rate-coded\"),\n            passing_fibres_list=[get_projection(\"proj_5_6_rate-coded\")],\n            passing_fibres_strength=0.2,\n            model=model,\n            auto_implement=True,\n        )\n        model = dbs.model\n\n        ### compile model\n        model.compile(compile_folder_name=\"DBS_test_rate_coded\")\n\n        ### create monitors\n        mon_dict = {}\n        for pop_name in model.populations:\n            mon_dict[pop_name] = [\"r\"]\n        mon = CompNeuroMonitors(mon_dict)\n\n        ### run simulation and get data from monitors\n        recordings, recording_times = do_simulation(\n            mon, dbs, dbs_val_list, dbs_key_list\n        )\n\n        ### plot data\n        plot_rate_coded(\n            dbs_val_list=dbs_val_list,\n            recordings=recordings,\n            recording_times=recording_times,\n            model=model,\n            plotting=plotting,\n        )\n\n        ### check dbs effects\n        check_dbs_effects_rate_coded(\n            dbs_val_list,\n            recordings,\n            model,\n            recording_times,\n        )\n    return 1\n\n\nif __name__ == \"__main__\":\n    main(plotting=True)\n</code></pre>"},{"location":"examples/dbs/#console-output_1","title":"Console Output","text":"<pre><code>$ python dbs_stimulator.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\n\nWARNING during compile of model dbs_test_spiking_dbs: There are initialized models which are not created, thus not compiled! models:\ndbs_test_spiking\n\nCompiling ...  OK \nGenerate fig DBS_spiking_figure/membrane_trial_0.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_0.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_1.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_1.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_2.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_2.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_3.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_3.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_4.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_4.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_5.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_5.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_6.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_6.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_7.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_7.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_8.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_8.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_9.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_9.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_10.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_10.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_11.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_11.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_12.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_12.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_13.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_13.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\n\nWARNING during compile of model dbs_test_rate-coded_dbs: There are initialized models which are not created, thus not compiled! models:\ndbs_test_spiking\ndbs_test_spiking_dbs\ndbs_test_rate-coded\n\nCompiling ...  OK \nGenerate fig DBS_rate_figure/activity_trial_0.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_1.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_2.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_3.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_4.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_5.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_6.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_7.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_8.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_9.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_10.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_11.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_12.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_13.png... Done\n</code></pre>"},{"location":"examples/experiment/","title":"Define Experiments","text":""},{"location":"examples/experiment/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the CompNeuroExp class to combine simulations, model and recordings in an experiment. It is shown how to define an experiment, how to run it and how to get the results.</p>"},{"location":"examples/experiment/#code","title":"Code","text":"<pre><code>from CompNeuroPy import (\n    CompNeuroExp,\n    CompNeuroSim,\n    CompNeuroMonitors,\n    CompNeuroModel,\n    current_step,\n    current_ramp,\n    PlotRecordings,\n)\nfrom CompNeuroPy.full_models import HHmodelBischop\nfrom ANNarchy import dt, setup, get_population\n\n\n### combine both simulations and recordings in an experiment\nclass MyExp(CompNeuroExp):\n    \"\"\"\n    Define an experiment by inheriting from CompNeuroExp.\n\n    CompNeuroExp provides the attributes:\n\n        monitors (CompNeuroMonitors):\n            a CompNeuroMonitors object to do recordings, define during init otherwise\n            None\n        data (dict):\n            a dictionary for storing any optional data\n\n    and the functions:\n        reset():\n            resets the model and monitors\n        results():\n            returns a results object\n        store_model_state():\n            stores the state of the model used for reset\n        reset_model_state():\n            resets the stored model state\n    \"\"\"\n\n    def __init__(\n        self,\n        model: CompNeuroModel,\n        sim_step: CompNeuroSim,\n        sim_ramp: CompNeuroSim,\n        monitors: CompNeuroMonitors,\n    ):\n        \"\"\"\n        Initialize the experiment and additionally store the model and simulations.\n\n        Args:\n            model (CompNeuroModel):\n                a CompNeuroModel object\n            sim_step (CompNeuroSim):\n                a CompNeuroSim object for the step simulation\n            sim_ramp (CompNeuroSim):\n                a CompNeuroSim object for the ramp simulation\n            monitors (CompNeuroMonitors):\n                a CompNeuroMonitors object\n        \"\"\"\n        self.model = model\n        self.sim_step = sim_step\n        self.sim_ramp = sim_ramp\n        super().__init__(monitors)\n\n    def run(self, E_L: float = -68.0):\n        \"\"\"\n        Do the simulations and recordings.\n\n        To use the CompNeuroExp class, you need to define a run function which\n        does the simulations and recordings. The run function should return the\n        results object which can be obtained by calling self.results().\n\n        Args:\n            E_L (float, optional):\n                leak reversal potential of the population, which is set at the beginning\n                of the experiment run. Default: -68 mV\n\n        Returns:\n            results (CompNeuroExp._ResultsCl):\n                results object with attributes:\n                    recordings (list):\n                        list of recordings\n                    recording_times (recording_times_cl):\n                        recording times object\n                    mon_dict (dict):\n                        dict of recorded variables of the monitors\n                    data (dict):\n                        dict with optional data stored during the experiment\n        \"\"\"\n        ### call reset at the beginning of the experiment to ensure that the model\n        ### is in the same state at the beginning of each experiment run\n        ### we stored the state that the membrane potential is -90 before (see below)\n        ### this can be seen in the results plots\n        self.reset()\n\n        ### also always start the monitors, they are stopped automatically at the end\n        self.monitors.start()\n\n        ### set the leak reversal potential of the population, be aware that this\n        ### will be undone by the reset function if you don't set the parameters\n        ### argument to False\n        get_population(self.model.populations[0]).E_L = E_L\n\n        ### SIMULATION START\n        sim_ramp.run()\n        ### if you want to reset the model, you should use the objects reset()\n        ### it's the same as the ANNarchy reset + it resets the CompNeuroMonitors\n        ### creating a new chunk, optionally not changing the parameters (but still the\n        ### dynamic variables)\n        self.reset(parameters=False)\n        sim_step.run()\n        ### SIMULATION END\n\n        ### optional: store anything you want in the data dict, for example information\n        ### about the simulations\n        self.data[\"sim\"] = [sim_ramp.simulation_info(), sim_step.simulation_info()]\n        self.data[\"population_name\"] = self.model.populations[0]\n        self.data[\"time_step\"] = dt()\n\n        ### return results using self.results()\n        return self.results()\n\n\nif __name__ == \"__main__\":\n    ### create and compile a model\n    setup(dt=0.01)\n    model = HHmodelBischop()\n\n    ### define recordings before experiment\n    monitors = CompNeuroMonitors({model.populations[0]: [\"v\"]})\n\n    ### define some simulations e.g. using CompNeuroSim\n    ### in the experiment we 1st conduct a ramp simulation\n    sim_ramp = CompNeuroSim(\n        simulation_function=current_ramp,\n        simulation_kwargs={\n            \"pop\": model.populations[0],\n            \"a0\": 0,\n            \"a1\": 100,\n            \"dur\": 1000,\n            \"n\": 50,\n        },\n    )\n    ### and 2nd a step simulation\n    sim_step = CompNeuroSim(\n        simulation_function=current_step,\n        simulation_kwargs={\n            \"pop\": model.populations[0],\n            \"t1\": 500,\n            \"t2\": 500,\n            \"a1\": 0,\n            \"a2\": 50,\n        },\n    )\n\n    ### init and run the experiment\n    my_exp = MyExp(monitors=monitors, model=model, sim_step=sim_step, sim_ramp=sim_ramp)\n\n    ### demonstration of the store_model_state function\n    ### the current state of the model is the compilation state, e.g. v should be -68\n    print(f\"Compilation state v = {get_population(model.populations[0]).v}\")\n    ### the reset function of CompNeuroExp resets to the compilation state by default\n    ### but you can also store the state of model compartments and reset to this state\n    ### here for example we store that the membrane potential is -90\n    get_population(model.populations[0]).v = -90.0\n    my_exp.store_model_state(compartment_list=model.populations)\n\n    ### one use case is to run an experiment multiple times e.g. with different\n    ### parameters\n    results_run1 = my_exp.run()\n    results_run2 = my_exp.run(E_L=-90.0)\n\n    ### plot of the membrane potential from the first and second chunk using results\n    ### experiment run 1\n    PlotRecordings(\n        figname=\"example_experiment_sim_ramp.png\",\n        recordings=results_run1.recordings,\n        recording_times=results_run1.recording_times,\n        chunk=0,\n        shape=(1, 1),\n        plan={\n            \"position\": [1],\n            \"compartment\": [results_run1.data[\"population_name\"]],\n            \"variable\": [\"v\"],\n            \"format\": [\"line\"],\n        },\n    )\n    PlotRecordings(\n        figname=\"example_experiment_sim_step.png\",\n        recordings=results_run1.recordings,\n        recording_times=results_run1.recording_times,\n        chunk=1,\n        shape=(1, 1),\n        plan={\n            \"position\": [1],\n            \"compartment\": [results_run1.data[\"population_name\"]],\n            \"variable\": [\"v\"],\n            \"format\": [\"line\"],\n        },\n    )\n    ### experiment run 2\n    PlotRecordings(\n        figname=\"example_experiment2_sim_ramp.png\",\n        recordings=results_run2.recordings,\n        recording_times=results_run2.recording_times,\n        chunk=0,\n        shape=(1, 1),\n        plan={\n            \"position\": [1],\n            \"compartment\": [results_run2.data[\"population_name\"]],\n            \"variable\": [\"v\"],\n            \"format\": [\"line\"],\n        },\n    )\n    PlotRecordings(\n        figname=\"example_experiment2_sim_step.png\",\n        recordings=results_run2.recordings,\n        recording_times=results_run2.recording_times,\n        chunk=1,\n        shape=(1, 1),\n        plan={\n            \"position\": [1],\n            \"compartment\": [results_run2.data[\"population_name\"]],\n            \"variable\": [\"v\"],\n            \"format\": [\"line\"],\n        },\n    )\n\n    ### print data and mon_dict from results\n    print(\"\\nrun1:\")\n    print(\"    data:\")\n    for key, value in results_run1.data.items():\n        print(f\"        {key}:\", value)\n    print(\"    mon_dict:\")\n    for key, value in results_run1.mon_dict.items():\n        print(f\"        {key}:\", value)\n    print(\"\\nrun2:\")\n    print(\"    data:\")\n    for key, value in results_run2.data.items():\n        print(f\"        {key}:\", value)\n    print(\"    mon_dict:\")\n    for key, value in results_run2.mon_dict.items():\n        print(f\"        {key}:\", value)\n</code></pre>"},{"location":"examples/experiment/#console-output","title":"Console Output","text":"<pre><code>$ python experiment.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nCompilation state v = [-68.]\nGenerate fig example_experiment_sim_ramp.png... Done\n\nGenerate fig example_experiment_sim_step.png... Done\n\nGenerate fig example_experiment2_sim_ramp.png... Done\n\nGenerate fig example_experiment2_sim_step.png... Done\n\n\nrun1:\n    data:\n        sim: [&lt;CompNeuroPy.generate_simulation.SimInfo object at 0x7f71f8cd1f00&gt;, &lt;CompNeuroPy.generate_simulation.SimInfo object at 0x7f71f8cd1fc0&gt;]\n        population_name: HH_Bischop\n        time_step: 0.01\n    mon_dict:\n        HH_Bischop: ['v']\n\nrun2:\n    data:\n        sim: [&lt;CompNeuroPy.generate_simulation.SimInfo object at 0x7f71f9181570&gt;, &lt;CompNeuroPy.generate_simulation.SimInfo object at 0x7f71f8c5a8c0&gt;]\n        population_name: HH_Bischop\n        time_step: 0.01\n    mon_dict:\n        HH_Bischop: ['v']\n</code></pre>"},{"location":"examples/generate_models/","title":"Generate Models","text":""},{"location":"examples/generate_models/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the CompNeuroModel class to create and compile models. It is shown how to define a model creation function, how to initialize, create, compile a model and how to get information about the model.</p> <p>The model \"my_model\" is imported in other examples run_and_monitor_simulations.py.</p>"},{"location":"examples/generate_models/#code","title":"Code","text":"<pre><code>from ANNarchy import Population\nfrom CompNeuroPy import CompNeuroModel\nfrom CompNeuroPy.neuron_models import PoissonNeuron\nfrom tabulate import tabulate\n\n\n### define model_creation_function\ndef two_poisson(params, a):\n    \"\"\"\n    Generates two Poisson neuron populations.\n\n    Args:\n        params (dict):\n            Dictionary containing some paramters for the model with following keys:\n                's1'/'s2' : sizes of pop1/pop2\n                'n1'/'n2' : names of pop1/pop2\n        a (int):\n            Unused parameter for demonstration purposes only.\n    \"\"\"\n    ### create two populations\n    Population(params[\"s1\"], neuron=PoissonNeuron, name=params[\"n1\"])\n    Population(params[\"s2\"], neuron=PoissonNeuron, name=params[\"n2\"])\n    ### print unused parameter\n    print(f\"created model, other parameters: {a}\")\n\n\n### Let's initialize a first model\n### define the parameters argument of the model creation function\nparams = {\"s1\": 3, \"s2\": 3, \"n1\": \"first_poisson\", \"n2\": \"second_poisson\"}\n\n### use CompNeuroModel to initialize the model, not create or compile it yet\nmy_model = CompNeuroModel(\n    model_creation_function=two_poisson,\n    model_kwargs={\n        \"params\": params,\n        \"a\": 1,\n    },\n    name=\"my_model\",\n    description=\"my simple Poisson neuron model\",\n    do_create=False,\n    do_compile=False,\n    compile_folder_name=\"annarchy_my_model\",\n)\n\n### this initialized the first model\n### we could now create and compile it, but we will do this inside main\n### it could also be imported in other scripts and then created/compiled there\n\n\ndef main():\n    ### initialize a second model\n    ### this time directly create it, but not compile it yet, models can only be created\n    ### if not compiled yet\n    params = {\"s1\": 1, \"s2\": 1, \"n1\": \"pop1\", \"n2\": \"pop2\"}\n    my_model2 = CompNeuroModel(\n        model_creation_function=two_poisson,\n        model_kwargs={\"params\": params, \"a\": 2},\n        do_compile=False,\n    )\n\n    ### now create also first model, and compile everything (automatically since we did\n    ### not set do_compile=False)\n    my_model.create()\n\n    ### print some name, description, populations and projections of the models in\n    ### tabular form\n    models_data = [\n        [\n            my_model.name,\n            my_model.description,\n            my_model.populations,\n            my_model.projections,\n        ],\n        [\n            my_model2.name,\n            my_model2.description,\n            my_model2.populations,\n            my_model2.projections,\n        ],\n    ]\n    headers = [\"Model\", \"Description\", \"Populations\", \"Projections\"]\n    print(tabulate(models_data, headers, tablefmt=\"grid\"))\n\n    return 1\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/generate_models/#console-output","title":"Console Output","text":"<pre><code>$ python create_model.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\ncreated model, other parameters: 2\ncreated model, other parameters: 1\nCompiling ...  OK \n+----------+--------------------------------+-------------------------------------+---------------+\n| Model    | Description                    | Populations                         | Projections   |\n+==========+================================+=====================================+===============+\n| my_model | my simple Poisson neuron model | ['first_poisson', 'second_poisson'] | []            |\n+----------+--------------------------------+-------------------------------------+---------------+\n| model1   |                                | ['pop1', 'pop2']                    | []            |\n+----------+--------------------------------+-------------------------------------+---------------+\n</code></pre>"},{"location":"examples/monitor_recordings/","title":"Monitor Recordings","text":""},{"location":"examples/monitor_recordings/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the CompNeuroMonitors class to record variables. It is shown how to start/pause monitors, how to split recordings into chunks and optionally reset the model and how to get recordings during and after simulation.</p>"},{"location":"examples/monitor_recordings/#code","title":"Code","text":"<pre><code>from ANNarchy import Population, setup, simulate, compile\nfrom CompNeuroPy import (\n    CompNeuroMonitors,\n    PlotRecordings,\n)\nfrom CompNeuroPy.neuron_models import Izhikevich2007\n\n\ndef main():\n    ### setup ANNarchy timestep and create results folder\n    setup(dt=0.1)\n\n    ### first we create two populations, each consist of 1 neuron\n    Population(1, neuron=Izhikevich2007(I_app=0), name=\"my_pop1\")\n    Population(1, neuron=Izhikevich2007(I_app=52), name=\"my_pop2\")\n\n    ### compile\n    compile()\n\n    ### after compilation we can define the monitors using the monitor_dictionary\n    ### and the CompNeuroMonitors class\n    ### for my_pop1 we use a recording period of 2 ms\n    ### for my_pop2 we do not give a recording preiod, therefore record every timestep\n    monitor_dictionary = {\"my_pop1;2\": [\"v\", \"spike\"], \"my_pop2\": [\"v\"]}\n    mon = CompNeuroMonitors(monitor_dictionary)\n\n    ### In this part we demonstrate starting/pausing all monitors\n    ### simulate for 100 ms [0, 100]\n    simulate(100)\n\n    ### start all monitors and simulate for 100 ms [100, 200]\n    mon.start()\n    simulate(100)\n\n    ### pause all monitors and simulate for 100 ms [200, 300]\n    mon.pause()\n    simulate(100)\n\n    ### In this part we demonstrate starting single monitors\n    ### start only monitor for my_pop1 and simulate for 100 ms [300, 400]\n    mon.start(compartment_list=[\"my_pop1\"])\n    simulate(100)\n\n    ### start all monitors and simulate for 100 ms [400, 500]\n    mon.start()\n    simulate(100)\n\n    ### In this part we demonstrate pausing single monitors\n    ### pause monitor for my_pop1 and simulate for 100 ms [500, 600]\n    mon.pause(compartment_list=[\"my_pop1\"])\n    simulate(100)\n\n    ### start all monitors and simulate for 100 ms [600, 700]\n    mon.start()\n    simulate(100)\n\n    ### In this part we demonstrate chunking recordings by reset\n    ### reset WITHOUT model, creating new chunk --&gt; first chunk [0, 700]\n    ### also in this chunk do not record the first 100 ms\n    ### WITHOUT model --&gt; time continues at 700 ms [700, 800]\n    mon.reset(model=False)\n    mon.pause()\n    simulate(100)\n\n    ### start all monitors and simulate for 700 ms [800, 1500]\n    mon.start()\n    simulate(700)\n\n    ### reset WITH model, creating new chunk --&gt; second chunk [700, 1500]\n    ### in third chunk time is reset to 0 ms\n    ### also in this chunk do not record the first 100 ms [0, 100]\n    mon.reset(model=True)\n    mon.pause()\n    simulate(100)\n\n    ### start all monitors and simulate for 700 ms [100, 800]\n    mon.start()\n    simulate(700)\n\n    ### Next we demonstrate getting recordings DURING SIMULATION by using\n    ### get_recordings_and_clear\n    ### this also resets the monitors back to their initialized state, i.e. there are no\n    ### recordings and they are not started yet\n    ### recordings1 consists of 3 chunks, third chunk [0, 800]\n    recordings1, recording_times1 = mon.get_recordings_and_clear()\n\n    ### Now continue simulation, creating NEW RECORDINGS, monitors are not started yet\n    ### model was not reset, so time continues at 800 ms\n    ### simulate for 100 ms [800, 900]\n    simulate(100)\n\n    ### start all monitors and simulate for 100 ms [900, 1000]\n    mon.start()\n    simulate(100)\n\n    ### reset monitors and model, creating new chunk --&gt; first chunk [800, 1000]\n    ### simulate for 100 ms [0, 100]\n    mon.reset(model=True)\n    simulate(100)\n\n    ### get recordings using get_recordings_and_clear\n    ### this time directly start recording again\n    ### recordings2 consists of 2 chunks, second chunk [0, 100]\n    recordings2, recording_times2 = mon.get_recordings_and_clear()\n\n    ### Now continue simulation, creating NEW RECORDINGS\n    ### directly start monitors and reset model so time is reset to 0 ms\n    ### simulate for 100 ms [0, 100]\n    mon.start()\n    mon.reset(model=True)\n    simulate(100)\n\n    ### get recordings the normal way (simultions are finished)\n    ### recordings3 consists of 1 chunk [0, 100]\n    recordings3 = mon.get_recordings()\n    recording_times3 = mon.get_recording_times()\n\n    ### print the idx and time lims of the recordings and the sizes of the recorded\n    ### arrays\n    print(\"#################### ALL RECORDINGS INFO ####################\")\n    recordings_list = [recordings1, recordings2, recordings3]\n    for all_times_idx, all_times in enumerate(\n        [recording_times1.all(), recording_times2.all(), recording_times3.all()]\n    ):\n        print(f\"recordings{all_times_idx+1}\")\n        for chunk in range(len(all_times)):\n            print(f\"\\tchunk: {chunk}\")\n            for pop_name in [\"my_pop1\", \"my_pop2\"]:\n                print(f\"\\t\\tpop_name: {pop_name}\")\n                print(\n                    f\"\\t\\trecording_array_size: {recordings_list[all_times_idx][chunk][f'{pop_name};v'].shape}\"\n                )\n                for time_point in [\"start\", \"stop\"]:\n                    print(f\"\\t\\t\\ttime_point: {time_point}\")\n                    for unit in [\"ms\", \"idx\"]:\n                        print(f\"\\t\\t\\t\\tunit: {unit}\")\n                        for period in range(\n                            len(all_times[chunk][pop_name][time_point][unit])\n                        ):\n                            print(\n                                f\"\\t\\t\\t\\t\\tperiod {period}: {all_times[chunk][pop_name][time_point][unit][period]}\"\n                            )\n    print(\"#############################################################\")\n\n    ### plot recordings 1 consisting of 3 chunks\n    for chunk in range(len(recordings1)):\n        ### using plot_recordings which plots the recordings of one chunk\n        PlotRecordings(\n            figname=f\"monitor_recordings_1_chunk{chunk}.png\",\n            recordings=recordings1,\n            recording_times=recording_times1,\n            shape=(2, 2),\n            plan={\n                \"position\": [1, 2, 3],\n                \"compartment\": [\"my_pop1\", \"my_pop2\", \"my_pop1\"],\n                \"variable\": [\"v\", \"v\", \"spike\"],\n                \"format\": [\"line\", \"line\", \"raster\"],\n            },\n            chunk=chunk,\n        )\n\n    ### plot recordings 2 consisting of 2 chunks\n    for chunk in range(len(recordings2)):\n        ### using plot_recordings which plots the recordings of one chunk\n        PlotRecordings(\n            figname=f\"monitor_recordings_2_chunk{chunk}.png\",\n            recordings=recordings2,\n            recording_times=recording_times2,\n            shape=(2, 2),\n            plan={\n                \"position\": [1, 2, 3],\n                \"compartment\": [\"my_pop1\", \"my_pop2\", \"my_pop1\"],\n                \"variable\": [\"v\", \"v\", \"spike\"],\n                \"format\": [\"line\", \"line\", \"raster\"],\n            },\n            chunk=chunk,\n        )\n\n    ### plot recordings 3 consisting of 1 chunk\n    for chunk in range(len(recordings3)):\n        ### using plot_recordings which plots the recordings of one chunk\n        PlotRecordings(\n            figname=f\"monitor_recordings_3_chunk{chunk}.png\",\n            recordings=recordings3,\n            recording_times=recording_times3,\n            shape=(2, 2),\n            plan={\n                \"position\": [1, 2, 3],\n                \"compartment\": [\"my_pop1\", \"my_pop2\", \"my_pop1\"],\n                \"variable\": [\"v\", \"v\", \"spike\"],\n                \"format\": [\"line\", \"line\", \"raster\"],\n            },\n            chunk=chunk,\n        )\n\n    return 1\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/monitor_recordings/#conosole-output","title":"Conosole Output","text":"<pre><code>$ python monitor_recordings.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nCompiling ...  OK \n#################### ALL RECORDINGS INFO ####################\nrecordings1\n    chunk: 0\n        pop_name: my_pop1\n        recording_array_size: (200, 1)\n            time_point: start\n                unit: ms\n                    period 0: 100.0\n                    period 1: 300.0\n                    period 2: 600.0\n                unit: idx\n                    period 0: 0\n                    period 1: 50\n                    period 2: 150\n            time_point: stop\n                unit: ms\n                    period 0: 198.0\n                    period 1: 498.0\n                    period 2: 698.0\n                unit: idx\n                    period 0: 49\n                    period 1: 149\n                    period 2: 199\n        pop_name: my_pop2\n        recording_array_size: (4000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 100.0\n                    period 1: 400.0\n                unit: idx\n                    period 0: 0\n                    period 1: 1000\n            time_point: stop\n                unit: ms\n                    period 0: 199.9\n                    period 1: 699.9\n                unit: idx\n                    period 0: 999\n                    period 1: 3999\n    chunk: 1\n        pop_name: my_pop1\n        recording_array_size: (350, 1)\n            time_point: start\n                unit: ms\n                    period 0: 800.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 1498.0\n                unit: idx\n                    period 0: 349\n        pop_name: my_pop2\n        recording_array_size: (7000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 800.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 1499.9\n                unit: idx\n                    period 0: 6999\n    chunk: 2\n        pop_name: my_pop1\n        recording_array_size: (350, 1)\n            time_point: start\n                unit: ms\n                    period 0: 100.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 798.0\n                unit: idx\n                    period 0: 349\n        pop_name: my_pop2\n        recording_array_size: (7000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 100.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 799.9\n                unit: idx\n                    period 0: 6999\nrecordings2\n    chunk: 0\n        pop_name: my_pop1\n        recording_array_size: (50, 1)\n            time_point: start\n                unit: ms\n                    period 0: 900.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 998.0\n                unit: idx\n                    period 0: 49\n        pop_name: my_pop2\n        recording_array_size: (1000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 900.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 999.9\n                unit: idx\n                    period 0: 999\n    chunk: 1\n        pop_name: my_pop1\n        recording_array_size: (50, 1)\n            time_point: start\n                unit: ms\n                    period 0: 0.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 98.0\n                unit: idx\n                    period 0: 49\n        pop_name: my_pop2\n        recording_array_size: (1000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 0.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 99.9\n                unit: idx\n                    period 0: 999\nrecordings3\n    chunk: 0\n        pop_name: my_pop1\n        recording_array_size: (50, 1)\n            time_point: start\n                unit: ms\n                    period 0: 0.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 98.0\n                unit: idx\n                    period 0: 49\n        pop_name: my_pop2\n        recording_array_size: (1000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 0.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 99.9\n                unit: idx\n                    period 0: 999\n#############################################################\nGenerate fig monitor_recordings_1_chunk0.png... \n  WARNING PlotRecordings: my_pop1 does not contain any spikes in the given time interval.\nDone\n\nGenerate fig monitor_recordings_1_chunk1.png... \n  WARNING PlotRecordings: my_pop1 does not contain any spikes in the given time interval.\nDone\n\nGenerate fig monitor_recordings_1_chunk2.png... \n  WARNING PlotRecordings: my_pop1 does not contain any spikes in the given time interval.\nDone\n\nGenerate fig monitor_recordings_2_chunk0.png... \n  WARNING PlotRecordings: my_pop1 does not contain any spikes in the given time interval.\nDone\n\nGenerate fig monitor_recordings_2_chunk1.png... Done\n\nGenerate fig monitor_recordings_3_chunk0.png... Done\n</code></pre>"},{"location":"examples/opt_neuron/","title":"Optimize a neuron model","text":""},{"location":"examples/opt_neuron/#optimize-neuron-model-from-data","title":"Optimize neuron model from data","text":""},{"location":"examples/opt_neuron/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the OptNeuron class to fit an ANNarchy neuron model to some experimental data.</p>"},{"location":"examples/opt_neuron/#code","title":"Code","text":"<pre><code>from CompNeuroPy import CompNeuroExp, CompNeuroSim, current_step, rmse\nfrom CompNeuroPy.opt_neuron import OptNeuron\nimport numpy as np\nfrom ANNarchy import Neuron, dt\n\n### in this example we want to fit an ANNarchy neuron model to some data (which ca be\n### somehow obtained by simulating the neuron and recording variables) for this example,\n### we have the following simple neuron model, you must not use the :population flag\n### for the parameters!\nmy_neuron = Neuron(\n    parameters=\"\"\"\n        I_app = 0\n        a = 0\n        b = 0\n    \"\"\",\n    equations=\"\"\"\n        r = a*I_app + b\n    \"\"\",\n)\n\n\n### Now we need some \"experimental data\" which will be provided to the OptNeuron class\n### with the argument results_soll.\ndef get_experimental_data():\n    \"\"\"\n    Return experimental data.\n\n    Assume we have two recordings of the rate r of a single neuron from two different\n    current step experiments. Both have length = 1000 ms and after 500 ms the current is\n    changed, thus also the rate.\n\n    Returns:\n        return_dict (dict):\n            Dictionary with keys \"results_soll\" and \"time_step\" and values the\n            experimental data and the time step in ms with which the date was obtained,\n            respectively.\n    \"\"\"\n    r_arr = np.empty((2, 1000))\n    ### first recording\n    r_arr[0, :500] = 2\n    r_arr[0, 500:] = 6\n    ### second recording\n    r_arr[1, :500] = 2\n    r_arr[1, 500:] = 10\n    ### time step in ms\n    time_step = 1\n\n    return_dict = {\"results_soll\": r_arr, \"time_step\": time_step}\n    return return_dict\n\n\n### We know how our experimental data was obtained. This is what we have to define as an\n### CompNeuroExp for the OptNeuron class.\nclass my_exp(CompNeuroExp):\n    \"\"\"\n    Define an experiment by inheriting from CompNeuroExp.\n\n    CompNeuroExp provides the attributes:\n\n        monitors (CompNeuroMonitors):\n            a CompNeuroMonitors object to do recordings, define during init otherwise\n            None\n        data (dict):\n            a dictionary for storing any optional data\n\n    and the functions:\n        reset():\n            resets the model and monitors\n        results():\n            returns a results object\n    \"\"\"\n\n    def run(self, population_name):\n        \"\"\"\n        Do the simulations and recordings.\n\n        To use the CompNeuroExp class, you need to define a run function which\n        does the simulations and recordings. The run function should return the\n        results object which can be obtained by calling self.results().\n\n        For using the CompNeuroExp for OptNeuron, the run function should have\n        one argument which is the name of the population which is automatically created\n        by OptNeuron, containing a single or multiple neurons of the neuron model which\n        should be optimized. Thus, the run function should be able to run the experiment\n        with a single or multiple neurons in the given population!\n\n        Args:\n            population_name (str):\n                name of the population with neurons of the tuned neuron model, this will\n                be automatically provided by OptNeuron\n\n        Returns:\n            results (CompNeuroExp._ResultsCl):\n                results object with attributes:\n                    recordings (list):\n                        list of recordings\n                    recording_times (recording_times_cl):\n                        recording times object\n                    mon_dict (dict):\n                        dict of recorded variables of the monitors\n                    data (dict):\n                        dict with optional data stored during the experiment\n        \"\"\"\n        ### you have to start monitors within the run function, otherwise nothing will\n        ### be recorded\n        self.monitors.start()\n\n        ### do simulations and recordings using the provided CompNeuroMonitors object\n        ### (recording the varables specified during the initialization of OptNeuron\n        ### class) and e.g. the CompNeuroSim class\n        sim_step = CompNeuroSim(\n            simulation_function=current_step,\n            simulation_kwargs={\n                \"pop\": population_name,\n                \"t1\": 500,\n                \"t2\": 500,\n                \"a1\": 0,\n                \"a2\": 5,\n            },\n            kwargs_warning=False,\n            name=\"test\",\n            monitor_object=self.monitors,\n        )\n\n        ### run the simulation\n        sim_step.run()\n        ### Here we reset the model and monitors, creating a new chunk for the next sim\n        ### use the self.reset() function to reset the model and monitors!\n        ### OptNeuron sets the parameters (defined in the variables_bounds dict) of the\n        ### neuron model before each run.\n        ### By using the reset function of the CompNeuroExp class you reset the model to\n        ### this state (all varaiables/parameters not defined in variable bounds are\n        ### reset to compile state)\n        self.reset()\n        sim_step.run({\"a2\": 10})\n\n        ### optional: store anything you want in the data dict. For example infomration\n        ### about the simulations. This is not used for the optimization but can be\n        ### retrieved after the optimization is finished\n        self.data[\"sim\"] = sim_step.simulation_info()\n        self.data[\"population_name\"] = population_name\n        self.data[\"time_step\"] = dt()\n\n        ### return results, use the object's self.results()\n        return self.results()\n\n\n### Next, the OptNeuron class needs a function to calculate the loss.\ndef get_loss(results_ist: CompNeuroExp._ResultsCl, results_soll):\n    \"\"\"\n    Function which has to have the arguments results_ist and results_soll and should\n    calculate and return the loss. This structure is needed for the OptNeuron class.\n\n    Args:\n        results_ist (object):\n            the results object returned by the run function of experiment (see above)\n        results_soll (any):\n            the target data directly provided to OptNeuron during initialization\n\n    Returns:\n        loss (float or list of floats):\n            the loss\n    \"\"\"\n    ### get the recordings and other important things for calculating the loss from\n    ### results_ist, we do not use all available information here, but you could\n    rec_ist = results_ist.recordings\n    pop_ist = results_ist.data[\"population_name\"]\n\n    ### the get_loss function should always calculate the loss for neuron rank 0!\n    neuron = 0\n\n    ### get the data for calculating the loss from the results_soll\n    r_target_0 = results_soll[0]\n    r_target_1 = results_soll[1]\n\n    ### get the data for calculating the loss from the recordings of the\n    ### optimized neuron model\n    r_ist_0 = rec_ist[0][f\"{pop_ist};r\"][:, neuron]\n    r_ist_1 = rec_ist[1][f\"{pop_ist};r\"][:, neuron]\n\n    ### calculate the loss, e.g. the root mean squared error\n    rmse1 = rmse(r_target_0, r_ist_0)\n    rmse2 = rmse(r_target_1, r_ist_1)\n\n    ### return the loss, one can return a singel value or a list of values which will\n    ### be summed during the optimization\n    return [rmse1, rmse2]\n\n\n### now we need to define which variables should be optimized and between which bounds\nvariables_bounds = {\"a\": [-10, 10], \"b\": [-10, 10]}\n\n\ndef main():\n    ### get experimental data\n    experimental_data = get_experimental_data()\n\n    ### intitialize optimization\n    opt = OptNeuron(\n        experiment=my_exp,\n        get_loss_function=get_loss,\n        variables_bounds=variables_bounds,\n        neuron_model=my_neuron,\n        results_soll=experimental_data[\"results_soll\"],\n        time_step=experimental_data[\"time_step\"],\n        compile_folder_name=\"annarchy_opt_neuron_example_from_data\",\n        method=\"deap\",\n        record=[\"r\"],\n    )\n\n    ### run the optimization, define how often the experiment should be repeated\n    fit = opt.run(max_evals=100, results_file_name=\"best_from_data\")\n\n    ### print optimized parameters, we should get around a=0.8 and b=2\n    print(\"a\", fit[\"a\"])\n    print(\"b\", fit[\"b\"])\n    print(list(fit.keys()))\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/opt_neuron/#console-output","title":"Console Output","text":"<pre><code>$ python run_opt_neuron_from_data.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nOptNeuron: Initialize OptNeuron... do not create anything with ANNarchy before!\nOptNeuron: WARNING: attributes ['I_app', 'r'] are not used/initialized.\nchecking neuron_models, experiment, get_loss...Done\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:03&lt;00:00, 26.66gen/s, best loss: 0.00000]\na 0.8000000007960777\nb 1.9999999939091158\n['a', 'b', 'logbook', 'deap_pop', 'loss', 'all_loss', 'std', 'results', 'results_soll']\n</code></pre>"},{"location":"examples/opt_neuron/#optimize-neuron-model-from-other-neuron-model","title":"Optimize neuron model from other neuron model","text":""},{"location":"examples/opt_neuron/#introduction_1","title":"Introduction","text":"<p>This example demonstrates how to use the OptNeuron class to fit an ANNarchy neuron model to the dynamics of another ANNarchy neuron model in a specific experiment.</p> <p>The experiment and variable_bounds used are imported from the other example run_opt_neuron_from_data.py.</p>"},{"location":"examples/opt_neuron/#code_1","title":"Code","text":"<pre><code>from CompNeuroPy import CompNeuroExp, rmse\nfrom CompNeuroPy.opt_neuron import OptNeuron\nfrom ANNarchy import Neuron\n\n### import the experiment and variables_bounds\nfrom run_opt_neuron_from_data import my_exp, variables_bounds\nfrom run_opt_neuron_from_data import my_neuron as simple_neuron\n\n\n### for this example we want to fit a simple neuron model to replicate the dynamics of a\n### more complex neuron model, the simple model is imported from the other example\n### 'run_opt_neuron_from_data.py' and the complex model is defined here\ncomplex_neuron = Neuron(\n    parameters=\"\"\"\n        I_app = 0\n        m0 = 1\n        m1 = 2\n        m2 = 3\n        n0 = 1\n        n1 = 0\n        n2 = -1\n    \"\"\",\n    equations=\"\"\"\n        r = m0*I_app + n0 + m1*I_app + n1 + m2*I_app + n2\n    \"\"\",\n)\n\n\n### Next, the OptNeuron class needs a function to calculate the loss.\ndef get_loss(\n    results_ist: CompNeuroExp._ResultsCl, results_soll: CompNeuroExp._ResultsCl\n):\n    \"\"\"\n    Function which has to have the arguments results_ist and results_soll and should\n    calculate and return the loss. This structure is needed for the OptNeuron class.\n\n    Args:\n        results_ist (object):\n            the results object returned by the run function of experiment (see above),\n            conducting the experiment with the optimized neuron model\n        results_soll (any):\n            the results object returned by the run function of experiment (see above),\n            conducting the experiment with the target neuron model\n\n    Returns:\n        loss (float or list of floats):\n            the loss\n    \"\"\"\n\n    ### get the recordings and other important things from the results_ist (results\n    ### generated during the optimization using the defrined CompNeuroExp from above)\n    rec_ist = results_ist.recordings\n    pop_ist = results_ist.data[\"population_name\"]\n    rec_soll = results_soll.recordings\n    pop_soll = results_soll.data[\"population_name\"]\n\n    ### the get_loss function should always calculate the loss for neuron rank 0! For\n    ### both, the target and the optimized neuron model.\n    neuron = 0\n\n    ### get the data for calculating the loss from the recordings of the\n    ### target neuron model\n    v_soll_0 = rec_soll[0][pop_soll + \";r\"][:, neuron]\n    v_soll_1 = rec_soll[1][pop_soll + \";r\"][:, neuron]\n\n    ### get the data for calculating the loss from the recordings of the\n    ### optimized neuron model\n    v_ist_0 = rec_ist[0][pop_ist + \";r\"][:, neuron]\n    v_ist_1 = rec_ist[1][pop_ist + \";r\"][:, neuron]\n\n    ### calculate the loss, e.g. the root mean squared error\n    rmse1 = rmse(v_soll_0, v_ist_0)\n    rmse2 = rmse(v_soll_1, v_ist_1)\n\n    ### return the loss, one can return a singel value or a list of values which will\n    ### be summed during the optimization\n    return [rmse1, rmse2]\n\n\ndef main():\n    ### define optimization\n    opt = OptNeuron(\n        experiment=my_exp,\n        get_loss_function=get_loss,\n        variables_bounds=variables_bounds,\n        neuron_model=simple_neuron,\n        target_neuron_model=complex_neuron,\n        time_step=1,\n        compile_folder_name=\"annarchy_opt_neuron_example_from_neuron\",\n        method=\"deap\",\n        record=[\"r\"],\n    )\n\n    ### run the optimization, define how often the experiment should be repeated\n    fit = opt.run(max_evals=100, results_file_name=\"best_from_neuron\")\n\n    ### print optimized parameters, we should get around a=6 and b=0\n    print(\"a\", fit[\"a\"])\n    print(\"b\", fit[\"b\"])\n    print(list(fit.keys()))\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/opt_neuron/#console-output_1","title":"Console Output","text":"<pre><code>$ python run_opt_neuron_from_neuron.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nOptNeuron: Initialize OptNeuron... do not create anything with ANNarchy before!\nOptNeuron: WARNING: attributes ['I_app', 'r'] are not used/initialized.\nchecking neuron_models, experiment, get_loss...Done\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:03&lt;00:00, 26.96gen/s, best loss: 0.00000]\na 5.99999999677215\nb 2.8379565285300652e-08\n['a', 'b', 'logbook', 'deap_pop', 'loss', 'all_loss', 'std', 'results', 'results_soll']\n</code></pre>"},{"location":"examples/plot_recordings/","title":"Plot Recordings","text":""},{"location":"examples/plot_recordings/#introduction","title":"Introduction","text":"<p>This example demonstrates how to plot recordings (from CompNeuroMonitors) using the PlotRecordings class. The different plotting formats for spiking and non-spiking data (populations and projections) are demonstrated.</p> <p>This example loads data generated with other example run_and_monitor_simulations.py.</p>"},{"location":"examples/plot_recordings/#code","title":"Code","text":"<pre><code>from CompNeuroPy import load_variables, PlotRecordings\n\n\ndef main():\n    ### load data generated with other example \"run_and_monitor_simulations.py\"\n    loaded_dict = load_variables(\n        name_list=[\"recordings\", \"recording_times\", \"increase_rates_pop_info\"],\n        path=\"run_and_monitor_simulations/\",\n    )\n\n    ### define what should be plotted in which subplot, here 14 subplots are defined to\n    ### demonstrate the different plotting formats for spiking and non-spiking variables\n    plan_dict = {\n        \"position\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14],\n        \"compartment\": [\n            \"first_poisson\",\n            \"first_poisson\",\n            \"first_poisson\",\n            \"first_poisson\",\n            \"first_poisson\",\n            \"second_poisson\",\n            \"second_poisson\",\n            \"second_poisson\",\n            \"second_poisson\",\n            \"ampa_proj\",\n            \"ampa_proj\",\n            \"ampa_proj\",\n            \"ampa_proj\",\n        ],\n        \"variable\": [\n            \"spike\",\n            \"spike\",\n            \"spike\",\n            \"spike\",\n            \"spike\",\n            \"p\",\n            \"p\",\n            \"p\",\n            \"p\",\n            \"w\",\n            \"w\",\n            \"w\",\n            \"w\",\n        ],\n        \"format\": [\n            \"raster\",\n            \"mean\",\n            \"hybrid\",\n            \"interspike\",\n            \"cv\",\n            \"line\",\n            \"line_mean\",\n            \"matrix\",\n            \"matrix_mean\",\n            \"line\",\n            \"line_mean\",\n            \"matrix\",\n            \"matrix_mean\",\n        ],\n    }\n\n    ### plot first chunk\n    PlotRecordings(\n        figname=\"run_and_monitor_simulations/my_two_poissons_chunk_0.png\",\n        recordings=loaded_dict[\"recordings\"],\n        recording_times=loaded_dict[\"recording_times\"],\n        shape=(3, 5),\n        plan=plan_dict,\n    )\n    ### plot second chunk\n    PlotRecordings(\n        figname=\"run_and_monitor_simulations/my_two_poissons_chunk_1.png\",\n        recordings=loaded_dict[\"recordings\"],\n        recording_times=loaded_dict[\"recording_times\"],\n        shape=(3, 5),\n        plan=plan_dict,\n        chunk=1,\n    )\n\n    return 1\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/plot_recordings/#console-output","title":"Console Output","text":"<pre><code>$ python plot_recordings.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nGenerate fig run_and_monitor_simulations/my_two_poissons_chunk_0.png... Done\n\nGenerate fig run_and_monitor_simulations/my_two_poissons_chunk_1.png... Done\n</code></pre>"},{"location":"examples/run_and_monitor_simulations/","title":"Generate Simulations","text":""},{"location":"examples/run_and_monitor_simulations/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the CompNeuroSim class to define simulations. It is shown how to define the simulation functions, requirements and how to use the simulation information object.</p> <p>This example imports the \"my_model\" from other example create_model.py and saves recorded data used in other example plot_recordings.py.</p>"},{"location":"examples/run_and_monitor_simulations/#code","title":"Code","text":"<pre><code>import numpy as np\nfrom CompNeuroPy import (\n    CompNeuroMonitors,\n    CompNeuroSim,\n    ReqPopHasAttr,\n    save_variables,\n    CompNeuroModel,\n)\nfrom ANNarchy import (\n    simulate,\n    get_population,\n    Population,\n    Neuron,\n    Projection,\n    Synapse,\n    Uniform,\n)\nfrom CompNeuroPy.examples.create_model import my_model\n\n\n### CompNeuroSim is a class to define simulations\n### It requires a simulation function, which we will define here:\ndef set_rates(pop_name: str, rates: float = 0.0, duration: float = 0.0):\n    \"\"\"\n    Sets the rates variable of a population given by pop_name and simulates duration ms.\n\n    Args:\n        pop_name (str):\n            name of the population\n        rates (float, optional):\n            rates variable of the population\n        duration (float, optional):\n            duration of the simulation in ms\n    \"\"\"\n    ### set rates and simulate\n    get_population(pop_name).rates = rates\n    simulate(duration)\n\n\n### Also create a second more complex simulation function\ndef increase_rates(\n    pop_name: str | list[str],\n    rate_step: float = 0.0,\n    time_step: float = 0.0,\n    nr_steps: int = 0,\n):\n    \"\"\"\n    Increase rates variable of population(s).\n\n    Args:\n        pop_name (str or list of str):\n            name of population(s)\n        rate_step (float, optional):\n            increase of rate with each step, initial step = current rates of pop\n        time_step (float, optional):\n            duration of each step in ms\n        nr_steps (int, optional):\n            number of steps\n    \"\"\"\n\n    ### convert single pop into list\n    pop_name_list = pop_name\n    if not (isinstance(pop_name_list, list)):\n        pop_name_list = [pop_name_list]\n\n    ### define initial value for rates for each pop (assume all neurons have same rates)\n    start_rate_arr = np.array(\n        [get_population(pop_name).rates[0] for pop_name in pop_name_list]\n    )\n\n    ### simulate all steps\n    for step in range(nr_steps):\n        ### calculate rates for each pop\n        rates_arr = step * rate_step + start_rate_arr\n        ### set rates variable of all populations\n        for pop_idx, pop_name in enumerate(pop_name_list):\n            set_rates(\n                pop_name, rates=rates_arr[pop_idx], duration=0\n            )  # use already defined simulation set_rates\n        ### then simulate step\n        set_rates(pop_name_list[0], rates=rates_arr[0], duration=time_step)\n\n    ### simulation_functions can return some information which may be helpful later\n    ### the simulation arguments do not need to be returned, since they are accessible\n    ### through the CompNeuroSim object anyway (see below)\n    return {\"duration\": time_step * nr_steps, \"d_rates\": rate_step * nr_steps}\n\n\n### see below why we need this function\ndef extend_model(my_model: CompNeuroModel):\n    \"\"\"\n    Create a simple projections and a projection with decaying weights.\n\n    Args:\n        my_model (CompNeuroModel):\n            model to which the projection should be added\n    \"\"\"\n\n    ### create a simple population for later use\n    Population(1, neuron=Neuron(equations=\"r=0\"), name=\"simple_pop\")\n\n    ### create a projection with decaying weights to demonstrate recording of projection\n    proj = Projection(\n        pre=my_model.populations[0],\n        post=my_model.populations[1],\n        target=\"ampa\",\n        synapse=Synapse(parameters=\"tau=500\", equations=\"dw/dt=-w/tau\"),\n        name=\"ampa_proj\",\n    )\n    proj.connect_all_to_all(weights=Uniform(1.0, 2.0))\n\n\ndef main():\n    ### create and compile the model from other example \"create_model.py\"\n    my_model.create(do_compile=False)\n\n    ### extend the model to demonstrate the functionality of CompNeuroSim requirements\n    ### (see below) and the recording of projections (recorded data will be used in\n    ### other example \"plot_recordings.py\")\n    extend_model(my_model)\n    my_model.compile()\n\n    ### Define Monitors, recording p and spike from both model populations with periods\n    ### of 10 ms and 15 ms and the weights of the ampa projection with period of 10 ms\n    monitor_dictionary = {\n        f\"{my_model.populations[0]};10\": [\"p\", \"spike\"],\n        f\"{my_model.populations[1]};15\": [\"p\", \"spike\"],\n        \"ampa_proj;10\": [\"w\"],\n    }\n    mon = CompNeuroMonitors(monitor_dictionary)\n\n    ### Now use CompNeuroSim to define a simulation. Use the previously defined\n    ### simulation functions and define their arguments as kwargs dictionary. Give the\n    ### simulation a name and description and you can also define requirements for the\n    ### simulation. Here, for example, we require that the populations contain the\n    ### attribute 'rates'. One can define multiple requirements in a list of\n    ### dictionaries. The arguments of the requirements can be inherited from the\n    ### simulation kwargs by using the syntax 'simulation_kwargs.&lt;kwarg_name&gt;'.\n    ### The monitor object is also given to the simulation, so that the simulation\n    ### runs can be automatically associated with the monitor recording chunks.\n    increase_rates_pop = CompNeuroSim(\n        simulation_function=increase_rates,\n        simulation_kwargs={\n            \"pop_name\": my_model.populations[0],\n            \"rate_step\": 10,\n            \"time_step\": 100,\n            \"nr_steps\": 15,\n        },\n        name=\"increase_rates_pop\",\n        description=\"increase rates variable of pop\",\n        requirements=[\n            {\"req\": ReqPopHasAttr, \"pop\": \"simulation_kwargs.pop_name\", \"attr\": \"rates\"}\n        ],\n        monitor_object=mon,\n    )\n\n    ### Now let's use this simulation\n    ### Simulate 500 ms without recordings and then run the simulation\n    simulate(500)\n    mon.start()\n    increase_rates_pop.run()\n\n    ### resetting monitors and model, creating new recording chunk\n    mon.reset()\n\n    ### again simulate 700 ms without recording\n    ### then run the simulation with different simulation kwargs (for all populations)\n    mon.pause()\n    simulate(700)\n    mon.start()\n    increase_rates_pop.run({\"pop_name\": my_model.populations})\n    simulate(500)\n\n    ### now again change the pop_name kwarg but use the simple_pop population without\n    ### the required attribute 'rates'\n    ### this will raise an error\n    try:\n        increase_rates_pop.run({\"pop_name\": \"simple_pop\"})\n    except Exception as e:\n        print(\"\\n###############################################\")\n        print(\n            \"Running simulation with population not containing attribute 'rates' causes the following error:\"\n        )\n        print(e)\n        print(\"###############################################\\n\")\n\n    ### get recordings and recording times from the CompNeuroMonitors object\n    recordings = mon.get_recordings()\n    recording_times = mon.get_recording_times()\n\n    ### get the simulation information object from the CompNeuroSim object\n    increase_rates_pop_info = increase_rates_pop.simulation_info()\n\n    ### save the recordings, recording times and simulation information\n    save_variables(\n        variable_list=[recordings, recording_times, increase_rates_pop_info],\n        name_list=[\"recordings\", \"recording_times\", \"increase_rates_pop_info\"],\n        path=\"run_and_monitor_simulations\",\n    )\n\n    ### print the information contained in the simulation information object\n    print(\"\\nA simulation object contains:\")\n    print(\"name\\n\", increase_rates_pop_info.name)\n    print(\"\\ndescription\\n\", increase_rates_pop_info.description)\n    print(\"\\nstart (for each run)\\n\", increase_rates_pop_info.start)\n    print(\"\\nend (for each run)\\n\", increase_rates_pop_info.end)\n    print(\"\\ninfo (for each run)\\n\", increase_rates_pop_info.info)\n    print(\"\\nkwargs (for each run)\\n\", increase_rates_pop_info.kwargs)\n    print(\"\\nmonitor chunk (for each run)\\n\", increase_rates_pop_info.monitor_chunk)\n\n    return 1\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/run_and_monitor_simulations/#console-output","title":"Console Output","text":"<pre><code>$ python run_and_monitor_simulations.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\ncreated model, other parameters: 1\nCompiling ...  OK \n\n###############################################\nRunning simulation with population not containing attribute 'rates' causes the following error:\nPopulation simple_pop does not contain attribute rates!\n\n###############################################\n\n\nA simulation object contains:\nname\n increase_rates_pop\n\ndescription\n increase rates variable of pop\n\nstart (for each run)\n [500.0, 700.0]\n\nend (for each run)\n [2000.0, 2200.0]\n\ninfo (for each run)\n [{'duration': 1500, 'd_rates': 150}, {'duration': 1500, 'd_rates': 150}]\n\nkwargs (for each run)\n [{'pop_name': 'first_poisson', 'rate_step': 10, 'time_step': 100, 'nr_steps': 15}, {'pop_name': ['first_poisson', 'second_poisson'], 'rate_step': 10, 'time_step': 100, 'nr_steps': 15}]\n\nmonitor chunk (for each run)\n [0, 1]\n</code></pre>"},{"location":"main/dbs_stimulator/","title":"DBS Stimulator","text":""},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator","title":"<code>CompNeuroPy.dbs.DBSstimulator</code>","text":"<p>Class for stimulating a population with DBS.</p> <p>Warning</p> <p>If you use auto_implement, pointers to the populations and projections of the model are not valid anymore (new populations and projections are created)! Use a CompNeuroPy model working with names of populations and projections anyway (recommended) or use the update_pointers method.</p> <p>Examples:</p> <pre><code>from ANNarchy import Population, Izhikevich, compile, simulate, setup\nfrom CompNeuroPy import DBSstimulator\n\n# setup ANNarchy\nsetup(dt=0.1)\n\n# create populations\npopulation1 = Population(10, neuron=Izhikevich, name=\"my_pop1\")\npopulation2 = Population(10, neuron=Izhikevich, name=\"my_pop2\")\n&gt;&gt;&gt;\n# create DBS stimulator\ndbs = DBSstimulator(\n    stimulated_population=population1,\n    population_proportion=0.5,\n    dbs_depolarization=30,\n    auto_implement=True,\n)\n\n# update pointers to correct populations\npopulation1, population2 = dbs.update_pointers(\n    pointer_list=[population1, population2]\n)\n\n# compile network\ncompile()\n\n# run simulation\n# 1000 ms without dbs\nsimulate(1000)\n# 1000 ms with dbs\ndbs.on()\nsimulate(1000)\n# 1000 ms without dbs\ndbs.off()\nsimulate(1000)\n</code></pre> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>class DBSstimulator:\n    \"\"\"\n    Class for stimulating a population with DBS.\n\n    !!! warning\n        If you use auto_implement, pointers to the populations and projections of\n        the model are not valid anymore (new populations and projections are\n        created)! Use a CompNeuroPy model working with names of populations and\n        projections anyway (recommended) or use the update_pointers method.\n\n    Examples:\n        ```python\n        from ANNarchy import Population, Izhikevich, compile, simulate, setup\n        from CompNeuroPy import DBSstimulator\n\n        # setup ANNarchy\n        setup(dt=0.1)\n\n        # create populations\n        population1 = Population(10, neuron=Izhikevich, name=\"my_pop1\")\n        population2 = Population(10, neuron=Izhikevich, name=\"my_pop2\")\n        &gt;&gt;&gt;\n        # create DBS stimulator\n        dbs = DBSstimulator(\n            stimulated_population=population1,\n            population_proportion=0.5,\n            dbs_depolarization=30,\n            auto_implement=True,\n        )\n\n        # update pointers to correct populations\n        population1, population2 = dbs.update_pointers(\n            pointer_list=[population1, population2]\n        )\n\n        # compile network\n        compile()\n\n        # run simulation\n        # 1000 ms without dbs\n        simulate(1000)\n        # 1000 ms with dbs\n        dbs.on()\n        simulate(1000)\n        # 1000 ms without dbs\n        dbs.off()\n        simulate(1000)\n        ```\n    \"\"\"\n\n    @check_types()\n    def __init__(\n        self,\n        stimulated_population: Population,\n        population_proportion: float = 1.0,\n        excluded_populations_list: list[Population] = [],\n        dbs_depolarization: float = 0.0,\n        orthodromic: bool = False,\n        antidromic: bool = False,\n        efferents: bool = False,\n        afferents: bool = False,\n        passing_fibres: bool = False,\n        passing_fibres_list: list[Projection] = [],\n        passing_fibres_strength: float | list[float] = 1.0,\n        sum_branches: bool = True,\n        dbs_pulse_frequency_Hz: float = 130.0,\n        dbs_pulse_width_us: float = 300.0,\n        axon_spikes_per_pulse: float = 1.0,\n        axon_rate_amp: float | dict[Population | str, float] = 1.0,\n        seed: int | None = None,\n        auto_implement: bool = False,\n        model: generate_model | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize DBS stimulator.\n\n        !!! warning\n            Do this before compiling the model!\n\n        Args:\n            stimulated_population (Population):\n                Population which is stimulated by DBS\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: 1.0.\n            excluded_populations_list (list, optional):\n                List of populations which are excluded from DBS effects, they are not\n                affected and their axons do not generate axon spikes. Default: [].\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: 0.0.\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically.\n                Default: False.\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: False.\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: False.\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: False.\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: False.\n            passing_fibres_list (list of Projections, optional):\n                List of projections which pass the DBS stimulated region and therefore\n                are activated by DBS. Default: [], also set passing_fibres True!\n            passing_fibres_strength (float or list of float, optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: 1.\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: True.\n            dbs_pulse_frequency_Hz (float, optional):\n                Frequency of the DBS pulse. Default: 130 Hz.\n            dbs_pulse_width_us (float, optional):\n                Width of the DBS pulse. Default: 300 us.\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: 1.\n            axon_rate_amp (float or dict of float, optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value)\n                You can specify the default value by using the key \"default\", e.g.\n                {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n                pop forward a rate of 1.0 during DBS. Default: 1.0.\n            seed (int, optional):\n                Seed for the random distribution of affected neurons based on\n                population_proportion. Default: None.\n            auto_implement (bool, optional):\n                If True, automatically implement DBS mechanisms to the model. Only\n                supported for Izhikevich spiking models and rate-coded models.\n                Default: False.\n                TODO test what happens with mixed models\n            model (generate_model, optional):\n                CompNeuroPy model which is used to automatically implement DBS\n                mechanisms, should not be compiled!. Default: None, i.e., use all\n                populations and projections of the current magic model\n        \"\"\"\n\n        if auto_implement:\n            ### recreate model with DBS mechanisms\n            ### give all variables containing Populations and Projections\n            ### and also recreate them during recreating the model\n            ### variables are:\n            ### - stimulated_population\n            ### - excluded_populations_list\n            ### - passing_fibres_list\n            ### - axon_rate_amp\n            if not isinstance(model, type(None)):\n                ### CompNeuroPy model given\n                ### recreate model with DBS mechanisms\n                create_dbs_model_obj = _CreateDBSmodelcnp(\n                    model,\n                    stimulated_population,\n                    excluded_populations_list,\n                    passing_fibres_list,\n                    axon_rate_amp,\n                )\n                ### get the new CompNeuroPy model\n                model = create_dbs_model_obj.model\n            else:\n                ### no CompNeuroPy model given --&gt; use all populations and projections of the current magic model\n                ### recreate model with DBS mechanisms\n                create_dbs_model_obj = _CreateDBSmodel(\n                    stimulated_population,\n                    excluded_populations_list,\n                    passing_fibres_list,\n                    axon_rate_amp,\n                )\n            ### get the new variables containing Populations and Projections\n            stimulated_population = create_dbs_model_obj.stimulated_population\n            excluded_populations_list = create_dbs_model_obj.excluded_populations_list\n            passing_fibres_list = create_dbs_model_obj.passing_fibres_list\n            axon_rate_amp = create_dbs_model_obj.axon_rate_amp\n\n        ### set parameters\n        self.stimulated_population = stimulated_population\n        self.population_proportion = population_proportion\n        self.excluded_populations_list = excluded_populations_list\n        self.dbs_depolarization = dbs_depolarization\n        self.orthodromic = orthodromic\n        self.antidromic = antidromic\n        self.efferents = efferents\n        self.afferents = afferents\n        self.passing_fibres = passing_fibres\n        self.passing_fibres_list = passing_fibres_list\n        self.passing_fibres_strength = passing_fibres_strength\n        self.sum_branches = sum_branches\n        self.dbs_pulse_width_us = dbs_pulse_width_us\n        self.axon_spikes_per_pulse = axon_spikes_per_pulse\n        self.axon_rate_amp = axon_rate_amp\n        self.seed = seed\n        self.model = model\n\n        ### ANNarchy constants for DBS\n        self._set_constants(dbs_pulse_frequency_Hz)\n\n        ### randomly select affected neurons i.e. create dbs_on_array\n        self.dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n\n    def _create_dbs_on_array(self, population_proportion: float, seed: int):\n        \"\"\"\n        Create an array with the shape of the stimulated population with ones and zeros\n        randomly distributed with the specified population_proportion.\n\n        Args:\n            population_proportion (float):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly\n            seed (int):\n                Seed for the random distribution of affected neurons based on\n                population_proportion\n\n        Returns:\n            dbs_on_array (np.array):\n                Array with the shape of the stimulated population with ones and zeros\n                randomly distributed with the specified population_proportion\n        \"\"\"\n        ### create random number generator\n        rng = np.random.default_rng(seed)\n        ### create an array of zeros with the shape of the population, then flatten it\n        dbs_on_array = np.zeros(self.stimulated_population.geometry).flatten()\n        ### get the number of affected neurons based on the population_proportion\n        number_of_affected_neurons = population_proportion * dbs_on_array.size\n        ### randomly ceil or floor the number of affected neurons\n        number_of_affected_neurons = int(\n            rng.choice(\n                [\n                    np.ceil(number_of_affected_neurons),\n                    np.floor(number_of_affected_neurons),\n                ]\n            )\n        )\n        ### insert ones to the dbs_on_array\n        dbs_on_array[:number_of_affected_neurons] = 1\n        ### shuffle array\n        rng.shuffle(dbs_on_array)\n        ### reshape array to the shape of the population\n        dbs_on_array = dbs_on_array.reshape(self.stimulated_population.geometry)\n        ### return array\n        return dbs_on_array\n\n    def _set_constants(self, dbs_pulse_frequency_Hz: float):\n        \"\"\"\n        Set constants for DBS.\n\n        Args:\n            dbs_pulse_frequency_Hz (float):\n                Frequency of the DBS pulse in Hz\n        \"\"\"\n        # pulse frequency:\n        Constant(\"dbs_pulse_frequency_Hz\", dbs_pulse_frequency_Hz)\n        # pulse width:\n        # Neumant et al.. 2023: 60us but Meier et al. 2022: 300us... 60us = 0.06ms is very small for ANNarchy simulations\n        Constant(\"dbs_pulse_width_us\", self.dbs_pulse_width_us)\n\n        ### add global function for DBS pulse\n        add_function(\n            \"pulse(time_ms) = ite(modulo(time_ms*1000, 1000000./dbs_pulse_frequency_Hz) &lt; dbs_pulse_width_us, 1., 0.)\"\n        )\n\n    def _axon_spikes_per_pulse_to_prob(self, axon_spikes_per_pulse: float):\n        \"\"\"\n        Convert number of axon spikes per pulse to probability of axon spikes per\n        timestep during DBS pulse\n\n        Args:\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n\n        Returns:\n            prob_axon_spike_time_step (float):\n                Probability of axon spikes per timestep during DBS pulse\n        \"\"\"\n        return np.clip(\n            (axon_spikes_per_pulse * 1000 * dt() / self.dbs_pulse_width_us), 0, 1\n        )\n\n    def _set_depolarization(self, dbs_depolarization: float | None = None):\n        \"\"\"\n        Set depolarization of population.\n\n        Args:\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: None,\n                i.e., use value from initialization\n        \"\"\"\n        ### either use given depolarization or use default value\n        if isinstance(dbs_depolarization, type(None)):\n            dbs_depolarization = self.dbs_depolarization\n\n        ### set depolarization of population\n        for pop in populations():\n            if pop == self.stimulated_population:\n                pop.dbs_depolarization = dbs_depolarization\n            else:\n                pop.dbs_depolarization = 0\n\n    def _set_axon_spikes(\n        self,\n        orthodromic: bool | None = None,\n        antidromic: bool | None = None,\n        efferents: bool | None = None,\n        afferents: bool | None = None,\n        passing_fibres: bool | None = None,\n        passing_fibres_strength: float | list[float] | None = None,\n        sum_branches: bool | None = None,\n        axon_spikes_per_pulse: float | None = None,\n        axon_rate_amp: float | dict[Population | str, float] | None = None,\n    ):\n        \"\"\"\n        Set axon spikes forwarding orthodromic\n\n        Args:\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically,\n                Default: None, i.e., use value from initialization\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: None, i.e., use value from\n                initialization\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: None, i.e., use value from initialization\n            passing_fibres_strength (float | list[float], optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: None, i.e., use value from initialization\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: None, i.e., use value from initialization\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: None, i.e., use\n                value from initialization\n            axon_rate_amp (float | dict[Population | str, float], optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value)\n                You can specify the default value by using the key \"default\", e.g.\n                {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n                pop forward a rate of 1.0 during DBS. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n\n        ### either use given orthodromic or use default value\n        if isinstance(orthodromic, type(None)):\n            orthodromic = self.orthodromic\n        ### either use given antidromic or use default value\n        if isinstance(antidromic, type(None)):\n            antidromic = self.antidromic\n        ### either use given efferents or use default value\n        if isinstance(efferents, type(None)):\n            efferents = self.efferents\n        ### either use given afferents or use default value\n        if isinstance(afferents, type(None)):\n            afferents = self.afferents\n        ### either use given afferents or use default value\n        if isinstance(passing_fibres, type(None)):\n            passing_fibres = self.passing_fibres\n        ### either use given passing_fibres_strength or use default value\n        if isinstance(passing_fibres_strength, type(None)):\n            passing_fibres_strength = self.passing_fibres_strength\n        ### either use given sum_branches or use default value\n        if isinstance(sum_branches, type(None)):\n            sum_branches = self.sum_branches\n        ### either use given axon_spikes_per_pulse or use default value\n        if isinstance(axon_spikes_per_pulse, type(None)):\n            axon_spikes_per_pulse = self.axon_spikes_per_pulse\n        ### either use given axon_rate_amp or use default value\n        if isinstance(axon_rate_amp, type(None)):\n            axon_rate_amp = self.axon_rate_amp\n\n        ### check if passing_fibres_strength is a list\n        if not isinstance(passing_fibres_strength, list):\n            passing_fibres_strength = [passing_fibres_strength] * len(\n                self.passing_fibres_list\n            )\n        ### check if axon_rate_amp is a dict or float\n        if isinstance(axon_rate_amp, dict):\n            ### check if default key is missing\n            if \"default\" not in axon_rate_amp.keys():\n                ### add the key \"default\" with the value 1.0 to the dict\n                axon_rate_amp[\"default\"] = 1.0\n        else:\n            ### create dict with default value\n            axon_rate_amp = {\"default\": axon_rate_amp}\n\n        ### deactivate DBS axon transmission\n        self._deactivate_axon_DBS()\n\n        ### activate orthodromic transmission for all projections\n        if orthodromic:\n            self._set_orthodromic(\n                efferents,\n                afferents,\n                passing_fibres,\n                passing_fibres_strength,\n                axon_spikes_per_pulse,\n                axon_rate_amp,\n            )\n\n        ### activate antidromic transmission for all populations\n        if antidromic:\n            self._set_antidromic(\n                efferents,\n                afferents,\n                passing_fibres,\n                passing_fibres_strength,\n                sum_branches,\n                axon_spikes_per_pulse,\n            )\n\n    def _deactivate_axon_DBS(self):\n        \"\"\"\n        Deactivate axon spikes forwarding for both orthodromic and antidromic.\n        \"\"\"\n        for pop in populations():\n            ### deactivate axon spike genearation for all populations\n            pop.prob_axon_spike = 0\n            pop.axon_rate_amp = 0\n            ### deactivate antidromic transmission for all populations\n            pop.antidromic = 0\n            pop.antidromic_prob = 0\n\n        ### deactivate orthodromic transmission for all projections\n        for proj in projections():\n            proj.axon_transmission = 0\n            proj.p_axon_spike_trans = 0\n\n    def _set_orthodromic(\n        self,\n        efferents: bool,\n        afferents: bool,\n        passing_fibres: bool,\n        passing_fibres_strength: list[float],\n        axon_spikes_per_pulse: float,\n        axon_rate_amp: dict[Population | str, float],\n    ):\n        \"\"\"\n        Set orthodromic axon spikes forwarding.\n\n        Args:\n            efferents (bool):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            afferents (bool):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            passing_fibres (bool):\n                If True, DBS affects the passing fibres of the stimulated population\n                (orthodromic and/or antidromic have to be True too and there have to\n                be passing fibres in the passing_fibres_list)\n            passing_fibres_strength (list[float]):\n                List of float values between 0 and 1 defining how strong the passing\n                fibres are activated by DBS (0: not activated, 1: fully activated\n                like projections in DBS stimulated region)\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n            axon_rate_amp (dict[Population | str, float]):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded\n                on axons caused by DBS. The dictionary has to contain the key\n                \"default\" with the default value for all projections and can contain\n                keys for each population with a different value for the axon_rate of\n                the efferent axons of this population.\n        \"\"\"\n        if efferents:\n            ### activate all efferent projections\n            projection_list = projections(pre=self.stimulated_population)\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.post in self.excluded_populations_list:\n                    continue\n                ### activate axon transmission\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = 1\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n        if afferents:\n            ### activate all afferent projections\n            projection_list = projections(post=self.stimulated_population)\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.pre in self.excluded_populations_list:\n                    continue\n                ### activate axon transmission\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = 1\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n        if passing_fibres:\n            ### activate all passing projections\n            for proj_idx, proj in enumerate(self.passing_fibres_list):\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = passing_fibres_strength[proj_idx]\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n    def _set_antidromic(\n        self,\n        efferents: bool,\n        afferents: bool,\n        passing_fibres: bool,\n        passing_fibres_strength: list[float],\n        sum_branches: bool,\n        axon_spikes_per_pulse: float,\n    ):\n        \"\"\"\n        Set antidromic axon spikes forwarding.\n\n        Args:\n            efferents (bool):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            afferents (bool):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            passing_fibres (bool):\n                If True, DBS affects the passing fibres of the stimulated population\n                (orthodromic and/or antidromic have to be True too and there have to\n                be passing fibres in the passing_fibres_list)\n            passing_fibres_strength (list[float]):\n                List of float values between 0 and 1 defining how strong the passing\n                fibres are activated by DBS (0: not activated, 1: fully activated\n                like projections in DBS stimulated region)\n            sum_branches (bool):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n        \"\"\"\n\n        if efferents:\n            ### activate all efferent projections, i.e. antodromic activation of stimulated population\n            pop = self.stimulated_population\n            pop.antidromic = 1\n            pop.antidromic_prob = 1\n            pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                axon_spikes_per_pulse\n            )\n        if afferents:\n            ### activate all afferent projections, i.e. all presynaptic populations of stimulated population\n            ### get presynaptic projections\n            projection_list = projections(post=self.stimulated_population)\n            ### get presynaptic populations from projections\n            presyn_pop_list = []\n            presyn_pop_name_list = []\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.pre in self.excluded_populations_list:\n                    continue\n                ### check if presynaptic population is already in list\n                if proj.pre.name not in presyn_pop_name_list:\n                    presyn_pop_name_list.append(proj.pre.name)\n                    presyn_pop_list.append(proj.pre)\n            ### set antidromic for all presynaptic populations\n            for pop in presyn_pop_list:\n                pop.antidromic = 1\n                pop.antidromic_prob = np.mean(self.stimulated_population.dbs_on)\n                pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n        if passing_fibres:\n            ### get presynaptic populations from passing fibres projections\n            presyn_pop_list = []\n            presyn_pop_name_list = []\n            for proj in self.passing_fibres_list:\n                ### check if presynaptic population is already in list\n                if proj.pre.name not in presyn_pop_name_list:\n                    presyn_pop_name_list.append(proj.pre.name)\n                    presyn_pop_list.append(proj.pre)\n            ### get antidomic_prob for each presynatic population with the passing_fibres_strength\n            antidromic_prob_list = [0] * len(presyn_pop_list)\n            for pop_idx, pop in enumerate(presyn_pop_list):\n                ### get all passing fibres and their strength of a presynaptic pop\n                passing_fibres_strength_of_pop_list = []\n                for proj_idx, proj in enumerate(self.passing_fibres_list):\n                    if proj.pre.name == pop.name:\n                        passing_fibres_strength_of_pop_list.append(\n                            passing_fibres_strength[proj_idx]\n                        )\n                ### check if the probs of the single axon branches should be summed up\n                ### if for example a presynaptic pop contributes to two passing fibres, the axons of the presynaptic pop split up into two branches\n                ### thus, if these two branches are both stimulated, they both forward APs antidromic\n                ### thus, sum up the antidromic_prob of the single branches to obtain the antidromic spikes which affect the presynaptic pop\n                ### if sum_branches is False, then this would represent that the stimulation at the axon is before it splits up into multiple branches and there should not be different passing_fibres_strengths for the same presynaptic pop\n                if sum_branches:\n                    antidromic_prob_list[pop_idx] = sum(\n                        passing_fibres_strength_of_pop_list\n                    )\n                else:\n                    if len(set(passing_fibres_strength_of_pop_list)) != 1:\n                        ### list contains different values\n                        raise ValueError(\n                            \"Different passing fibres strengths for the same presynaptic population detected. This is not possible if sum_branches is False.\"\n                        )\n                    ### all values are the same, thus take the first one\n                    antidromic_prob_list[pop_idx] = passing_fibres_strength_of_pop_list[\n                        0\n                    ]\n\n                ### TODO\n                ### if summing axon branches leads to a prob &gt; 1, then\n                ### the prob should be set to 1\n                ### the axon spike generation in this pop should be increased\n                ### and all axon spike transmissions from this pop should be decreased by the same factor\n                ### this is not implemented yet... maybe in the future\n                if antidromic_prob_list[pop_idx] &gt; 1:\n                    raise ValueError(\n                        \"Summing the passing fibres strengths of a presynaptic population leads to a antidromic spike probability &gt; 1. This is not possible yet.\"\n                    )\n\n            ### set antidromic for all presynaptic populations\n            for pop_idx, pop in enumerate(presyn_pop_list):\n                pop.antidromic = 1\n                pop.antidromic_prob = antidromic_prob_list[pop_idx]\n                pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n\n    @check_types()\n    def on(\n        self,\n        population_proportion: float | None = None,\n        dbs_depolarization: float | None = None,\n        orthodromic: bool | None = None,\n        antidromic: bool | None = None,\n        efferents: bool | None = None,\n        afferents: bool | None = None,\n        passing_fibres: bool | None = None,\n        passing_fibres_strength: float | list[float] | None = None,\n        sum_branches: bool | None = None,\n        axon_spikes_per_pulse: float | None = None,\n        axon_rate_amp: float | dict[Population | str, float] | None = None,\n        seed: int | None = None,\n    ):\n        \"\"\"\n        Activate DBS.\n\n        Args:\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: None, i.e., use value from\n                initialization\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: None,\n                i.e., use value from initialization\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically.\n                Default: None, i.e., use value from initialization\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: None, i.e., use value from\n                initialization\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: None, i.e., use value from initialization\n            passing_fibres_strength (float | list[float], optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: None, i.e., use value from initialization\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: None, i.e., use value from initialization\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: None, i.e., use\n                value from initialization\n            axon_rate_amp (float | dict[Population | str, float], optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value). You can specify the default value by using the key \"default\",\n                e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations\n                except pop forward a rate of 1.0 during DBS. Default: None, i.e., use\n                value from initialization\n            seed (int, optional):\n                Seed for the random number generator. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n\n        ### set DBS on for all populations\n        ### also sets the proportion of affected neurons, call this before set_depolarization and set_axon_spikes!\n        self._set_dbs_on(population_proportion, seed)\n\n        ### set depolarization of population\n        self._set_depolarization(dbs_depolarization)\n\n        ### set axon spikes forwarding\n        self._set_axon_spikes(\n            orthodromic,\n            antidromic,\n            efferents,\n            afferents,\n            passing_fibres,\n            passing_fibres_strength,\n            sum_branches,\n            axon_spikes_per_pulse,\n            axon_rate_amp,\n        )\n\n    def _set_dbs_on(self, population_proportion: float | None, seed: int | None):\n        \"\"\"\n        Set DBS on for all populations, for the stimulated population only the specified\n        proportion is affected by DBS.\n\n        Args:\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: None, i.e., use value from\n                initialization\n            seed (int, optional):\n                Seed for the random number generator. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n        ### set parameters for the creation of the DBS on array\n        ### either use given population_proportion or use default value\n        if isinstance(population_proportion, type(None)):\n            population_proportion = self.population_proportion\n        ### either use given seed or use default value\n        if isinstance(seed, type(None)):\n            seed = self.seed\n\n        ### if seed and population_propotion are the same as in the initialization, use the same dbs_on_array\n        if seed == self.seed and population_proportion == self.population_proportion:\n            ### use the same dbs_on_array as in the initialization\n            dbs_on_array = self.dbs_on_array\n        else:\n            ### create new dbs_on_array\n            dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n\n        ### set DBS on for all populations\n        for pop in populations():\n            ### of the stimulated population only the specified proportion is affected by DBS\n            if pop == self.stimulated_population:\n                pop.dbs_on = dbs_on_array\n            else:\n                pop.dbs_on = 1\n\n    def off(self):\n        \"\"\"\n        Deactivate DBS.\n        \"\"\"\n        ### set DBS off for all populations\n        for pop in populations():\n            pop.dbs_on = 0\n            pop.prob_axon_spike = 0\n            pop.axon_rate_amp = 0\n\n        ### deactivate DBS axon transmission\n        self._deactivate_axon_DBS()\n\n    def update_pointers(self, pointer_list):\n        \"\"\"\n        Update pointers to populations and projections after recreating the model.\n\n        Args:\n            pointer_list (list):\n                List of pointers to populations and projections\n\n        Returns:\n            pointer_list_new (list):\n                List of pointers to populations and projections of the new model\n        \"\"\"\n        ### update pointers\n        pointer_list_new: list[Population | Projection] = []\n        for pointer in pointer_list:\n            compartment_name = pointer.name\n            if isinstance(pointer, Population):\n                pointer_list_new.append(get_population(compartment_name))\n            elif isinstance(pointer, Projection):\n                pointer_list_new.append(get_projection(compartment_name))\n            else:\n                raise TypeError(\n                    f\"Pointer {pointer} is neither a Population nor a Projection\"\n                )\n        return pointer_list_new\n</code></pre>"},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator.__init__","title":"<code>__init__(stimulated_population, population_proportion=1.0, excluded_populations_list=[], dbs_depolarization=0.0, orthodromic=False, antidromic=False, efferents=False, afferents=False, passing_fibres=False, passing_fibres_list=[], passing_fibres_strength=1.0, sum_branches=True, dbs_pulse_frequency_Hz=130.0, dbs_pulse_width_us=300.0, axon_spikes_per_pulse=1.0, axon_rate_amp=1.0, seed=None, auto_implement=False, model=None)</code>","text":"<p>Initialize DBS stimulator.</p> <p>Warning</p> <p>Do this before compiling the model!</p> <p>Parameters:</p> Name Type Description Default <code>stimulated_population</code> <code>Population</code> <p>Population which is stimulated by DBS</p> required <code>population_proportion</code> <code>float</code> <p>Proportion of the stimulated population which is affected by DBS, neurons are distributed randomly. Default: 1.0.</p> <code>1.0</code> <code>excluded_populations_list</code> <code>list</code> <p>List of populations which are excluded from DBS effects, they are not affected and their axons do not generate axon spikes. Default: [].</p> <code>[]</code> <code>dbs_depolarization</code> <code>float</code> <p>Depolarization effect of the DBS pulse to local soma. Default: 0.0.</p> <code>0.0</code> <code>orthodromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded orthodromically. Default: False.</p> <code>False</code> <code>antidromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded antidromically, only available in spiking networks. Default: False.</p> <code>False</code> <code>efferents</code> <code>bool</code> <p>If True, DBS affects the efferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>afferents</code> <code>bool</code> <p>If True, DBS affects the afferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>passing_fibres</code> <code>bool</code> <p>If True, DBS affects the passing fibres of the stimulated region defined in passing_fibres_list (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>passing_fibres_list</code> <code>list of Projections</code> <p>List of projections which pass the DBS stimulated region and therefore are activated by DBS. Default: [], also set passing_fibres True!</p> <code>[]</code> <code>passing_fibres_strength</code> <code>float or list of float</code> <p>Single value or list of float values between 0 and 1 defining how strong the passing fibres are activated by DBS (0: not activated, 1: fully activated like the projections in the DBS stimulated region). Default: 1.</p> <code>1.0</code> <code>sum_branches</code> <code>bool</code> <p>If True, the antidromic_prob of a presynaptic population (defining how many axon spikes affect the pop antidromically) of passing fibres is the sum of the passing_fibres_strengths of the single axon branches. Default: True.</p> <code>True</code> <code>dbs_pulse_frequency_Hz</code> <code>float</code> <p>Frequency of the DBS pulse. Default: 130 Hz.</p> <code>130.0</code> <code>dbs_pulse_width_us</code> <code>float</code> <p>Width of the DBS pulse. Default: 300 us.</p> <code>300.0</code> <code>axon_spikes_per_pulse</code> <code>float</code> <p>Number of average axon spikes per DBS pulse. Default: 1.</p> <code>1.0</code> <code>axon_rate_amp</code> <code>float or dict of float</code> <p>Similar to prob_axon_spike in spiking model. Which rate is forwarded on axons caused by DBS. You can specify this for each population individually by using a dictionary (keys = Population instances) axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate of 1.5 during DBS (all other affected projections forward the default value) You can specify the default value by using the key \"default\", e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except pop forward a rate of 1.0 during DBS. Default: 1.0.</p> <code>1.0</code> <code>seed</code> <code>int</code> <p>Seed for the random distribution of affected neurons based on population_proportion. Default: None.</p> <code>None</code> <code>auto_implement</code> <code>bool</code> <p>If True, automatically implement DBS mechanisms to the model. Only supported for Izhikevich spiking models and rate-coded models. Default: False. TODO test what happens with mixed models</p> <code>False</code> <code>model</code> <code>generate_model</code> <p>CompNeuroPy model which is used to automatically implement DBS mechanisms, should not be compiled!. Default: None, i.e., use all populations and projections of the current magic model</p> <code>None</code> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    stimulated_population: Population,\n    population_proportion: float = 1.0,\n    excluded_populations_list: list[Population] = [],\n    dbs_depolarization: float = 0.0,\n    orthodromic: bool = False,\n    antidromic: bool = False,\n    efferents: bool = False,\n    afferents: bool = False,\n    passing_fibres: bool = False,\n    passing_fibres_list: list[Projection] = [],\n    passing_fibres_strength: float | list[float] = 1.0,\n    sum_branches: bool = True,\n    dbs_pulse_frequency_Hz: float = 130.0,\n    dbs_pulse_width_us: float = 300.0,\n    axon_spikes_per_pulse: float = 1.0,\n    axon_rate_amp: float | dict[Population | str, float] = 1.0,\n    seed: int | None = None,\n    auto_implement: bool = False,\n    model: generate_model | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize DBS stimulator.\n\n    !!! warning\n        Do this before compiling the model!\n\n    Args:\n        stimulated_population (Population):\n            Population which is stimulated by DBS\n        population_proportion (float, optional):\n            Proportion of the stimulated population which is affected by DBS,\n            neurons are distributed randomly. Default: 1.0.\n        excluded_populations_list (list, optional):\n            List of populations which are excluded from DBS effects, they are not\n            affected and their axons do not generate axon spikes. Default: [].\n        dbs_depolarization (float, optional):\n            Depolarization effect of the DBS pulse to local soma. Default: 0.0.\n        orthodromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded orthodromically.\n            Default: False.\n        antidromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded antidromically,\n            only available in spiking networks. Default: False.\n        efferents (bool, optional):\n            If True, DBS affects the efferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: False.\n        afferents (bool, optional):\n            If True, DBS affects the afferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: False.\n        passing_fibres (bool, optional):\n            If True, DBS affects the passing fibres of the stimulated region defined\n            in passing_fibres_list (orthodromic and/or antidromic have to be True\n            too). Default: False.\n        passing_fibres_list (list of Projections, optional):\n            List of projections which pass the DBS stimulated region and therefore\n            are activated by DBS. Default: [], also set passing_fibres True!\n        passing_fibres_strength (float or list of float, optional):\n            Single value or list of float values between 0 and 1 defining how strong\n            the passing fibres are activated by DBS (0: not activated, 1: fully\n            activated like the projections in the DBS stimulated region).\n            Default: 1.\n        sum_branches (bool, optional):\n            If True, the antidromic_prob of a presynaptic population (defining how\n            many axon spikes affect the pop antidromically) of passing fibres is\n            the sum of the passing_fibres_strengths of the single axon branches.\n            Default: True.\n        dbs_pulse_frequency_Hz (float, optional):\n            Frequency of the DBS pulse. Default: 130 Hz.\n        dbs_pulse_width_us (float, optional):\n            Width of the DBS pulse. Default: 300 us.\n        axon_spikes_per_pulse (float, optional):\n            Number of average axon spikes per DBS pulse. Default: 1.\n        axon_rate_amp (float or dict of float, optional):\n            Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n            axons caused by DBS. You can specify this for each population\n            individually by using a dictionary (keys = Population instances)\n            axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n            of 1.5 during DBS (all other affected projections forward the default\n            value)\n            You can specify the default value by using the key \"default\", e.g.\n            {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n            pop forward a rate of 1.0 during DBS. Default: 1.0.\n        seed (int, optional):\n            Seed for the random distribution of affected neurons based on\n            population_proportion. Default: None.\n        auto_implement (bool, optional):\n            If True, automatically implement DBS mechanisms to the model. Only\n            supported for Izhikevich spiking models and rate-coded models.\n            Default: False.\n            TODO test what happens with mixed models\n        model (generate_model, optional):\n            CompNeuroPy model which is used to automatically implement DBS\n            mechanisms, should not be compiled!. Default: None, i.e., use all\n            populations and projections of the current magic model\n    \"\"\"\n\n    if auto_implement:\n        ### recreate model with DBS mechanisms\n        ### give all variables containing Populations and Projections\n        ### and also recreate them during recreating the model\n        ### variables are:\n        ### - stimulated_population\n        ### - excluded_populations_list\n        ### - passing_fibres_list\n        ### - axon_rate_amp\n        if not isinstance(model, type(None)):\n            ### CompNeuroPy model given\n            ### recreate model with DBS mechanisms\n            create_dbs_model_obj = _CreateDBSmodelcnp(\n                model,\n                stimulated_population,\n                excluded_populations_list,\n                passing_fibres_list,\n                axon_rate_amp,\n            )\n            ### get the new CompNeuroPy model\n            model = create_dbs_model_obj.model\n        else:\n            ### no CompNeuroPy model given --&gt; use all populations and projections of the current magic model\n            ### recreate model with DBS mechanisms\n            create_dbs_model_obj = _CreateDBSmodel(\n                stimulated_population,\n                excluded_populations_list,\n                passing_fibres_list,\n                axon_rate_amp,\n            )\n        ### get the new variables containing Populations and Projections\n        stimulated_population = create_dbs_model_obj.stimulated_population\n        excluded_populations_list = create_dbs_model_obj.excluded_populations_list\n        passing_fibres_list = create_dbs_model_obj.passing_fibres_list\n        axon_rate_amp = create_dbs_model_obj.axon_rate_amp\n\n    ### set parameters\n    self.stimulated_population = stimulated_population\n    self.population_proportion = population_proportion\n    self.excluded_populations_list = excluded_populations_list\n    self.dbs_depolarization = dbs_depolarization\n    self.orthodromic = orthodromic\n    self.antidromic = antidromic\n    self.efferents = efferents\n    self.afferents = afferents\n    self.passing_fibres = passing_fibres\n    self.passing_fibres_list = passing_fibres_list\n    self.passing_fibres_strength = passing_fibres_strength\n    self.sum_branches = sum_branches\n    self.dbs_pulse_width_us = dbs_pulse_width_us\n    self.axon_spikes_per_pulse = axon_spikes_per_pulse\n    self.axon_rate_amp = axon_rate_amp\n    self.seed = seed\n    self.model = model\n\n    ### ANNarchy constants for DBS\n    self._set_constants(dbs_pulse_frequency_Hz)\n\n    ### randomly select affected neurons i.e. create dbs_on_array\n    self.dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n</code></pre>"},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator.on","title":"<code>on(population_proportion=None, dbs_depolarization=None, orthodromic=None, antidromic=None, efferents=None, afferents=None, passing_fibres=None, passing_fibres_strength=None, sum_branches=None, axon_spikes_per_pulse=None, axon_rate_amp=None, seed=None)</code>","text":"<p>Activate DBS.</p> <p>Parameters:</p> Name Type Description Default <code>population_proportion</code> <code>float</code> <p>Proportion of the stimulated population which is affected by DBS, neurons are distributed randomly. Default: None, i.e., use value from initialization</p> <code>None</code> <code>dbs_depolarization</code> <code>float</code> <p>Depolarization effect of the DBS pulse to local soma. Default: None, i.e., use value from initialization</p> <code>None</code> <code>orthodromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded orthodromically. Default: None, i.e., use value from initialization</p> <code>None</code> <code>antidromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded antidromically, only available in spiking networks. Default: None, i.e., use value from initialization</p> <code>None</code> <code>efferents</code> <code>bool</code> <p>If True, DBS affects the efferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>afferents</code> <code>bool</code> <p>If True, DBS affects the afferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>passing_fibres</code> <code>bool</code> <p>If True, DBS affects the passing fibres of the stimulated region defined in passing_fibres_list (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>passing_fibres_strength</code> <code>float | list[float]</code> <p>Single value or list of float values between 0 and 1 defining how strong the passing fibres are activated by DBS (0: not activated, 1: fully activated like the projections in the DBS stimulated region). Default: None, i.e., use value from initialization</p> <code>None</code> <code>sum_branches</code> <code>bool</code> <p>If True, the antidromic_prob of a presynaptic population (defining how many axon spikes affect the pop antidromically) of passing fibres is the sum of the passing_fibres_strengths of the single axon branches. Default: None, i.e., use value from initialization</p> <code>None</code> <code>axon_spikes_per_pulse</code> <code>float</code> <p>Number of average axon spikes per DBS pulse. Default: None, i.e., use value from initialization</p> <code>None</code> <code>axon_rate_amp</code> <code>float | dict[Population | str, float]</code> <p>Similar to prob_axon_spike in spiking model. Which rate is forwarded on axons caused by DBS. You can specify this for each population individually by using a dictionary (keys = Population instances) axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate of 1.5 during DBS (all other affected projections forward the default value). You can specify the default value by using the key \"default\", e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except pop forward a rate of 1.0 during DBS. Default: None, i.e., use value from initialization</p> <code>None</code> <code>seed</code> <code>int</code> <p>Seed for the random number generator. Default: None, i.e., use value from initialization</p> <code>None</code> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>@check_types()\ndef on(\n    self,\n    population_proportion: float | None = None,\n    dbs_depolarization: float | None = None,\n    orthodromic: bool | None = None,\n    antidromic: bool | None = None,\n    efferents: bool | None = None,\n    afferents: bool | None = None,\n    passing_fibres: bool | None = None,\n    passing_fibres_strength: float | list[float] | None = None,\n    sum_branches: bool | None = None,\n    axon_spikes_per_pulse: float | None = None,\n    axon_rate_amp: float | dict[Population | str, float] | None = None,\n    seed: int | None = None,\n):\n    \"\"\"\n    Activate DBS.\n\n    Args:\n        population_proportion (float, optional):\n            Proportion of the stimulated population which is affected by DBS,\n            neurons are distributed randomly. Default: None, i.e., use value from\n            initialization\n        dbs_depolarization (float, optional):\n            Depolarization effect of the DBS pulse to local soma. Default: None,\n            i.e., use value from initialization\n        orthodromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded orthodromically.\n            Default: None, i.e., use value from initialization\n        antidromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded antidromically,\n            only available in spiking networks. Default: None, i.e., use value from\n            initialization\n        efferents (bool, optional):\n            If True, DBS affects the efferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: None,\n            i.e., use value from initialization\n        afferents (bool, optional):\n            If True, DBS affects the afferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: None,\n            i.e., use value from initialization\n        passing_fibres (bool, optional):\n            If True, DBS affects the passing fibres of the stimulated region defined\n            in passing_fibres_list (orthodromic and/or antidromic have to be True\n            too). Default: None, i.e., use value from initialization\n        passing_fibres_strength (float | list[float], optional):\n            Single value or list of float values between 0 and 1 defining how strong\n            the passing fibres are activated by DBS (0: not activated, 1: fully\n            activated like the projections in the DBS stimulated region).\n            Default: None, i.e., use value from initialization\n        sum_branches (bool, optional):\n            If True, the antidromic_prob of a presynaptic population (defining how\n            many axon spikes affect the pop antidromically) of passing fibres is\n            the sum of the passing_fibres_strengths of the single axon branches.\n            Default: None, i.e., use value from initialization\n        axon_spikes_per_pulse (float, optional):\n            Number of average axon spikes per DBS pulse. Default: None, i.e., use\n            value from initialization\n        axon_rate_amp (float | dict[Population | str, float], optional):\n            Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n            axons caused by DBS. You can specify this for each population\n            individually by using a dictionary (keys = Population instances)\n            axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n            of 1.5 during DBS (all other affected projections forward the default\n            value). You can specify the default value by using the key \"default\",\n            e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations\n            except pop forward a rate of 1.0 during DBS. Default: None, i.e., use\n            value from initialization\n        seed (int, optional):\n            Seed for the random number generator. Default: None, i.e., use value\n            from initialization\n    \"\"\"\n\n    ### set DBS on for all populations\n    ### also sets the proportion of affected neurons, call this before set_depolarization and set_axon_spikes!\n    self._set_dbs_on(population_proportion, seed)\n\n    ### set depolarization of population\n    self._set_depolarization(dbs_depolarization)\n\n    ### set axon spikes forwarding\n    self._set_axon_spikes(\n        orthodromic,\n        antidromic,\n        efferents,\n        afferents,\n        passing_fibres,\n        passing_fibres_strength,\n        sum_branches,\n        axon_spikes_per_pulse,\n        axon_rate_amp,\n    )\n</code></pre>"},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator.off","title":"<code>off()</code>","text":"<p>Deactivate DBS.</p> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>def off(self):\n    \"\"\"\n    Deactivate DBS.\n    \"\"\"\n    ### set DBS off for all populations\n    for pop in populations():\n        pop.dbs_on = 0\n        pop.prob_axon_spike = 0\n        pop.axon_rate_amp = 0\n\n    ### deactivate DBS axon transmission\n    self._deactivate_axon_DBS()\n</code></pre>"},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator.update_pointers","title":"<code>update_pointers(pointer_list)</code>","text":"<p>Update pointers to populations and projections after recreating the model.</p> <p>Parameters:</p> Name Type Description Default <code>pointer_list</code> <code>list</code> <p>List of pointers to populations and projections</p> required <p>Returns:</p> Name Type Description <code>pointer_list_new</code> <code>list</code> <p>List of pointers to populations and projections of the new model</p> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>def update_pointers(self, pointer_list):\n    \"\"\"\n    Update pointers to populations and projections after recreating the model.\n\n    Args:\n        pointer_list (list):\n            List of pointers to populations and projections\n\n    Returns:\n        pointer_list_new (list):\n            List of pointers to populations and projections of the new model\n    \"\"\"\n    ### update pointers\n    pointer_list_new: list[Population | Projection] = []\n    for pointer in pointer_list:\n        compartment_name = pointer.name\n        if isinstance(pointer, Population):\n            pointer_list_new.append(get_population(compartment_name))\n        elif isinstance(pointer, Projection):\n            pointer_list_new.append(get_projection(compartment_name))\n        else:\n            raise TypeError(\n                f\"Pointer {pointer} is neither a Population nor a Projection\"\n            )\n    return pointer_list_new\n</code></pre>"},{"location":"main/define_experiment/","title":"Define Experiments","text":""},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp","title":"<code>CompNeuroPy.experiment.CompNeuroExp</code>","text":"<p>Experiment combining simulations and recordings.</p> <p>Use this class as a parent class for your experiment. You have to additionally implement a run function which runs the simulations and controlls the recordings. The run function should return the results of the experiment by calling the results function of the CompNeuroExp class.</p> <p>Attributes:</p> Name Type Description <code>monitors</code> <code>CompNeuroMonitors</code> <p>CompNeuroMonitors object for recordings</p> <code>data</code> <code>dict</code> <p>dict for storing optional data</p> <p>Examples:</p> <pre><code>from CompNeuroPy import CompNeuroExp\nfrom ANNarchy import simulate\n\nclass MyExperiment(CompNeuroExp):\n    def run(self):\n        # run simulations and control recordings\n        self.monitors.start()\n        simulate(1000)\n        self.reset()\n        simulate(1000)\n        # store optional data\n        self.data[\"duration\"] = 2000\n        # return results\n        return self.results()\n</code></pre> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>class CompNeuroExp:\n    \"\"\"\n    Experiment combining simulations and recordings.\n\n    Use this class as a parent class for your experiment. You have to additionally\n    implement a run function which runs the simulations and controlls the recordings.\n    The run function should return the results of the experiment by calling the results\n    function of the CompNeuroExp class.\n\n    Attributes:\n        monitors (CompNeuroMonitors):\n            CompNeuroMonitors object for recordings\n        data (dict):\n            dict for storing optional data\n\n    Examples:\n        ```python\n        from CompNeuroPy import CompNeuroExp\n        from ANNarchy import simulate\n\n        class MyExperiment(CompNeuroExp):\n            def run(self):\n                # run simulations and control recordings\n                self.monitors.start()\n                simulate(1000)\n                self.reset()\n                simulate(1000)\n                # store optional data\n                self.data[\"duration\"] = 2000\n                # return results\n                return self.results()\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        monitors: CompNeuroMonitors | None = None,\n    ):\n        \"\"\"\n        Initialize the experiment.\n\n        Args:\n            monitors (CompNeuroMonitors):\n                CompNeuroMonitors object for recordings\n        \"\"\"\n        self.monitors = monitors\n        self.data = {}  # dict for optional data\n        self._model_state = None\n\n    def store_model_state(self, compartment_list: list[str]):\n        \"\"\"\n        Store the state of the model. If this is called, reset does not reset the model\n        to compile state but to the state stored here.\n\n        Args:\n            compartment_list (list[str]):\n                list of compartments to store the state of\n        \"\"\"\n        self._model_state = mf._get_all_attributes(compartment_list)\n\n    def reset_model_state(self):\n        \"\"\"\n        Reset the stored model state.\n        \"\"\"\n        self._model_state = None\n\n    def reset(\n        self,\n        populations=True,\n        projections=False,\n        synapses=False,\n        model=True,\n        model_state=True,\n        parameters=True,\n    ):\n        \"\"\"\n        Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the\n        experiment.\n\n        !!! warning\n            If you want the network to have the same state at the beginning of each\n            experiment run, you should call this function at the beginning of the run\n            function of the CompNeuroExp class (except using OptNeuron)! If you only\n            want to have the same time for the network at the beginning of each\n            experiment run, set populations, projections, and synapses to False and\n            model to True. If you want to set parameters during the experiment and also\n            reset the dynamic variables without resetting the parameters, set parameters\n            to False.\n\n        Args:\n            populations (bool, optional):\n                reset populations. Defaults to True.\n            projections (bool, optional):\n                reset projections. Defaults to False.\n            synapses (bool, optional):\n                reset synapses. Defaults to False.\n            model (bool, optional):\n                If False, do ignore all other arguments (the network state doesn't\n                change) and only reset the CompNeuroMonitors (creating new chunk)\n                Default: True.\n            model_state (bool, optional):\n                If True, reset the model to the stored model state instead of\n                compilation state (all compartments not stored in the model state will\n                still be resetted to compilation state). Default: True.\n            parameters (bool, optional):\n                If True, reset the parameters of the model (either to compile or stored\n                state). Default: True.\n        \"\"\"\n        reset_kwargs = {}\n        reset_kwargs[\"populations\"] = populations\n        reset_kwargs[\"projections\"] = projections\n        reset_kwargs[\"synapses\"] = synapses\n        reset_kwargs[\"monitors\"] = True\n\n        ### reset CompNeuroMonitors and ANNarchy model\n        if self.monitors is not None:\n            ### there are monitors, therefore use theri reset function\n            self.monitors.reset(model=model, **reset_kwargs, parameters=parameters)\n            ### after reset, set the state of the model to the stored state\n            if model_state and self._model_state is not None and model is True:\n                ### if parameters=False, they are not set\n                mf._set_all_attributes(self._model_state, parameters=parameters)\n        elif model is True:\n            if parameters is False:\n                ### if parameters=False, get parameters before reset and set them after\n                ### reset\n                parameters_dict = mf._get_all_parameters()\n            ### there are no monitors, but model should be resetted, therefore use\n            ### ANNarchy's reset function\n            reset(**reset_kwargs)\n            if parameters is False:\n                ### if parameters=False, set parameters after reset\n                mf._set_all_parameters(parameters_dict)\n            ### after reset, set the state of the model to the stored state\n            if model_state and self._model_state is not None:\n                ### if parameters=False, they are not set\n                mf._set_all_attributes(self._model_state, parameters=parameters)\n\n    def results(self):\n        \"\"\"\n        !!! warning\n            Call this function at the end of the run function of the CompNeuroExp class!\n\n        !!! warning\n            Calling this function resets the CompNeuroMonitors. For example, if you\n            simulate two recording chunks in the run function and you run the experiment\n            twice, you will get two recording chunks for each experiment run (not two\n            for the first and four for the second run). But ANNarchy is not resetted\n            automatically! So the network time and state (activity etc.) at the\n            beginning of the second run is the same as at the end of the first run. To\n            prevent this use the reset function of the CompNeuroExp class.\n\n        Returns:\n            results_obj (CompNeuroExp._ResultsCl):\n                Object with attributes:\n                    recordings (list):\n                        list of recordings\n                    recording_times (recording_times_cl):\n                        recording times object\n                    mon_dict (dict):\n                        dict of recorded variables of the monitors\n                    data (dict):\n                        dict with optional data stored during the experiment\n        \"\"\"\n        obj = self._ResultsCl()\n        if self.monitors is not None:\n            (\n                obj.recordings,\n                obj.recording_times,\n            ) = self.monitors.get_recordings_and_clear()\n            obj.mon_dict = self.monitors.mon_dict\n        else:\n            obj.recordings = []\n            obj.recording_times = None\n            obj.mon_dict = {}\n        ### need deepcopy here because experiment can be run mutliple times and within\n        ### experiment the entries of self.data can be changed, and without deepcopy\n        ### the data of older results objects would also be changed\n        obj.data = deepcopy(self.data)\n\n        return obj\n\n    class _ResultsCl:\n        \"\"\"\n        Class for storing the results of the experiment.\n\n        Attributes:\n            recordings (list):\n                list of recordings\n            recording_times (recording_times_cl):\n                recording times object\n            mon_dict (dict):\n                dict of recorded variables of the monitors\n            data (dict):\n                dict with optional data stored during the experiment\n        \"\"\"\n\n        def __init__(self) -&gt; None:\n            self.recordings: list\n            self.recording_times: RecordingTimes\n            self.mon_dict: dict\n            self.data: dict\n\n    def run(self) -&gt; _ResultsCl:\n        \"\"\"\n        !!! warning\n            This function has to be implemented by the user!\n        \"\"\"\n        raise NotImplementedError(\n            \"\"\"\n                You have to implement a run function which runs the simulations and\n                controlls the recordings. The run function should return the results of\n                the experiment by calling the results function of the CompNeuroExp class.\n            \"\"\"\n        )\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.__init__","title":"<code>__init__(monitors=None)</code>","text":"<p>Initialize the experiment.</p> <p>Parameters:</p> Name Type Description Default <code>monitors</code> <code>CompNeuroMonitors</code> <p>CompNeuroMonitors object for recordings</p> <code>None</code> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def __init__(\n    self,\n    monitors: CompNeuroMonitors | None = None,\n):\n    \"\"\"\n    Initialize the experiment.\n\n    Args:\n        monitors (CompNeuroMonitors):\n            CompNeuroMonitors object for recordings\n    \"\"\"\n    self.monitors = monitors\n    self.data = {}  # dict for optional data\n    self._model_state = None\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.store_model_state","title":"<code>store_model_state(compartment_list)</code>","text":"<p>Store the state of the model. If this is called, reset does not reset the model to compile state but to the state stored here.</p> <p>Parameters:</p> Name Type Description Default <code>compartment_list</code> <code>list[str]</code> <p>list of compartments to store the state of</p> required Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def store_model_state(self, compartment_list: list[str]):\n    \"\"\"\n    Store the state of the model. If this is called, reset does not reset the model\n    to compile state but to the state stored here.\n\n    Args:\n        compartment_list (list[str]):\n            list of compartments to store the state of\n    \"\"\"\n    self._model_state = mf._get_all_attributes(compartment_list)\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.reset_model_state","title":"<code>reset_model_state()</code>","text":"<p>Reset the stored model state.</p> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def reset_model_state(self):\n    \"\"\"\n    Reset the stored model state.\n    \"\"\"\n    self._model_state = None\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.reset","title":"<code>reset(populations=True, projections=False, synapses=False, model=True, model_state=True, parameters=True)</code>","text":"<p>Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the experiment.</p> <p>Warning</p> <p>If you want the network to have the same state at the beginning of each experiment run, you should call this function at the beginning of the run function of the CompNeuroExp class (except using OptNeuron)! If you only want to have the same time for the network at the beginning of each experiment run, set populations, projections, and synapses to False and model to True. If you want to set parameters during the experiment and also reset the dynamic variables without resetting the parameters, set parameters to False.</p> <p>Parameters:</p> Name Type Description Default <code>populations</code> <code>bool</code> <p>reset populations. Defaults to True.</p> <code>True</code> <code>projections</code> <code>bool</code> <p>reset projections. Defaults to False.</p> <code>False</code> <code>synapses</code> <code>bool</code> <p>reset synapses. Defaults to False.</p> <code>False</code> <code>model</code> <code>bool</code> <p>If False, do ignore all other arguments (the network state doesn't change) and only reset the CompNeuroMonitors (creating new chunk) Default: True.</p> <code>True</code> <code>model_state</code> <code>bool</code> <p>If True, reset the model to the stored model state instead of compilation state (all compartments not stored in the model state will still be resetted to compilation state). Default: True.</p> <code>True</code> <code>parameters</code> <code>bool</code> <p>If True, reset the parameters of the model (either to compile or stored state). Default: True.</p> <code>True</code> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def reset(\n    self,\n    populations=True,\n    projections=False,\n    synapses=False,\n    model=True,\n    model_state=True,\n    parameters=True,\n):\n    \"\"\"\n    Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the\n    experiment.\n\n    !!! warning\n        If you want the network to have the same state at the beginning of each\n        experiment run, you should call this function at the beginning of the run\n        function of the CompNeuroExp class (except using OptNeuron)! If you only\n        want to have the same time for the network at the beginning of each\n        experiment run, set populations, projections, and synapses to False and\n        model to True. If you want to set parameters during the experiment and also\n        reset the dynamic variables without resetting the parameters, set parameters\n        to False.\n\n    Args:\n        populations (bool, optional):\n            reset populations. Defaults to True.\n        projections (bool, optional):\n            reset projections. Defaults to False.\n        synapses (bool, optional):\n            reset synapses. Defaults to False.\n        model (bool, optional):\n            If False, do ignore all other arguments (the network state doesn't\n            change) and only reset the CompNeuroMonitors (creating new chunk)\n            Default: True.\n        model_state (bool, optional):\n            If True, reset the model to the stored model state instead of\n            compilation state (all compartments not stored in the model state will\n            still be resetted to compilation state). Default: True.\n        parameters (bool, optional):\n            If True, reset the parameters of the model (either to compile or stored\n            state). Default: True.\n    \"\"\"\n    reset_kwargs = {}\n    reset_kwargs[\"populations\"] = populations\n    reset_kwargs[\"projections\"] = projections\n    reset_kwargs[\"synapses\"] = synapses\n    reset_kwargs[\"monitors\"] = True\n\n    ### reset CompNeuroMonitors and ANNarchy model\n    if self.monitors is not None:\n        ### there are monitors, therefore use theri reset function\n        self.monitors.reset(model=model, **reset_kwargs, parameters=parameters)\n        ### after reset, set the state of the model to the stored state\n        if model_state and self._model_state is not None and model is True:\n            ### if parameters=False, they are not set\n            mf._set_all_attributes(self._model_state, parameters=parameters)\n    elif model is True:\n        if parameters is False:\n            ### if parameters=False, get parameters before reset and set them after\n            ### reset\n            parameters_dict = mf._get_all_parameters()\n        ### there are no monitors, but model should be resetted, therefore use\n        ### ANNarchy's reset function\n        reset(**reset_kwargs)\n        if parameters is False:\n            ### if parameters=False, set parameters after reset\n            mf._set_all_parameters(parameters_dict)\n        ### after reset, set the state of the model to the stored state\n        if model_state and self._model_state is not None:\n            ### if parameters=False, they are not set\n            mf._set_all_attributes(self._model_state, parameters=parameters)\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.results","title":"<code>results()</code>","text":"<p>Warning</p> <p>Call this function at the end of the run function of the CompNeuroExp class!</p> <p>Warning</p> <p>Calling this function resets the CompNeuroMonitors. For example, if you simulate two recording chunks in the run function and you run the experiment twice, you will get two recording chunks for each experiment run (not two for the first and four for the second run). But ANNarchy is not resetted automatically! So the network time and state (activity etc.) at the beginning of the second run is the same as at the end of the first run. To prevent this use the reset function of the CompNeuroExp class.</p> <p>Returns:</p> Name Type Description <code>results_obj</code> <code>_ResultsCl</code> <p>Object with attributes:     recordings (list):         list of recordings     recording_times (recording_times_cl):         recording times object     mon_dict (dict):         dict of recorded variables of the monitors     data (dict):         dict with optional data stored during the experiment</p> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def results(self):\n    \"\"\"\n    !!! warning\n        Call this function at the end of the run function of the CompNeuroExp class!\n\n    !!! warning\n        Calling this function resets the CompNeuroMonitors. For example, if you\n        simulate two recording chunks in the run function and you run the experiment\n        twice, you will get two recording chunks for each experiment run (not two\n        for the first and four for the second run). But ANNarchy is not resetted\n        automatically! So the network time and state (activity etc.) at the\n        beginning of the second run is the same as at the end of the first run. To\n        prevent this use the reset function of the CompNeuroExp class.\n\n    Returns:\n        results_obj (CompNeuroExp._ResultsCl):\n            Object with attributes:\n                recordings (list):\n                    list of recordings\n                recording_times (recording_times_cl):\n                    recording times object\n                mon_dict (dict):\n                    dict of recorded variables of the monitors\n                data (dict):\n                    dict with optional data stored during the experiment\n    \"\"\"\n    obj = self._ResultsCl()\n    if self.monitors is not None:\n        (\n            obj.recordings,\n            obj.recording_times,\n        ) = self.monitors.get_recordings_and_clear()\n        obj.mon_dict = self.monitors.mon_dict\n    else:\n        obj.recordings = []\n        obj.recording_times = None\n        obj.mon_dict = {}\n    ### need deepcopy here because experiment can be run mutliple times and within\n    ### experiment the entries of self.data can be changed, and without deepcopy\n    ### the data of older results objects would also be changed\n    obj.data = deepcopy(self.data)\n\n    return obj\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.run","title":"<code>run()</code>","text":"<p>Warning</p> <p>This function has to be implemented by the user!</p> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def run(self) -&gt; _ResultsCl:\n    \"\"\"\n    !!! warning\n        This function has to be implemented by the user!\n    \"\"\"\n    raise NotImplementedError(\n        \"\"\"\n            You have to implement a run function which runs the simulations and\n            controlls the recordings. The run function should return the results of\n            the experiment by calling the results function of the CompNeuroExp class.\n        \"\"\"\n    )\n</code></pre>"},{"location":"main/define_experiment/#full-example","title":"Full Example","text":"<p>A full example is available in the Examples.</p>"},{"location":"main/generate_models/","title":"Generate Models","text":""},{"location":"main/generate_models/#introduction","title":"Introduction","text":"<p>One can create a CompNeuroPy-model using the <code>CompNeuroModel</code> class. The <code>CompNeuroModel</code> class takes as one argument the <code>model_creation_function</code>. In this function a classical ANNarchy model is created (populations, projections). The <code>CompNeuroModel</code> class only adds a framework to the model. Neccessary for a CompNeuroPy-model is to define unique names for all populations and projections. Models are created in three steps:</p> <ol> <li>model initialization: the initialization of the <code>CompNeuroModel</code> object, initializes the framework of the model without creating the ANNarchy objects (populations, projections)</li> <li>model creation: create the ANNarchy objects (populations, projections), i.e., run the <code>model_creation function</code></li> <li>model compilation: compile all created models</li> </ol>"},{"location":"main/generate_models/#example","title":"Example","text":"<pre><code>from CompNeuroPy import CompNeuroModel\nmy_model = CompNeuroModel(model_creation_function=create_model,  ### the most important part, this function creates the model (populations, projections)\n                          model_kwargs={'a':1, 'b':2},           ### define the two arguments a and b of function create_model\n                          name='my_model',                       ### you can give the model a name\n                          description='my simple example model', ### you can give the model a description\n                          do_create=True,                        ### create the model directly\n                          do_compile=True,                       ### let the model (and all models created before) compile directly\n                          compile_folder_name='my_model')        ### name of the saved compilation folder\n</code></pre> <p>The following function could be the corresponding model_creation_function:</p> <pre><code>from ANNarchy import Population, Izhikevich\ndef create_model(a, b):\n    pop = Population(geometry=a, neuron=Izhikevich, name='Izh_pop_a') ### first population, size a\n    pop.b = 0                                                         ### some parameter adjustment\n    Population(geometry=b, neuron=Izhikevich, name='Izh_pop_b')       ### second population, size b\n</code></pre> <p>Here, two populations are created (both use built-in Izhikevich neuron model of ANNarchy). The function does not require a return value. It is important that all populations and projections have unique names.</p> <p>A more detailed example is available in the Examples.</p>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel","title":"<code>CompNeuroPy.generate_model.CompNeuroModel</code>","text":"<p>Class for creating and compiling a model.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>name of the model</p> <code>description</code> <code>str</code> <p>description of the model</p> <code>model_creation_function</code> <code>function</code> <p>function which creates the model</p> <code>compile_folder_name</code> <code>str</code> <p>name of the folder in which the model is compiled</p> <code>model_kwargs</code> <code>dict</code> <p>keyword arguments for model_creation_function</p> <code>populations</code> <code>list</code> <p>list of names of all populations of the model</p> <code>projections</code> <code>list</code> <p>list of names of all projections of the model</p> <code>created</code> <code>bool</code> <p>True if the model is created</p> <code>compiled</code> <code>bool</code> <p>True if the model is compiled</p> <code>attribute_df</code> <code>pandas dataframe</code> <p>dataframe containing all attributes of the model compartments</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>class CompNeuroModel:\n    \"\"\"\n    Class for creating and compiling a model.\n\n    Attributes:\n        name (str):\n            name of the model\n        description (str):\n            description of the model\n        model_creation_function (function):\n            function which creates the model\n        compile_folder_name (str):\n            name of the folder in which the model is compiled\n        model_kwargs (dict):\n            keyword arguments for model_creation_function\n        populations (list):\n            list of names of all populations of the model\n        projections (list):\n            list of names of all projections of the model\n        created (bool):\n            True if the model is created\n        compiled (bool):\n            True if the model is compiled\n        attribute_df (pandas dataframe):\n            dataframe containing all attributes of the model compartments\n    \"\"\"\n\n    _initialized_models = {}\n    _compiled_models = {}\n    _compiled_models_updated = False\n\n    @check_types()\n    def __init__(\n        self,\n        model_creation_function: Callable,\n        model_kwargs: dict | None = None,\n        name: str = \"model\",\n        description: str = \"\",\n        do_create: bool = True,\n        do_compile: bool = True,\n        compile_folder_name: str = \"annarchy\",\n    ):\n        \"\"\"\n        Initializes the CompNeuroModel class.\n\n        Args:\n            model_creation_function (function):\n                Function which creates the model.\n            model_kwargs (dict):\n                Keyword arguments for model_creation_function. Default: None.\n            name (str):\n                Name of the model. Default: \"model\".\n            description (str):\n                Description of the model. Default: \"\".\n            do_create (bool):\n                If True the model is created directly. Default: True.\n            do_compile (bool):\n                If True the model is compiled directly. Default: True.\n            compile_folder_name (str):\n                Name of the folder in which the model is compiled. Default: \"annarchy\".\n        \"\"\"\n        self.name = name\n        if name == \"model\":\n            self.name = name + str(self._nr_models())\n        self.description = description\n        self.model_creation_function = model_creation_function\n        self.compile_folder_name = compile_folder_name\n        self.model_kwargs = model_kwargs\n        self.populations = []\n        self.projections = []\n        self.created = False\n        self.compiled = False\n        self._attribute_df = None\n        self._attribute_df_compiled = False\n        if do_create:\n            self.create(do_compile=do_compile, compile_folder_name=compile_folder_name)\n\n    @property\n    def compiled(self):\n        \"\"\"\n        True if the model is compiled.\n        \"\"\"\n        ### check if ANNarchy was compiled and _compiled_models is not updated yet\n        if mf.annarchy_compiled() and not self._compiled_models_updated:\n            self._update_compiled_models()\n        return self._compiled_models[self.name]\n\n    @compiled.setter\n    def compiled(self, value):\n        \"\"\"\n        Setter for compiled property.\n        \"\"\"\n        self._compiled_models[self.name] = value\n\n    @property\n    def created(self):\n        \"\"\"\n        True if the model is created.\n        \"\"\"\n        return self._initialized_models[self.name]\n\n    @created.setter\n    def created(self, value):\n        \"\"\"\n        Setter for created property.\n        \"\"\"\n        self._initialized_models[self.name] = value\n\n    @property\n    def attribute_df(self):\n        \"\"\"\n        Dataframe containing all attributes of the model compartments.\n        \"\"\"\n        ### check if ANNarchy was compiled and _attribute_df is not updated yet\n        if mf.annarchy_compiled() and not self._attribute_df_compiled:\n            self._update_attribute_df_weights()\n        return self._attribute_df\n\n    def _update_compiled_models(self):\n        \"\"\"\n        Updates _compiled_models to True for all models.\n        \"\"\"\n        ### update _compiled_models\n        for key in self._compiled_models.keys():\n            self._compiled_models[key] = True\n        self._compiled_models_updated = True\n\n    def _update_attribute_df_weights(self):\n        \"\"\"\n        Updates _attribute_df for the weights of all projections.\n        \"\"\"\n        for proj_name in self.projections:\n            values = get_projection(proj_name).w\n            self._update_attribute_df(\n                compartment=proj_name, parameter_name=\"w\", parameter_value=values\n            )\n        self._attribute_df_compiled = True\n\n    def compile(self, compile_folder_name=None):\n        \"\"\"\n        Compiles a created model.\n\n        Args:\n            compile_folder_name (str, optional):\n                Name of the folder in which the model is compiled. Default: value from\n                initialization.\n        \"\"\"\n        ### check if this model is created\n        if self.created:\n            if compile_folder_name == None:\n                compile_folder_name = self.compile_folder_name\n\n            ### check if other models were initialized but not created --&gt; warn that they are not compiled\n            not_created_model_list = self._check_if_models_created()\n            if len(not_created_model_list) &gt; 0:\n                print(\n                    \"\\nWARNING during compile of model \"\n                    + self.name\n                    + \": There are initialized models which are not created, thus not compiled! models:\\n\"\n                    + \"\\n\".join(not_created_model_list)\n                    + \"\\n\"\n                )\n            mf.compile_in_folder(compile_folder_name, silent=True)\n            self.compiled = True\n\n            ### update attribute_df to compiled state, since weights are only available\n            ### after compilation\n            self._update_attribute_df_weights()\n        else:\n            print(\"\\n\")\n            assert False, (\n                \"ERROR during compile of model \"\n                + self.name\n                + \": Only compile the model after it has been created!\"\n            )\n\n    def create(self, do_compile=True, compile_folder_name=None):\n        \"\"\"\n        Creates a model and optionally compiles it directly.\n\n        Args:\n            do_compile (bool, optional):\n                If True the model is compiled directly. Default: True.\n            compile_folder_name (str, optional):\n                Name of the folder in which the model is compiled. Default: value from\n                initialization.\n        \"\"\"\n        if self.created:\n            print(\"model\", self.name, \"already created!\")\n        else:\n            initial_existing_model = mf.get_full_model()\n            ### create model populations and projections\n            if self.model_kwargs != None:\n                self.model_creation_function(**self.model_kwargs)\n            else:\n                self.model_creation_function()\n            self.created = True\n\n            ### check which populations and projections have been added\n            post_existing_model = mf.get_full_model()\n            ### save only added not all projections/populations\n            for initial_pop in initial_existing_model[\"populations\"]:\n                post_existing_model[\"populations\"].remove(initial_pop)\n            for initial_proj in initial_existing_model[\"projections\"]:\n                post_existing_model[\"projections\"].remove(initial_proj)\n            self.populations = post_existing_model[\"populations\"]\n            self.projections = post_existing_model[\"projections\"]\n\n            ### check if names of populations and projections are unique\n            self._check_double_compartments()\n\n            ### create parameter dictionary\n            self._attribute_df = self._get_attribute_df()\n\n            if do_compile:\n                self.compile(compile_folder_name)\n\n    def _check_if_models_created(self):\n        \"\"\"\n        Checks which CompNeuroPy models are created\n\n        Returns:\n            not_created_model_list (list):\n                list of names of all initialized CompNeuroPy models which are not\n                created yet\n        \"\"\"\n        not_created_model_list = []\n        for key in self._initialized_models.keys():\n            if self._initialized_models[key] == False:\n                not_created_model_list.append(key)\n\n        return not_created_model_list\n\n    def _nr_models(self):\n        \"\"\"\n        Returns:\n            nr_models (int):\n                The current number of initialized (not considering \"created\")\n                CompNeuroPy models\n        \"\"\"\n        return len(list(self._initialized_models.keys()))\n\n    def set_param(self, compartment, parameter_name, parameter_value):\n        \"\"\"\n        Sets the specified parameter of the specified compartment.\n\n        Args:\n            compartment (str):\n                name of model compartment\n            parameter_name (str):\n                name of parameter of the compartment\n            parameter_value (number or array-like with shape of compartment geometry):\n                the value or values of the parameter\n\n        Raises:\n            AssertionError: if model is not created\n            AssertionError: if compartment is neither a population nor a projection of\n                the model\n        \"\"\"\n        ### catch if model is not created\n        assert (\n            self.created == True\n        ), f\"ERROR set_param: model {self.name} has to be created before setting parameters!\"\n\n        ### check if compartment is in populations or projections\n        comp_in_pop = compartment in self.populations\n        comp_in_proj = compartment in self.projections\n\n        if comp_in_pop:\n            comp_obj = get_population(compartment)\n        elif comp_in_proj:\n            comp_obj = get_projection(compartment)\n        else:\n            assert (\n                comp_in_pop or comp_in_proj\n            ), f\"ERROR set_param: setting parameter {parameter_name} of compartment {compartment}. The compartment is neither a population nor a projection of the model {self.name}!\"\n\n        ### set the parameter value\n        setattr(comp_obj, parameter_name, parameter_value)\n\n        ### update the model attribute_df\n        self._update_attribute_df(compartment, parameter_name, parameter_value)\n\n    def _update_attribute_df(self, compartment, parameter_name, parameter_value):\n        \"\"\"\n        updates the attribute df for a specific paramter\n\n        Args:\n            compartment (str):\n                name of model compartment\n            parameter_name (str):\n                name of parameter of the compartment\n            parameter_value (number or array-like with shape of compartment geometry):\n                the value or values of the parameter\n        \"\"\"\n        paramter_mask = (\n            (self._attribute_df[\"compartment_name\"] == compartment).astype(int)\n            * (self._attribute_df[\"attribute_name\"] == parameter_name).astype(int)\n        ).astype(bool)\n        parameter_idx = np.arange(paramter_mask.size).astype(int)[paramter_mask][0]\n        min_val = af.get_minimum(parameter_value)\n        max_val = af.get_maximum(parameter_value)\n        if min_val != max_val:\n            self._attribute_df.at[parameter_idx, \"value\"] = f\"[{min_val}, {max_val}]\"\n        else:\n            self._attribute_df.at[parameter_idx, \"value\"] = str(min_val)\n        self._attribute_df.at[parameter_idx, \"definition\"] = \"modified\"\n\n    def _check_double_compartments(self):\n        \"\"\"\n        Goes over all compartments of the model and checks if compartment is only a\n        population or a projection and not both.\n\n        Raises:\n            AssertionError: if model is not created\n            AssertionError: if compartment is both a population and a projection\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.created == True\n        ), f\"ERROR model {self.name}: model has to be created before checking for double compartments!\"\n        ### only have to go over populations and check if they are also projections (go over projections not neccessary)\n        pop_in_projections_list = []\n        pop_in_projections = False\n        for pop_name in self.populations:\n            if pop_name in self.projections:\n                pop_in_projections_list.append(pop_name)\n                pop_in_projections = True\n\n        assert (\n            pop_in_projections == False\n        ), f\"ERROR model {self.name}: One or multiple compartments are both population and projection ({pop_in_projections_list}). Rename them!\"\n\n    def _get_attribute_df(self):\n        \"\"\"\n        Creates a dataframe containing the attributes of all model compartments.\n\n        Returns:\n            attribute_df (pandas dataframe):\n                dataframe containing all attributes of the model compartments\n\n        Raises:\n            AssertionError: if model is not created\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.created == True\n        ), f\"ERROR model {self.name}: model has to be created before creating paramteer dictionary!\"\n\n        ### create empty paramteter dict\n        attribute_dict = {\n            \"compartment_type\": [],\n            \"compartment_name\": [],\n            \"attribute_name\": [],\n            \"value\": [],\n            \"definition\": [],\n        }\n\n        ### fill paramter dict with population attributes\n        for pop in self.populations:\n            for attribute in vars(get_population(pop))[\"attributes\"]:\n                ### store min and max of attribute\n                ### create numpy array with getattr to use numpy min max function\n                values = np.array(\n                    [getattr(get_population(pop), attribute)]\n                    + [getattr(get_population(pop), attribute)]\n                )\n                attribute_dict[\"compartment_type\"].append(\"population\")\n                attribute_dict[\"compartment_name\"].append(pop)\n                attribute_dict[\"attribute_name\"].append(attribute)\n                if values.min() != values.max():\n                    attribute_dict[\"value\"].append(f\"[{values.min()}, {values.max()}]\")\n                else:\n                    attribute_dict[\"value\"].append(str(values.min()))\n                attribute_dict[\"definition\"].append(\"init\")\n\n        ### fill paramter dict with projection attributes\n        for proj in self.projections:\n            for attribute in vars(get_projection(proj))[\"attributes\"]:\n                ### store min and max of attribute\n                ### create numpy array with getattr to use numpy min max function\n                values = np.array(\n                    [getattr(get_projection(proj), attribute)]\n                    + [getattr(get_projection(proj), attribute)]\n                )\n                attribute_dict[\"compartment_type\"].append(\"projection\")\n                attribute_dict[\"compartment_name\"].append(proj)\n                attribute_dict[\"attribute_name\"].append(attribute)\n                if values.min() != values.max():\n                    attribute_dict[\"value\"].append(f\"[{values.min()}, {values.max()}]\")\n                else:\n                    attribute_dict[\"value\"].append(values.min())\n                attribute_dict[\"definition\"].append(\"init\")\n\n        ### return dataframe\n        return pd.DataFrame(attribute_dict)\n</code></pre>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.compiled","title":"<code>compiled</code>  <code>property</code> <code>writable</code>","text":"<p>True if the model is compiled.</p>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.created","title":"<code>created</code>  <code>property</code> <code>writable</code>","text":"<p>True if the model is created.</p>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.attribute_df","title":"<code>attribute_df</code>  <code>property</code>","text":"<p>Dataframe containing all attributes of the model compartments.</p>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.__init__","title":"<code>__init__(model_creation_function, model_kwargs=None, name='model', description='', do_create=True, do_compile=True, compile_folder_name='annarchy')</code>","text":"<p>Initializes the CompNeuroModel class.</p> <p>Parameters:</p> Name Type Description Default <code>model_creation_function</code> <code>function</code> <p>Function which creates the model.</p> required <code>model_kwargs</code> <code>dict</code> <p>Keyword arguments for model_creation_function. Default: None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the model. Default: \"model\".</p> <code>'model'</code> <code>description</code> <code>str</code> <p>Description of the model. Default: \"\".</p> <code>''</code> <code>do_create</code> <code>bool</code> <p>If True the model is created directly. Default: True.</p> <code>True</code> <code>do_compile</code> <code>bool</code> <p>If True the model is compiled directly. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: \"annarchy\".</p> <code>'annarchy'</code> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    model_creation_function: Callable,\n    model_kwargs: dict | None = None,\n    name: str = \"model\",\n    description: str = \"\",\n    do_create: bool = True,\n    do_compile: bool = True,\n    compile_folder_name: str = \"annarchy\",\n):\n    \"\"\"\n    Initializes the CompNeuroModel class.\n\n    Args:\n        model_creation_function (function):\n            Function which creates the model.\n        model_kwargs (dict):\n            Keyword arguments for model_creation_function. Default: None.\n        name (str):\n            Name of the model. Default: \"model\".\n        description (str):\n            Description of the model. Default: \"\".\n        do_create (bool):\n            If True the model is created directly. Default: True.\n        do_compile (bool):\n            If True the model is compiled directly. Default: True.\n        compile_folder_name (str):\n            Name of the folder in which the model is compiled. Default: \"annarchy\".\n    \"\"\"\n    self.name = name\n    if name == \"model\":\n        self.name = name + str(self._nr_models())\n    self.description = description\n    self.model_creation_function = model_creation_function\n    self.compile_folder_name = compile_folder_name\n    self.model_kwargs = model_kwargs\n    self.populations = []\n    self.projections = []\n    self.created = False\n    self.compiled = False\n    self._attribute_df = None\n    self._attribute_df_compiled = False\n    if do_create:\n        self.create(do_compile=do_compile, compile_folder_name=compile_folder_name)\n</code></pre>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.compile","title":"<code>compile(compile_folder_name=None)</code>","text":"<p>Compiles a created model.</p> <p>Parameters:</p> Name Type Description Default <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: value from initialization.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def compile(self, compile_folder_name=None):\n    \"\"\"\n    Compiles a created model.\n\n    Args:\n        compile_folder_name (str, optional):\n            Name of the folder in which the model is compiled. Default: value from\n            initialization.\n    \"\"\"\n    ### check if this model is created\n    if self.created:\n        if compile_folder_name == None:\n            compile_folder_name = self.compile_folder_name\n\n        ### check if other models were initialized but not created --&gt; warn that they are not compiled\n        not_created_model_list = self._check_if_models_created()\n        if len(not_created_model_list) &gt; 0:\n            print(\n                \"\\nWARNING during compile of model \"\n                + self.name\n                + \": There are initialized models which are not created, thus not compiled! models:\\n\"\n                + \"\\n\".join(not_created_model_list)\n                + \"\\n\"\n            )\n        mf.compile_in_folder(compile_folder_name, silent=True)\n        self.compiled = True\n\n        ### update attribute_df to compiled state, since weights are only available\n        ### after compilation\n        self._update_attribute_df_weights()\n    else:\n        print(\"\\n\")\n        assert False, (\n            \"ERROR during compile of model \"\n            + self.name\n            + \": Only compile the model after it has been created!\"\n        )\n</code></pre>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.create","title":"<code>create(do_compile=True, compile_folder_name=None)</code>","text":"<p>Creates a model and optionally compiles it directly.</p> <p>Parameters:</p> Name Type Description Default <code>do_compile</code> <code>bool</code> <p>If True the model is compiled directly. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: value from initialization.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def create(self, do_compile=True, compile_folder_name=None):\n    \"\"\"\n    Creates a model and optionally compiles it directly.\n\n    Args:\n        do_compile (bool, optional):\n            If True the model is compiled directly. Default: True.\n        compile_folder_name (str, optional):\n            Name of the folder in which the model is compiled. Default: value from\n            initialization.\n    \"\"\"\n    if self.created:\n        print(\"model\", self.name, \"already created!\")\n    else:\n        initial_existing_model = mf.get_full_model()\n        ### create model populations and projections\n        if self.model_kwargs != None:\n            self.model_creation_function(**self.model_kwargs)\n        else:\n            self.model_creation_function()\n        self.created = True\n\n        ### check which populations and projections have been added\n        post_existing_model = mf.get_full_model()\n        ### save only added not all projections/populations\n        for initial_pop in initial_existing_model[\"populations\"]:\n            post_existing_model[\"populations\"].remove(initial_pop)\n        for initial_proj in initial_existing_model[\"projections\"]:\n            post_existing_model[\"projections\"].remove(initial_proj)\n        self.populations = post_existing_model[\"populations\"]\n        self.projections = post_existing_model[\"projections\"]\n\n        ### check if names of populations and projections are unique\n        self._check_double_compartments()\n\n        ### create parameter dictionary\n        self._attribute_df = self._get_attribute_df()\n\n        if do_compile:\n            self.compile(compile_folder_name)\n</code></pre>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.set_param","title":"<code>set_param(compartment, parameter_name, parameter_value)</code>","text":"<p>Sets the specified parameter of the specified compartment.</p> <p>Parameters:</p> Name Type Description Default <code>compartment</code> <code>str</code> <p>name of model compartment</p> required <code>parameter_name</code> <code>str</code> <p>name of parameter of the compartment</p> required <code>parameter_value</code> <code>number or array-like with shape of compartment geometry</code> <p>the value or values of the parameter</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>if model is not created</p> <code>AssertionError</code> <p>if compartment is neither a population nor a projection of the model</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def set_param(self, compartment, parameter_name, parameter_value):\n    \"\"\"\n    Sets the specified parameter of the specified compartment.\n\n    Args:\n        compartment (str):\n            name of model compartment\n        parameter_name (str):\n            name of parameter of the compartment\n        parameter_value (number or array-like with shape of compartment geometry):\n            the value or values of the parameter\n\n    Raises:\n        AssertionError: if model is not created\n        AssertionError: if compartment is neither a population nor a projection of\n            the model\n    \"\"\"\n    ### catch if model is not created\n    assert (\n        self.created == True\n    ), f\"ERROR set_param: model {self.name} has to be created before setting parameters!\"\n\n    ### check if compartment is in populations or projections\n    comp_in_pop = compartment in self.populations\n    comp_in_proj = compartment in self.projections\n\n    if comp_in_pop:\n        comp_obj = get_population(compartment)\n    elif comp_in_proj:\n        comp_obj = get_projection(compartment)\n    else:\n        assert (\n            comp_in_pop or comp_in_proj\n        ), f\"ERROR set_param: setting parameter {parameter_name} of compartment {compartment}. The compartment is neither a population nor a projection of the model {self.name}!\"\n\n    ### set the parameter value\n    setattr(comp_obj, parameter_name, parameter_value)\n\n    ### update the model attribute_df\n    self._update_attribute_df(compartment, parameter_name, parameter_value)\n</code></pre>"},{"location":"main/generate_simulations/","title":"Generate Simulations","text":""},{"location":"main/generate_simulations/#introduction","title":"Introduction","text":"<p>A CompNeuroPy-simulation can be created using the <code>CompNeuroSim</code> class. Similar to the <code>CompNeuroModel</code> class, a function must be defined that contains the actual simulation (the simulation_function) and the <code>CompNeuroSim</code> object adds a clear framework. A <code>CompNeuroSim</code> is first initialized and can then be run multiple times.</p>"},{"location":"main/generate_simulations/#example","title":"Example:","text":"<pre><code>from CompNeuroPy import CompNeuroSim\nmy_simulation = CompNeuroSim(simulation_function=some_simulation,           ### the most important part, this function defines the simulation\n                            simulation_kwargs={'pop':pop1, 'duration':100}, ### define the two arguments pop and duration of simulation_function\n                            name='my_simulation',                           ### you can give the simulation a name\n                            description='my simple example simulation',     ### you can give the simulation a description\n                            requirements=[req],                             ### a list of requirements for the simulation (here only a single requirement)\n                            kwargs_warning=True,                            ### should a warning be printed if simulation kwargs change in future runs\n                            monitor_object = mon)                           ### the Monitors object which is used to record variables                   \n</code></pre> <p>A possible simulation_function could be: <pre><code>def some_simulation(pop, duration=1):\n    get_population(pop).a = 5  ### adjust paramter a of pop\n    get_population(pop).b = 5  ### adjust paramter b of pop\n    simulate(duration)         ### simulate the duration in ms\n\n    ### return some info\n    ### will later be accessible for each run\n    return {'paramter a': a, 'paramter b': b, 'a_x_duration': a*duration} \n</code></pre></p> <p>And a corresponding requirement could be: <pre><code>from CompNeuroPy import ReqPopHasAttr\nreq = {'req':ReqPopHasAttr, 'pop':pop1, 'attr':['a', 'b']}\n</code></pre> Here, one checks if the population pop1 contains the attributes a and b. The <code>ReqPopHasAttr</code> is a built-in requirements-class of CompNeuroPy (see below).</p> <p>A more detailed example is available in the Examples.</p>"},{"location":"main/generate_simulations/#simulation-information","title":"Simulation information","text":"<p>The function simulation_info() returns a <code>SimInfo</code> object which contains usefull information about the simulation runs (see below). The <code>SimInfo</code> object also provides usefull analysis functions associated with specific simulation functions. Currently it provides the get_current_arr() which returns arrays containing the input current for each time step of the built-in simulation functions current_step(), current_stim(), and current_ramp().</p>"},{"location":"main/generate_simulations/#simulation-functions","title":"Simulation functions","text":"<p>Just define a classic ANNarchy simulation in a function. Within the functions, the ANNarchy functions get_population() and get_projection() can be used to access the populations and projections using the population and projection names provided by a <code>CompNeuroModel</code>. The return value of the simulation function can later be retrieved from the <code>SimInfo</code> object (the info attribute) in a list containing the return value for each run of the simulation.</p>"},{"location":"main/generate_simulations/#example_1","title":"Example:","text":"<pre><code>from ANNarchy import simulate, get_population\n\ndef current_step(pop, t1=500, t2=500, a1=0, a2=100):\n    \"\"\"\n        stimulates a given population in two periods with two input currents\n\n        pop: population name of population, which should be stimulated with input current\n             neuron model of population has to contain \"I_app\" as input current in pA\n        t1/t2: times in ms before/after current step\n        a1/a2: current amplitudes before/after current step in pA\n    \"\"\"\n\n    ### save prev input current\n    I_prev = get_population(pop).I_app\n\n    ### first/pre current step simulation\n    get_population(pop).I_app = a1\n    simulate(t1)\n\n    ### second/post current step simulation\n    get_population(pop).I_app = a2\n    simulate(t2)\n\n    ### reset input current to previous value\n    get_population(pop).I_app = I_prev\n\n    ### return some additional information which could be usefull\n    return {'duration':t1+t2}\n</code></pre>"},{"location":"main/generate_simulations/#requirements","title":"Requirements","text":"<p>In order to perform simulations with models, the models must almost always fulfill certain requirements. For example, if the input current of a population is to be set, this population (or the neuron model) must of course have the corresponding variable. Such preconditions can be tested in advance with the <code>simulation_requirements</code> classes. They only need to contain a function run() to test the requirements (if requirements are not met, cause an error). In CompNeuroPy predefined <code>simulation_requirements</code> classes are available (CompNeuroPy.simulation_requirements; currently only <code>ReqPopHasAttr</code>). In the <code>CompNeuroSim</code> class, the requirements are passed as arguments in a list (see above). Each requirement (list entry) must be defined as a dictionary with keys req (the requirement class) and the arguments of the requirement class (e.g., pop and attr for the <code>ReqPopHasAttr</code>).</p> <p>Here two requirements are defined (both <code>ReqPopHasAttr</code>). All populations of my_model should contain the attribute (variable or parameter) 'I' and all populations of my_other_model should contain the attribute 'v':</p> <pre><code>req1 = {'req':ReqPopHasAttr, 'pop':my_model.populations, 'attr':'I'}\nreq2 = {'req':ReqPopHasAttr, 'pop':my_other_model.populations, 'attr':'v'}\nmy_two_model_simulation = CompNeuroSim(..., requirements=[req1, req2])\n</code></pre> <p>As described above, new simulation_kwargs can be passed to the run() function of a <code>CompNeuroSim</code> object. Thus, one could initially pass a particular model as simulation_kwargs and for a later run pass a different model. If the requirements are defined as shown above, it is not tested again whether the new model (e.g. my_third_model) also fulfills the requirements (because the requirements were defined for my_model and my_other_model). To work around this, an argument for a <code>simulation_requirements</code> class can also be linked to a simulation_kwargs entry. Thus, if new simulation_kwargs are used, also the simulation_requirements arguments adapt. This can be done using a string with the syntax \"simulation_kwargs.&lt;kwarg_name&gt;.&lt;optional_attribute_of_kwarg&gt;\", as shown in this example:</p> <pre><code>req1 = {'req':ReqPopHasAttr, 'pop':\"simulation_kwargs.model1.populations\", 'attr':'I'}\nreq2 = {'req':ReqPopHasAttr, 'pop':\"simulation_kwargs.model2.populations\", 'attr':'v'}\nmy_two_model_simulation = CompNeuroSim(simulation_kwargs={'model1':my_model, 'model2':my_other_model, 'parameter':5},\n                                        ...,\n                                        requirements=[req1, req2])\n...\nmy_two_model_simulation.run({'model1':my_third_model})\n</code></pre> <p>Due to the string \"simulation_kwargs.model1.populations\" the pop argument of req1 is now linked to model1 (defined in the simulation_kwargs). Thus, in the run where a different model (my_third_model) is used for model1, req1 is automatically tested for the new model1.</p>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim","title":"<code>CompNeuroPy.generate_simulation.CompNeuroSim</code>","text":"<p>Class for generating a CompNeuroPy simulation.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>class CompNeuroSim:\n    \"\"\"\n    Class for generating a CompNeuroPy simulation.\n    \"\"\"\n\n    _initialized_simulations = []\n\n    def __init__(\n        self,\n        simulation_function: Callable,\n        simulation_kwargs: dict | None = None,\n        name: str = \"simulation\",\n        description: str = \"\",\n        requirements: list | None = None,\n        kwargs_warning: bool = False,\n        monitor_object: CompNeuroMonitors | None = None,\n    ):\n        \"\"\"\n        Args:\n            simulation_function (function):\n                Function which runs the simulation.\n            simulation_kwargs (dict, optional):\n                Dictionary of arguments for the simulation_function. Default: None.\n            name (str, optional):\n                Name of the simulation. Default: \"simulation\".\n            description (str, optional):\n                Description of the simulation. Default: \"\".\n            requirements (list, optional):\n                List of requirements for the simulation. It's a list of dictionaries\n                which contain the requirement class itself (key: \"req\") and the\n                corresponding arguments (keys are the names of the arguments). The\n                arguments can be inherited from the simulation kwargs by using the\n                syntax 'simulation_kwargs.&lt;kwarg_name&gt;'. Default: None.\n            kwargs_warning (bool, optional):\n                If True, a warning is printed if the simulation_kwargs are changed\n                during the simulation. Default: False.\n            monitor_object (CompNeuroMonitors object, optional):\n                CompNeuroMonitors object to automatically track the recording chunk for each\n                simulation run. Default: None.\n        \"\"\"\n        # set simulation function\n        self.name = name\n        if name == \"simulation\":\n            self.name = name + str(self._nr_simulations())\n        self._initialized_simulations.append(self.name)\n        self.description = description\n        self.simulation_function = simulation_function\n        self.simulation_kwargs = simulation_kwargs\n        if requirements is None:\n            self.requirements = []\n        else:\n            self.requirements = requirements\n        self.start = []\n        self.end = []\n        self.info = []\n        self.kwargs = []\n        if kwargs_warning:\n            self._warned = False\n        else:\n            self._warned = True\n        self.monitor_object = monitor_object\n        if monitor_object is not None:\n            self.monitor_chunk = []\n        else:\n            self.monitor_chunk = None\n\n        ### test initial requirements\n        self._test_req(simulation_kwargs=simulation_kwargs)\n\n    def run(self, simulation_kwargs: dict | None = None):\n        \"\"\"\n        Runs the simulation function. With each run extend start, end list containing\n        start and end time of the corresponding run and the info list containing the\n        return value of the simulation function.\n\n        Args:\n            simulation_kwargs (dict, optional):\n                Temporary simulation kwargs which override the initialized simulation\n                kwargs. Default: None, i.e., use values from initialization.\n        \"\"\"\n\n        ### define the current simulation kwargs\n        if simulation_kwargs is not None:\n            if self.simulation_kwargs is not None:\n                ### not replace initialized kwargs completely but only the kwargs which are given\n                tmp_kwargs = self.simulation_kwargs.copy()\n                for key, val in simulation_kwargs.items():\n                    tmp_kwargs[key] = val\n            else:\n                ### there are no initial kwargs --&gt; only use the kwargs which are given\n                tmp_kwargs = simulation_kwargs\n            if not (self._warned) and len(self.requirements) &gt; 0:\n                print(\n                    \"\\nWARNING! run\",\n                    self.name,\n                    \"changed simulation kwargs, initial requirements may no longer be fulfilled!\\n\",\n                )\n                self._warned = True\n        else:\n            tmp_kwargs = self.simulation_kwargs\n\n        ### before each run, test requirements\n        self._test_req(simulation_kwargs=tmp_kwargs)\n\n        ### and append current simulation kwargs to the kwargs variable\n        self.kwargs.append(tmp_kwargs)\n\n        ### and append the current chunk of the monitors object to the chunk variable\n        if self.monitor_object is not None:\n            self.monitor_chunk.append(self.monitor_object.current_chunk())\n\n        ### run the simulation, store start and end simulation time\n        self.start.append(get_time())\n        if tmp_kwargs is not None:\n            self.info.append(self.simulation_function(**tmp_kwargs))\n        else:\n            self.info.append(self.simulation_function())\n        self.end.append(get_time())\n\n    def _nr_simulations(self):\n        \"\"\"\n        Returns the current number of initialized CompNeuroPy simulations.\n        \"\"\"\n        return len(self._initialized_simulations)\n\n    def _test_req(self, simulation_kwargs=None):\n        \"\"\"\n        Tests the initialized requirements with the current simulation_kwargs.\n        \"\"\"\n\n        if simulation_kwargs is None:  # --&gt; use the initial simulation_kwargs\n            simulation_kwargs = self.simulation_kwargs\n\n        for req in self.requirements:\n            ### check if requirement_kwargs are given besides the requirement itself\n            if len(list(req.keys())) &gt; 1:\n                ### remove the requirement itself from the kwargs\n                req_kwargs = ef.remove_key(req, \"req\")\n                ### check if req_kwargs reference to simulation_kwargs, if yes, use the\n                ### current simulation kwargs instead of the intial ones\n                for key, val in req_kwargs.items():\n                    if isinstance(val, str):\n                        val_split = val.split(\".\")\n                        ### check if val is a reference to simulation_kwargs\n                        if val_split[0] == \"simulation_kwargs\":\n                            if len(val_split) == 1:\n                                ### val is only simulation_kwargs\n                                req_kwargs = simulation_kwargs\n                            elif len(val_split) == 2:\n                                ### val is simulation_kwargs.something\n                                req_kwargs[key] = simulation_kwargs[val_split[1]]\n                            else:\n                                ### val is simulation_kwargs.something.something... e.g. key='pops' and val= 'simulation_kwargs.model.populations'\n                                req_kwargs[key] = eval(\n                                    'simulation_kwargs[\"'\n                                    + val_split[1]\n                                    + '\"].'\n                                    + \".\".join(val_split[2:])\n                                )\n                ### run the requirement using the current req_kwargs\n                req[\"req\"](**req_kwargs).run()\n\n            else:\n                ### a requirement is given without kwargs --&gt; just run it\n                req[\"req\"]().run()\n\n    def get_current_arr(self, dt, flat=False):\n        \"\"\"\n        Method exclusively for current_step simulation functions. Gets the current array\n        (input current value for each time step) of all runs.\n\n        !!! warning\n            This method will be removed soon. Use the get_current_arr method of the\n            SimInfo class instead.\n\n        Args:\n            dt (float):\n                Time step size of the simulation.\n            flat (bool, optional):\n                If True, returns a flattened array. Assumes that all runs are run\n                consecutively without brakes. Default: False, i.e., returns a list of\n                arrays.\n\n        Returns:\n            current_arr (list of arrays):\n                List of arrays containing the current values for each time step of each\n                run. If flat=True, returns a flattened array.\n        \"\"\"\n        assert (\n            self.simulation_function.__name__ == \"current_step\"\n        ), 'ERROR get_current_arr: Simulation has to be \"current_step\"!'\n        ### TODO: remove because deprecated\n        print(\n            \"WARNING get_current_arr function will only be available in SimInfo soon.\"\n        )\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t1 = self.kwargs[run][\"t1\"]\n            t2 = self.kwargs[run][\"t2\"]\n            a1 = self.kwargs[run][\"a1\"]\n            a2 = self.kwargs[run][\"a2\"]\n\n            if t1 &gt; 0 and t2 &gt; 0:\n                current_arr.append(\n                    np.concatenate(\n                        [\n                            np.ones(int(round(t1 / dt))) * a1,\n                            np.ones(int(round(t2 / dt))) * a2,\n                        ]\n                    )\n                )\n            elif t2 &gt; 0:\n                current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n            else:\n                current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    def simulation_info(self):\n        \"\"\"\n        Returns a SimInfo object containing the simulation information.\n\n        Returns:\n            simulation_info_obj (SimInfo):\n                Simulation information object.\n        \"\"\"\n\n        simulation_info_obj = SimInfo(\n            self.name,\n            self.description,\n            self.simulation_function.__name__,\n            self.start,\n            self.end,\n            self.info,\n            self.kwargs,\n            self.monitor_chunk,\n        )\n\n        return simulation_info_obj\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim.__init__","title":"<code>__init__(simulation_function, simulation_kwargs=None, name='simulation', description='', requirements=None, kwargs_warning=False, monitor_object=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>simulation_function</code> <code>function</code> <p>Function which runs the simulation.</p> required <code>simulation_kwargs</code> <code>dict</code> <p>Dictionary of arguments for the simulation_function. Default: None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the simulation. Default: \"simulation\".</p> <code>'simulation'</code> <code>description</code> <code>str</code> <p>Description of the simulation. Default: \"\".</p> <code>''</code> <code>requirements</code> <code>list</code> <p>List of requirements for the simulation. It's a list of dictionaries which contain the requirement class itself (key: \"req\") and the corresponding arguments (keys are the names of the arguments). The arguments can be inherited from the simulation kwargs by using the syntax 'simulation_kwargs.'. Default: None. <code>None</code> <code>kwargs_warning</code> <code>bool</code> <p>If True, a warning is printed if the simulation_kwargs are changed during the simulation. Default: False.</p> <code>False</code> <code>monitor_object</code> <code>CompNeuroMonitors object</code> <p>CompNeuroMonitors object to automatically track the recording chunk for each simulation run. Default: None.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def __init__(\n    self,\n    simulation_function: Callable,\n    simulation_kwargs: dict | None = None,\n    name: str = \"simulation\",\n    description: str = \"\",\n    requirements: list | None = None,\n    kwargs_warning: bool = False,\n    monitor_object: CompNeuroMonitors | None = None,\n):\n    \"\"\"\n    Args:\n        simulation_function (function):\n            Function which runs the simulation.\n        simulation_kwargs (dict, optional):\n            Dictionary of arguments for the simulation_function. Default: None.\n        name (str, optional):\n            Name of the simulation. Default: \"simulation\".\n        description (str, optional):\n            Description of the simulation. Default: \"\".\n        requirements (list, optional):\n            List of requirements for the simulation. It's a list of dictionaries\n            which contain the requirement class itself (key: \"req\") and the\n            corresponding arguments (keys are the names of the arguments). The\n            arguments can be inherited from the simulation kwargs by using the\n            syntax 'simulation_kwargs.&lt;kwarg_name&gt;'. Default: None.\n        kwargs_warning (bool, optional):\n            If True, a warning is printed if the simulation_kwargs are changed\n            during the simulation. Default: False.\n        monitor_object (CompNeuroMonitors object, optional):\n            CompNeuroMonitors object to automatically track the recording chunk for each\n            simulation run. Default: None.\n    \"\"\"\n    # set simulation function\n    self.name = name\n    if name == \"simulation\":\n        self.name = name + str(self._nr_simulations())\n    self._initialized_simulations.append(self.name)\n    self.description = description\n    self.simulation_function = simulation_function\n    self.simulation_kwargs = simulation_kwargs\n    if requirements is None:\n        self.requirements = []\n    else:\n        self.requirements = requirements\n    self.start = []\n    self.end = []\n    self.info = []\n    self.kwargs = []\n    if kwargs_warning:\n        self._warned = False\n    else:\n        self._warned = True\n    self.monitor_object = monitor_object\n    if monitor_object is not None:\n        self.monitor_chunk = []\n    else:\n        self.monitor_chunk = None\n\n    ### test initial requirements\n    self._test_req(simulation_kwargs=simulation_kwargs)\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim.run","title":"<code>run(simulation_kwargs=None)</code>","text":"<p>Runs the simulation function. With each run extend start, end list containing start and end time of the corresponding run and the info list containing the return value of the simulation function.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_kwargs</code> <code>dict</code> <p>Temporary simulation kwargs which override the initialized simulation kwargs. Default: None, i.e., use values from initialization.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def run(self, simulation_kwargs: dict | None = None):\n    \"\"\"\n    Runs the simulation function. With each run extend start, end list containing\n    start and end time of the corresponding run and the info list containing the\n    return value of the simulation function.\n\n    Args:\n        simulation_kwargs (dict, optional):\n            Temporary simulation kwargs which override the initialized simulation\n            kwargs. Default: None, i.e., use values from initialization.\n    \"\"\"\n\n    ### define the current simulation kwargs\n    if simulation_kwargs is not None:\n        if self.simulation_kwargs is not None:\n            ### not replace initialized kwargs completely but only the kwargs which are given\n            tmp_kwargs = self.simulation_kwargs.copy()\n            for key, val in simulation_kwargs.items():\n                tmp_kwargs[key] = val\n        else:\n            ### there are no initial kwargs --&gt; only use the kwargs which are given\n            tmp_kwargs = simulation_kwargs\n        if not (self._warned) and len(self.requirements) &gt; 0:\n            print(\n                \"\\nWARNING! run\",\n                self.name,\n                \"changed simulation kwargs, initial requirements may no longer be fulfilled!\\n\",\n            )\n            self._warned = True\n    else:\n        tmp_kwargs = self.simulation_kwargs\n\n    ### before each run, test requirements\n    self._test_req(simulation_kwargs=tmp_kwargs)\n\n    ### and append current simulation kwargs to the kwargs variable\n    self.kwargs.append(tmp_kwargs)\n\n    ### and append the current chunk of the monitors object to the chunk variable\n    if self.monitor_object is not None:\n        self.monitor_chunk.append(self.monitor_object.current_chunk())\n\n    ### run the simulation, store start and end simulation time\n    self.start.append(get_time())\n    if tmp_kwargs is not None:\n        self.info.append(self.simulation_function(**tmp_kwargs))\n    else:\n        self.info.append(self.simulation_function())\n    self.end.append(get_time())\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim.get_current_arr","title":"<code>get_current_arr(dt, flat=False)</code>","text":"<p>Method exclusively for current_step simulation functions. Gets the current array (input current value for each time step) of all runs.</p> <p>Warning</p> <p>This method will be removed soon. Use the get_current_arr method of the SimInfo class instead.</p> <p>Parameters:</p> Name Type Description Default <code>dt</code> <code>float</code> <p>Time step size of the simulation.</p> required <code>flat</code> <code>bool</code> <p>If True, returns a flattened array. Assumes that all runs are run consecutively without brakes. Default: False, i.e., returns a list of arrays.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>current_arr</code> <code>list of arrays</code> <p>List of arrays containing the current values for each time step of each run. If flat=True, returns a flattened array.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def get_current_arr(self, dt, flat=False):\n    \"\"\"\n    Method exclusively for current_step simulation functions. Gets the current array\n    (input current value for each time step) of all runs.\n\n    !!! warning\n        This method will be removed soon. Use the get_current_arr method of the\n        SimInfo class instead.\n\n    Args:\n        dt (float):\n            Time step size of the simulation.\n        flat (bool, optional):\n            If True, returns a flattened array. Assumes that all runs are run\n            consecutively without brakes. Default: False, i.e., returns a list of\n            arrays.\n\n    Returns:\n        current_arr (list of arrays):\n            List of arrays containing the current values for each time step of each\n            run. If flat=True, returns a flattened array.\n    \"\"\"\n    assert (\n        self.simulation_function.__name__ == \"current_step\"\n    ), 'ERROR get_current_arr: Simulation has to be \"current_step\"!'\n    ### TODO: remove because deprecated\n    print(\n        \"WARNING get_current_arr function will only be available in SimInfo soon.\"\n    )\n    current_arr = []\n    for run in range(len(self.kwargs)):\n        t1 = self.kwargs[run][\"t1\"]\n        t2 = self.kwargs[run][\"t2\"]\n        a1 = self.kwargs[run][\"a1\"]\n        a2 = self.kwargs[run][\"a2\"]\n\n        if t1 &gt; 0 and t2 &gt; 0:\n            current_arr.append(\n                np.concatenate(\n                    [\n                        np.ones(int(round(t1 / dt))) * a1,\n                        np.ones(int(round(t2 / dt))) * a2,\n                    ]\n                )\n            )\n        elif t2 &gt; 0:\n            current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n        else:\n            current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n    if flat:\n        return np.concatenate(current_arr)\n    else:\n        return current_arr\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim.simulation_info","title":"<code>simulation_info()</code>","text":"<p>Returns a SimInfo object containing the simulation information.</p> <p>Returns:</p> Name Type Description <code>simulation_info_obj</code> <code>SimInfo</code> <p>Simulation information object.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def simulation_info(self):\n    \"\"\"\n    Returns a SimInfo object containing the simulation information.\n\n    Returns:\n        simulation_info_obj (SimInfo):\n            Simulation information object.\n    \"\"\"\n\n    simulation_info_obj = SimInfo(\n        self.name,\n        self.description,\n        self.simulation_function.__name__,\n        self.start,\n        self.end,\n        self.info,\n        self.kwargs,\n        self.monitor_chunk,\n    )\n\n    return simulation_info_obj\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.SimInfo","title":"<code>CompNeuroPy.generate_simulation.SimInfo</code>","text":"<p>Class for storing the simulation information.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the simulation.</p> <code>description</code> <code>str</code> <p>Description of the simulation.</p> <code>simulation_function</code> <code>str</code> <p>Name of the simulation function.</p> <code>start</code> <code>list</code> <p>List of start times of the simulation runs.</p> <code>end</code> <code>list</code> <p>List of end times of the simulation runs.</p> <code>info</code> <code>list</code> <p>List of return values of the simulation function of each simulation run.</p> <code>kwargs</code> <code>list</code> <p>List of simulation kwargs of the simulation function of each simulation run.</p> <code>monitor_chunk</code> <code>list</code> <p>List of recording chunks of the used CompNeuroMonitors object of each simulation run.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>class SimInfo:\n    \"\"\"\n    Class for storing the simulation information.\n\n    Attributes:\n        name (str):\n            Name of the simulation.\n        description (str):\n            Description of the simulation.\n        simulation_function (str):\n            Name of the simulation function.\n        start (list):\n            List of start times of the simulation runs.\n        end (list):\n            List of end times of the simulation runs.\n        info (list):\n            List of return values of the simulation function of each simulation run.\n        kwargs (list):\n            List of simulation kwargs of the simulation function of each simulation run.\n        monitor_chunk (list):\n            List of recording chunks of the used CompNeuroMonitors object of each simulation run.\n    \"\"\"\n\n    def __init__(\n        self,\n        name,\n        description,\n        simulation_function,\n        start,\n        end,\n        info,\n        kwargs,\n        monitor_chunk,\n    ):\n        \"\"\"\n        Initialization of the simulation information object.\n\n        Args:\n            name (str):\n                Name of the simulation.\n            description (str):\n                Description of the simulation.\n            simulation_function (str):\n                Name of the simulation function.\n            start (list):\n                List of start times of the simulation runs.\n            end (list):\n                List of end times of the simulation runs.\n            info (list):\n                List of return values of the simulation function of each simulation run.\n            kwargs (list):\n                List of simulation kwargs of the simulation function of each simulation\n                run.\n            monitor_chunk (list):\n                List of recording chunks of the used CompNeuroMonitors object of each simulation\n                run.\n        \"\"\"\n        self.name = name\n        self.description = description\n        self.simulation_function = simulation_function\n        self.start = start\n        self.end = end\n        self.info = info\n        self.kwargs = kwargs\n        self.monitor_chunk = monitor_chunk\n\n    def get_current_arr(self, dt, flat=False):\n        \"\"\"\n        Method exclusively for the following simulation functions (built-in\n        CompNeuroPy):\n            - current_step\n            - current_stim\n            - current_ramp\n        Gets the current array (input current value for each time step) of all runs.\n\n        Args:\n            dt (float):\n                Time step size of the simulation.\n            flat (bool, optional):\n                If True, returns a flattened array. Assumes that all runs are run\n                consecutively without brakes. Default: False, i.e., returns a list of\n                arrays.\n\n        Returns:\n            current_arr (list of arrays):\n                List of arrays containing the current values for each time step of each\n                run. If flat=True, returns a flattened array.\n        \"\"\"\n        assert (\n            self.simulation_function == \"current_step\"\n            or self.simulation_function == \"current_stim\"\n            or self.simulation_function == \"current_ramp\"\n        ), 'ERROR get_current_arr: Simulation has to be \"current_step\", \"current_stim\" or \"current_ramp\"!'\n\n        if self.simulation_function == \"current_step\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                t1 = self.kwargs[run][\"t1\"]\n                t2 = self.kwargs[run][\"t2\"]\n                a1 = self.kwargs[run][\"a1\"]\n                a2 = self.kwargs[run][\"a2\"]\n\n                if t1 &gt; 0 and t2 &gt; 0:\n                    current_arr.append(\n                        np.concatenate(\n                            [\n                                np.ones(int(round(t1 / dt))) * a1,\n                                np.ones(int(round(t2 / dt))) * a2,\n                            ]\n                        )\n                    )\n                elif t2 &gt; 0:\n                    current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n                else:\n                    current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n\n        elif self.simulation_function == \"current_stim\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                t = self.kwargs[run][\"t\"]\n                a = self.kwargs[run][\"a\"]\n\n                if t &gt; 0:\n                    current_arr.append(np.ones(int(round(t / dt))) * a)\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n\n        elif self.simulation_function == \"current_ramp\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                amp = self.kwargs[run][\"a0\"]\n                current_arr_ramp = []\n                for stim_idx in range(self.kwargs[run][\"n\"]):\n                    t = self.info[run][\"dur_stim\"]\n                    a = amp\n                    current_arr_ramp.append(np.ones(int(round(t / dt))) * a)\n                    amp = amp + self.info[run][\"da\"]\n                current_arr.append(list(np.concatenate(current_arr_ramp)))\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.SimInfo.__init__","title":"<code>__init__(name, description, simulation_function, start, end, info, kwargs, monitor_chunk)</code>","text":"<p>Initialization of the simulation information object.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the simulation.</p> required <code>description</code> <code>str</code> <p>Description of the simulation.</p> required <code>simulation_function</code> <code>str</code> <p>Name of the simulation function.</p> required <code>start</code> <code>list</code> <p>List of start times of the simulation runs.</p> required <code>end</code> <code>list</code> <p>List of end times of the simulation runs.</p> required <code>info</code> <code>list</code> <p>List of return values of the simulation function of each simulation run.</p> required <code>kwargs</code> <code>list</code> <p>List of simulation kwargs of the simulation function of each simulation run.</p> required <code>monitor_chunk</code> <code>list</code> <p>List of recording chunks of the used CompNeuroMonitors object of each simulation run.</p> required Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def __init__(\n    self,\n    name,\n    description,\n    simulation_function,\n    start,\n    end,\n    info,\n    kwargs,\n    monitor_chunk,\n):\n    \"\"\"\n    Initialization of the simulation information object.\n\n    Args:\n        name (str):\n            Name of the simulation.\n        description (str):\n            Description of the simulation.\n        simulation_function (str):\n            Name of the simulation function.\n        start (list):\n            List of start times of the simulation runs.\n        end (list):\n            List of end times of the simulation runs.\n        info (list):\n            List of return values of the simulation function of each simulation run.\n        kwargs (list):\n            List of simulation kwargs of the simulation function of each simulation\n            run.\n        monitor_chunk (list):\n            List of recording chunks of the used CompNeuroMonitors object of each simulation\n            run.\n    \"\"\"\n    self.name = name\n    self.description = description\n    self.simulation_function = simulation_function\n    self.start = start\n    self.end = end\n    self.info = info\n    self.kwargs = kwargs\n    self.monitor_chunk = monitor_chunk\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.SimInfo.get_current_arr","title":"<code>get_current_arr(dt, flat=False)</code>","text":"<p>Method exclusively for the following simulation functions (built-in CompNeuroPy):     - current_step     - current_stim     - current_ramp Gets the current array (input current value for each time step) of all runs.</p> <p>Parameters:</p> Name Type Description Default <code>dt</code> <code>float</code> <p>Time step size of the simulation.</p> required <code>flat</code> <code>bool</code> <p>If True, returns a flattened array. Assumes that all runs are run consecutively without brakes. Default: False, i.e., returns a list of arrays.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>current_arr</code> <code>list of arrays</code> <p>List of arrays containing the current values for each time step of each run. If flat=True, returns a flattened array.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def get_current_arr(self, dt, flat=False):\n    \"\"\"\n    Method exclusively for the following simulation functions (built-in\n    CompNeuroPy):\n        - current_step\n        - current_stim\n        - current_ramp\n    Gets the current array (input current value for each time step) of all runs.\n\n    Args:\n        dt (float):\n            Time step size of the simulation.\n        flat (bool, optional):\n            If True, returns a flattened array. Assumes that all runs are run\n            consecutively without brakes. Default: False, i.e., returns a list of\n            arrays.\n\n    Returns:\n        current_arr (list of arrays):\n            List of arrays containing the current values for each time step of each\n            run. If flat=True, returns a flattened array.\n    \"\"\"\n    assert (\n        self.simulation_function == \"current_step\"\n        or self.simulation_function == \"current_stim\"\n        or self.simulation_function == \"current_ramp\"\n    ), 'ERROR get_current_arr: Simulation has to be \"current_step\", \"current_stim\" or \"current_ramp\"!'\n\n    if self.simulation_function == \"current_step\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t1 = self.kwargs[run][\"t1\"]\n            t2 = self.kwargs[run][\"t2\"]\n            a1 = self.kwargs[run][\"a1\"]\n            a2 = self.kwargs[run][\"a2\"]\n\n            if t1 &gt; 0 and t2 &gt; 0:\n                current_arr.append(\n                    np.concatenate(\n                        [\n                            np.ones(int(round(t1 / dt))) * a1,\n                            np.ones(int(round(t2 / dt))) * a2,\n                        ]\n                    )\n                )\n            elif t2 &gt; 0:\n                current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n            else:\n                current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    elif self.simulation_function == \"current_stim\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t = self.kwargs[run][\"t\"]\n            a = self.kwargs[run][\"a\"]\n\n            if t &gt; 0:\n                current_arr.append(np.ones(int(round(t / dt))) * a)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    elif self.simulation_function == \"current_ramp\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            amp = self.kwargs[run][\"a0\"]\n            current_arr_ramp = []\n            for stim_idx in range(self.kwargs[run][\"n\"]):\n                t = self.info[run][\"dur_stim\"]\n                a = amp\n                current_arr_ramp.append(np.ones(int(round(t / dt))) * a)\n                amp = amp + self.info[run][\"da\"]\n            current_arr.append(list(np.concatenate(current_arr_ramp)))\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n</code></pre>"},{"location":"main/model_configurator/","title":"Model Configurator","text":"<p>Working on it.</p>"},{"location":"main/monitors_recordings/","title":"Monitors / Recordings","text":""},{"location":"main/monitors_recordings/#create-monitors","title":"Create Monitors","text":"<p>CompNeuroPy provides a <code>CompNeuroMonitors</code> class that can be used to easily create and control multiple ANNarchy monitors at once. To create a <code>CompNeuroMonitors</code> object, all that is needed is a monitors_dictionary that defines which variables should be recorded for each model component. All populations and projections have to have unique names to work with <code>CompNeuroMonitors</code>. The keys of the monitor_dictionary are the names of the model components (in example below \"my_pop1\" and \"my_pop2\"). The key can also include a recording period (the time between two recordings, given after a \";\"), e.g. record the variables of my_pop1 only every 10 ms would look like this: 'pop;my_pop1;10':['v', 'spike']. The default period is the time step of the simulation for populations and 1000 times the timestep for projections. The values of the monitor_dictionary are lists of all the variables that should be recorded from the corresponding components. The names of components (populations, projections) could be provided by a <code>CompNeuroModel</code>.</p>"},{"location":"main/monitors_recordings/#example","title":"Example:","text":"<p>Here the variables v and spike should be recorded of the population with the name \"my_pop1\" and the variable v should be recorded from the population with the name \"my_pop2\":</p> <pre><code>from CompNeuroPy import CompNeuroMonitors\nmonitor_dictionary = {'my_pop1':['v', 'spike'], 'my_pop2':['v']}\nmon = CompNeuroMonitors(monitor_dictionary)\n</code></pre> <p>A full example is available in the Examples.</p>"},{"location":"main/monitors_recordings/#chunks-and-periods","title":"Chunks and periods","text":"<p>In CompNeuroPy, recordings are divided into so-called chunks and periods. Chunks are simulation sections that are separated by monitor resets (optionally also reset the model). A chunk can consist of several periods. A period represents the time span between the start and pause of a monitor recording. To divide a simulation into chunks and periods, a <code>CompNeuroMonitors</code> object provides the three functions start(), pause() and reset().</p> <p>At the beginning of a simulation, the monitors do not start automatically which is why the start() function must be called at least once. The start() function can also be used to resume paused recordings. With the function pause() recordings are paused. The function reset() starts a new chunk for the recordings (the end of a chunk is also always the end of a period, i.e. the last period of the corresponding chunk). After calling reset() the monitors remain in their current mode (active or paused). By default reset() also resets the model to the compile status (time = 0) by calling the ANNarchy reset() function and has the same arguments. If the argument model is set to False, the ANNarchy reset() function is not called and only a new chunk is created.</p>"},{"location":"main/monitors_recordings/#example_1","title":"Example:","text":"<pre><code>### first chunk, one period\nsimulate(100) # 100 ms not recorded\nmon.start()   # start all monitors\nsimulate(100) # 100 ms recorded\n\n### second chunk, two periods\nmon.reset()   # model reset, beginning of new chunk\nsimulate(100) # 100 ms recorded (monitors were active before reset --&gt; still active)\nmon.pause()   # pause all monitors\nsimulate(100) # 100 ms not recorded\nmon.start()   # start all monitors\nsimulate(100) # 100 ms recorded\n</code></pre>"},{"location":"main/monitors_recordings/#get-recordings","title":"Get recordings","text":"<p>The recordings can be obtained from the <code>CompNeuroMonitors</code> object using the get_recordings() function. This returns a list of dictionaries (one for each chunk). The dictionaries contain the recorded data defined with the monitor_dictionary at the <code>CompNeuroMonitors</code> initialization. In the recordings dictionaries the keys have the following structure: \"&lt;component_name&gt;;variable\"; the corresponding dictionary values are the recordings of the respective variable. The dictionaries always contain the time step of the simulation (key = \"dt\"), the periods (time between recorded values) for each component (key = \"&lt;component_name&gt;;period\") and the attributes of each component (key = \"&lt;component_name&gt;;parameter_dict\").</p>"},{"location":"main/monitors_recordings/#example_2","title":"Example:","text":"<pre><code>recordings = mon.get_recordings()\ny1 = recordings[0]['my_pop1;v'] ### variable v of my_pop1 from 1st chunk\ny2 = recordings[1]['my_pop1;v'] ### variable v of my_pop1 from 2nd chunk\n</code></pre>"},{"location":"main/monitors_recordings/#get-recording-times","title":"Get recording times","text":"<p>In addition to the recordings themselves, recording times can also be obtained from the <code>CompNeuroMonitors</code> object, which is very useful for later analyses. With the function get_recording_times() of the <code>CompNeuroMonitors</code> object a <code>RecordingTimes</code> object can be obtained. From the <code>RecordingTimes</code> object one can get time limits (in ms) and coresponding indizes for the recordings.</p>"},{"location":"main/monitors_recordings/#example_3","title":"Example:","text":"<pre><code>recording_times = mon.get_recording_times()\nstart_time = recording_times.time_lims(chunk=1, period=1)[0] ### 200 ms\nstart_idx  = recording_times.idx_lims(chunk=1, period=1)[0]  ### 1000, if dt == 0.1\nend_time   = recording_times.time_lims(chunk=1, period=1)[1] ### 300 ms\nend_idx    = recording_times.idx_lims(chunk=1, period=1)[1]  ### 2000\n</code></pre> <p>You can combine the recordings of both chunks of the example simulation shown above into a single time array and a single value array using the <code>RecordingTimes</code> object's combine_chunks function: <pre><code>time_arr, value_arr = recording_times.combine_chunks(recordings, 'my_pop1;v', 'consecutive')\n</code></pre></p>"},{"location":"main/monitors_recordings/#plot-recordings","title":"Plot recordings","text":"<p>To get a quick overview of the recordings, CompNeuroPy provides the <code>PlotRecordings</code> class.</p>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors","title":"<code>CompNeuroPy.monitors.CompNeuroMonitors</code>","text":"<p>Class to bring together ANNarchy monitors into one object.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>class CompNeuroMonitors:\n    \"\"\"\n    Class to bring together ANNarchy monitors into one object.\n    \"\"\"\n\n    def __init__(self, mon_dict={}):\n        \"\"\"\n        Initialize CompNeuroMonitors object by creating ANNarchy monitors.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"compartment_name;period\" where period is optional and\n                val=list with variables to record.\n        \"\"\"\n        self.mon = self._add_monitors(mon_dict)\n        self.mon_dict = mon_dict\n        self._init_internals(init_call=True)\n\n    def _init_internals(self, init_call=False):\n        \"\"\"\n        Initialize the following internal variables:\n            - timings (dict):\n                dict with key=\"pop_name\" for populations and \"proj_name\" for projections\n                for each recorded population and projection and\n                val={\"currently_paused\": True, \"start\": [], \"stop\": []}\n            - recordings (list):\n                list with recordings of all chunks. Set to empty list.\n            - recording_times (list):\n                list with recording times of all chunks. Set to empty list.\n            - already_got_recordings (bool):\n                True if recordings were already requested, False otherwise. Set to\n                False.\n            - already_got_recording_times (bool):\n                True if recording_times were already requested, False otherwise. Set to\n                False.\n            - get_recordings_reset_call (bool):\n                True if get_recordings() and get_recording_times() are called within\n                reset(), False otherwise. Set to False.\n\n        Args:\n            init_call (bool, optional):\n                True if called from __init__(), False otherwise. Default: False.\n        \"\"\"\n        if init_call is False:\n            #### pause all ANNarchy monitors because currently paused will be set to False\n            self.pause()\n\n        ### initialize timings\n        timings = {}\n        for key, val in self.mon_dict.items():\n            _, compartment, _ = self._unpack_mon_dict_keys(key)\n            timings[compartment] = {\"currently_paused\": True, \"start\": [], \"stop\": []}\n        self.timings = timings\n\n        ### initialize recordings and recording_times etc.\n        self.recordings = []\n        self.recording_times = []\n        self.already_got_recordings = False\n        self.already_got_recording_times = False\n        self.get_recordings_reset_call = False\n\n    @check_types()\n    def start(self, compartment_list: list | None = None):\n        \"\"\"\n        Start or resume recording of all recorded compartments in compartment_list.\n\n        Args:\n            compartment_list (list, optional):\n                List with compartment names to start or resume recording. Default: None,\n                i.e., all compartments of initialized mon_dict are started or resumed.\n        \"\"\"\n        if compartment_list == None:\n            mon_dict_key_list = list(self.mon_dict.keys())\n            compartment_list = [\n                self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n            ]\n\n        self.timings = self._start_monitors(compartment_list, self.mon, self.timings)\n\n    @check_types()\n    def pause(self, compartment_list: list | None = None):\n        \"\"\"\n        Pause recording of all recorded compartments in compartment_list.\n\n        Args:\n            compartment_list (list, optional):\n                List with compartment names to pause recording. Default: None,\n                i.e., all compartments of initialized mon_dict are paused.\n        \"\"\"\n        if compartment_list == None:\n            mon_dict_key_list = list(self.mon_dict.keys())\n            compartment_list = [\n                self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n            ]\n\n        self.timings = self._pause_monitors(compartment_list, self.mon, self.timings)\n\n    def reset(\n        self,\n        populations=True,\n        projections=False,\n        synapses=False,\n        monitors=True,\n        model=True,\n        parameters=True,\n        net_id=0,\n    ):\n        \"\"\"\n        Create a new recording chunk by getting recordings and recording times of the\n        current chunk and optionally resetting the model. Recordings are automatically\n        resumed in the new chunk if they are not paused.\n\n        Args:\n            populations (bool, optional):\n                If True, reset populations. Default: True.\n            projections (bool, optional):\n                If True, reset projections. Default: False.\n            synapses (bool, optional):\n                If True, reset synapses. Default: False.\n            monitors (bool, optional):\n                If True, reset ANNarchy monitors. Default: True.\n            model (bool, optional):\n                If True, reset model. Default: True.\n            parameters (bool, optional):\n                If True, reset the parameters of popilations and projections. Default:\n                True.\n            net_id (int, optional):\n                Id of the network to reset. Default: 0.\n        \"\"\"\n        ### TODO rename this function to new_chunk() or something like that and let\n        ### recordings and recording times be returned\n        self.get_recordings_reset_call = True\n        self.get_recordings()\n        self.get_recording_times()\n        self.get_recordings_reset_call = False\n        self.already_got_recordings = (\n            False  # after reset one can still update recordings\n        )\n        self.already_got_recording_times = (\n            False  # after reset one can still update recording_times\n        )\n\n        ### reset timings, after reset, add a zero to start if the monitor is still\n        ### running (this is not resetted by reset())\n        ### if the model was not resetted --&gt; do add current time instead of zero\n        for key in self.timings.keys():\n            self.timings[key][\"start\"] = []\n            self.timings[key][\"stop\"] = []\n            if self.timings[key][\"currently_paused\"] == False:\n                if model:\n                    self.timings[key][\"start\"].append(0)\n                else:\n                    self.timings[key][\"start\"].append(\n                        np.round(get_time(), af.get_number_of_decimals(dt()))\n                    )\n\n        ### reset model\n        if model:\n            if parameters is False:\n                ### if parameters=False, get parameters before reset and set them after\n                ### reset\n                parameters_dict = mf._get_all_parameters()\n            reset(populations, projections, synapses, monitors, net_id=net_id)\n            if parameters is False:\n                ### if parameters=False, set parameters after reset\n                mf._set_all_parameters(parameters_dict)\n\n    def current_chunk(self):\n        \"\"\"\n        Get the index of the current chunk.\n\n        Returns:\n            current_chunk_idx (int):\n                Index of the current chunk. If no recordings are currently active,\n                returns None.\n        \"\"\"\n        ### if recordings are currently active --&gt; return chunk in which these recordings will be saved\n        ### check if there are currently active recordings\n        active_recordings = False\n        for key, val in self.mon_dict.items():\n            _, compartment, _ = self._unpack_mon_dict_keys(key)\n            if not (self.timings[compartment][\"currently_paused\"]):\n                ### tere are currently active recordings\n                active_recordings = True\n\n        if active_recordings:\n            current_chunk_idx = len(self.recordings)\n            return current_chunk_idx\n        else:\n            ### if currently no recordings are active return None\n            return None\n\n    def get_recordings(self) -&gt; list[dict]:\n        \"\"\"\n        Get recordings of all recorded compartments.\n\n        Returns:\n            recordings (list):\n                List with recordings of all chunks.\n        \"\"\"\n        ### only if recordings in current chunk and get_recodings was not already called add current chunk to recordings\n        if (\n            self._any_recordings_in_current_chunk()\n            and self.already_got_recordings is False\n        ):\n            ### update recordings\n            self.recordings.append(self._get_monitors(self.mon_dict, self.mon))\n            ### upade already_got_recordings --&gt; it will not update recordings again\n            self.already_got_recordings = True\n\n            if not (self.get_recordings_reset_call):\n                if len(self.recordings) == 0:\n                    print(\n                        \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                    )\n            return self.recordings\n        else:\n            if not (self.get_recordings_reset_call):\n                if len(self.recordings) == 0:\n                    print(\n                        \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                    )\n            return self.recordings\n\n    def get_recording_times(self):\n        \"\"\"\n        Get recording times of all recorded compartments.\n\n        Returns:\n            recording_times (recording_times_cl):\n                Object with recording times of all chunks.\n        \"\"\"\n\n        temp_timings = self._get_temp_timings()\n\n        ### only append temp_timings of current chunk if there are recordings in current chunk at all and if get_recordings was not already called (double call would add the same chunk again)\n        if (\n            self._any_recordings_in_current_chunk()\n            and self.already_got_recording_times is False\n        ):\n            self.recording_times.append(temp_timings)\n\n        ### upade already_got_recording_times --&gt; it will not update recording_times again\n        self.already_got_recording_times = True\n\n        ### generate a object from recording_times and return this instead of the dict\n        recording_times_ob = RecordingTimes(self.recording_times)\n\n        if not (self.get_recordings_reset_call):\n            if len(self.recording_times) == 0:\n                print(\n                    \"WARNING get_recording_times: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return recording_times_ob\n\n    def get_recordings_and_clear(self):\n        \"\"\"\n        The default get_recordings method should be called at the end of the simulation.\n        The get_recordings_and_clear method allows to get several times recordings with\n        the same monitor object and to simulate between the calls. Sets the internal\n        variables back to their initial state. Usefull if you repeat a simulation +\n        recording several times and you do not want to always create new chunks.\n\n        !!! warning\n            If you want to continue recording after calling this method, you have to\n            call start() again.\n\n        Returns:\n            recordings (list):\n                List with recordings of all chunks.\n            recording_times (recording_times_cl):\n                Object with recording times of all chunks.\n        \"\"\"\n        ret0 = self.get_recordings()\n        ret1 = self.get_recording_times()\n        self._init_internals()\n        ret = (ret0, ret1)\n        return ret\n\n    def _correct_start_stop(self, start_time_arr, stop_time_arr, period):\n        \"\"\"\n        Corrects the start and stop times of recordings to the actual start and stop\n        times of recorded values.\n\n        Args:\n            start_time_arr (np.array):\n                Array with start times of recordings, obtained with get_time() function\n                of ANNarchy.\n            stop_time_arr (np.array):\n                Array with stop times of recordings, obtained with get_time() function\n                of ANNarchy.\n            period (float):\n                Time difference between recording values specified by the user.\n\n        Returns:\n            actual_start_time (np.array):\n                Array with actual start times of recorded values.\n            actual_stop_time (np.array):\n                Array with actual stop times of recorded values.\n            nr_rec_vals (np.array):\n                Array with number of recorded values between start and stop.\n        \"\"\"\n        # actual_period = int(period / dt()) * dt()\n        actual_start_time = np.ceil(start_time_arr / period) * period\n\n        actual_stop_time = np.ceil(stop_time_arr / period - 1) * period\n\n        nr_rec_vals = 1 + (actual_stop_time - actual_start_time) / period\n\n        return (actual_start_time, actual_stop_time, nr_rec_vals)\n\n    def _get_temp_timings(self):\n        \"\"\"\n        Generates a timings dictionary with time lims and idx lims for each compartment.\n        Calculates the idx lims of the recordings based on the time lims.\n\n        Returns:\n            temp_timings (dict):\n                Dict with time lims and idx lims for each compartment.\n        \"\"\"\n        temp_timings = {}\n        for key in self.mon_dict.keys():\n            _, compartment, period = self._unpack_mon_dict_keys(key)\n            if len(self.timings[compartment][\"start\"]) &gt; len(\n                self.timings[compartment][\"stop\"]\n            ):\n                ### was started/resumed but never stoped after --&gt; use current time for stop time\n                self.timings[compartment][\"stop\"].append(get_time())\n            ### calculate the idx of the recorded arrays which correspond to the timings and remove 'currently_paused'\n            ### get for each start-stop pair the corrected start stop timings (when teh values were actually recorded, depends on period and timestep)\n            ### and also get the number of recorded values for start-stop pair\n            start_time_arr = np.array(self.timings[compartment][\"start\"])\n            stop_time_arr = np.array(self.timings[compartment][\"stop\"])\n            (\n                start_time_arr,\n                stop_time_arr,\n                nr_rec_vals_arr,\n            ) = self._correct_start_stop(start_time_arr, stop_time_arr, period)\n\n            ### with the number of recorded values -&gt; get start and end idx for each start-stop pair\n            start_idx = [\n                np.sum(nr_rec_vals_arr[0:i]).astype(int)\n                for i in range(nr_rec_vals_arr.size)\n            ]\n            stop_idx = [\n                np.sum(nr_rec_vals_arr[0 : i + 1]).astype(int) - 1\n                for i in range(nr_rec_vals_arr.size)\n            ]\n\n            ### return start-stop pair info in timings format\n            temp_timings[compartment] = {\n                \"start\": {\n                    \"ms\": np.round(\n                        start_time_arr, af.get_number_of_decimals(dt())\n                    ).tolist(),\n                    \"idx\": start_idx,\n                },\n                \"stop\": {\n                    \"ms\": np.round(\n                        stop_time_arr, af.get_number_of_decimals(dt())\n                    ).tolist(),\n                    \"idx\": stop_idx,\n                },\n            }\n        return temp_timings\n\n    def _any_recordings_in_current_chunk(self):\n        \"\"\"\n        Check if there are any recordings in the current chunk.\n\n        Returns:\n            any_recordings (bool):\n                True if there are any recordings in the current chunk, False otherwise.\n        \"\"\"\n        temp_timings = self._get_temp_timings()\n\n        ### generate a temp object of temp timings to check if there were recordings at all\n        recording_times_ob_temp = RecordingTimes([temp_timings])\n        return recording_times_ob_temp._any_recordings(chunk=0)\n\n    def _add_monitors(self, mon_dict: dict):\n        \"\"\"\n        Generate monitors defined by mon_dict.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"compartment_name;period\" where period is optional and\n                val=list with variables to record.\n\n        Returns:\n            mon (dict):\n                dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n        \"\"\"\n        mon = {}\n        for key, val in mon_dict.items():\n            compartmentType, compartment, period = self._unpack_mon_dict_keys(\n                key, warning=True\n            )\n            ### check if compartment is pop\n            if compartmentType == \"pop\":\n                mon[compartment] = Monitor(\n                    get_population(compartment), val, start=False, period=period\n                )\n            ### check if compartment is proj\n            if compartmentType == \"proj\":\n                mon[compartment] = Monitor(\n                    get_projection(compartment), val, start=False, period=period\n                )\n        return mon\n\n    def _start_monitors(self, compartment_list, mon, timings=None):\n        \"\"\"\n        Starts or resumes monitores defined by compartment_list.\n\n        Args:\n            compartment_list (list):\n                List with compartment names to start or resume recording.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n            timings (dict, optional):\n                timings variable of the CompNeuroMonitors object. Default: None.\n\n        Returns:\n            timings (dict):\n                timings variable of the CompNeuroMonitors object.\n        \"\"\"\n        ### for each compartment generate started variable (because compartments can ocure multiple times if multiple variables of them are recorded --&gt; do not start same monitor multiple times)\n        started = {}\n        for compartment_name in compartment_list:\n            started[compartment_name] = False\n\n        if timings == None:\n            ### information about pauses not available, just start\n            for compartment_name in compartment_list:\n                if started[compartment_name] == False:\n                    mon[compartment_name].start()\n                    print(\"start\", compartment_name)\n                    started[compartment_name] = True\n            return None\n        else:\n            ### information about pauses available, start if not paused, resume if paused\n            for compartment_name in compartment_list:\n                if started[compartment_name] == False:\n                    if timings[compartment_name][\"currently_paused\"]:\n                        if len(timings[compartment_name][\"start\"]) &gt; 0:\n                            ### resume\n                            mon[compartment_name].resume()\n                        else:\n                            ### initial start\n                            mon[compartment_name].start()\n                    started[compartment_name] = True\n                    ### update currently_paused\n                    timings[compartment_name][\"currently_paused\"] = False\n                    ### never make start longer than stop+1!... this can be caused if start is called multiple times without pause in between\n                    if len(timings[compartment_name][\"start\"]) &lt;= len(\n                        timings[compartment_name][\"stop\"]\n                    ):\n                        timings[compartment_name][\"start\"].append(get_time())\n            return timings\n\n    def _pause_monitors(self, compartment_list, mon, timings=None):\n        \"\"\"\n        Pause monitores defined by compartment_list.\n\n        Args:\n            compartment_list (list):\n                List with compartment names to pause recording.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n            timings (dict, optional):\n                timings variable of the CompNeuroMonitors object. Default: None.\n\n        Returns:\n            timings (dict):\n                timings variable of the CompNeuroMonitors object.\n        \"\"\"\n        ### for each compartment generate paused variable (because compartments can ocure multiple times if multiple variables of them are recorded --&gt; do not pause same monitor multiple times)\n        paused = {}\n        for compartment_name in compartment_list:\n            paused[compartment_name] = False\n\n        for compartment_name in compartment_list:\n            if paused[compartment_name] == False:\n                mon[compartment_name].pause()\n                paused[compartment_name] = True\n\n        if timings != None:\n            ### information about pauses is available, update it\n            for key, val in paused.items():\n                timings[key][\"currently_paused\"] = True\n                ### never make pause longer than start, this can be caused if pause is called multiple times without start in between\n                if len(timings[key][\"stop\"]) &lt; len(timings[key][\"start\"]):\n                    timings[key][\"stop\"].append(get_time())\n                ### if pause is directly called after start --&gt; start == stop --&gt; remove these entries, this is no actual period\n                if (\n                    len(timings[key][\"stop\"]) == len(timings[key][\"start\"])\n                    and timings[key][\"stop\"][-1] == timings[key][\"start\"][-1]\n                ):\n                    timings[key][\"stop\"] = timings[key][\"stop\"][:-1]\n                    timings[key][\"start\"] = timings[key][\"start\"][:-1]\n            return timings\n        else:\n            return None\n\n    def _get_monitors(self, mon_dict, mon):\n        \"\"\"\n        Get recorded values from ANNarchy monitors defined by mon_dict.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"compartment_name;period\" where period is optional and\n                val=list with variables to record.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n\n        Returns:\n            recordings (dict):\n                Dict with key=\"compartment_name;variable\" and val=list with recorded\n                values.\n        \"\"\"\n        recordings = {}\n        for key, val in mon_dict.items():\n            compartment_type, compartment, period = self._unpack_mon_dict_keys(key)\n            recordings[f\"{compartment};period\"] = period\n            if compartment_type == \"pop\":\n                pop = get_population(compartment)\n                parameter_dict = {\n                    param_name: getattr(pop, param_name)\n                    for param_name in pop.parameters\n                }\n                recordings[f\"{compartment};parameter_dict\"] = parameter_dict\n            if compartment_type == \"proj\":\n                proj = get_projection(compartment)\n                parameter_dict = {\n                    param_name: getattr(proj, param_name)\n                    for param_name in proj.parameters\n                }\n                recordings[f\"{compartment};parameters\"] = parameter_dict\n            for val_val in val:\n                temp = mon[compartment].get(val_val)\n                recordings[f\"{compartment};{val_val}\"] = temp\n        recordings[\"dt\"] = dt()\n        return recordings\n\n    def _unpack_mon_dict_keys(self, s: str, warning: bool = False):\n        \"\"\"\n        Unpacks a string of the form \"compartment_name;period\" or\n        \"compartment_name\" into its components. If period is not provided\n        it is set to dt() for populations and dt()*1000 for projections.\n\n        Args:\n            s (str):\n                String to be unpacked\n            warning (bool, optional):\n                If True, print warning if period is not provided for projections.\n\n        Returns:\n            compartment_type (str):\n                Compartment type\n            compartment_name (str):\n                Compartment name\n            period (float):\n                Period of the compartment\n        \"\"\"\n        ### split string\n        splitted_s = s.split(\";\")\n\n        ### get name\n        compartment_name = splitted_s[0]\n\n        ### get type\n        pop_list = [pop.name for pop in populations()]\n        proj_list = [proj.name for proj in projections()]\n        if compartment_name in pop_list and compartment_name in proj_list:\n            ### raise error because name is in both lists\n            print(\n                \"ERROR CompNeuroMonitors._unpack_mon_dict_keys(): compartment_name is both populaiton and projection\"\n            )\n            quit()\n        elif compartment_name in pop_list:\n            compartment_type = \"pop\"\n        elif compartment_name in proj_list:\n            compartment_type = \"proj\"\n\n        ### get period\n        if len(splitted_s) == 2:\n            period = float(splitted_s[1])\n        else:\n            period = {\"pop\": dt(), \"proj\": dt() * 1000}[compartment_type]\n            ### print warning for compartment_type proj\n            if compartment_type == \"proj\" and warning:\n                print(\n                    f\"WARNING CompNeuroMonitors: no period provided for projection {compartment_name}, period set to {period} ms\"\n                )\n        period = round(period / dt()) * dt()\n\n        return compartment_type, compartment_name, period\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.__init__","title":"<code>__init__(mon_dict={})</code>","text":"<p>Initialize CompNeuroMonitors object by creating ANNarchy monitors.</p> <p>Parameters:</p> Name Type Description Default <code>mon_dict</code> <code>dict</code> <p>dict with key=\"compartment_name;period\" where period is optional and val=list with variables to record.</p> <code>{}</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def __init__(self, mon_dict={}):\n    \"\"\"\n    Initialize CompNeuroMonitors object by creating ANNarchy monitors.\n\n    Args:\n        mon_dict (dict):\n            dict with key=\"compartment_name;period\" where period is optional and\n            val=list with variables to record.\n    \"\"\"\n    self.mon = self._add_monitors(mon_dict)\n    self.mon_dict = mon_dict\n    self._init_internals(init_call=True)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.start","title":"<code>start(compartment_list=None)</code>","text":"<p>Start or resume recording of all recorded compartments in compartment_list.</p> <p>Parameters:</p> Name Type Description Default <code>compartment_list</code> <code>list</code> <p>List with compartment names to start or resume recording. Default: None, i.e., all compartments of initialized mon_dict are started or resumed.</p> <code>None</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>@check_types()\ndef start(self, compartment_list: list | None = None):\n    \"\"\"\n    Start or resume recording of all recorded compartments in compartment_list.\n\n    Args:\n        compartment_list (list, optional):\n            List with compartment names to start or resume recording. Default: None,\n            i.e., all compartments of initialized mon_dict are started or resumed.\n    \"\"\"\n    if compartment_list == None:\n        mon_dict_key_list = list(self.mon_dict.keys())\n        compartment_list = [\n            self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n        ]\n\n    self.timings = self._start_monitors(compartment_list, self.mon, self.timings)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.pause","title":"<code>pause(compartment_list=None)</code>","text":"<p>Pause recording of all recorded compartments in compartment_list.</p> <p>Parameters:</p> Name Type Description Default <code>compartment_list</code> <code>list</code> <p>List with compartment names to pause recording. Default: None, i.e., all compartments of initialized mon_dict are paused.</p> <code>None</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>@check_types()\ndef pause(self, compartment_list: list | None = None):\n    \"\"\"\n    Pause recording of all recorded compartments in compartment_list.\n\n    Args:\n        compartment_list (list, optional):\n            List with compartment names to pause recording. Default: None,\n            i.e., all compartments of initialized mon_dict are paused.\n    \"\"\"\n    if compartment_list == None:\n        mon_dict_key_list = list(self.mon_dict.keys())\n        compartment_list = [\n            self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n        ]\n\n    self.timings = self._pause_monitors(compartment_list, self.mon, self.timings)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.reset","title":"<code>reset(populations=True, projections=False, synapses=False, monitors=True, model=True, parameters=True, net_id=0)</code>","text":"<p>Create a new recording chunk by getting recordings and recording times of the current chunk and optionally resetting the model. Recordings are automatically resumed in the new chunk if they are not paused.</p> <p>Parameters:</p> Name Type Description Default <code>populations</code> <code>bool</code> <p>If True, reset populations. Default: True.</p> <code>True</code> <code>projections</code> <code>bool</code> <p>If True, reset projections. Default: False.</p> <code>False</code> <code>synapses</code> <code>bool</code> <p>If True, reset synapses. Default: False.</p> <code>False</code> <code>monitors</code> <code>bool</code> <p>If True, reset ANNarchy monitors. Default: True.</p> <code>True</code> <code>model</code> <code>bool</code> <p>If True, reset model. Default: True.</p> <code>True</code> <code>parameters</code> <code>bool</code> <p>If True, reset the parameters of popilations and projections. Default: True.</p> <code>True</code> <code>net_id</code> <code>int</code> <p>Id of the network to reset. Default: 0.</p> <code>0</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def reset(\n    self,\n    populations=True,\n    projections=False,\n    synapses=False,\n    monitors=True,\n    model=True,\n    parameters=True,\n    net_id=0,\n):\n    \"\"\"\n    Create a new recording chunk by getting recordings and recording times of the\n    current chunk and optionally resetting the model. Recordings are automatically\n    resumed in the new chunk if they are not paused.\n\n    Args:\n        populations (bool, optional):\n            If True, reset populations. Default: True.\n        projections (bool, optional):\n            If True, reset projections. Default: False.\n        synapses (bool, optional):\n            If True, reset synapses. Default: False.\n        monitors (bool, optional):\n            If True, reset ANNarchy monitors. Default: True.\n        model (bool, optional):\n            If True, reset model. Default: True.\n        parameters (bool, optional):\n            If True, reset the parameters of popilations and projections. Default:\n            True.\n        net_id (int, optional):\n            Id of the network to reset. Default: 0.\n    \"\"\"\n    ### TODO rename this function to new_chunk() or something like that and let\n    ### recordings and recording times be returned\n    self.get_recordings_reset_call = True\n    self.get_recordings()\n    self.get_recording_times()\n    self.get_recordings_reset_call = False\n    self.already_got_recordings = (\n        False  # after reset one can still update recordings\n    )\n    self.already_got_recording_times = (\n        False  # after reset one can still update recording_times\n    )\n\n    ### reset timings, after reset, add a zero to start if the monitor is still\n    ### running (this is not resetted by reset())\n    ### if the model was not resetted --&gt; do add current time instead of zero\n    for key in self.timings.keys():\n        self.timings[key][\"start\"] = []\n        self.timings[key][\"stop\"] = []\n        if self.timings[key][\"currently_paused\"] == False:\n            if model:\n                self.timings[key][\"start\"].append(0)\n            else:\n                self.timings[key][\"start\"].append(\n                    np.round(get_time(), af.get_number_of_decimals(dt()))\n                )\n\n    ### reset model\n    if model:\n        if parameters is False:\n            ### if parameters=False, get parameters before reset and set them after\n            ### reset\n            parameters_dict = mf._get_all_parameters()\n        reset(populations, projections, synapses, monitors, net_id=net_id)\n        if parameters is False:\n            ### if parameters=False, set parameters after reset\n            mf._set_all_parameters(parameters_dict)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.current_chunk","title":"<code>current_chunk()</code>","text":"<p>Get the index of the current chunk.</p> <p>Returns:</p> Name Type Description <code>current_chunk_idx</code> <code>int</code> <p>Index of the current chunk. If no recordings are currently active, returns None.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def current_chunk(self):\n    \"\"\"\n    Get the index of the current chunk.\n\n    Returns:\n        current_chunk_idx (int):\n            Index of the current chunk. If no recordings are currently active,\n            returns None.\n    \"\"\"\n    ### if recordings are currently active --&gt; return chunk in which these recordings will be saved\n    ### check if there are currently active recordings\n    active_recordings = False\n    for key, val in self.mon_dict.items():\n        _, compartment, _ = self._unpack_mon_dict_keys(key)\n        if not (self.timings[compartment][\"currently_paused\"]):\n            ### tere are currently active recordings\n            active_recordings = True\n\n    if active_recordings:\n        current_chunk_idx = len(self.recordings)\n        return current_chunk_idx\n    else:\n        ### if currently no recordings are active return None\n        return None\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.get_recordings","title":"<code>get_recordings()</code>","text":"<p>Get recordings of all recorded compartments.</p> <p>Returns:</p> Name Type Description <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recordings(self) -&gt; list[dict]:\n    \"\"\"\n    Get recordings of all recorded compartments.\n\n    Returns:\n        recordings (list):\n            List with recordings of all chunks.\n    \"\"\"\n    ### only if recordings in current chunk and get_recodings was not already called add current chunk to recordings\n    if (\n        self._any_recordings_in_current_chunk()\n        and self.already_got_recordings is False\n    ):\n        ### update recordings\n        self.recordings.append(self._get_monitors(self.mon_dict, self.mon))\n        ### upade already_got_recordings --&gt; it will not update recordings again\n        self.already_got_recordings = True\n\n        if not (self.get_recordings_reset_call):\n            if len(self.recordings) == 0:\n                print(\n                    \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return self.recordings\n    else:\n        if not (self.get_recordings_reset_call):\n            if len(self.recordings) == 0:\n                print(\n                    \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return self.recordings\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.get_recording_times","title":"<code>get_recording_times()</code>","text":"<p>Get recording times of all recorded compartments.</p> <p>Returns:</p> Name Type Description <code>recording_times</code> <code>recording_times_cl</code> <p>Object with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recording_times(self):\n    \"\"\"\n    Get recording times of all recorded compartments.\n\n    Returns:\n        recording_times (recording_times_cl):\n            Object with recording times of all chunks.\n    \"\"\"\n\n    temp_timings = self._get_temp_timings()\n\n    ### only append temp_timings of current chunk if there are recordings in current chunk at all and if get_recordings was not already called (double call would add the same chunk again)\n    if (\n        self._any_recordings_in_current_chunk()\n        and self.already_got_recording_times is False\n    ):\n        self.recording_times.append(temp_timings)\n\n    ### upade already_got_recording_times --&gt; it will not update recording_times again\n    self.already_got_recording_times = True\n\n    ### generate a object from recording_times and return this instead of the dict\n    recording_times_ob = RecordingTimes(self.recording_times)\n\n    if not (self.get_recordings_reset_call):\n        if len(self.recording_times) == 0:\n            print(\n                \"WARNING get_recording_times: no recordings available, empty list returned. Maybe forgot start()?\"\n            )\n    return recording_times_ob\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.get_recordings_and_clear","title":"<code>get_recordings_and_clear()</code>","text":"<p>The default get_recordings method should be called at the end of the simulation. The get_recordings_and_clear method allows to get several times recordings with the same monitor object and to simulate between the calls. Sets the internal variables back to their initial state. Usefull if you repeat a simulation + recording several times and you do not want to always create new chunks.</p> <p>Warning</p> <p>If you want to continue recording after calling this method, you have to call start() again.</p> <p>Returns:</p> Name Type Description <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> <code>recording_times</code> <code>recording_times_cl</code> <p>Object with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recordings_and_clear(self):\n    \"\"\"\n    The default get_recordings method should be called at the end of the simulation.\n    The get_recordings_and_clear method allows to get several times recordings with\n    the same monitor object and to simulate between the calls. Sets the internal\n    variables back to their initial state. Usefull if you repeat a simulation +\n    recording several times and you do not want to always create new chunks.\n\n    !!! warning\n        If you want to continue recording after calling this method, you have to\n        call start() again.\n\n    Returns:\n        recordings (list):\n            List with recordings of all chunks.\n        recording_times (recording_times_cl):\n            Object with recording times of all chunks.\n    \"\"\"\n    ret0 = self.get_recordings()\n    ret1 = self.get_recording_times()\n    self._init_internals()\n    ret = (ret0, ret1)\n    return ret\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes","title":"<code>CompNeuroPy.monitors.RecordingTimes</code>","text":"Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>class RecordingTimes:\n    def __init__(self, recording_times_list):\n        \"\"\"\n        Initialize RecordingTimes object.\n\n        Args:\n            recording_times_list (list):\n                List with recording times of all chunks.\n        \"\"\"\n        self.recording_times_list = recording_times_list\n\n    def time_lims(\n        self,\n        chunk: int | None = None,\n        compartment: str | None = None,\n        period: int | None = None,\n    ):\n        \"\"\"\n        Get the time limits recordings of of a specified chunk/model compartment in ms.\n\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment from\n            monitor.\n        period (int, optional):\n            Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop time of the specified chunk/model compartment.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR time_lims(): No recordings/recording_times available.\"\n        return self._lims(\"ms\", chunk, compartment, period)\n\n    def idx_lims(\n        self,\n        chunk: int | None = None,\n        compartment: str | None = None,\n        period: int | None = None,\n    ):\n        \"\"\"\n        Get the index limits of recordings of a specified chunk/model compartment.\n\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment from\n            monitor.\n        period (int, optional):\n            Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop index of the specified chunk/model\n                compartment.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR idx_lims(): No recordings/recording_times available.\"\n        return self._lims(\"idx\", chunk, compartment, period)\n\n    def all(self):\n        \"\"\"\n        Get the recording times of all chunks, compartments, periods in ms and index.\n\n        Returns:\n            recording_times_list (list):\n                List with recording times of all chunks.\n        \"\"\"\n        return self.recording_times_list\n\n    def nr_periods(self, chunk=None, compartment=None):\n        \"\"\"\n        Get the number of recording periods (start-pause) of a specified chunk/model\n        compartment.\n\n        Args:\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n            compartment (str, optional):\n                Name of the compartment. Default: None, i.e., first model compartment\n                from monitor.\n\n        Returns:\n            nr_periods (int):\n                Number of recording periods (start-pause) of a specified chunk/model\n                compartment.\n        \"\"\"\n        chunk = self._check_chunk(chunk)\n        compartment = self.__check_compartment__(compartment, chunk)\n        return self._get_nr_periods(chunk, compartment)\n\n    def combine_periods(\n        self,\n        recordings: list,\n        recording_data_str: str,\n        chunk: int = 0,\n        fill: str | float = \"none\",\n    ):\n        \"\"\"\n        Combines the data of all periods of a specified chunk/model compartment.\n\n        Args:\n            recordings (list):\n                List with recordings of all chunks.\n            recording_data_str (str):\n                String specifying the compartment name and the variable to combine.\n                Format: \"compartment_name;variable_name\"\n            chunk (int, optional):\n                Index of the chunk. Default: 0.\n            fill (str|float, optional):\n                How recording pauses should be filled. Can be \"none\" (no filling),\n                \"nan\" (fill with nan), \"interpolate\" (interpolate with nearest) or a\n                float (fill with this value). Default: \"none\".\n\n        Returns:\n            time_arr (np.array):\n                Array with time values in ms.\n            data_arr (np.array):\n                Array with the recorded variable.\n        \"\"\"\n        compartment = recording_data_str.split(\";\")[0]\n        period_time = recordings[0][f\"{compartment};period\"]\n        nr_periods = self._get_nr_periods(chunk, compartment)\n        time_step = recordings[0][\"dt\"]\n        time_list = []\n\n        ### get data arr\n        data_arr = recordings[chunk][recording_data_str]\n\n        ### get time arr\n        for period in range(nr_periods):\n            start_time, end_time = self.time_lims(\n                chunk=chunk, compartment=compartment, period=period\n            )\n            start_time = round(start_time, af.get_number_of_decimals(time_step))\n            end_time = round(end_time, af.get_number_of_decimals(time_step))\n            times = np.arange(start_time, end_time + period_time / 2, period_time)\n            time_list.append(times)\n        time_arr = np.concatenate(time_list, 0)\n\n        ### fill gaps with nan or interpolate\n        if fill == \"nan\":\n            time_arr, data_arr = af.time_data_add_nan(\n                time_arr,\n                data_arr,\n                fill_time_step=period_time,\n            )\n        elif fill == \"interpolate\":\n            full_time_arr = np.arange(\n                time_arr[0], time_arr[-1] + period_time / 2, period_time\n            )\n            f = interp1d(time_arr, data_arr, kind=\"nearest\", axis=0)\n            data_arr = f(full_time_arr)\n            time_arr = full_time_arr\n        elif isinstance(fill, (int, float)):\n            time_arr, data_arr = af.time_data_fill_gaps(\n                time_arr,\n                data_arr,\n                fill_time_step=period_time,\n                fill=fill,\n            )\n\n        return time_arr, data_arr\n\n    def combine_chunks(\n        self, recordings: list, recording_data_str: str, mode=\"sequential\"\n    ):\n        \"\"\"\n        Combines the data of all chunks of recordings. Time periods without recordings\n        AT THE BEGINNING OF chunks or WITHIN chunks (i.e. recording pauses) are\n        considered and filled with nan values.\n\n        !!! warning\n            If you use mode=\"consecutive\": Missing recordings at the end of chunks\n            (simulated but not recorded) are not considered, this leads to times which\n            differ from the original simulation times (these time periods without\n            recording are simply ignored)!\n\n        Args:\n            recordings (list):\n                List with recordings of all chunks.\n            recording_data_str (str):\n                String specifying the compartment name and the variable to combine.\n                Format: \"compartment_name;variable_name\"\n            mode (str, optional):\n                How should the time array be generated. Can be \"sequential\" or\n                \"consecutive\". Default: \"sequential\".\n                - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;\n                    [0, 1, ..., 100, 0, 1, ..., 250]\n                - \"consecutive\": each chunk starts at the last stop time of the previous\n                    chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]\n\n        Returns:\n            time_arr (np.array):\n                Array with time values in ms.\n            data_arr (np.array):\n                Array with the recorded variable.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR combine_chunks(): No recordings/recording_times available.\"\n\n        compartment = recording_data_str.split(\";\")[0]\n        period_time = recordings[0][f\"{compartment};period\"]\n        time_step = recordings[0][\"dt\"]\n        nr_chunks = self._get_nr_chunks()\n        data_list = []\n        time_list = []\n        pre_chunk_start_time = 0\n\n        for chunk in range(nr_chunks):\n            ### append data list with data of all periods of this chunk\n            data_list.append(recordings[chunk][recording_data_str])\n\n            ### nr of periods in this chunk\n            nr_periods = self._get_nr_periods(chunk, compartment)\n\n            ### start time of chunk depends on mode\n            if mode == \"sequential\":\n                chunk_start_time = 0\n            elif mode == \"consecutive\":\n                if chunk == 0:\n                    chunk_start_time = 0\n                else:\n                    ### TODO this uses the wrong end time if there is a pause at the end\n                    ### of the last chunk but it is not possible to get the info how long\n                    ### nothing was recorded at the end of a chunk (all I save is from\n                    ### when to when something is recorded)\n                    last_stop_time = self.recording_times_list[chunk - 1][compartment][\n                        \"stop\"\n                    ][\"ms\"][-1]\n                    chunk_start_time = (\n                        pre_chunk_start_time + last_stop_time + period_time\n                    )\n                    pre_chunk_start_time = chunk_start_time\n            else:\n                print(\"ERROR recording_times.combine_data, Wrong mode.\")\n                quit()\n\n            ### append the time list with all times of the periods\n            for period in range(nr_periods):\n                start_time = (\n                    self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                        0\n                    ]\n                    + chunk_start_time\n                )\n                end_time = (\n                    self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                        1\n                    ]\n                    + chunk_start_time\n                )\n                start_time = round(start_time, af.get_number_of_decimals(time_step))\n                end_time = round(end_time, af.get_number_of_decimals(time_step))\n                times = np.arange(start_time, end_time + period_time / 2, period_time)\n                time_list.append(times)\n\n        ### flatten the two lists\n        data_arr = np.concatenate(data_list, 0)\n        time_arr = np.concatenate(time_list, 0)\n\n        ### check if there are gaps in the time array\n        ### fill them with the corersponding times and\n        ### the data array with nan values\n        time_arr, data_arr = af.time_data_add_nan(\n            time_arr,\n            data_arr,\n            fill_time_step=period_time,\n        )\n\n        return time_arr, data_arr\n\n    def _lims(self, string, chunk=None, compartment=None, period=None):\n        \"\"\"\n        Get the limits of recordings of a specified chunk/model compartment.\n\n        Args:\n            string (str):\n                String specifying the type of limits to return. Can be \"ms\" for time\n                limits in ms or \"idx\" for index limits.\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n            compartment (str, optional):\n                Name of the compartment. Default: None, i.e., first model compartment\n                from monitor.\n            period (int, optional):\n                Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop time/index of the specified chunk/model\n                compartment.\n        \"\"\"\n\n        chunk = self._check_chunk(chunk)\n        compartment = self.__check_compartment__(compartment, chunk)\n        period_0, period_1 = self._check_period(period, chunk, compartment)\n        lims = (\n            self.recording_times_list[chunk][compartment][\"start\"][string][period_0],\n            self.recording_times_list[chunk][compartment][\"stop\"][string][period_1],\n        )\n        return lims\n\n    def __check_compartment__(self, compartment, chunk):\n        if compartment == None:\n            ### by default just use the first compartment\n            compartment = list(self.recording_times_list[chunk].keys())[0]\n        elif compartment in list(self.recording_times_list[chunk].keys()):\n            compartment = compartment\n        else:\n            print(\n                'ERROR recording_times, given compartment \"'\n                + str(compartment)\n                + '\" not available'\n            )\n            quit()\n\n        return compartment\n\n    def _check_period(self, period, chunk, compartment):\n        \"\"\"\n        Check if period is given.\n\n        Args:\n            period (int, optional):\n                Index of the period. Default: None, i.e., all periods.\n            chunk (int):\n                Index of the chunk.\n            compartment (str):\n                Name of the compartment.\n\n        Returns:\n            period_0 (int):\n                Index of the first period.\n            period_1 (int):\n                Index of the last period. If perios is given, period_0 == period_1.\n        \"\"\"\n        if period == None:\n            ### by default use all periods\n            period_0 = 0\n            period_1 = (\n                len(self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]) - 1\n            )\n        elif period &lt; len(\n            self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]\n        ):\n            period_0 = period\n            period_1 = period\n        else:\n            print(\"ERROR recording_times, given period not available\")\n            quit()\n\n        return period_0, period_1\n\n    def _check_chunk(self, chunk):\n        \"\"\"\n        Check if chunk is given.\n\n        Args:\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n\n        Returns:\n            chunk (int):\n                Index of the chunk.\n        \"\"\"\n        if chunk is None:\n            ### by default use first chunk\n            chunk = 0\n        elif chunk &lt; self._get_nr_chunks():\n            chunk = chunk\n        else:\n            print(\"ERROR recording_times, given chunk not available\")\n            quit()\n\n        return chunk\n\n    def _get_nr_chunks(self):\n        \"\"\"\n        Get the number of chunks of the recordings.\n\n        Returns:\n            nr_chunks (int):\n                Number of chunks.\n        \"\"\"\n        return len(self.recording_times_list)\n\n    def _get_nr_periods(self, chunk, compartment):\n        \"\"\"\n        Get the number of recording periods (start-pause) of a specified chunk/model\n        compartment.\n\n        Args:\n            chunk (int):\n                Index of the chunk.\n            compartment (str):\n                Name of the compartment.\n\n        Returns:\n            nr_periods (int):\n                Number of recording periods (start-pause) of a specified chunk/model\n                compartment.\n        \"\"\"\n        return len(self.recording_times_list[chunk][compartment][\"start\"][\"idx\"])\n\n    def _any_recordings(self, chunk):\n        \"\"\"\n        Check all periods and compartments if there are any recordings.\n\n        Args:\n            chunk (int):\n                Index of the chunk.\n\n        Returns:\n            found_recordings (bool):\n                True if there are any recordings in the chunk, False otherwise.\n        \"\"\"\n        compartment_list = list(self.recording_times_list[chunk].keys())\n        found_recordings = False\n        for compartment in compartment_list:\n            nr_periods_of_compartment = len(\n                self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]\n            )\n\n            for period_idx in range(nr_periods_of_compartment):\n                idx_lims = self.idx_lims(\n                    chunk=chunk, compartment=compartment, period=period_idx\n                )\n                if np.diff(idx_lims)[0] &gt; 0:\n                    found_recordings = True\n\n        return found_recordings\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.__init__","title":"<code>__init__(recording_times_list)</code>","text":"<p>Initialize RecordingTimes object.</p> <p>Parameters:</p> Name Type Description Default <code>recording_times_list</code> <code>list</code> <p>List with recording times of all chunks.</p> required Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def __init__(self, recording_times_list):\n    \"\"\"\n    Initialize RecordingTimes object.\n\n    Args:\n        recording_times_list (list):\n            List with recording times of all chunks.\n    \"\"\"\n    self.recording_times_list = recording_times_list\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.time_lims","title":"<code>time_lims(chunk=None, compartment=None, period=None)</code>","text":"<p>Get the time limits recordings of of a specified chunk/model compartment in ms.</p> <p>chunk (int, optional):     Index of the chunk. Default: None, i.e., first chunk. compartment (str, optional):     Name of the compartment. Default: None, i.e., first model compartment from     monitor. period (int, optional):     Index of the period. Default: None, i.e., all periods.</p> <p>Returns:</p> Name Type Description <code>lims</code> <code>tuple</code> <p>Tuple with start and stop time of the specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def time_lims(\n    self,\n    chunk: int | None = None,\n    compartment: str | None = None,\n    period: int | None = None,\n):\n    \"\"\"\n    Get the time limits recordings of of a specified chunk/model compartment in ms.\n\n    chunk (int, optional):\n        Index of the chunk. Default: None, i.e., first chunk.\n    compartment (str, optional):\n        Name of the compartment. Default: None, i.e., first model compartment from\n        monitor.\n    period (int, optional):\n        Index of the period. Default: None, i.e., all periods.\n\n    Returns:\n        lims (tuple):\n            Tuple with start and stop time of the specified chunk/model compartment.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR time_lims(): No recordings/recording_times available.\"\n    return self._lims(\"ms\", chunk, compartment, period)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.idx_lims","title":"<code>idx_lims(chunk=None, compartment=None, period=None)</code>","text":"<p>Get the index limits of recordings of a specified chunk/model compartment.</p> <p>chunk (int, optional):     Index of the chunk. Default: None, i.e., first chunk. compartment (str, optional):     Name of the compartment. Default: None, i.e., first model compartment from     monitor. period (int, optional):     Index of the period. Default: None, i.e., all periods.</p> <p>Returns:</p> Name Type Description <code>lims</code> <code>tuple</code> <p>Tuple with start and stop index of the specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def idx_lims(\n    self,\n    chunk: int | None = None,\n    compartment: str | None = None,\n    period: int | None = None,\n):\n    \"\"\"\n    Get the index limits of recordings of a specified chunk/model compartment.\n\n    chunk (int, optional):\n        Index of the chunk. Default: None, i.e., first chunk.\n    compartment (str, optional):\n        Name of the compartment. Default: None, i.e., first model compartment from\n        monitor.\n    period (int, optional):\n        Index of the period. Default: None, i.e., all periods.\n\n    Returns:\n        lims (tuple):\n            Tuple with start and stop index of the specified chunk/model\n            compartment.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR idx_lims(): No recordings/recording_times available.\"\n    return self._lims(\"idx\", chunk, compartment, period)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.all","title":"<code>all()</code>","text":"<p>Get the recording times of all chunks, compartments, periods in ms and index.</p> <p>Returns:</p> Name Type Description <code>recording_times_list</code> <code>list</code> <p>List with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def all(self):\n    \"\"\"\n    Get the recording times of all chunks, compartments, periods in ms and index.\n\n    Returns:\n        recording_times_list (list):\n            List with recording times of all chunks.\n    \"\"\"\n    return self.recording_times_list\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.nr_periods","title":"<code>nr_periods(chunk=None, compartment=None)</code>","text":"<p>Get the number of recording periods (start-pause) of a specified chunk/model compartment.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>int</code> <p>Index of the chunk. Default: None, i.e., first chunk.</p> <code>None</code> <code>compartment</code> <code>str</code> <p>Name of the compartment. Default: None, i.e., first model compartment from monitor.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>nr_periods</code> <code>int</code> <p>Number of recording periods (start-pause) of a specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def nr_periods(self, chunk=None, compartment=None):\n    \"\"\"\n    Get the number of recording periods (start-pause) of a specified chunk/model\n    compartment.\n\n    Args:\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment\n            from monitor.\n\n    Returns:\n        nr_periods (int):\n            Number of recording periods (start-pause) of a specified chunk/model\n            compartment.\n    \"\"\"\n    chunk = self._check_chunk(chunk)\n    compartment = self.__check_compartment__(compartment, chunk)\n    return self._get_nr_periods(chunk, compartment)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.combine_periods","title":"<code>combine_periods(recordings, recording_data_str, chunk=0, fill='none')</code>","text":"<p>Combines the data of all periods of a specified chunk/model compartment.</p> <p>Parameters:</p> Name Type Description Default <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> required <code>recording_data_str</code> <code>str</code> <p>String specifying the compartment name and the variable to combine. Format: \"compartment_name;variable_name\"</p> required <code>chunk</code> <code>int</code> <p>Index of the chunk. Default: 0.</p> <code>0</code> <code>fill</code> <code>str | float</code> <p>How recording pauses should be filled. Can be \"none\" (no filling), \"nan\" (fill with nan), \"interpolate\" (interpolate with nearest) or a float (fill with this value). Default: \"none\".</p> <code>'none'</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>Array with time values in ms.</p> <code>data_arr</code> <code>array</code> <p>Array with the recorded variable.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def combine_periods(\n    self,\n    recordings: list,\n    recording_data_str: str,\n    chunk: int = 0,\n    fill: str | float = \"none\",\n):\n    \"\"\"\n    Combines the data of all periods of a specified chunk/model compartment.\n\n    Args:\n        recordings (list):\n            List with recordings of all chunks.\n        recording_data_str (str):\n            String specifying the compartment name and the variable to combine.\n            Format: \"compartment_name;variable_name\"\n        chunk (int, optional):\n            Index of the chunk. Default: 0.\n        fill (str|float, optional):\n            How recording pauses should be filled. Can be \"none\" (no filling),\n            \"nan\" (fill with nan), \"interpolate\" (interpolate with nearest) or a\n            float (fill with this value). Default: \"none\".\n\n    Returns:\n        time_arr (np.array):\n            Array with time values in ms.\n        data_arr (np.array):\n            Array with the recorded variable.\n    \"\"\"\n    compartment = recording_data_str.split(\";\")[0]\n    period_time = recordings[0][f\"{compartment};period\"]\n    nr_periods = self._get_nr_periods(chunk, compartment)\n    time_step = recordings[0][\"dt\"]\n    time_list = []\n\n    ### get data arr\n    data_arr = recordings[chunk][recording_data_str]\n\n    ### get time arr\n    for period in range(nr_periods):\n        start_time, end_time = self.time_lims(\n            chunk=chunk, compartment=compartment, period=period\n        )\n        start_time = round(start_time, af.get_number_of_decimals(time_step))\n        end_time = round(end_time, af.get_number_of_decimals(time_step))\n        times = np.arange(start_time, end_time + period_time / 2, period_time)\n        time_list.append(times)\n    time_arr = np.concatenate(time_list, 0)\n\n    ### fill gaps with nan or interpolate\n    if fill == \"nan\":\n        time_arr, data_arr = af.time_data_add_nan(\n            time_arr,\n            data_arr,\n            fill_time_step=period_time,\n        )\n    elif fill == \"interpolate\":\n        full_time_arr = np.arange(\n            time_arr[0], time_arr[-1] + period_time / 2, period_time\n        )\n        f = interp1d(time_arr, data_arr, kind=\"nearest\", axis=0)\n        data_arr = f(full_time_arr)\n        time_arr = full_time_arr\n    elif isinstance(fill, (int, float)):\n        time_arr, data_arr = af.time_data_fill_gaps(\n            time_arr,\n            data_arr,\n            fill_time_step=period_time,\n            fill=fill,\n        )\n\n    return time_arr, data_arr\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.combine_chunks","title":"<code>combine_chunks(recordings, recording_data_str, mode='sequential')</code>","text":"<p>Combines the data of all chunks of recordings. Time periods without recordings AT THE BEGINNING OF chunks or WITHIN chunks (i.e. recording pauses) are considered and filled with nan values.</p> <p>Warning</p> <p>If you use mode=\"consecutive\": Missing recordings at the end of chunks (simulated but not recorded) are not considered, this leads to times which differ from the original simulation times (these time periods without recording are simply ignored)!</p> <p>Parameters:</p> Name Type Description Default <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> required <code>recording_data_str</code> <code>str</code> <p>String specifying the compartment name and the variable to combine. Format: \"compartment_name;variable_name\"</p> required <code>mode</code> <code>str</code> <p>How should the time array be generated. Can be \"sequential\" or \"consecutive\". Default: \"sequential\". - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;     [0, 1, ..., 100, 0, 1, ..., 250] - \"consecutive\": each chunk starts at the last stop time of the previous     chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]</p> <code>'sequential'</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>Array with time values in ms.</p> <code>data_arr</code> <code>array</code> <p>Array with the recorded variable.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def combine_chunks(\n    self, recordings: list, recording_data_str: str, mode=\"sequential\"\n):\n    \"\"\"\n    Combines the data of all chunks of recordings. Time periods without recordings\n    AT THE BEGINNING OF chunks or WITHIN chunks (i.e. recording pauses) are\n    considered and filled with nan values.\n\n    !!! warning\n        If you use mode=\"consecutive\": Missing recordings at the end of chunks\n        (simulated but not recorded) are not considered, this leads to times which\n        differ from the original simulation times (these time periods without\n        recording are simply ignored)!\n\n    Args:\n        recordings (list):\n            List with recordings of all chunks.\n        recording_data_str (str):\n            String specifying the compartment name and the variable to combine.\n            Format: \"compartment_name;variable_name\"\n        mode (str, optional):\n            How should the time array be generated. Can be \"sequential\" or\n            \"consecutive\". Default: \"sequential\".\n            - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;\n                [0, 1, ..., 100, 0, 1, ..., 250]\n            - \"consecutive\": each chunk starts at the last stop time of the previous\n                chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]\n\n    Returns:\n        time_arr (np.array):\n            Array with time values in ms.\n        data_arr (np.array):\n            Array with the recorded variable.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR combine_chunks(): No recordings/recording_times available.\"\n\n    compartment = recording_data_str.split(\";\")[0]\n    period_time = recordings[0][f\"{compartment};period\"]\n    time_step = recordings[0][\"dt\"]\n    nr_chunks = self._get_nr_chunks()\n    data_list = []\n    time_list = []\n    pre_chunk_start_time = 0\n\n    for chunk in range(nr_chunks):\n        ### append data list with data of all periods of this chunk\n        data_list.append(recordings[chunk][recording_data_str])\n\n        ### nr of periods in this chunk\n        nr_periods = self._get_nr_periods(chunk, compartment)\n\n        ### start time of chunk depends on mode\n        if mode == \"sequential\":\n            chunk_start_time = 0\n        elif mode == \"consecutive\":\n            if chunk == 0:\n                chunk_start_time = 0\n            else:\n                ### TODO this uses the wrong end time if there is a pause at the end\n                ### of the last chunk but it is not possible to get the info how long\n                ### nothing was recorded at the end of a chunk (all I save is from\n                ### when to when something is recorded)\n                last_stop_time = self.recording_times_list[chunk - 1][compartment][\n                    \"stop\"\n                ][\"ms\"][-1]\n                chunk_start_time = (\n                    pre_chunk_start_time + last_stop_time + period_time\n                )\n                pre_chunk_start_time = chunk_start_time\n        else:\n            print(\"ERROR recording_times.combine_data, Wrong mode.\")\n            quit()\n\n        ### append the time list with all times of the periods\n        for period in range(nr_periods):\n            start_time = (\n                self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                    0\n                ]\n                + chunk_start_time\n            )\n            end_time = (\n                self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                    1\n                ]\n                + chunk_start_time\n            )\n            start_time = round(start_time, af.get_number_of_decimals(time_step))\n            end_time = round(end_time, af.get_number_of_decimals(time_step))\n            times = np.arange(start_time, end_time + period_time / 2, period_time)\n            time_list.append(times)\n\n    ### flatten the two lists\n    data_arr = np.concatenate(data_list, 0)\n    time_arr = np.concatenate(time_list, 0)\n\n    ### check if there are gaps in the time array\n    ### fill them with the corersponding times and\n    ### the data array with nan values\n    time_arr, data_arr = af.time_data_add_nan(\n        time_arr,\n        data_arr,\n        fill_time_step=period_time,\n    )\n\n    return time_arr, data_arr\n</code></pre>"},{"location":"main/optimize_neuron/","title":"Optimize a neuron model","text":""},{"location":"main/optimize_neuron/#introduction","title":"Introduction","text":"<p>CompNeuroPy provides the <code>OptNeuron</code> class which can be used to define your optimization of an ANNarchy neuron model (tuning the parameters). You can either optimize your neuron model to some data or try to reproduce the dynamics of a different neuron model (for example to reduce a more complex model). In both cases, you have to define the experiment which generates the data of interest with your neuron model.</p> <p>Warning</p> <p>OptNeuron has to be imported from \"CompNeuroPy.opt_neuron\" and you have to install torch, sbi, pybads and hyperopt (e.g. pip install torch sbi pybads hyperopt) separately.</p> <p>Used optimization methods:</p> <ul> <li> <p>hyperopt (using the Tree of Parzen Estimators (TPE))</p> <ul> <li>Bergstra, J., Yamins, D., Cox, D. D. (2013) Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures. TProc. of the 30th International Conference on Machine Learning (ICML 2013), June 2013, pp. I-115 to I-23. pdf</li> </ul> </li> <li> <p>sbi</p> <ul> <li>Tejero-Cantero et al., (2020). sbi: A toolkit for simulation-based inference. Journal of Open Source Software, 5(52), 2505, https://doi.org/10.21105/joss.02505</li> </ul> </li> <li> <p>deap (using the CMAES strategy)</p> <ul> <li>Fortin, F. A., De Rainville, F. M., Gardner, M. A. G., Parizeau, M., &amp; Gagn\u00e9, C. (2012). DEAP: Evolutionary algorithms made easy. The Journal of Machine Learning Research, 13(1), 2171-2175. pdf</li> </ul> </li> <li> <p>pybads</p> <ul> <li>Singh, G. S., &amp; Acerbi, L. (2023). PyBADS: Fast and robust black-box optimization in Python. arXiv preprint arXiv:2306.15576.</li> <li>Acerbi, L., &amp; Ma, W. J. (2017). Practical Bayesian optimization for model fitting with Bayesian adaptive direct search. Advances in neural information processing systems, 30. pdf</li> </ul> </li> </ul>"},{"location":"main/optimize_neuron/#example","title":"Example:","text":"<pre><code>opt = OptNeuron(\n    experiment=my_exp,\n    get_loss_function=get_loss,\n    variables_bounds=variables_bounds,\n    results_soll=experimental_data[\"results_soll\"],\n    time_step=experimental_data[\"time_step\"],\n    compile_folder_name=\"annarchy_opt_neuron_example\",\n    neuron_model=my_neuron,\n    method=\"hyperopt\",\n    record=[\"r\"],\n)\n</code></pre> <p>A full example is available in the Examples.</p>"},{"location":"main/optimize_neuron/#run-the-optimization","title":"Run the optimization","text":"<p>To run the optimization simply call the run() function of the <code>OptNeuron</code> object.</p>"},{"location":"main/optimize_neuron/#define-the-experiment","title":"Define the experiment","text":"<p>You have to define a <code>CompNeuroExp</code> object containing a run() function. In the run() function simulations and recordings are performed.</p> <p>Warning</p> <p>While defining the <code>CompNeuroExp</code> run() function for the optimization with <code>OptNeuron</code> you must observe the following rules:</p> <ul> <li>the run() function has to take a single argument (besides self) which contains the name of the population consiting of a single neuron or multiple neurons of the optimized neuron model (you can use this to access the population)</li> <li>thus, the simulation has to be compatible with a population consisting of a single or multiple neurons</li> <li>use the self.reset() function within the run() function to create new recording chunks and reset the model parameters/variables!</li> <li><code>OptNeuron</code> automatically sets the parameters/variables defined in the variables_bounds before each run, self.reset() will reset the model to this state (all parameters/variables not defined in variables_bounds are reset to compile state)</li> <li>be aware that the target neuron model is always resetted to compile state (this affects results_soll)!</li> <li>using self.reset(parameters=False) in the run() function keeps all parameter changes you do during the experiment</li> <li>start the monitors before you want to record something by calling self.monitors.start()</li> <li>the best parameters, the corresponding loss, and the corresponding results of the experiment will be available after the optimization, you can store any additional data which should be available after optimiozation in the self.data attribute</li> <li>do not call the functions store_model_state() and reset_model_state() of the <code>CompNeuroExp</code> class within the run() function!</li> </ul>"},{"location":"main/optimize_neuron/#example_1","title":"Example:","text":"<pre><code>class my_exp(CompNeuroExp):\n    \"\"\"\n    Define an experiment by inheriting from CompNeuroExp.\n\n    CompNeuroExp provides the attributes:\n\n        monitors (CompNeuroMonitors):\n            a CompNeuroMonitors object to do recordings, define during init otherwise\n            None\n        data (dict):\n            a dictionary for storing any optional data\n\n    and the functions:\n        reset():\n            resets the model and monitors\n        results():\n            returns a results object\n    \"\"\"\n\n    def run(self, population_name):\n        \"\"\"\n        Do the simulations and recordings.\n\n        To use the CompNeuroExp class, you need to define a run function which\n        does the simulations and recordings. The run function should return the\n        results object which can be obtained by calling self.results().\n\n        For using the CompNeuroExp for OptNeuron, the run function should have\n        one argument which is the name of the population which is automatically created\n        by OptNeuron, containing a single neuron of the model which should be optimized.\n\n        Args:\n            population_name (str):\n                name of the population which contains a single neuron, this will be\n                automatically provided by opt_neuron\n\n        Returns:\n            results (CompNeuroExp._ResultsCl):\n                results object with attributes:\n                    recordings (list):\n                        list of recordings\n                    recording_times (recording_times_cl):\n                        recording times object\n                    mon_dict (dict):\n                        dict of recorded variables of the monitors\n                    data (dict):\n                        dict with optional data stored during the experiment\n        \"\"\"\n        ### you have to start monitors within the run function, otherwise nothing will\n        ### be recorded\n        self.monitors.start()\n\n        ### run the simulation, if you reset the monitors/model the model_state argument\n        ### has to be True (Default)\n        ...\n        simulate(100)\n        self.reset()\n        ...\n\n        ### optional: store anything you want in the data dict. For example infomration\n        ### about the simulations. This is not used for the optimization but can be\n        ### retrieved after the optimization is finished\n        self.data[\"sim\"] = sim_step.simulation_info()\n        self.data[\"population_name\"] = population_name\n        self.data[\"time_step\"] = dt()\n\n        ### return results, use the object's self.results()\n        return self.results()\n</code></pre>"},{"location":"main/optimize_neuron/#the-get_loss_function","title":"The get_loss_function","text":"<p>The get_loss_function must have two arguments. When this function is called during optimization, the first argument is always the results object returned by the experiment, i.e. the results of the neuron you want to optimize. The second argument depends on whether you have specified results_soll, i.e. data to be reproduced by the neuron_model, or whether you have specified a target_neuron_model whose results are to be reproduced by the neuron_model. Thus, the second argument is either results_soll provided to the <code>OptNeuron</code> class during initialization or another results object (returned by the <code>CompNeuroExp</code> run function), generated with the target_neuron_model.</p> <p>Warning</p> <p>You always have to work with the neuron rank 0 within the get_loss_function!</p>"},{"location":"main/optimize_neuron/#example_2","title":"Example:","text":"<p>In this example we assume, that results_soll was provided during initialization of the <code>OptNeuron</code> class (no target_neuron_model used). <pre><code>def get_loss(results_ist: CompNeuroExp._ResultsCl, results_soll):\n    \"\"\"\n    Function which has to have the arguments results_ist and results_soll and should\n    calculates and return the loss. This structure is needed for the OptNeuron class.\n\n    Args:\n        results_ist (object):\n            the results object returned by the run function of experiment (see above)\n        results_soll (any):\n            the target data directly provided to OptNeuron during initialization\n\n    Returns:\n        loss (float or list of floats):\n            the loss\n    \"\"\"\n    ### get the recordings and other important things for calculating the loss from\n    ### results_ist, we do not use all available information here, but you could\n    rec_ist = results_ist.recordings\n    pop_ist = results_ist.data[\"population_name\"]\n    neuron = 0\n\n    ### get the data for calculating the loss from the results_soll\n    r_target_0 = results_soll[0]\n    r_target_1 = results_soll[1]\n\n    ### get the data for calculating the loss from the recordings\n    r_ist_0 = rec_ist[0][f\"{pop_ist};r\"][:, neuron]\n    r_ist_1 = rec_ist[1][f\"{pop_ist};r\"][:, neuron]\n\n    ### calculate the loss, e.g. the root mean squared error\n    rmse1 = rmse(r_target_0, r_ist_0)\n    rmse2 = rmse(r_target_1, r_ist_1)\n\n    ### return the loss, one can return a singel value or a list of values which will\n    ### be summed during the optimization\n    return [rmse1, rmse2]\n</code></pre></p>"},{"location":"main/optimize_neuron/#CompNeuroPy.opt_neuron.OptNeuron","title":"<code>CompNeuroPy.opt_neuron.OptNeuron</code>","text":"<p>This class is used to optimize neuron models with ANNarchy.</p> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>class OptNeuron:\n    \"\"\"\n    This class is used to optimize neuron models with ANNarchy.\n    \"\"\"\n\n    opt_created = []\n\n    @check_types(warnings=False)\n    def __init__(\n        self,\n        experiment: Type[CompNeuroExp],\n        get_loss_function: Callable[[Any, Any], float | list[float]],\n        variables_bounds: dict[str, float | str | list[float | str]],\n        neuron_model: Neuron,\n        results_soll: Any | None = None,\n        target_neuron_model: Neuron | None = None,\n        time_step: float = 1.0,\n        recording_period: float | None = None,\n        compile_folder_name: str = \"annarchy_OptNeuron\",\n        num_rep_loss: int = 1,\n        method: str = \"deap\",\n        prior=None,\n        fv_space: list = None,\n        record: list[str] = [],\n        cma_params_dict: dict = {},\n        bads_params_dict: dict = {},\n        source_solutions: list[tuple[np.ndarray, float]] = [],\n        variables_bounds_guess: None | dict[str, list[float]] = None,\n        verbose=False,\n    ):\n        \"\"\"\n        This prepares the optimization. To run the optimization call the run function.\n\n        Args:\n            experiment (CompNeuroExp class):\n                CompNeuroExp class containing a 'run' function which defines the\n                simulations and recordings\n            get_loss_function (function):\n                function which takes results_ist and results_soll as arguments and\n                calculates/returns the loss\n            variables_bounds (dict):\n                Dictionary with parameter names (keys) and their bounds (values). If\n                single values are given as values, the parameter is constant, i.e., not\n                optimized. If a list is given as value, the parameter is optimized and\n                the list contains the lower and upper bound of the parameter (order is\n                not important). If strings instead of numbers are given, the string is\n                interpreted as an mathematical expression which is evaluated with the\n                other parameter values (i.e. {\"x\":[0,1],\"dxy\":[-1,1],\"y\":\"x+dxy\",\"z\":5}).\n            neuron_model (ANNarchy Neuron):\n                The neuron model whose parameters should be optimized.\n            results_soll (Any, optional):\n                Some variable which contains the target data and can be used by the\n                get_loss_function (second argument of get_loss_function)\n                !!! warning\n                    Either provide results_soll or a target_neuron_model not both!\n                Default: None.\n            target_neuron_model (ANNarchy Neuron, optional):\n                The neuron model which produces the target data by running the\n                experiment.\n                !!! warning\n                    Either provide results_soll or a target_neuron_model not both!\n                Default: None.\n            time_step (float, optional):\n                The time step for the simulation in ms. Default: 1.\n            recording_period (float, optional):\n                The recording period for the simulation in ms. Default: None, i.e., the\n                time_step is used.\n            compile_folder_name (string, optional):\n                The name of the annarchy compilation folder within annarchy_folders/.\n                Default: 'annarchy_OptNeuron'.\n            num_rep_loss (int, optional):\n                Only interesting for noisy simulations/models. How often should the\n                simulaiton be run to calculate the loss (the defined number of losses\n                is obtained and averaged). Default: 1.\n            method (str, optional):\n                Either 'deap', 'sbi', or 'hyperopt'. Defines the tool which is used for\n                optimization. Default: 'deap'.\n            prior (distribution, optional):\n                The prior distribution used by sbi. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n            fv_space (list, optional):\n                The search space for hyperopt. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n            record (list, optional):\n                List of strings which define what variables of the tuned neuron should\n                be recorded. Default: [].\n            cma_params_dict (dict, optional):\n                Dictionary with parameters for the deap.cma.Strategy. Default: {}.\n                See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy) for more information.\n            bads_params_dict (dict, optional):\n                Dictionary with parameters for the bads optimization. Default: {}.\n                See [here](https://acerbilab.github.io/pybads/api/options/bads_options.html) for more information.\n            source_solutions (list, optional):\n                List of tuples with the source solutions. Each tuple contains a numpy\n                array with the parameter values and the loss. Used for initialization of\n                cma optimization with deap. Default: [].\n            variables_bounds_guess (dict, optional):\n                Dictionary with parameter names (keys) and their bounds (values) as\n                list. These bounds define the region there the minimum is expected. Used\n                for the BADS optimization. Default: None.\n            verbose (bool, optional):\n                If True, print additional information. Default: False.\n        \"\"\"\n\n        if len(self.opt_created) &gt; 0:\n            print(\n                \"OptNeuron: Error: Already another OptNeuron created. Only create one per python session!\"\n            )\n            quit()\n        else:\n            print(\n                \"OptNeuron: Initialize OptNeuron... do not create anything with ANNarchy before!\"\n            )\n\n            ### set object variables\n            self.verbose = verbose\n            self.verbose_run = False\n            self.opt_created.append(1)\n            self.record = record\n            self.results_soll = results_soll\n            self.variables_bounds = variables_bounds\n            self.fitting_variables_name_list = self._get_fitting_variables_name_list()\n            self.method = method\n            if method == \"hyperopt\":\n                if fv_space is None:\n                    self.fv_space = self._get_hyperopt_space()\n                else:\n                    self.fv_space = fv_space\n            self.const_params = self._get_const_params()\n            self.num_rep_loss = num_rep_loss\n            self.neuron_model = neuron_model\n            if method == \"sbi\":\n                self.prior = self._get_prior(prior)\n            self.target_neuron = target_neuron_model\n            self.compile_folder_name = compile_folder_name\n            self._get_loss = get_loss_function\n            self.cma_params_dict = cma_params_dict\n            self.source_solutions = source_solutions\n            self.variables_bounds_guess = variables_bounds_guess\n            self.bads_params_dict = bads_params_dict\n            self.loss_history = []\n            self.start_time = time()\n            self.recording_period = recording_period\n\n            ### if using deap pop size is the number of individuals for the optimization\n            if method == \"deap\":\n                self._deap_cma = self._prepare_deap_cma()\n                self.popsize = self._deap_cma.deap_dict[\"strategy\"].lambda_\n            else:\n                self.popsize = 1\n            if self.verbose:\n                print(\"OptNeuron: popsize:\", self.popsize)\n\n            ### check target_neuron/results_soll\n            self._check_target()\n            ### check neuron models\n            self._check_neuron_models()\n\n            ### setup ANNarchy\n            setup(dt=time_step)\n\n            ### create and compile model\n            ### if neuron models and target neuron model --&gt; create both models then\n            ### test, then clear and create only model for neuron model\n            model, target_model, monitors = self._generate_models(self.popsize)\n\n            self.pop = model.populations[0]\n            if target_model is not None:\n                self.pop_target = target_model.populations[0]\n            else:\n                self.pop_target = None\n            ### create experiment with current monitors\n            self.experiment = experiment(monitors=monitors)\n\n            ### check variables of model\n            self._test_variables()\n\n            ### check neuron models, experiment, get_loss\n            ### if results_soll is None -_&gt; generate results_soll\n            self._check_get_loss_function()\n\n            ### after checking neuron models, experiment, get_loss\n            ### clear ANNarchy and create/compile again only\n            ### standard model, thus recreate also monitors and experiment\n            mf.cnp_clear()\n            model, _, monitors = self._generate_models(self.popsize)\n            self.monitors = monitors\n            self.experiment = experiment(monitors=monitors)\n\n    def _get_lower_upper_p0(self):\n        \"\"\"\n        Returns the lower and upper bounds and the initial values for the cma\n        optimization with deap.\n\n        Returns:\n            lower (np.array):\n                The lower bounds for the optimization.\n            upper (np.array):\n                The upper bounds for the optimization.\n            p0 (np.array):\n                The initial values for the optimization.\n        \"\"\"\n\n        lower = np.array(\n            [\n                min(self.variables_bounds[name])\n                for name in self.fitting_variables_name_list\n            ]\n        )\n        upper = np.array(\n            [\n                max(self.variables_bounds[name])\n                for name in self.fitting_variables_name_list\n            ]\n        )\n        p0 = np.array(\n            [\n                np.random.uniform(\n                    min(self.variables_bounds[key]),\n                    max(self.variables_bounds[key]),\n                )\n                for key in self.fitting_variables_name_list\n            ]\n        )\n        return lower, upper, p0\n\n    def _get_lower_upper_x0(self):\n        \"\"\"\n        Returns the lower and upper bounds and the initial values for the optimization\n        with bads.\n\n        Returns:\n            lower (np.array):\n                The lower bounds for the optimization.\n            upper (np.array):\n                The upper bounds for the optimization.\n            x0 (np.array):\n                The initial values for the optimization.\n            lower_guess (np.array):\n                The lower bounds for the optimization where the minimum is expected.\n            upper_guess (np.array):\n                The upper bounds for the optimization where the minimum is expected.\n        \"\"\"\n        lower, upper, x0 = self._get_lower_upper_p0()\n\n        if not isinstance(self.variables_bounds_guess, type(None)):\n            lower_guess = np.array(\n                [\n                    min(self.variables_bounds_guess[name])\n                    for name in self.fitting_variables_name_list\n                ]\n            )\n            upper_guess = np.array(\n                [\n                    max(self.variables_bounds_guess[name])\n                    for name in self.fitting_variables_name_list\n                ]\n            )\n        else:\n            lower_guess = deepcopy(lower)\n            upper_guess = deepcopy(upper)\n\n        return lower, upper, x0, lower_guess, upper_guess\n\n    def _prepare_deap_cma(self):\n        \"\"\"\n        Initializes the DeapCma class.\n\n        Returns:\n            deap_cma (DeapCma):\n                The initialized DeapCma object.\n        \"\"\"\n\n        LOWER, UPPER, p0 = self._get_lower_upper_p0()\n\n        deap_cma = ef.DeapCma(\n            max_evals=0,\n            lower=LOWER,\n            upper=UPPER,\n            evaluate_function=self._deap_simulation_wrapper,\n            p0=p0,\n            param_names=self.fitting_variables_name_list,\n            learn_rate_factor=1,\n            damping_factor=1,\n            verbose=False,\n            plot_file=None,\n            cma_params_dict=self.cma_params_dict,\n            source_solutions=self.source_solutions,\n        )\n        return deap_cma\n\n    class _NullContextManager:\n        def __enter__(self):\n            # This method is called when entering the context\n            pass\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # This method is called when exiting the context\n            pass\n\n    def _generate_models(self, popsize=1):\n        \"\"\"\n        Generates the tuned model and the target_model (only if results_soll is None).\n\n        Args:\n            popsize (int, optional):\n                The number of neurons in the population(s). Default: 1.\n\n        Returns:\n            model (CompNeuroModel):\n                The model which is used for the optimization.\n\n            target_model (CompNeuroModel):\n                The model which is used to generate the target data. If results_soll is\n                provided, target_model is None.\n\n            monitors (CompNeuroMonitors):\n                The monitors which are used to record the data. If no variables are\n                recorded, monitors is None.\n        \"\"\"\n        with self._NullContextManager() if self.verbose else ef.suppress_stdout():\n            model = None\n            target_model = None\n            monitors = None\n            if self.results_soll is None:\n                if self.verbose:\n                    print(\n                        \"OptNeuron: Create two models (optimized and target for obtaining results_soll)\"\n                    )\n                    print(\"optimized neuron model:\", self.neuron_model)\n                    print(\"target neuron model:\", self.target_neuron)\n                ### create two models\n                model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\n                        \"neuron\": self.neuron_model,\n                        \"name\": \"model_neuron\",\n                        \"size\": popsize,\n                    },\n                    name=\"standard_model\",\n                    do_create=True,\n                    do_compile=False,\n                    compile_folder_name=self.compile_folder_name,\n                )\n\n                target_model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\n                        \"neuron\": self.target_neuron,\n                        \"name\": \"target_model_neuron\",\n                        \"size\": 1,\n                    },\n                    name=\"target_model\",\n                    do_create=True,\n                    do_compile=True,\n                    compile_folder_name=self.compile_folder_name,\n                )\n\n                ### create monitors\n                if len(self.record) &gt; 0:\n                    recording_period_str = (\n                        f\";{self.recording_period}\"\n                        if self.recording_period is not None\n                        and (\"spike\" not in self.record or len(self.record) &gt; 1)\n                        else \"\"\n                    )\n                    monitors = CompNeuroMonitors(\n                        {\n                            f\"{pop_name}{recording_period_str}\": self.record\n                            for pop_name in [\n                                model.populations[0],\n                                target_model.populations[0],\n                            ]\n                        }\n                    )\n\n            else:\n                if self.verbose:\n                    print(\n                        \"OptNeuron: Create one model (optimized, results_soll is available)\"\n                    )\n                    print(\"optimized neuron model:\", self.neuron_model)\n                ### create one model\n                model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\n                        \"neuron\": self.neuron_model,\n                        \"name\": \"model_neuron\",\n                        \"size\": popsize,\n                    },\n                    name=\"single_model\",\n                    do_create=True,\n                    do_compile=True,\n                    compile_folder_name=self.compile_folder_name,\n                )\n                ### create monitors\n                if len(self.record) &gt; 0:\n                    recording_period_str = (\n                        f\";{self.recording_period}\"\n                        if self.recording_period is not None\n                        and (\"spike\" not in self.record or len(self.record) &gt; 1)\n                        else \"\"\n                    )\n                    monitors = CompNeuroMonitors(\n                        {f\"{model.populations[0]}{recording_period_str}\": self.record}\n                    )\n\n        return model, target_model, monitors\n\n    def _check_neuron_models(self):\n        \"\"\"\n        Checks if the neuron models are ANNarchy neuron models.\n        \"\"\"\n        if not (isinstance(self.neuron_model, type(Neuron()))) or (\n            self.target_neuron is not None\n            and not (isinstance(self.target_neuron, type(Neuron())))\n        ):\n            print(\n                \"OptNeuron: Error: neuron_model and/or target_neuron_model have to be ANNarchy neuron models\"\n            )\n            quit()\n\n    def _check_target(self):\n        \"\"\"\n        Check if either results_soll or target_neuron are provided and not both.\n        \"\"\"\n        if self.target_neuron is None and self.results_soll is None:\n            print(\n                \"OptNeuron: Error: Either provide results_soll or target_neuron_model\"\n            )\n            quit()\n        elif self.target_neuron is not None and self.results_soll is not None:\n            print(\n                \"OptNeuron: Error: Either provide results_soll or target_neuron_model, not both\"\n            )\n            quit()\n\n    def _get_prior(self, prior):\n        \"\"\"\n        Get the prior distribution used by sbi. If no prior is given, uniform\n        distributions between the variable bounds are assumed. If a prior is given,\n        this prior is used.\n\n        Args:\n            prior (distribution, optional):\n                The prior distribution used by sbi. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n\n        Returns:\n            prior (distribution):\n                The prior distribution used by sbi.\n        \"\"\"\n        if prior is None:\n            prior_min = []\n            prior_max = []\n            for _, param_bounds in self.variables_bounds.items():\n                if isinstance(param_bounds, list):\n                    prior_min.append(param_bounds[0])\n                    prior_max.append(param_bounds[1])\n\n            return utils.BoxUniform(\n                low=torch.as_tensor(prior_min), high=torch.as_tensor(prior_max)\n            )\n        else:\n            return prior\n\n    def _get_fitting_variables_name_list(self):\n        \"\"\"\n        Returns a list with the names of the fitting variables.\n\n        Returns:\n            fitting_variables_name_list (list):\n                list with names of fitting variables\n        \"\"\"\n        name_list = []\n        for param_name, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                name_list.append(param_name)\n\n        if self.verbose:\n            print(\"OptNeuron: Fitting variables:\", name_list)\n        return name_list\n\n    def _get_hyperopt_space(self):\n        \"\"\"\n        Generates the hyperopt variable space from the fitting variable bounds. The\n        variable space is a uniform distribution between the bounds.\n\n        Returns:\n            fitting_variables_space (list):\n                list with hyperopt variables\n        \"\"\"\n        fitting_variables_space = []\n        for param_name, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                fitting_variables_space.append(\n                    hp.uniform(param_name, min(param_bounds), max(param_bounds))\n                )\n        return fitting_variables_space\n\n    def _get_const_params(self):\n        \"\"\"\n        Returns:\n            const_params (dict):\n                Dictionary with constant variables. The keys are the parameter names\n                and the values are the parameter values.\n        \"\"\"\n        const_params = {}\n        for param_name, param_bounds in self.variables_bounds.items():\n            if not (isinstance(param_bounds, list)):\n                const_params[param_name] = param_bounds\n\n        if self.verbose:\n            print(\"OptNeuron: Constant parameters:\", const_params)\n        return const_params\n\n    def _check_get_loss_function(self):\n        \"\"\"\n        Checks if the get_loss_function is compatible to the experiment and the neuron\n        model(s). To test, the experiment is run once with the tuned neuron model\n        (generating results_ist) and once with the target neuron model (if provided,\n        generating results_soll). Then, the get_loss_function is called with the\n        results_ist and results_soll.\n        \"\"\"\n        print(\"checking neuron_models, experiment, get_loss...\", end=\"\")\n\n        fitparams = []\n        for bounds in self.variables_bounds.values():\n            if isinstance(bounds, list):\n                fitparams.append(bounds[0])\n        if self.verbose:\n            print(\n                f\"fitparams selected for checking: {fitparams} ({self.fitting_variables_name_list})\"\n            )\n\n        if self.results_soll is not None:\n            ### only generate results_ist with standard neuron model\n            results_ist = self._run_simulator_with_results(fitparams)[\"results\"]\n        else:\n            ### run simulator with both populations (standard neuron model and target\n            ### neuron model) and generatate results_ist and results_soll\n            results_ist = self._run_simulator_with_results(fitparams)[\"results\"]\n            self.results_soll = self._run_simulator_with_results(\n                fitparams, pop=self.pop_target\n            )[\"results\"]\n\n        try:\n            self._wrapper_get_loss(results_ist, self.results_soll)\n        except:\n            print(\n                \"\\nThe get_loss_function, experiment and neuron model(s) are not compatible:\\n\"\n            )\n            traceback.print_exc()\n            quit()\n        print(\"Done\\n\")\n\n    def _wrapper_get_loss(self, results_ist, results_soll):\n        \"\"\"\n        Makes it possible to use the get_loss_function with multiple neurons. The\n        get_loss_function should always calculate the loss for neuron rank 0!\n\n        Args:\n            results_ist (object):\n                the results object returned by the run function of experiment (see above)\n                it can contain recordings of multiple neurons\n            results_soll (any):\n                the target data directly provided to OptNeuron during initialization\n                it always contains only the recordings of a single neuron\n\n        Returns:\n            all_loss_list (list):\n                list of lists containing the 'all_loss_list' for each neuron\n        \"\"\"\n        ### loop over neurons and calculate all_loss_list for each neuron\n        all_loss_list = []\n        for neuron_idx in range(self.popsize):\n            results_ist_neuron = self._get_results_of_single_neuron(\n                results_ist, neuron_idx\n            )\n            all_loss_list.append(self._get_loss(results_ist_neuron, results_soll))\n\n        return all_loss_list\n\n    def _get_results_of_single_neuron(self, results, neuron_idx):\n        \"\"\"\n        Returns a results object which contains only the recordings of the given neuron\n        index. The defined neuron will be neuron rank 0 in the returned results object.\n\n        Args:\n            results (object):\n                the results object returned by the run function of experiment (see above)\n                it can contain recordings of multiple neurons\n            neuron_idx (int):\n                index of the neuron whose recordings should be returned\n\n        Returns:\n            results_neuron (object):\n                the results object as returned by the run function of experiment for a\n                single neuron\n        \"\"\"\n        ### if only one neuron, simply return results\n        if self.popsize == 1:\n            return results\n\n        ### if multiple neurons, return results for single neuron, do not change\n        ### original results!\n        results_neuron = deepcopy(results)\n\n        ### loop over chunks and recordings and select only the recordings of the\n        ### defined neuron\n        for chunk in range(len(results_neuron.recordings)):\n            for rec_key in results_neuron.recordings[chunk].keys():\n                ### adjust spike dictionary\n                if \"spike\" in rec_key and not (\"target\" in rec_key):\n                    results_neuron.recordings[chunk][rec_key] = {\n                        0: results_neuron.recordings[chunk][rec_key][neuron_idx]\n                    }\n                ### adjust all recorded arrays\n                elif not (\n                    \"period\" in rec_key\n                    or \"parameter_dict\" in rec_key\n                    or \"dt\" in rec_key\n                    or \"target\" in rec_key\n                ):\n                    results_neuron.recordings[chunk][rec_key] = (\n                        results_neuron.recordings[chunk][rec_key][\n                            :, neuron_idx\n                        ].reshape(-1, 1)\n                    )\n                ### adjust parameter_dict\n                elif \"parameter_dict\" in rec_key and not (\"target\" in rec_key):\n                    results_neuron.recordings[chunk][rec_key] = {\n                        parameter_dict_key: np.array(\n                            [\n                                results_neuron.recordings[chunk][rec_key][\n                                    parameter_dict_key\n                                ][neuron_idx]\n                            ]\n                        )\n                        for parameter_dict_key in results_neuron.recordings[chunk][\n                            rec_key\n                        ].keys()\n                    }\n\n        return results_neuron\n\n    def _raw_neuron(self, neuron, name, size):\n        \"\"\"\n        Generates a population with one neuron of the given neuron model.\n\n        Args:\n            neuron (ANNarchy Neuron):\n                The neuron model.\n            name (str):\n                The name of the population.\n            size (int):\n                The number of neurons in the population.\n        \"\"\"\n        Population(size, neuron=neuron, name=name)\n\n    def _test_variables(self):\n        \"\"\"\n        Check if the tuned neuron model contains all parameters which are defined in\n        variables_bounds or even more.\n        \"\"\"\n        ### collect all names\n        all_vars_names = np.concatenate(\n            [\n                np.array(list(self.const_params.keys())),\n                np.array(self.fitting_variables_name_list),\n            ]\n        ).tolist()\n        ### check if pop has these parameters\n        pop_parameter_names = get_population(self.pop).attributes.copy()\n        for name in pop_parameter_names.copy():\n            if name in all_vars_names:\n                all_vars_names.remove(name)\n                pop_parameter_names.remove(name)\n        if len(pop_parameter_names) &gt; 0:\n            print(\n                \"OptNeuron: WARNING: attributes\",\n                pop_parameter_names,\n                \"are not used/initialized.\",\n            )\n        if len(all_vars_names) &gt; 0:\n            print(\n                \"OptNeuron: WARNING: The neuron_model does not contain parameters\",\n                all_vars_names,\n                \"!\",\n            )\n\n    def _run_simulator(self, fitparams):\n        \"\"\"\n        Runs the function simulator with the multiprocessing manager (if function is\n        called multiple times this saves memory, otherwise same as calling simulator\n        directly).\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters or list of lists with values\n                for fitting parameters (first dimension is the number of parameters,\n                second dimension is the number of neurons)\n\n        Returns:\n            return_dict (dict):\n                dictionary needed for optimization with hyperopt, containing the loss,\n                the loss variance (in case of noisy models with multiple runs per loss\n                calculation), and the status (STATUS_OK for hyperopt).\n        \"\"\"\n\n        ### initialize manager and generate m_list = dictionary to save data\n        manager = multiprocessing.Manager()\n        m_list = manager.dict()\n\n        ### in case of noisy models, here optionally run multiple simulations, to mean the loss\n        loss_list_over_runs = []\n\n        return_results = False\n        for _ in range(self.num_rep_loss):\n            ### initialize for each run a new rng (--&gt; not always have same noise in case of noisy models/simulations)\n            rng = np.random.default_rng()\n            ### run simulator with multiprocessign manager\n            proc = Process(\n                target=self._simulator, args=(fitparams, rng, m_list, return_results)\n            )\n            proc.start()\n            proc.join()\n            ### get simulation results/loss (list of losses for each neuron)\n            loss_list_over_runs.append(m_list[0])\n\n        ### create loss array, first dimension is the number of runs, second dimension\n        ### is the number of neurons\n        loss_arr = np.array(loss_list_over_runs)\n\n        ### calculate mean and std of loss over runs\n        if self.num_rep_loss &gt; 1:\n            ### multiple runs, mean over runs\n            ### -&gt; resulting in 1D arrays for neurons\n            loss_ret_arr = np.mean(loss_arr, 0)\n            std_ret_arr = np.std(loss_arr, 0)\n        else:\n            ### just take the first entry (the only one)\n            ### -&gt; resulting in 1D arrays for neurons\n            loss_ret_arr = loss_arr[0]\n            std_ret_arr = np.array([None] * self.popsize)\n\n        ### if only one neuron, return loss and std as single values\n        if self.popsize == 1:\n            loss = loss_ret_arr[0]\n            std = std_ret_arr[0]\n        else:\n            loss = loss_ret_arr\n            std = std_ret_arr\n\n        ### append best loss and time since start to loss_history\n        self.loss_history.append([af.get_minimum(loss), time() - self.start_time])\n\n        ### return loss and other things for optimization, if multiple neurons\n        ### --&gt; loss and std are arrays with loss/std for each neuron\n        if self.num_rep_loss &gt; 1:\n            return {\"status\": STATUS_OK, \"loss\": loss, \"loss_variance\": std}\n        else:\n            return {\"status\": STATUS_OK, \"loss\": loss}\n\n    def _sbi_simulation_wrapper(self, fitparams):\n        \"\"\"\n        This function is called by sbi. It calls the simulator function and\n        returns the loss and adjusts the format of the input parameters.\n\n        Args:\n            fitparams (tensor):\n                either a batch of parameters (tensor with two dimensions) or a single\n                parameter set\n\n        Returns:\n            loss (tensor):\n                loss as tensor for sbi inference\n        \"\"\"\n        fitparams = np.asarray(fitparams)\n        if len(fitparams.shape) == 2:\n            ### batch parameters!\n            data = []\n            ### TODO the run_simulator_function can now handle multiple parameter sets\n            ### and directly can return the loss for each parameter set, but the model\n            ### has to have the corrects size, i.e., the number of neurons has to be\n            ### the same as the number of parameter sets, maybe adjust sbi to this\n            for idx in range(fitparams.shape[0]):\n                data.append(self._run_simulator(fitparams[idx])[\"loss\"])\n        else:\n            ### single parameter set!\n            data = [self._run_simulator(fitparams)[\"loss\"]]\n\n        return torch.as_tensor(data)\n\n    def _deap_simulation_wrapper(self, population: list):\n        \"\"\"\n        This function is called by deap. It calls the simulator function and\n        returns the loss and adjusts the format of the input parameters.\n\n        Args:\n            population (list):\n                list of lists with values for fitting parameters (first dimension is\n                the number of neurons, second dimension is the number of parameters)\n                given by deap\n        \"\"\"\n        ### transpose population list (now first dimension is the number of parameters,)\n        populationT = np.array(population).T.tolist()\n        ### get loss list\n        loss_list = self._run_simulator(populationT)[\"loss\"]\n        ### return loss list as list of tuples (deap needs this format)\n        return [(loss_list[neuron_idx],) for neuron_idx in range(len(population))]\n\n    def _bads_simulation_wrapper(self, fitparams: list):\n        \"\"\"\n        This function is called by bads. It calls the simulator function and\n        returns the loss.\n        \"\"\"\n        return self._run_simulator(fitparams)[\"loss\"]\n\n    def _run_simulator_with_results(self, fitparams, pop=None):\n        \"\"\"\n        Runs the function simulator with the multiprocessing manager (if function is\n        called multiple times this saves memory, otherwise same as calling simulator\n        directly) and also returns the results.\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters or list of lists with values\n                for fitting parameters (first dimension is the number of parameters,\n                second dimension is the number of neurons)\n\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n\n        Returns:\n            return_dict (dict):\n                dictionary needed for optimization with hyperopt, containing the loss,\n                the loss variance (in case of noisy models with multiple runs per loss\n                calculation), and the status (STATUS_OK for hyperopt) and the results\n                generated by the experiment.\n        \"\"\"\n        ### check if pop is given\n        if pop is None:\n            pop = self.pop\n        ### initialize manager and generate m_list = dictionary to save data\n        manager = multiprocessing.Manager()\n        m_list = manager.dict()\n\n        ### in case of noisy models, here optionally run multiple simulations, to mean\n        ### the loss\n        loss_list_over_runs = []\n        all_loss_list_over_runs = []\n        return_results = True\n        if self.verbose:\n            print(f\"OptNeuron: run simulator with results {self.num_rep_loss} times\")\n        for _ in range(self.num_rep_loss):\n            ### initialize for each run a new rng (--&gt; not always have same noise in\n            ### case of noisy models/simulations)\n            rng = np.random.default_rng()\n            ### run simulator with multiprocessign manager\n            proc = Process(\n                target=self._simulator,\n                args=(fitparams, rng, m_list, return_results, pop),\n            )\n            proc.start()\n            proc.join()\n            ### get simulation results/loss\n            ### list of losses for each neuron\n            loss_list_over_runs.append(m_list[0])\n            ### results object of experiment\n            results_ist = m_list[1]\n            ### list of the all_loss_list for each neuron\n            all_loss_list_over_runs.append(m_list[2])\n\n        ### create loss array, first dimension is the number of runs, second dimension\n        ### is the number of neurons\n        loss_arr = np.array(loss_list_over_runs)\n        ### create all_loss array, first dimension is the number of runs, second\n        ### dimension is the number of neurons, third dimension is the number of\n        ### individual losses\n        all_loss_arr = np.array(all_loss_list_over_runs)\n\n        ### calculate mean and std of loss over runs\n        if self.num_rep_loss &gt; 1:\n            ### resulting in 1D arrays for neurons\n            loss = np.mean(loss_arr, 0)\n            std = np.std(loss_arr)\n            ### resulting in 2D array for neurons (1st dim) and individual losses (2nd dim)\n            all_loss = np.mean(all_loss_arr, 0)\n        else:\n            ### just take the first entry (the only one)\n            ### resulting in 1D arrays for neurons\n            loss = loss_arr[0]\n            std = np.array([None] * self.popsize)\n            ### resulting in 2D array for neurons (1st dim) and individual losses (2nd dim)\n            all_loss = all_loss_arr[0]\n\n        ### if only one neuron, return loss and std as single values and all_loss as\n        ### single 1D array (length is the number of individual losses)\n        if self.popsize == 1:\n            loss = loss[0]\n            std = std[0]\n            all_loss = all_loss[0]\n        else:\n            loss = loss\n            std = std\n            all_loss = all_loss\n\n        ### return loss and other things for optimization and results\n        if self.num_rep_loss &gt; 1:\n            return {\n                \"status\": STATUS_OK,\n                \"loss\": loss,\n                \"loss_variance\": std,\n                \"std\": std,\n                \"all_loss\": all_loss,\n                \"results\": results_ist,\n            }\n        else:\n            return {\n                \"status\": STATUS_OK,\n                \"loss\": loss,\n                \"std\": std,\n                \"all_loss\": all_loss,\n                \"results\": results_ist,\n            }\n\n    def _simulator(\n        self, fitparams, rng, m_list=[0, 0, 0], return_results=False, pop=None\n    ):\n        \"\"\"\n        Runs the experiment with the given parameters and 'returns' the loss and\n        optionally the results and all individual losses of the get_loss_function. The\n        'returned' values are saved in m_list.\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters or list of lists with values\n                for fitting parameters (first dimension is the number of parameters,\n                second dimension is the number of neurons)\n\n            rng (numpy random generator):\n                random generator for the simulation\n\n            m_list (list, optional):\n                list with the loss, the results, and the all_loss. Default: [0, 0, 0].\n\n            return_results (bool, optional):\n                If True, the results are returned. Default: False.\n\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n        \"\"\"\n        ### TODO use rng here and add it to CompNeuroExp\n        ### check if pop is given\n        if pop is None:\n            pop = self.pop\n\n        ### set parameters which should not be optimized and parameters which should be\n        ### optimized before the experiment, they should not be resetted by the\n        ### experiment!\n        self._set_fitting_parameters(fitparams, pop=pop)\n        if self.verbose_run:\n            param_dict = {\n                param_name: (\n                    fitparams[param_name_idx]\n                    if isinstance(fitparams[param_name_idx], list)\n                    else [fitparams[param_name_idx]]\n                )\n                for param_name_idx, param_name in enumerate(\n                    self.fitting_variables_name_list\n                )\n            }\n            print(\"OptNeuron: run simulator with parameters:\")\n            ef.print_df(pd.DataFrame(param_dict))\n\n        ### conduct loaded experiment\n        self.experiment.store_model_state(compartment_list=[pop])\n        results = self.experiment.run(pop)\n        self.experiment.reset()\n\n        if self.results_soll is not None:\n            ### compute loss_list, loss for each neuron\n            loss_list = []\n            ### wrapper_get_loss returns list (neurons) of lists (individual losses)\n            all_loss_list = self._wrapper_get_loss(results, self.results_soll)\n            ### loop over neurons\n            for all_loss in all_loss_list:\n                ### if all_loss is list, sum up individual losses\n                if isinstance(all_loss, list) or isinstance(\n                    all_loss, type(np.zeros(1))\n                ):\n                    loss_list.append(sum(all_loss))\n                ### if all_loss is single value, just append to loss_list\n                else:\n                    loss_list.append(all_loss)\n        else:\n            all_loss_list = [999] * self.popsize\n            loss_list = [999] * self.popsize\n\n        ### \"return\" loss and other optional things\n        m_list[0] = loss_list\n        if return_results:\n            m_list[1] = results\n            m_list[2] = all_loss_list\n\n    def _set_fitting_parameters(\n        self,\n        fitparams,\n        pop,\n    ):\n        \"\"\"\n        Sets all given parameters for the population pop.\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters, either a single list or a list\n                of lists (first dimension is the number of parameters, second dimension\n                is the number of neurons)\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n        \"\"\"\n        ### only set parameters of the fitted neuron model\n        if pop != self.pop:\n            return\n\n        ### get all variables dict (combine fitting variables and const variables)\n        all_variables_dict = self.const_params.copy()\n        if self.verbose:\n            print(\"OptNeuron: set fitting parameters:\")\n            print(f\"  fitparams: {fitparams} ({self.fitting_variables_name_list})\")\n            print(f\"  starting with const: {all_variables_dict}\")\n\n        ### multiply const params for number of neurons\n        for const_param_key, const_param_val in all_variables_dict.items():\n            if not (isinstance(const_param_val, str)):\n                all_variables_dict[const_param_key] = [\n                    all_variables_dict[const_param_key]\n                ] * self.popsize\n        if self.verbose:\n            print(f\"  adjusting for pop size: {all_variables_dict}\")\n\n        ### add fitting variables\n        for fitting_variable_idx, fitting_variable_name in enumerate(\n            self.fitting_variables_name_list\n        ):\n            if not (isinstance(fitparams[fitting_variable_idx], list)):\n                add_params = [fitparams[fitting_variable_idx]] * self.popsize\n            else:\n                add_params = fitparams[fitting_variable_idx]\n            all_variables_dict[fitting_variable_name] = add_params\n        if self.verbose:\n            print(f\"  add fitting variables: {all_variables_dict}\")\n\n        ### evaluate variables defined by a str\n        for key, val in all_variables_dict.items():\n            if isinstance(val, str):\n                all_variables_dict[key] = [\n                    ef.evaluate_expression_with_dict(\n                        val,\n                        {\n                            all_variables_key: all_variables_dict[all_variables_key][\n                                neuron_idx\n                            ]\n                            for all_variables_key in all_variables_dict.keys()\n                            if not (\n                                isinstance(all_variables_dict[all_variables_key], str)\n                            )\n                        },\n                    )\n                    for neuron_idx in range(self.popsize)\n                ]\n        if self.verbose:\n            print(f\"  add str variables: {all_variables_dict}\")\n\n        ### set parameters\n        for param_name, param_val in all_variables_dict.items():\n            pop_parameter_names = get_population(pop).attributes\n            ### only if param_name in parameter attributes\n            if param_name in pop_parameter_names:\n                if self.popsize == 1:\n                    setattr(get_population(pop), param_name, param_val[0])\n                else:\n                    setattr(get_population(pop), param_name, param_val)\n\n    def _test_fit(self, fitparams_dict):\n        \"\"\"\n        Runs the experiment with the optimized parameters obtained with hyperopt and\n        returns the loss, the results and all individual losses of the\n        get_loss_function.\n\n        Args:\n            fitparams_dict (dict):\n                dictionary with parameter names (keys) and their values (values)\n\n        Returns:\n            fit (dict):\n                dictionary containing the loss, the loss variance (in case of noisy\n                models with multiple runs per loss calculation), and the status\n                (STATUS_OK for hyperopt) and the results generated by the experiment.\n        \"\"\"\n        results = self._run_simulator_with_results(\n            [fitparams_dict[name] for name in self.fitting_variables_name_list]\n        )\n        ### if self.popsize &gt; 1 --&gt; transform results, loss etc. to only 1 neuron\n        if self.popsize &gt; 1:\n            results[\"loss\"] = results[\"loss\"][0]\n            results[\"std\"] = results[\"std\"][0]\n            results[\"all_loss\"] = results[\"all_loss\"][0]\n            results[\"results\"] = self._get_results_of_single_neuron(\n                results[\"results\"], 0\n            )\n        return results\n\n    def _run_with_sbi(self, max_evals, sbi_plot_file):\n        \"\"\"\n        Runs the optimization with sbi.\n\n        Args:\n            max_evals (int):\n                number of runs the optimization method performs\n\n            sbi_plot_file (str):\n                If you use \"sbi\": the name of the figure which will be saved and shows\n                the posterior.\n\n        Returns:\n            best (dict):\n                dictionary containing the optimized parameters and the posterior.\n        \"\"\"\n        ### get prior bounds\n        prior_min = []\n        prior_max = []\n        for _, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                prior_min.append(param_bounds[0])\n                prior_max.append(param_bounds[1])\n\n        ### run sbi\n        simulator, prior = prepare_for_sbi(\n            self._sbi_simulation_wrapper,\n            self.prior,\n            {\n                \"lower_bound\": torch.as_tensor(prior_min),\n                \"upper_bound\": torch.as_tensor(prior_max),\n            },\n        )\n        inference = SNPE(prior, density_estimator=\"mdn\")\n        theta, x = simulate_for_sbi(\n            simulator=simulator,\n            proposal=prior,\n            num_simulations=max_evals,\n            num_workers=1,\n        )\n        density_estimator = inference.append_simulations(theta, x).train()\n        posterior = inference.build_posterior(density_estimator)\n        x_o = torch.as_tensor([0])  # data which should be obtained: loss==0\n        posterior = posterior.set_default_x(x_o)\n\n        ### get best params\n        posterior_samples = posterior.sample(\n            (10000,)\n        )  # posterior = distribution P(params|data) --&gt; set data and then sample possible parameters\n        best_params = posterior_samples[\n            torch.argmax(posterior.log_prob(posterior_samples))\n        ].numpy()  # sampled parameters with highest prob in posterior\n\n        ### create best dict with best parameters\n        best = {}\n        for param_idx, param_name in enumerate(self.fitting_variables_name_list):\n            best[param_name] = best_params[param_idx]\n\n        ### also return posterior\n        best[\"posterior\"] = posterior\n\n        ### plot posterior\n        plot_limits = [\n            [prior_min[idx], prior_max[idx]] for idx in range(len(prior_max))\n        ]\n        analysis.pairplot(\n            posterior_samples,\n            limits=plot_limits,\n            ticks=plot_limits,\n            fig_size=(5, 5),\n            labels=self.fitting_variables_name_list,\n        )\n\n        ### save plot\n        sf.create_dir(\"/\".join(sbi_plot_file.split(\"/\")[:-1]))\n        plt.savefig(sbi_plot_file, dpi=300)\n\n        return best\n\n    def _run_with_bads(self, max_evals):\n        \"\"\"\n        TODO\n        \"\"\"\n\n        ### prepare bads\n        target = self._bads_simulation_wrapper\n        lower, upper, x0, lower_guess, upper_guess = self._get_lower_upper_x0()\n\n        ### TODO bads can handle noisy functions, one can retunr two values, loss and std\n        self.bads_params_dict[\"uncertainty_handling\"] = False\n        self.bads_params_dict[\"max_fun_evals\"] = max_evals\n\n        ### run bads\n        bads = BADS(\n            fun=target,\n            x0=x0,\n            lower_bounds=lower,\n            upper_bounds=upper,\n            plausible_lower_bounds=lower_guess,\n            plausible_upper_bounds=upper_guess,\n            options=self.bads_params_dict,\n        )\n        optimize_result = bads.optimize()\n\n        ### create best dict with best parameters\n        best = {\n            fitting_variable_name: optimize_result[\"x\"][idx]\n            for idx, fitting_variable_name in enumerate(\n                self.fitting_variables_name_list\n            )\n        }\n        return best\n\n    @check_types()\n    def run(\n        self,\n        max_evals: int,\n        results_file_name: str = \"opt_neuron_results/best\",\n        sbi_plot_file: str = \"opt_neuron_plots/posterior.png\",\n        deap_plot_file: str = \"opt_neuron_plots/logbook.png\",\n        verbose: bool = False,\n    ):\n        \"\"\"\n        Runs the optimization.\n\n        Args:\n            max_evals (int):\n                number of runs the optimization method performs\n            results_file_name (str, optional):\n                name of the file which is saved. The file contains the optimized and\n                target results, the obtained parameters, the loss, and the SD of the\n                loss (in case of noisy models with multiple runs per loss calculation)\n                Default: \"best\".\n            sbi_plot_file (str, optional):\n                If you use \"sbi\": the name of the figure which will be saved and shows\n                the posterior. Default: \"posterior.png\".\n            deap_plot_file (str, optional):\n                If you use \"deap\": the name of the figure which will be saved and shows\n                the logbook. Default: \"logbook.png\".\n            verbose (bool, optional):\n                If True, detailed information is printed. Default: False.\n\n        Returns:\n            best (dict):\n                dictionary containing the optimized parameters (as keys) and:\n\n                - \"loss\": the loss\n                - \"all_loss\": the individual losses of the get_loss_function\n                - \"std\": the SD of the loss (in case of noisy models with multiple\n                    runs per loss calculation)\n                - \"results\": the results generated by the experiment\n                - \"results_soll\": the target results\n        \"\"\"\n        self.verbose = False\n        self.verbose_run = verbose\n        self.loss_history = []\n        self.start_time = time()\n        if self.method == \"hyperopt\":\n            ### run optimization with hyperopt and return best dict\n            best = fmin(\n                fn=self._run_simulator,\n                space=self.fv_space,\n                algo=tpe.suggest,\n                max_evals=max_evals,\n            )\n        elif self.method == \"sbi\":\n            ### run optimization with sbi and return best dict\n            best = self._run_with_sbi(max_evals, sbi_plot_file)\n        elif self.method == \"deap\":\n            best = self._run_with_deap(max_evals, deap_plot_file)\n        elif self.method == \"bads\":\n            if max_evals &lt; 4:\n                raise ValueError(\"bads needs at least 4 evaluations\")\n            best = self._run_with_bads(max_evals)\n        else:\n            print(\"ERROR run; method should be 'hyperopt', 'sbi', 'deap', or 'bads'\")\n            quit()\n        ### obtain loss for the best parameters\n        fit = self._test_fit(best)\n        best[\"loss\"] = float(fit[\"loss\"])\n        best[\"all_loss\"] = fit[\"all_loss\"]\n        best[\"std\"] = fit[\"std\"]\n        best[\"results\"] = fit[\"results\"]\n        best[\"results_soll\"] = self.results_soll\n        self.results = best\n\n        ### create loss history array\n        self.loss_history = np.array(self.loss_history)\n\n        ### SAVE OPTIMIZED PARAMS AND LOSS\n        ### save as pkl file\n        sf.save_variables(\n            [best],\n            [results_file_name.split(\"/\")[-1]],\n            (\n                \"/\".join(results_file_name.split(\"/\")[:-1])\n                if len(results_file_name.split(\"/\")) &gt; 1\n                else \"./\"\n            ),\n        )\n        ### save human readable as json file\n        json.dump(\n            {key: best[key] for key in self.fitting_variables_name_list + [\"loss\"]},\n            open(\n                f\"{results_file_name}.json\",\n                \"w\",\n            ),\n            indent=4,\n        )\n\n        return best\n\n    def _run_with_deap(self, max_evals, deap_plot_file):\n        \"\"\"\n        Runs the optimization with deap.\n\n        Args:\n            max_evals (int):\n                number of runs (here generations) the optimization method performs\n\n            deap_plot_file (str):\n                the name of the figure which will be saved and shows the logbook\n        \"\"\"\n\n        return self._deap_cma.run(\n            max_evals=max_evals,\n            plot_file=deap_plot_file,\n        )\n</code></pre>"},{"location":"main/optimize_neuron/#CompNeuroPy.opt_neuron.OptNeuron.__init__","title":"<code>__init__(experiment, get_loss_function, variables_bounds, neuron_model, results_soll=None, target_neuron_model=None, time_step=1.0, recording_period=None, compile_folder_name='annarchy_OptNeuron', num_rep_loss=1, method='deap', prior=None, fv_space=None, record=[], cma_params_dict={}, bads_params_dict={}, source_solutions=[], variables_bounds_guess=None, verbose=False)</code>","text":"<p>This prepares the optimization. To run the optimization call the run function.</p> <p>Parameters:</p> Name Type Description Default <code>experiment</code> <code>CompNeuroExp class</code> <p>CompNeuroExp class containing a 'run' function which defines the simulations and recordings</p> required <code>get_loss_function</code> <code>function</code> <p>function which takes results_ist and results_soll as arguments and calculates/returns the loss</p> required <code>variables_bounds</code> <code>dict</code> <p>Dictionary with parameter names (keys) and their bounds (values). If single values are given as values, the parameter is constant, i.e., not optimized. If a list is given as value, the parameter is optimized and the list contains the lower and upper bound of the parameter (order is not important). If strings instead of numbers are given, the string is interpreted as an mathematical expression which is evaluated with the other parameter values (i.e. {\"x\":[0,1],\"dxy\":[-1,1],\"y\":\"x+dxy\",\"z\":5}).</p> required <code>neuron_model</code> <code>ANNarchy Neuron</code> <p>The neuron model whose parameters should be optimized.</p> required <code>results_soll</code> <code>Any</code> <p>Some variable which contains the target data and can be used by the get_loss_function (second argument of get_loss_function)</p> <p>Warning</p> <p>Either provide results_soll or a target_neuron_model not both!</p> <p>Default: None.</p> <code>None</code> <code>target_neuron_model</code> <code>ANNarchy Neuron</code> <p>The neuron model which produces the target data by running the experiment.</p> <p>Warning</p> <p>Either provide results_soll or a target_neuron_model not both!</p> <p>Default: None.</p> <code>None</code> <code>time_step</code> <code>float</code> <p>The time step for the simulation in ms. Default: 1.</p> <code>1.0</code> <code>recording_period</code> <code>float</code> <p>The recording period for the simulation in ms. Default: None, i.e., the time_step is used.</p> <code>None</code> <code>compile_folder_name</code> <code>string</code> <p>The name of the annarchy compilation folder within annarchy_folders/. Default: 'annarchy_OptNeuron'.</p> <code>'annarchy_OptNeuron'</code> <code>num_rep_loss</code> <code>int</code> <p>Only interesting for noisy simulations/models. How often should the simulaiton be run to calculate the loss (the defined number of losses is obtained and averaged). Default: 1.</p> <code>1</code> <code>method</code> <code>str</code> <p>Either 'deap', 'sbi', or 'hyperopt'. Defines the tool which is used for optimization. Default: 'deap'.</p> <code>'deap'</code> <code>prior</code> <code>distribution</code> <p>The prior distribution used by sbi. Default: None, i.e., uniform distributions between the variable bounds are assumed.</p> <code>None</code> <code>fv_space</code> <code>list</code> <p>The search space for hyperopt. Default: None, i.e., uniform distributions between the variable bounds are assumed.</p> <code>None</code> <code>record</code> <code>list</code> <p>List of strings which define what variables of the tuned neuron should be recorded. Default: [].</p> <code>[]</code> <code>cma_params_dict</code> <code>dict</code> <p>Dictionary with parameters for the deap.cma.Strategy. Default: {}. See here for more information.</p> <code>{}</code> <code>bads_params_dict</code> <code>dict</code> <p>Dictionary with parameters for the bads optimization. Default: {}. See here for more information.</p> <code>{}</code> <code>source_solutions</code> <code>list</code> <p>List of tuples with the source solutions. Each tuple contains a numpy array with the parameter values and the loss. Used for initialization of cma optimization with deap. Default: [].</p> <code>[]</code> <code>variables_bounds_guess</code> <code>dict</code> <p>Dictionary with parameter names (keys) and their bounds (values) as list. These bounds define the region there the minimum is expected. Used for the BADS optimization. Default: None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print additional information. Default: False.</p> <code>False</code> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>@check_types(warnings=False)\ndef __init__(\n    self,\n    experiment: Type[CompNeuroExp],\n    get_loss_function: Callable[[Any, Any], float | list[float]],\n    variables_bounds: dict[str, float | str | list[float | str]],\n    neuron_model: Neuron,\n    results_soll: Any | None = None,\n    target_neuron_model: Neuron | None = None,\n    time_step: float = 1.0,\n    recording_period: float | None = None,\n    compile_folder_name: str = \"annarchy_OptNeuron\",\n    num_rep_loss: int = 1,\n    method: str = \"deap\",\n    prior=None,\n    fv_space: list = None,\n    record: list[str] = [],\n    cma_params_dict: dict = {},\n    bads_params_dict: dict = {},\n    source_solutions: list[tuple[np.ndarray, float]] = [],\n    variables_bounds_guess: None | dict[str, list[float]] = None,\n    verbose=False,\n):\n    \"\"\"\n    This prepares the optimization. To run the optimization call the run function.\n\n    Args:\n        experiment (CompNeuroExp class):\n            CompNeuroExp class containing a 'run' function which defines the\n            simulations and recordings\n        get_loss_function (function):\n            function which takes results_ist and results_soll as arguments and\n            calculates/returns the loss\n        variables_bounds (dict):\n            Dictionary with parameter names (keys) and their bounds (values). If\n            single values are given as values, the parameter is constant, i.e., not\n            optimized. If a list is given as value, the parameter is optimized and\n            the list contains the lower and upper bound of the parameter (order is\n            not important). If strings instead of numbers are given, the string is\n            interpreted as an mathematical expression which is evaluated with the\n            other parameter values (i.e. {\"x\":[0,1],\"dxy\":[-1,1],\"y\":\"x+dxy\",\"z\":5}).\n        neuron_model (ANNarchy Neuron):\n            The neuron model whose parameters should be optimized.\n        results_soll (Any, optional):\n            Some variable which contains the target data and can be used by the\n            get_loss_function (second argument of get_loss_function)\n            !!! warning\n                Either provide results_soll or a target_neuron_model not both!\n            Default: None.\n        target_neuron_model (ANNarchy Neuron, optional):\n            The neuron model which produces the target data by running the\n            experiment.\n            !!! warning\n                Either provide results_soll or a target_neuron_model not both!\n            Default: None.\n        time_step (float, optional):\n            The time step for the simulation in ms. Default: 1.\n        recording_period (float, optional):\n            The recording period for the simulation in ms. Default: None, i.e., the\n            time_step is used.\n        compile_folder_name (string, optional):\n            The name of the annarchy compilation folder within annarchy_folders/.\n            Default: 'annarchy_OptNeuron'.\n        num_rep_loss (int, optional):\n            Only interesting for noisy simulations/models. How often should the\n            simulaiton be run to calculate the loss (the defined number of losses\n            is obtained and averaged). Default: 1.\n        method (str, optional):\n            Either 'deap', 'sbi', or 'hyperopt'. Defines the tool which is used for\n            optimization. Default: 'deap'.\n        prior (distribution, optional):\n            The prior distribution used by sbi. Default: None, i.e., uniform\n            distributions between the variable bounds are assumed.\n        fv_space (list, optional):\n            The search space for hyperopt. Default: None, i.e., uniform\n            distributions between the variable bounds are assumed.\n        record (list, optional):\n            List of strings which define what variables of the tuned neuron should\n            be recorded. Default: [].\n        cma_params_dict (dict, optional):\n            Dictionary with parameters for the deap.cma.Strategy. Default: {}.\n            See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy) for more information.\n        bads_params_dict (dict, optional):\n            Dictionary with parameters for the bads optimization. Default: {}.\n            See [here](https://acerbilab.github.io/pybads/api/options/bads_options.html) for more information.\n        source_solutions (list, optional):\n            List of tuples with the source solutions. Each tuple contains a numpy\n            array with the parameter values and the loss. Used for initialization of\n            cma optimization with deap. Default: [].\n        variables_bounds_guess (dict, optional):\n            Dictionary with parameter names (keys) and their bounds (values) as\n            list. These bounds define the region there the minimum is expected. Used\n            for the BADS optimization. Default: None.\n        verbose (bool, optional):\n            If True, print additional information. Default: False.\n    \"\"\"\n\n    if len(self.opt_created) &gt; 0:\n        print(\n            \"OptNeuron: Error: Already another OptNeuron created. Only create one per python session!\"\n        )\n        quit()\n    else:\n        print(\n            \"OptNeuron: Initialize OptNeuron... do not create anything with ANNarchy before!\"\n        )\n\n        ### set object variables\n        self.verbose = verbose\n        self.verbose_run = False\n        self.opt_created.append(1)\n        self.record = record\n        self.results_soll = results_soll\n        self.variables_bounds = variables_bounds\n        self.fitting_variables_name_list = self._get_fitting_variables_name_list()\n        self.method = method\n        if method == \"hyperopt\":\n            if fv_space is None:\n                self.fv_space = self._get_hyperopt_space()\n            else:\n                self.fv_space = fv_space\n        self.const_params = self._get_const_params()\n        self.num_rep_loss = num_rep_loss\n        self.neuron_model = neuron_model\n        if method == \"sbi\":\n            self.prior = self._get_prior(prior)\n        self.target_neuron = target_neuron_model\n        self.compile_folder_name = compile_folder_name\n        self._get_loss = get_loss_function\n        self.cma_params_dict = cma_params_dict\n        self.source_solutions = source_solutions\n        self.variables_bounds_guess = variables_bounds_guess\n        self.bads_params_dict = bads_params_dict\n        self.loss_history = []\n        self.start_time = time()\n        self.recording_period = recording_period\n\n        ### if using deap pop size is the number of individuals for the optimization\n        if method == \"deap\":\n            self._deap_cma = self._prepare_deap_cma()\n            self.popsize = self._deap_cma.deap_dict[\"strategy\"].lambda_\n        else:\n            self.popsize = 1\n        if self.verbose:\n            print(\"OptNeuron: popsize:\", self.popsize)\n\n        ### check target_neuron/results_soll\n        self._check_target()\n        ### check neuron models\n        self._check_neuron_models()\n\n        ### setup ANNarchy\n        setup(dt=time_step)\n\n        ### create and compile model\n        ### if neuron models and target neuron model --&gt; create both models then\n        ### test, then clear and create only model for neuron model\n        model, target_model, monitors = self._generate_models(self.popsize)\n\n        self.pop = model.populations[0]\n        if target_model is not None:\n            self.pop_target = target_model.populations[0]\n        else:\n            self.pop_target = None\n        ### create experiment with current monitors\n        self.experiment = experiment(monitors=monitors)\n\n        ### check variables of model\n        self._test_variables()\n\n        ### check neuron models, experiment, get_loss\n        ### if results_soll is None -_&gt; generate results_soll\n        self._check_get_loss_function()\n\n        ### after checking neuron models, experiment, get_loss\n        ### clear ANNarchy and create/compile again only\n        ### standard model, thus recreate also monitors and experiment\n        mf.cnp_clear()\n        model, _, monitors = self._generate_models(self.popsize)\n        self.monitors = monitors\n        self.experiment = experiment(monitors=monitors)\n</code></pre>"},{"location":"main/optimize_neuron/#CompNeuroPy.opt_neuron.OptNeuron.run","title":"<code>run(max_evals, results_file_name='opt_neuron_results/best', sbi_plot_file='opt_neuron_plots/posterior.png', deap_plot_file='opt_neuron_plots/logbook.png', verbose=False)</code>","text":"<p>Runs the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>max_evals</code> <code>int</code> <p>number of runs the optimization method performs</p> required <code>results_file_name</code> <code>str</code> <p>name of the file which is saved. The file contains the optimized and target results, the obtained parameters, the loss, and the SD of the loss (in case of noisy models with multiple runs per loss calculation) Default: \"best\".</p> <code>'opt_neuron_results/best'</code> <code>sbi_plot_file</code> <code>str</code> <p>If you use \"sbi\": the name of the figure which will be saved and shows the posterior. Default: \"posterior.png\".</p> <code>'opt_neuron_plots/posterior.png'</code> <code>deap_plot_file</code> <code>str</code> <p>If you use \"deap\": the name of the figure which will be saved and shows the logbook. Default: \"logbook.png\".</p> <code>'opt_neuron_plots/logbook.png'</code> <code>verbose</code> <code>bool</code> <p>If True, detailed information is printed. Default: False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>best</code> <code>dict</code> <p>dictionary containing the optimized parameters (as keys) and:</p> <ul> <li>\"loss\": the loss</li> <li>\"all_loss\": the individual losses of the get_loss_function</li> <li>\"std\": the SD of the loss (in case of noisy models with multiple     runs per loss calculation)</li> <li>\"results\": the results generated by the experiment</li> <li>\"results_soll\": the target results</li> </ul> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>@check_types()\ndef run(\n    self,\n    max_evals: int,\n    results_file_name: str = \"opt_neuron_results/best\",\n    sbi_plot_file: str = \"opt_neuron_plots/posterior.png\",\n    deap_plot_file: str = \"opt_neuron_plots/logbook.png\",\n    verbose: bool = False,\n):\n    \"\"\"\n    Runs the optimization.\n\n    Args:\n        max_evals (int):\n            number of runs the optimization method performs\n        results_file_name (str, optional):\n            name of the file which is saved. The file contains the optimized and\n            target results, the obtained parameters, the loss, and the SD of the\n            loss (in case of noisy models with multiple runs per loss calculation)\n            Default: \"best\".\n        sbi_plot_file (str, optional):\n            If you use \"sbi\": the name of the figure which will be saved and shows\n            the posterior. Default: \"posterior.png\".\n        deap_plot_file (str, optional):\n            If you use \"deap\": the name of the figure which will be saved and shows\n            the logbook. Default: \"logbook.png\".\n        verbose (bool, optional):\n            If True, detailed information is printed. Default: False.\n\n    Returns:\n        best (dict):\n            dictionary containing the optimized parameters (as keys) and:\n\n            - \"loss\": the loss\n            - \"all_loss\": the individual losses of the get_loss_function\n            - \"std\": the SD of the loss (in case of noisy models with multiple\n                runs per loss calculation)\n            - \"results\": the results generated by the experiment\n            - \"results_soll\": the target results\n    \"\"\"\n    self.verbose = False\n    self.verbose_run = verbose\n    self.loss_history = []\n    self.start_time = time()\n    if self.method == \"hyperopt\":\n        ### run optimization with hyperopt and return best dict\n        best = fmin(\n            fn=self._run_simulator,\n            space=self.fv_space,\n            algo=tpe.suggest,\n            max_evals=max_evals,\n        )\n    elif self.method == \"sbi\":\n        ### run optimization with sbi and return best dict\n        best = self._run_with_sbi(max_evals, sbi_plot_file)\n    elif self.method == \"deap\":\n        best = self._run_with_deap(max_evals, deap_plot_file)\n    elif self.method == \"bads\":\n        if max_evals &lt; 4:\n            raise ValueError(\"bads needs at least 4 evaluations\")\n        best = self._run_with_bads(max_evals)\n    else:\n        print(\"ERROR run; method should be 'hyperopt', 'sbi', 'deap', or 'bads'\")\n        quit()\n    ### obtain loss for the best parameters\n    fit = self._test_fit(best)\n    best[\"loss\"] = float(fit[\"loss\"])\n    best[\"all_loss\"] = fit[\"all_loss\"]\n    best[\"std\"] = fit[\"std\"]\n    best[\"results\"] = fit[\"results\"]\n    best[\"results_soll\"] = self.results_soll\n    self.results = best\n\n    ### create loss history array\n    self.loss_history = np.array(self.loss_history)\n\n    ### SAVE OPTIMIZED PARAMS AND LOSS\n    ### save as pkl file\n    sf.save_variables(\n        [best],\n        [results_file_name.split(\"/\")[-1]],\n        (\n            \"/\".join(results_file_name.split(\"/\")[:-1])\n            if len(results_file_name.split(\"/\")) &gt; 1\n            else \"./\"\n        ),\n    )\n    ### save human readable as json file\n    json.dump(\n        {key: best[key] for key in self.fitting_variables_name_list + [\"loss\"]},\n        open(\n            f\"{results_file_name}.json\",\n            \"w\",\n        ),\n        indent=4,\n    )\n\n    return best\n</code></pre>"}]}