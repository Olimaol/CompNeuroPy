{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documentation for CompNeuroPy","text":"<p>CompNeuroPy is an assisting Python package for working with ANNarchy (GitHub, documentation, DOI). It is intended to help structure simulations with computational neuroscience models in a modular way and to make them more easily replicable. People who want to start working with ANNarchy are strongly recommended to first learn exclusively the functionality of ANNarchy. CompNeuroPy uses very few features of ANNarchy at this time. But also adds various special features.</p>"},{"location":"license/","title":"License","text":""},{"location":"license/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2022 Oliver Maith</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"additional/analysis_functions/","title":"Analysis Functions","text":""},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.PlotRecordings","title":"<code>PlotRecordings</code>","text":"<p>Plot recordings from CompNeuroMonitors.</p> <p>TODO: CHeck if there are memory issues with large recordings or many subplots.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>class PlotRecordings:\n    \"\"\"\n    Plot recordings from CompNeuroMonitors.\n\n    TODO: CHeck if there are memory issues with large recordings or many subplots.\n    \"\"\"\n\n    @check_types()\n    def __init__(\n        self,\n        figname: str,\n        recordings: list[dict],\n        recording_times: RecordingTimes,\n        shape: tuple[int, int],\n        plan: dict,\n        chunk: int = 0,\n        time_lim: None | tuple[float, float] = None,\n        dpi: int = 300,\n    ) -&gt; None:\n        \"\"\"\n        Create and save the plot.\n\n        Args:\n            figname (str):\n                The name of the figure to be saved.\n            recordings (list):\n                A recordings list obtained from CompNeuroMonitors.\n            recording_times (RecordingTimes):\n                The RecordingTimes object containing the recording times obtained from\n                CompNeuroMonitors.\n            shape (tuple):\n                The shape of the figure. (number of rows, number of columns)\n            plan (dict):\n                Defines which recordings are plotted in which subplot and how. The plan\n                has to contain the following keys: \"position\", \"compartment\",\n                \"variable\", \"format\". The values of the keys have to be lists of the\n                same length. The values of the key \"position\" have to be integers\n                between 1 and the number of subplots (defined by shape). The values of\n                the key \"compartment\" have to be the names of the model compartments as\n                strings. The values of the key \"variable\" have to be strings containing\n                the names of the recorded variables or equations using the recorded\n                variables. The values of the key \"format\" have to be strings defining\n                how the recordings are plotted. The following formats are available for\n                spike recordings: \"raster\", \"mean\", \"hybrid\", \"interspike\". The\n                following formats are available for other recordings: \"line\",\n                \"line_mean\", \"matrix\", \"matrix_mean\".\n            chunk (int, optional):\n                The chunk of the recordings to be plotted. Default: 0.\n            time_lim (tuple, optional):\n                Defines the x-axis for all subplots. The tuple contains two\n                numbers: start and end time in ms. The times have to be\n                within the chunk. Default: None, i.e., the whole chunk is plotted.\n            dpi (int, optional):\n                The dpi of the saved figure. Default: 300.\n        \"\"\"\n        ### print start message\n        print(f\"Generate fig {figname}\", end=\"... \", flush=True)\n\n        ### set attributes\n        self.figname = figname\n        self.recordings = recordings\n        self.recording_times = recording_times\n        self.shape = shape\n        self.plan = plan\n        self.chunk = chunk\n        self.time_lim = time_lim\n        self.dpi = dpi\n\n        ### get available compartments (from recordings) and recorded variables for each\n        ### compartment\n        (\n            self._compartment_list,\n            self._compartment_recordings_dict,\n        ) = self._get_compartment_recordings()\n\n        ### check plan keys and values\n        self._check_plan()\n\n        ### get start and end time for plotting and timestep\n        self._start_time, self._end_time, self._time_step = self._get_start_end_time()\n\n        ### get compbined time array for recordings of each compartment\n        self._time_arr_list = self._get_time_arr_list()\n\n        ### get data from recordings for each subplot\n        self._raw_data_list = self._get_raw_data_list()\n\n        ### create plot\n        self._plot()\n\n        ### print end message\n        print(\"Done\\n\")\n\n    def _get_compartment_recordings(self):\n        \"\"\"\n        Get available compartment names from recordings.\n        Get recorded variables (names) for each compartment.\n\n        Returns:\n            compartment_list (list):\n                List of compartment names.\n            compartment_recordings_dict (dict):\n                Dictionary with compartment names as keys and list of recorded variables\n                as values.\n        \"\"\"\n        ### check if chunk is valid\n        if self.chunk &gt;= len(self.recordings) or self.chunk &lt; 0:\n            print(\n                f\"\\nERROR PlotRecordings: chunk {self.chunk} is not valid.\\n\"\n                f\"Number of chunks: {len(self.recordings)}\\n\"\n            )\n            quit()\n\n        ### get compartment names and recorded variables for each compartment\n        compartment_list = []\n        compartment_recordings_dict = {}\n        for recordings_key in self.recordings[self.chunk].keys():\n            if \";\" not in recordings_key:\n                continue\n\n            ### get compartment\n            compartment, recorded_variable = recordings_key.split(\";\")\n            if compartment not in compartment_list:\n                compartment_list.append(compartment)\n                compartment_recordings_dict[compartment] = []\n\n            ### get recordings for compartment\n            if recorded_variable != \"period\" and recorded_variable != \"parameter_dict\":\n                compartment_recordings_dict[compartment].append(recorded_variable)\n\n        return compartment_list, compartment_recordings_dict\n\n    def _check_plan(self):\n        \"\"\"\n        Check if plan is valid.\n        \"\"\"\n\n        ### check if plan keys are valid\n        valid_keys = [\"position\", \"compartment\", \"variable\", \"format\"]\n        for key in self.plan.keys():\n            if key not in valid_keys:\n                print(\n                    f\"\\nERROR PlotRecordings: plan key {key} is not valid.\\n\"\n                    f\"Valid keys are {valid_keys}.\\n\"\n                )\n                quit()\n\n        ### check if plan values are valid (have same length)\n        for key in self.plan.keys():\n            if len(self.plan[key]) != len(self.plan[\"position\"]):\n                print(\n                    f\"\\nERROR PlotRecordings: plan value of key '{key}' has not the same length as plan value of key 'position'.\\n\"\n                )\n                quit()\n\n        ### check if plan positions are valid\n        ### check if min and max are valid\n        if get_minimum(self.plan[\"position\"]) &lt; 1:\n            print(\n                f\"\\nERROR PlotRecordings: plan position has to be &gt;= 1.\\n\"\n                f\"plan position: {self.plan['position']}\\n\"\n            )\n            quit()\n        if get_maximum(self.plan[\"position\"]) &gt; self.shape[0] * self.shape[1]:\n            print(\n                f\"\\nERROR PlotRecordings: plan position has to be &lt;= shape[0] * shape[1].\\n\"\n                f\"plan position: {self.plan['position']}\\n\"\n                f\"shape: {self.shape}\\n\"\n            )\n            quit()\n        ### check if plan positions are unique\n        if len(np.unique(self.plan[\"position\"])) != len(self.plan[\"position\"]):\n            print(\n                f\"\\nERROR PlotRecordings: plan position has to be unique.\\n\"\n                f\"plan position: {self.plan['position']}\\n\"\n            )\n            quit()\n\n        ### check if plan compartments are valid\n        for compartment in self.plan[\"compartment\"]:\n            if compartment not in self._compartment_list:\n                print(\n                    f\"\\nERROR PlotRecordings: plan compartment {compartment} is not valid.\\n\"\n                    f\"Valid compartments are {self._compartment_list}.\\n\"\n                )\n                quit()\n\n        ### check if plan variables are valid\n        for plot_idx in range(len(self.plan[\"variable\"])):\n            compartment = self.plan[\"compartment\"][plot_idx]\n            variable: str = self.plan[\"variable\"][plot_idx]\n            ### check if variable contains a mathematical expression\n            if \"+\" in variable or \"-\" in variable or \"*\" in variable or \"/\" in variable:\n                ### separate variables\n                variable = variable.replace(\" \", \"\")\n                variable = variable.replace(\"+\", \" \")\n                variable = variable.replace(\"-\", \" \")\n                variable = variable.replace(\"*\", \" \")\n                variable = variable.replace(\"/\", \" \")\n                variables_list = variable.split(\" \")\n                ### remove numbers\n                variables_list = [var for var in variables_list if not var.isdigit()]\n                ### spike and axon_spike are not allowed in equations\n                if \"spike\" in variables_list or \"axon_spike\" in variables_list:\n                    print(\n                        f\"\\nERROR PlotRecordings: plan variable {variable} is not valid.\\n\"\n                        f\"Variables 'spike' and 'axon_spike' are not allowed in equations.\\n\"\n                    )\n                    quit()\n            else:\n                variables_list = [variable]\n            ### check if variables are valid\n            for var in variables_list:\n                if var not in self._compartment_recordings_dict[compartment]:\n                    print(\n                        f\"\\nERROR PlotRecordings: plan variable {var} is not valid for compartment {compartment}.\\n\"\n                        f\"Valid variables are {self._compartment_recordings_dict[compartment]}.\\n\"\n                    )\n                    quit()\n\n        ### check if plan formats are valid\n        valid_formats_spike = [\"raster\", \"mean\", \"hybrid\", \"interspike\", \"cv\"]\n        valid_formats_other = [\"line\", \"line_mean\", \"matrix\", \"matrix_mean\"]\n        for plot_idx in range(len(self.plan[\"format\"])):\n            variable = self.plan[\"variable\"][plot_idx]\n            format = self.plan[\"format\"][plot_idx]\n            ### check if format is valid\n            if variable == \"spike\" or variable == \"axon_spike\":\n                if format not in valid_formats_spike:\n                    print(\n                        f\"\\nERROR PlotRecordings: plan format {format} is not valid for variable {variable}.\\n\"\n                        f\"Valid formats are {valid_formats_spike}.\\n\"\n                    )\n                    quit()\n            else:\n                if format not in valid_formats_other:\n                    print(\n                        f\"\\nERROR PlotRecordings: plan format {format} is not valid for variable {variable}.\\n\"\n                        f\"Valid formats are {valid_formats_other}.\\n\"\n                    )\n                    quit()\n\n    def _get_start_end_time(self):\n        \"\"\"\n        Check if time_lim is given and valid. If it's not given get it from recordings.\n        Get timestep from recordings.\n\n        Returns:\n            start_time (float):\n                The start time of the recordings.\n            end_time (float):\n                The end time of the recordings.\n            time_step (float):\n                The timestep of the recordings.\n\n        Raises:\n            ValueError: If given time_lim is not within the chunk.\n        \"\"\"\n\n        chunk_time_lims = self.recording_times.time_lims(chunk=self.chunk)\n        ### check if time_lim is given\n        if isinstance(self.time_lim, type(None)):\n            ### get start and end time from recording_times\n            start_time, end_time = chunk_time_lims\n        else:\n            ### check if time_lim is within chunk\n            if (\n                self.time_lim[0] &lt; chunk_time_lims[0]\n                or self.time_lim[1] &gt; chunk_time_lims[1]\n            ):\n                raise ValueError(\n                    f\"\\nERROR PlotRecordings: time_lim {self.time_lim} is not within chunk.\\n\"\n                    f\"chunk time lims: {chunk_time_lims[0]} - {chunk_time_lims[1]}\\n\"\n                )\n            start_time, end_time = self.time_lim\n\n        ### get timestep\n        time_step = self.recordings[self.chunk][\"dt\"]\n\n        return start_time, end_time, time_step\n\n    def _get_time_arr_list(self):\n        \"\"\"\n        Get combined time array for each subplot of plan.\n\n        Returns:\n            time_arr_list (list):\n                List with time arrays for each subplot of plan.\n        \"\"\"\n        ### loop over compartments of plan\n        time_arr_dict = {}\n        for compartment in np.unique(self.plan[\"compartment\"]):\n            actual_period = self.recordings[self.chunk][f\"{compartment};period\"]\n\n            ### get time array for each recording period of the chunk\n            time_arr_period_list = []\n            nr_periods = self.recording_times._get_nr_periods(\n                chunk=self.chunk, compartment=compartment\n            )\n            for period in range(nr_periods):\n                time_lims = self.recording_times.time_lims(\n                    chunk=self.chunk, compartment=compartment, period=period\n                )\n                start_time_preiod = time_lims[0]\n                end_time_period = round(\n                    time_lims[1] + actual_period, get_number_of_decimals(actual_period)\n                )\n                time_arr_period_list.append(\n                    np.arange(start_time_preiod, end_time_period, actual_period)\n                )\n\n            ### combine time arrays of periods\n            time_arr_dict[compartment] = np.concatenate(time_arr_period_list)\n\n        ### get time array for each subplot of plan\n        time_arr_list = []\n        for plot_idx in range(len(self.plan[\"position\"])):\n            compartment = self.plan[\"compartment\"][plot_idx]\n            time_arr_list.append(time_arr_dict[compartment])\n\n        return time_arr_list\n\n    def _get_raw_data_list(self):\n        \"\"\"\n        Get raw data for each subplot of plan.\n\n        Returns:\n            data_list (dict):\n                List with data for each subplot of plan.\n        \"\"\"\n        data_list = []\n        ### loop over subplots of plan\n        for plot_idx in range(len(self.plan[\"position\"])):\n            compartment = self.plan[\"compartment\"][plot_idx]\n            variable: str = self.plan[\"variable\"][plot_idx]\n            ### check if variable is equation\n            if \"+\" in variable or \"-\" in variable or \"*\" in variable or \"/\" in variable:\n                ### get the values of the recorded variables of the compartment, store\n                ### them in dict\n                value_dict = {\n                    rec_var_name: self.recordings[self.chunk][\n                        f\"{compartment};{rec_var_name}\"\n                    ]\n                    for rec_var_name in self._compartment_recordings_dict[compartment]\n                }\n                ### evaluate equation with these values\n                variable_data = ef.evaluate_expression_with_dict(\n                    expression=variable, value_dict=value_dict\n                )\n            else:\n                ### get data from recordings\n                variable_data = self.recordings[self.chunk][f\"{compartment};{variable}\"]\n            ### append data to data_list\n            data_list.append(variable_data)\n\n        return data_list\n\n    def _plot(self):\n        \"\"\"\n        Create plot.\n        \"\"\"\n        ### create figure\n        plt.figure(figsize=([6.4 * self.shape[1], 4.8 * self.shape[0]]))\n\n        ### loop over subplots of plan\n        for plot_idx in range(len(self.plan[\"position\"])):\n            ### create subplot\n            plt.subplot(self.shape[0], self.shape[1], self.plan[\"position\"][plot_idx])\n\n            ### fill subplot\n            self._fill_subplot(plot_idx)\n\n        ### save figure\n        plt.tight_layout()\n        figname_parts = self.figname.split(\"/\")\n        if len(figname_parts) &gt; 1:\n            save_dir = \"/\".join(figname_parts[:-1])\n            sf.create_dir(save_dir)\n        plt.savefig(self.figname, dpi=self.dpi)\n        plt.close()\n\n    def _fill_subplot(self, plot_idx):\n        \"\"\"\n        Fill subplot with data.\n\n        Args:\n            plot_idx (int):\n                The index of the subplot in the plan.\n        \"\"\"\n        variable: str = self.plan[\"variable\"][plot_idx]\n\n        ### general subplot settings\n        plt.xlabel(\"time [ms]\")\n        plt.xlim(self._start_time, self._end_time)\n\n        if variable == \"spike\" or variable == \"axon_spike\":\n            ### spike recordings\n            self._fill_subplot_spike(plot_idx)\n        else:\n            ### other (array) recordings\n            self._fill_subplot_other(plot_idx)\n\n    def _fill_subplot_spike(self, plot_idx):\n        \"\"\"\n        Fill subplot with spike data.\n\n        Args:\n            plot_idx (int):\n                The index of the subplot in the plan.\n        \"\"\"\n        ### get data\n        compartment = self.plan[\"compartment\"][plot_idx]\n        format: str = self.plan[\"format\"][plot_idx]\n        data = self._raw_data_list[plot_idx]\n\n        ### get spike times and ranks\n        spike_times, spike_ranks = my_raster_plot(data)\n        spike_times = spike_times * self._time_step\n\n        ### get spikes within time_lims\n        mask: np.ndarray = (\n            (spike_times &gt;= self._start_time).astype(int)\n            * (spike_times &lt;= self._end_time).astype(int)\n        ).astype(bool)\n\n        ### check if there are no spikes\n        if mask.size == 0:\n            ### set title\n            plt.title(f\"Spikes {compartment}\")\n            ### print warning\n            print(\n                f\"\\n  WARNING PlotRecordings: {compartment} does not contain any spikes in the given time interval.\"\n            )\n            ### plot text\n            plt.text(\n                0.5,\n                0.5,\n                f\"{compartment} does not contain any spikes.\",\n                va=\"center\",\n                ha=\"center\",\n            )\n            plt.xticks([])\n            plt.yticks([])\n            plt.xlim(0, 1)\n            plt.xlabel(\"\")\n            return\n\n        ### plot raster plot\n        if format == \"raster\" or format == \"hybrid\":\n            self._raster_plot(compartment, spike_ranks, spike_times, mask)\n\n        ### plot mean firing rate\n        if format == \"mean\" or format == \"hybrid\":\n            self._mean_firing_rate_plot(compartment, data, format)\n\n        ### plot interspike interval histogram\n        if format == \"interspike\":\n            self._interspike_interval_plot(compartment, data)\n\n        ### plot coefficient of variation histogram\n        if format == \"cv\":\n            self._coefficient_of_variation_plot(compartment, data)\n\n    def _raster_plot(self, compartment, spike_ranks, spike_times, mask):\n        \"\"\"\n        Plot raster plot.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            spike_ranks (array):\n                The spike ranks.\n            spike_times (array):\n                The spike times.\n            mask (array):\n                The mask for the spike times.\n        \"\"\"\n        ### set title\n        plt.title(f\"Spikes {compartment} ({spike_ranks.max() + 1})\")\n        ### check if there is only one neuron\n        if spike_ranks.max() == 0:\n            marker, size = [\"|\", 3000]\n        else:\n            marker, size = [\".\", 3]\n        ### plot spikes\n        plt.scatter(\n            spike_times[mask],\n            spike_ranks[mask],\n            color=\"k\",\n            marker=marker,\n            s=size,\n            linewidth=0.1,\n        )\n        ### set limits\n        plt.ylim(-0.5, spike_ranks.max() + 0.5)\n        ### set ylabel\n        plt.ylabel(\"# neurons\")\n        ### set yticks\n        if spike_ranks.max() == 0:\n            plt.yticks([0])\n        else:\n            plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n\n    def _mean_firing_rate_plot(self, compartment, data, format):\n        \"\"\"\n        Plot mean firing rate.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            data (array):\n                The spike data.\n            format (str):\n                The format of the plot.\n        \"\"\"\n        ### set title\n        plt.title(f\"Activity {compartment} ({len(data)})\")\n        ### set axis\n        ax = plt.gca()\n        color = \"k\"\n        ### for hybrid format plot mean firing rate in second y-axis\n        if format == \"hybrid\":\n            ax = plt.gca().twinx()\n            color = \"r\"\n        ### get mean firing rate\n        time_arr, firing_rate = get_pop_rate(\n            spikes=data,\n            t_start=self._start_time,\n            t_end=self._end_time,\n            time_step=self._time_step,\n        )\n        ### plot mean firing rate\n        ax.plot(time_arr, firing_rate, color=color)\n        ### set limits\n        ax.set_xlim(self._start_time, self._end_time)\n        ### set ylabel\n        ax.set_ylabel(\"Mean firing rate [Hz]\", color=color)\n        ax.tick_params(axis=\"y\", colors=color)\n\n    def _interspike_interval_plot(self, compartment, data):\n        \"\"\"\n        Plot interspike interval histogram.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            data (dict):\n                The spike data.\n        \"\"\"\n        ### set title\n        plt.title(f\"Interspike interval histogram {compartment} ({len(data)})\")\n        ### get interspike intervals\n        interspike_intervals_list = inter_spike_interval(spikes=data)\n        ### plot histogram\n        plt.hist(\n            interspike_intervals_list,\n            bins=100,\n            range=(0, 200),\n            density=True,\n            color=\"k\",\n        )\n        ### set limits\n        plt.xlim(0, 200)\n        ### set ylabel\n        plt.ylabel(\"Probability\")\n        plt.xlabel(\"Interspike interval [ms]\")\n\n    def _coefficient_of_variation_plot(self, compartment, data):\n        \"\"\"\n        Plot coefficient of variation histogram.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            data (dict):\n                The spike data.\n        \"\"\"\n        ### set title\n        plt.title(f\"Coefficient of variation histogram {compartment} ({len(data)})\")\n        ### get coefficient of variation\n        coefficient_of_variation_dict = coefficient_of_variation(\n            spikes=data,\n            per_neuron=True,\n        )\n        coefficient_of_variation_list = list(coefficient_of_variation_dict.values())\n        ### plot histogram\n        plt.hist(\n            coefficient_of_variation_list,\n            bins=100,\n            range=(0, 2),\n            density=True,\n            color=\"k\",\n        )\n        ### set limits\n        plt.xlim(0, 2)\n        ### set ylabel\n        plt.ylabel(\"Probability\")\n        plt.xlabel(\"Coefficient of variation\")\n\n    def _fill_subplot_other(self, plot_idx):\n        \"\"\"\n        Fill subplot with array data.\n\n        Args:\n            plot_idx (int):\n                The index of the subplot in the plan.\n        \"\"\"\n        ### get data\n        compartment = self.plan[\"compartment\"][plot_idx]\n        variable: str = self.plan[\"variable\"][plot_idx]\n        format: str = self.plan[\"format\"][plot_idx]\n        data_arr = self._raw_data_list[plot_idx]\n        time_arr = self._time_arr_list[plot_idx]\n\n        ### get data within time_lims\n        mask: np.ndarray = (\n            (time_arr &gt;= self._start_time).astype(int)\n            * (time_arr &lt;= self._end_time).astype(int)\n        ).astype(bool)\n\n        ### fill gaps in time_arr and data_arr with nan\n        time_arr, data_arr = time_data_add_nan(\n            time_arr=time_arr[mask], data_arr=data_arr[mask], axis=0\n        )\n\n        ### plot line plot\n        if \"line\" in format:\n            self._line_plot(\n                compartment,\n                variable,\n                time_arr,\n                data_arr,\n                plot_idx,\n                mean=\"mean\" in format,\n            )\n\n        ### plot matrix plot\n        if \"matrix\" in format:\n            self._matrix_plot(\n                compartment,\n                variable,\n                time_arr,\n                data_arr,\n                plot_idx,\n                mean=\"mean\" in format,\n            )\n\n    def _line_plot(self, compartment, variable, time_arr, data_arr, plot_idx, mean):\n        \"\"\"\n        Plot line plot.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            variable (str):\n                The name of the variable.\n            time_arr (array):\n                The time array.\n            data_arr (array):\n                The data array.\n            plot_idx (int):\n                The index of the subplot in the plan.\n            mean (bool):\n                If True, plot the mean of the data. Population: average over neurons.\n                Projection: average over preneurons (results in one line for each\n                postneuron).\n        \"\"\"\n\n        ### set title\n        plt.title(f\"Variable {variable} of {compartment} ({data_arr.shape[1]})\")\n\n        ### Shape of data defines how to plot\n        ### 2D array where elements are no lists\n        ### = population data [time, neurons]\n        ### --&gt; plot line for each neuron\n        if len(data_arr.shape) == 2 and isinstance(data_arr[0, 0], list) is not True:\n            ### mean -&gt; average over neurons\n            if mean:\n                data_arr = np.mean(data_arr, 1, keepdims=True)\n            ### plot line for each neuron\n            for neuron in range(data_arr.shape[1]):\n                plt.plot(\n                    time_arr,\n                    data_arr[:, neuron],\n                    color=\"k\",\n                )\n\n        ### 2D array where elements are lists\n        ### = projection data [time, postneurons][preneurons]\n        ### 3D array\n        ### = projection data [time, postneurons, preneurons]\n        ### --&gt; plot line for each preneuron postneuron pair\n        elif len(data_arr.shape) == 3 or (\n            len(data_arr.shape) == 2 and isinstance(data_arr[0, 0], list) is True\n        ):\n            ### plot line for each preneuron postneuron pair\n            for post_neuron in range(data_arr.shape[1]):\n                ### the post_neuron has a constant number of preneurons\n                ### --&gt; create array with preneuron indices [time, preneurons]\n                post_neuron_data = np.array(data_arr[:, post_neuron])\n                ### mean -&gt; average over preneurons\n                if mean:\n                    post_neuron_data = np.mean(post_neuron_data, 1, keepdims=True)\n                for pre_neuron in range(post_neuron_data.shape[1]):\n                    plt.plot(\n                        time_arr,\n                        post_neuron_data[:, pre_neuron],\n                        color=\"k\",\n                    )\n        else:\n            print(\n                f\"\\nERROR PlotRecordings: shape of data not supported, {compartment}, {variable} in plot {plot_idx}.\\n\"\n            )\n\n    def _matrix_plot(self, compartment, variable, time_arr, data_arr, plot_idx, mean):\n        \"\"\"\n        Plot matrix plot.\n\n        Args:\n            compartment (str):\n                The name of the compartment.\n            variable (str):\n                The name of the variable.\n            time_arr (array):\n                The time array.\n            data_arr (array):\n                The data array.\n            plot_idx (int):\n                The index of the subplot in the plan.\n            mean (bool):\n                If True, plot the mean of the data. Population: average over neurons.\n                Projection: average over preneurons (results in one line for each\n                postneuron).\n        \"\"\"\n        ### number of neurons i.e. postneurons\n        nr_neurons = data_arr.shape[1]\n\n        ### Shape of data defines how to plot\n        ### 2D array where elements are no lists\n        ### = population data [time, neurons]\n        ### --&gt; plot matrix row for each neuron\n        ### mean -&gt; average over neurons\n        if len(data_arr.shape) == 2 and isinstance(data_arr[0, 0], list) is not True:\n            ### mean -&gt; average over neurons\n            if mean:\n                data_arr = np.mean(data_arr, 1, keepdims=True)\n\n        ### 2D array where elements are lists\n        ### = projection data [time, postneurons][preneurons]\n        ### 3D array\n        ### = projection data [time, postneurons, preneurons]\n        ### --&gt; plot matrix row for each preneuron postneuron pair (has to reshape to 2D array [time, neuron pair])\n        ### mean -&gt; average over preneurons\n        elif len(data_arr.shape) == 3 or (\n            len(data_arr.shape) == 2 and isinstance(data_arr[0, 0], list) is True\n        ):\n            array_2D_list = []\n            ### loop over postneurons\n            for post_neuron in range(data_arr.shape[1]):\n                ### the post_neuron has a constant number of preneurons\n                ### --&gt; create array with preneuron indices [time, preneurons]\n                post_neuron_data = np.array(data_arr[:, post_neuron])\n                ### mean --&gt; average over preneurons\n                if mean:\n                    post_neuron_data = np.mean(post_neuron_data, 1, keepdims=True)\n                ### append all preneurons arrays to array_2D_list\n                for pre_neuron in range(post_neuron_data.shape[1]):\n                    array_2D_list.append(post_neuron_data[:, pre_neuron])\n                ### append a None array to array_2D_list to separate postneurons\n                array_2D_list.append(np.empty(post_neuron_data.shape[0]) * np.nan)\n\n            ### convert array_2D_list to 2D array, not use last None array\n            data_arr = np.array(array_2D_list[:-1]).T\n\n        ### some other shape not supported\n        else:\n            print(\n                f\"\\nERROR PlotRecordings: shape of data not supported, {compartment}, {variable} in plot {plot_idx}.\\n\"\n            )\n\n        ### plot matrix row for each neuron or preneuron postneuron pair\n        plt.imshow(\n            data_arr.T,\n            aspect=\"auto\",\n            vmin=np.nanmin(data_arr),\n            vmax=np.nanmax(data_arr),\n            extent=[\n                time_arr.min()\n                - self.recordings[self.chunk][f\"{compartment};period\"] / 2,\n                time_arr.max()\n                + self.recordings[self.chunk][f\"{compartment};period\"] / 2,\n                data_arr.shape[1] - 0.5,\n                -0.5,\n            ],\n            cmap=\"viridis\",\n            interpolation=\"none\",\n        )\n        if data_arr.shape[1] == 1:\n            plt.yticks([0])\n        else:\n            ### all y ticks\n            y_tick_positions_all_arr = np.arange(data_arr.shape[1])\n            ### boolean array of valid y ticks\n            valid_y_ticks = np.logical_not(np.isnan(data_arr).any(axis=0))\n            ### get y tick labels\n            if False in valid_y_ticks:\n                ### there are nan entries\n                ### split at nan entries\n                y_tick_positions_split_list = np.array_split(\n                    y_tick_positions_all_arr, np.where(np.logical_not(valid_y_ticks))[0]\n                )\n                ### decrease by 1 after each nan entry\n                y_tick_positions_split_list = [\n                    y_tick_positions_split - idx_split\n                    for idx_split, y_tick_positions_split in enumerate(\n                        y_tick_positions_split_list\n                    )\n                ]\n                ### join split arrays\n                y_tick_labels_all_arr = np.concatenate(y_tick_positions_split_list)\n            else:\n                y_tick_labels_all_arr = y_tick_positions_all_arr\n\n            valid_y_ticks_selected_idx_arr = np.linspace(\n                0,\n                np.sum(valid_y_ticks),\n                num=min([10, np.sum(valid_y_ticks)]),\n                dtype=int,\n                endpoint=False,\n            )\n            valid_y_ticks_selected_arr = y_tick_positions_all_arr[valid_y_ticks][\n                valid_y_ticks_selected_idx_arr\n            ]\n            valid_y_ticks_labels_selected_arr = y_tick_labels_all_arr[valid_y_ticks][\n                valid_y_ticks_selected_idx_arr\n            ]\n\n            plt.yticks(valid_y_ticks_selected_arr, valid_y_ticks_labels_selected_arr)\n\n        ### set title\n        plt.title(\n            f\"Variable {variable} of {compartment} ({nr_neurons}) [{ef.sci(np.nanmin(data_arr))}, {ef.sci(np.nanmax(data_arr))}]\"\n        )\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.PlotRecordings.__init__","title":"<code>__init__(figname, recordings, recording_times, shape, plan, chunk=0, time_lim=None, dpi=300)</code>","text":"<p>Create and save the plot.</p> <p>Parameters:</p> Name Type Description Default <code>figname</code> <code>str</code> <p>The name of the figure to be saved.</p> required <code>recordings</code> <code>list</code> <p>A recordings list obtained from CompNeuroMonitors.</p> required <code>recording_times</code> <code>RecordingTimes</code> <p>The RecordingTimes object containing the recording times obtained from CompNeuroMonitors.</p> required <code>shape</code> <code>tuple</code> <p>The shape of the figure. (number of rows, number of columns)</p> required <code>plan</code> <code>dict</code> <p>Defines which recordings are plotted in which subplot and how. The plan has to contain the following keys: \"position\", \"compartment\", \"variable\", \"format\". The values of the keys have to be lists of the same length. The values of the key \"position\" have to be integers between 1 and the number of subplots (defined by shape). The values of the key \"compartment\" have to be the names of the model compartments as strings. The values of the key \"variable\" have to be strings containing the names of the recorded variables or equations using the recorded variables. The values of the key \"format\" have to be strings defining how the recordings are plotted. The following formats are available for spike recordings: \"raster\", \"mean\", \"hybrid\", \"interspike\". The following formats are available for other recordings: \"line\", \"line_mean\", \"matrix\", \"matrix_mean\".</p> required <code>chunk</code> <code>int</code> <p>The chunk of the recordings to be plotted. Default: 0.</p> <code>0</code> <code>time_lim</code> <code>tuple</code> <p>Defines the x-axis for all subplots. The tuple contains two numbers: start and end time in ms. The times have to be within the chunk. Default: None, i.e., the whole chunk is plotted.</p> <code>None</code> <code>dpi</code> <code>int</code> <p>The dpi of the saved figure. Default: 300.</p> <code>300</code> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    figname: str,\n    recordings: list[dict],\n    recording_times: RecordingTimes,\n    shape: tuple[int, int],\n    plan: dict,\n    chunk: int = 0,\n    time_lim: None | tuple[float, float] = None,\n    dpi: int = 300,\n) -&gt; None:\n    \"\"\"\n    Create and save the plot.\n\n    Args:\n        figname (str):\n            The name of the figure to be saved.\n        recordings (list):\n            A recordings list obtained from CompNeuroMonitors.\n        recording_times (RecordingTimes):\n            The RecordingTimes object containing the recording times obtained from\n            CompNeuroMonitors.\n        shape (tuple):\n            The shape of the figure. (number of rows, number of columns)\n        plan (dict):\n            Defines which recordings are plotted in which subplot and how. The plan\n            has to contain the following keys: \"position\", \"compartment\",\n            \"variable\", \"format\". The values of the keys have to be lists of the\n            same length. The values of the key \"position\" have to be integers\n            between 1 and the number of subplots (defined by shape). The values of\n            the key \"compartment\" have to be the names of the model compartments as\n            strings. The values of the key \"variable\" have to be strings containing\n            the names of the recorded variables or equations using the recorded\n            variables. The values of the key \"format\" have to be strings defining\n            how the recordings are plotted. The following formats are available for\n            spike recordings: \"raster\", \"mean\", \"hybrid\", \"interspike\". The\n            following formats are available for other recordings: \"line\",\n            \"line_mean\", \"matrix\", \"matrix_mean\".\n        chunk (int, optional):\n            The chunk of the recordings to be plotted. Default: 0.\n        time_lim (tuple, optional):\n            Defines the x-axis for all subplots. The tuple contains two\n            numbers: start and end time in ms. The times have to be\n            within the chunk. Default: None, i.e., the whole chunk is plotted.\n        dpi (int, optional):\n            The dpi of the saved figure. Default: 300.\n    \"\"\"\n    ### print start message\n    print(f\"Generate fig {figname}\", end=\"... \", flush=True)\n\n    ### set attributes\n    self.figname = figname\n    self.recordings = recordings\n    self.recording_times = recording_times\n    self.shape = shape\n    self.plan = plan\n    self.chunk = chunk\n    self.time_lim = time_lim\n    self.dpi = dpi\n\n    ### get available compartments (from recordings) and recorded variables for each\n    ### compartment\n    (\n        self._compartment_list,\n        self._compartment_recordings_dict,\n    ) = self._get_compartment_recordings()\n\n    ### check plan keys and values\n    self._check_plan()\n\n    ### get start and end time for plotting and timestep\n    self._start_time, self._end_time, self._time_step = self._get_start_end_time()\n\n    ### get compbined time array for recordings of each compartment\n    self._time_arr_list = self._get_time_arr_list()\n\n    ### get data from recordings for each subplot\n    self._raw_data_list = self._get_raw_data_list()\n\n    ### create plot\n    self._plot()\n\n    ### print end message\n    print(\"Done\\n\")\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.my_raster_plot","title":"<code>my_raster_plot(spikes)</code>","text":"<p>Returns two vectors representing for each recorded spike 1) the spike times and 2) the ranks of the neurons. The spike times are always in simulation steps (in contrast to default ANNarchy raster_plot).</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dict</code> <p>ANNarchy spike dict of one population</p> required <p>Returns:</p> Name Type Description <code>t</code> <code>array</code> <p>spike times in simulation steps</p> <code>n</code> <code>array</code> <p>ranks of the neurons</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def my_raster_plot(spikes: dict):\n    \"\"\"\n    Returns two vectors representing for each recorded spike 1) the spike times and 2)\n    the ranks of the neurons. The spike times are always in simulation steps (in\n    contrast to default ANNarchy raster_plot).\n\n    Args:\n        spikes (dict):\n            ANNarchy spike dict of one population\n\n    Returns:\n        t (array):\n            spike times in simulation steps\n        n (array):\n            ranks of the neurons\n    \"\"\"\n    t, n = raster_plot(spikes)\n    np.zeros(10)\n    t = np.round(t / dt(), 0).astype(int)\n    return t, n\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_nanmean","title":"<code>get_nanmean(a, axis=None, dtype=None)</code>","text":"<p>Same as np.nanmean but without printing warnings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Array containing numbers whose mean is desired. If <code>a</code> is not an array, a conversion is attempted.</p> required <code>axis</code> <code>None or int or tuple of ints</code> <p>Axis or axes along which the means are computed. The default is to compute the mean of the flattened array.</p> <p>.. numpy versionadded:: 1.7.0</p> <p>If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before.</p> <code>None</code> <code>dtype</code> <code>data - type</code> <p>Type to use in computing the mean.  For integer inputs, the default is <code>float64</code>; for floating point inputs, it is the same as the input dtype.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>m</code> <code>ndarray, see dtype parameter above</code> <p>If <code>out=None</code>, returns a new array containing the mean values, otherwise a reference to the output array is returned.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_nanmean(a, axis=None, dtype=None):\n    \"\"\"\n    Same as np.nanmean but without printing warnings.\n\n    Args:\n        a (array_like):\n            Array containing numbers whose mean is desired. If `a` is not an\n            array, a conversion is attempted.\n        axis (None or int or tuple of ints, optional):\n            Axis or axes along which the means are computed. The default is to\n            compute the mean of the flattened array.\n\n            .. numpy versionadded:: 1.7.0\n\n            If this is a tuple of ints, a mean is performed over multiple axes,\n            instead of a single axis or all the axes as before.\n        dtype (data-type, optional):\n            Type to use in computing the mean.  For integer inputs, the default\n            is `float64`; for floating point inputs, it is the same as the\n            input dtype.\n\n    Returns:\n        m (ndarray, see dtype parameter above):\n            If `out=None`, returns a new array containing the mean values,\n            otherwise a reference to the output array is returned.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        ret = np.nanmean(a, axis=axis, dtype=dtype)\n    return ret\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_nanstd","title":"<code>get_nanstd(a, axis=None, dtype=None)</code>","text":"<p>Same as np.nanstd but without printing warnings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array_like</code> <p>Calculate the standard deviation of these values.</p> required <code>axis</code> <code>None or int or tuple of ints</code> <p>Axis or axes along which the standard deviation is computed. The default is to compute the standard deviation of the flattened array.</p> <p>.. numpy versionadded:: 1.7.0</p> <p>If this is a tuple of ints, a standard deviation is performed over multiple axes, instead of a single axis or all the axes as before.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>Type to use in computing the standard deviation. For arrays of integer type the default is float64, for arrays of float types it is the same as the array type.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>standard_deviation</code> <code>ndarray, see dtype parameter above</code> <p>If <code>out</code> is None, return a new array containing the standard deviation, otherwise return a reference to the output array.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_nanstd(a, axis=None, dtype=None):\n    \"\"\"\n    Same as np.nanstd but without printing warnings.\n\n    Args:\n        a (array_like):\n            Calculate the standard deviation of these values.\n        axis (None or int or tuple of ints, optional):\n            Axis or axes along which the standard deviation is computed. The\n            default is to compute the standard deviation of the flattened array.\n\n            .. numpy versionadded:: 1.7.0\n\n            If this is a tuple of ints, a standard deviation is performed over\n            multiple axes, instead of a single axis or all the axes as before.\n        dtype (dtype, optional):\n            Type to use in computing the standard deviation. For arrays of\n            integer type the default is float64, for arrays of float types it is\n            the same as the array type.\n\n    Returns:\n        standard_deviation (ndarray, see dtype parameter above):\n            If `out` is None, return a new array containing the standard deviation,\n            otherwise return a reference to the output array.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        ret = np.nanstd(a, axis=axis, dtype=dtype)\n    return ret\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_population_power_spectrum","title":"<code>get_population_power_spectrum(spikes, time_step, t_start=None, t_end=None, fft_size=None)</code>","text":"<p>Generates power spectrum of population spikes, returns frequency_arr and power_spectrum_arr. Using the Welch methode from: Welch, P. (1967). The use of fast Fourier transform for the estimation of power spectra: a method based on time averaging over short, modified periodograms. IEEE Transactions on audio and electroacoustics, 15(2), 70-73.</p> <p>The spike arrays are splitted into multiple arrays and then multiple FFTs are performed and the results are averaged.</p> <p>Size of splitted signals and the time step of the simulation determine the frequency resolution and the maximum frequency:     maximum frequency [Hz] = 500 / time_step     frequency resolution [Hz] = 1000 / (time_step * fftSize)</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dicitonary</code> <p>ANNarchy spike dict of one population</p> required <code>time_step</code> <code>float</code> <p>time step of the simulation in ms</p> required <code>t_start</code> <code>float or int</code> <p>start time of analyzed data in ms. Default: time of first spike</p> <code>None</code> <code>t_end</code> <code>float or int</code> <p>end time of analyzed data in ms. Default: time of last spike</p> <code>None</code> <code>fft_size</code> <code>int</code> <p>signal size for the FFT (size of splitted arrays) has to be a power of 2. Default: maximum</p> <code>None</code> <p>Returns:</p> Name Type Description <code>frequency_arr</code> <code>array</code> <p>array with frequencies</p> <code>spectrum</code> <code>array</code> <p>array with power spectrum</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_population_power_spectrum(\n    spikes,\n    time_step,\n    t_start=None,\n    t_end=None,\n    fft_size=None,\n):\n    \"\"\"\n    Generates power spectrum of population spikes, returns frequency_arr and\n    power_spectrum_arr. Using the Welch methode from: Welch, P. (1967). The use of fast\n    Fourier transform for the estimation of power spectra: a method based on time\n    averaging over short, modified periodograms. IEEE Transactions on audio and\n    electroacoustics, 15(2), 70-73.\n\n    The spike arrays are splitted into multiple arrays and then multiple FFTs are\n    performed and the results are averaged.\n\n    Size of splitted signals and the time step of the simulation determine the frequency\n    resolution and the maximum frequency:\n        maximum frequency [Hz] = 500 / time_step\n        frequency resolution [Hz] = 1000 / (time_step * fftSize)\n\n    Args:\n        spikes (dicitonary):\n            ANNarchy spike dict of one population\n        time_step (float):\n            time step of the simulation in ms\n        t_start (float or int, optional):\n            start time of analyzed data in ms. Default: time of first spike\n        t_end (float or int, optional):\n            end time of analyzed data in ms. Default: time of last spike\n        fft_size (int, optional):\n            signal size for the FFT (size of splitted arrays)\n            has to be a power of 2. Default: maximum\n\n    Returns:\n        frequency_arr (array):\n            array with frequencies\n        spectrum (array):\n            array with power spectrum\n    \"\"\"\n\n    def ms_to_s(x):\n        return x / 1000\n\n    ### get population_size / sampling_frequency\n    populations_size = len(list(spikes.keys()))\n    sampling_frequency = 1 / ms_to_s(time_step)  # in Hz\n\n    ### check if there are spikes in data\n    t, _ = my_raster_plot(spikes)\n    if len(t) &lt; 2:\n        ### there are no 2 spikes\n        print(\"WARNING: get_population_power_spectrum: &lt;2 spikes!\")\n        ### --&gt; return None or zeros\n        if fft_size == None:\n            print(\n                \"ERROR: get_population_power_spectrum: &lt;2 spikes and no fft_size given!\"\n            )\n            quit()\n        else:\n            frequency_arr = np.fft.fftfreq(fft_size, 1.0 / sampling_frequency)\n            frequency_arr_ret = frequency_arr[2 : int(fft_size / 2)]\n            spectrum_ret = np.zeros(frequency_arr_ret.shape)\n            return [frequency_arr_ret, spectrum_ret]\n\n    ### check if t_start / t_end are None\n    if t_start == None:\n        t_start = round(t.min() * time_step, get_number_of_decimals(time_step))\n    if t_end == None:\n        t_end = round(t.max() * time_step, get_number_of_decimals(time_step))\n\n    ### calculate time\n    simulation_time = round(t_end - t_start, get_number_of_decimals(time_step))  # in ms\n\n    ### get fft_size\n    ### if None --&gt; as large as possible\n    if fft_size is None:\n        pow = 1\n        while (2 ** (pow + 1)) / sampling_frequency &lt; ms_to_s(simulation_time):\n            pow = pow + 1\n        fft_size = 2**pow\n\n    if ms_to_s(simulation_time) &lt; (fft_size / sampling_frequency):\n        ### catch a too large fft_size\n        print(\n            f\"Too large fft_size {fft_size} for duration {simulation_time} ms. FFT_size has to be smaller than {int(ms_to_s(simulation_time)*sampling_frequency)}!\"\n        )\n        return [np.zeros(int(fft_size / 2 - 2)), np.zeros(int(fft_size / 2 - 2))]\n    elif (np.log2(fft_size) - int(np.log2(fft_size))) != 0:\n        ### catch fft_size if its not power of 2\n        print(\"FFT_size hast to be power of 2!\")\n        return [np.zeros(int(fft_size / 2 - 2)), np.zeros(int(fft_size / 2 - 2))]\n    else:\n        print(\n            f\"power sepctrum, min = {1000 / (time_step * fft_size)}, max = {500 / time_step}\"\n        )\n        ### calculate frequency powers\n        spectrum = np.zeros((populations_size, fft_size))\n        for neuron in range(populations_size):\n            ### sampling steps array\n            spiketrain = np.zeros(\n                int(np.round(ms_to_s(simulation_time) * sampling_frequency))\n            )\n            ### spike times as sampling steps\n            idx = (\n                np.round(\n                    ms_to_s((np.array(spikes[neuron]) * time_step)) * sampling_frequency\n                )\n            ).astype(np.int32)\n            ### cut the spikes before t_start and after t_end\n            idx_start = ms_to_s(t_start) * sampling_frequency\n            idx_end = ms_to_s(t_end) * sampling_frequency\n            mask = ((idx &gt; idx_start).astype(int) * (idx &lt; idx_end).astype(int)).astype(\n                bool\n            )\n            idx = (idx[mask] - idx_start).astype(np.int32)\n\n            ### set spiketrain array to one if there was a spike at sampling step\n            spiketrain[idx] = 1\n\n            ### generate multiple overlapping sequences out of the spike trains\n            spiketrain_sequences = _hanning_split_overlap(\n                spiketrain, fft_size, int(fft_size / 2)\n            )\n\n            ### generate power spectrum\n            spectrum[neuron] = get_nanmean(\n                np.abs(np.fft.fft(spiketrain_sequences)) ** 2, 0\n            )\n\n        ### mean spectrum over all neurons\n        spectrum = get_nanmean(spectrum, 0)\n\n        frequency_arr = np.fft.fftfreq(fft_size, 1.0 / sampling_frequency)\n\n        return (frequency_arr[2 : int(fft_size / 2)], spectrum[2 : int(fft_size / 2)])\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_power_spektrum_from_time_array","title":"<code>get_power_spektrum_from_time_array(arr, presimulationTime, simulationTime, simulation_dt, samplingfrequency=250, fftSize=1024)</code>","text":"<p>Generates power spectrum of time signal (returns frequencies_arr and power_arr). Using the Welch methode (Welch,1967).</p> <p>amplingfrequency: to sample the arr, in Hz --&gt; max frequency = samplingfrequency / 2 fftSize: signal size for FFT, duration (in s) = fftSize / samplingfrequency --&gt; frequency resolution = samplingfrequency / fftSize</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>array</code> <p>time array, value for each timestep</p> required <code>presimulationTime</code> <code>float or int</code> <p>simulation time which will not be analyzed</p> required <code>simulationTime</code> <code>float or int</code> <p>analyzed simulation time</p> required <code>simulation_dt</code> <code>float or int</code> <p>simulation timestep</p> required <code>samplingfrequency</code> <code>float or int</code> <p>sampling frequency for sampling the time array. Default: 250</p> <code>250</code> <code>fftSize</code> <code>int</code> <p>signal size for the FFT (size of splitted arrays) has to be a power of 2. Default: 1024</p> <code>1024</code> <p>Returns:</p> Name Type Description <code>frequency_arr</code> <code>array</code> <p>array with frequencies</p> <code>spectrum</code> <code>array</code> <p>array with power spectrum</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_power_spektrum_from_time_array(\n    arr,\n    presimulationTime,\n    simulationTime,\n    simulation_dt,\n    samplingfrequency=250,\n    fftSize=1024,\n):\n    \"\"\"\n    Generates power spectrum of time signal (returns frequencies_arr and power_arr).\n    Using the Welch methode (Welch,1967).\n\n    amplingfrequency: to sample the arr, in Hz --&gt; max frequency = samplingfrequency / 2\n    fftSize: signal size for FFT, duration (in s) = fftSize / samplingfrequency\n    --&gt; frequency resolution = samplingfrequency / fftSize\n\n    Args:\n        arr (array):\n            time array, value for each timestep\n        presimulationTime (float or int):\n            simulation time which will not be analyzed\n        simulationTime (float or int):\n            analyzed simulation time\n        simulation_dt (float or int):\n            simulation timestep\n        samplingfrequency (float or int, optional):\n            sampling frequency for sampling the time array. Default: 250\n        fftSize (int, optional):\n            signal size for the FFT (size of splitted arrays)\n            has to be a power of 2. Default: 1024\n\n    Returns:\n        frequency_arr (array):\n            array with frequencies\n        spectrum (array):\n            array with power spectrum\n    \"\"\"\n\n    if (simulationTime / 1000) &lt; (fftSize / samplingfrequency):\n        print(\"Simulation time has to be &gt;=\", fftSize / samplingfrequency, \"s for FFT!\")\n        return [np.zeros(int(fftSize / 2 - 2)), np.zeros(int(fftSize / 2 - 2))]\n    else:\n        ### sampling steps array\n        sampling_arr = arr[0 :: int((1 / samplingfrequency) * 1000 / simulation_dt)]\n\n        ### generate multiple overlapping sequences\n        sampling_arr_sequences = _hanning_split_overlap(\n            sampling_arr, fftSize, int(fftSize / 2)\n        )\n\n        ### generate power spectrum\n        spektrum = get_nanmean(np.abs(np.fft.fft(sampling_arr_sequences)) ** 2, 0)\n\n        frequenzen = np.fft.fftfreq(fftSize, 1.0 / samplingfrequency)\n\n        return (frequenzen[2 : int(fftSize / 2)], spektrum[2 : int(fftSize / 2)])\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_pop_rate","title":"<code>get_pop_rate(spikes, t_start=None, t_end=None, time_step=1, t_smooth_ms=-1)</code>","text":"<p>Generates a smoothed population firing rate. Returns a time array and a firing rate array.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>dictionary</code> <p>ANNarchy spike dict of one population</p> required <code>t_start</code> <code>float or int</code> <p>start time of analyzed data in ms. Default: time of first spike</p> <code>None</code> <code>t_end</code> <code>float or int</code> <p>end time of analyzed data in ms. Default: time of last spike</p> <code>None</code> <code>time_step</code> <code>float or int</code> <p>time step of the simulation in ms. Default: 1</p> <code>1</code> <code>t_smooth_ms</code> <code>float or int</code> <p>time window for firing rate calculation in ms, if -1 --&gt; time window sizes are automatically detected. Default: -1</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>array with time steps in ms</p> <code>rate</code> <code>array</code> <p>array with population rate in Hz for each time step</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_pop_rate(\n    spikes: dict,\n    t_start: float | int | None = None,\n    t_end: float | int | None = None,\n    time_step: float | int = 1,\n    t_smooth_ms: float | int = -1,\n):\n    \"\"\"\n    Generates a smoothed population firing rate. Returns a time array and a firing rate\n    array.\n\n    Args:\n        spikes (dictionary):\n            ANNarchy spike dict of one population\n        t_start (float or int, optional):\n            start time of analyzed data in ms. Default: time of first spike\n        t_end (float or int, optional):\n            end time of analyzed data in ms. Default: time of last spike\n        time_step (float or int, optional):\n            time step of the simulation in ms. Default: 1\n        t_smooth_ms (float or int, optional):\n            time window for firing rate calculation in ms, if -1 --&gt; time window sizes\n            are automatically detected. Default: -1\n\n    Returns:\n        time_arr (array):\n            array with time steps in ms\n        rate (array):\n            array with population rate in Hz for each time step\n    \"\"\"\n    dt = time_step\n\n    t, _ = my_raster_plot(spikes)\n\n    ### check if there are spikes in population at all\n    if len(t) &gt; 1:\n        if t_start == None:\n            t_start = round(t.min() * time_step, get_number_of_decimals(time_step))\n        if t_end == None:\n            t_end = round(t.max() * time_step, get_number_of_decimals(time_step))\n\n        duration = round(t_end - t_start, get_number_of_decimals(time_step))\n\n        ### if t_smooth is given --&gt; use classic time_window method\n        if t_smooth_ms &gt; 0:\n            return _get_pop_rate_old(\n                spikes, duration, dt=dt, t_start=t_start, t_smooth_ms=t_smooth_ms\n            )\n        else:\n            ### concatenate all spike times and sort them\n            spike_arr = dt * np.sort(\n                np.concatenate(\n                    [np.array(spikes[neuron]).astype(int) for neuron in spikes.keys()]\n                )\n            )\n            nr_neurons = len(list(spikes.keys()))\n            nr_spikes = spike_arr.size\n\n            ### use _recursive_rate to get firing rate\n            ### spike array is splitted in time bins\n            ### time bins widths are automatically found\n            time_population_rate, population_rate = _recursive_rate(\n                spike_arr / 1000.0,\n                t0=t_start / 1000.0,\n                t1=(t_start + duration) / 1000.0,\n                duration_init=duration / 1000.0,\n                nr_neurons=nr_neurons,\n                nr_spikes=nr_spikes,\n            )\n            ### time_population_rate was returned in s --&gt; transform it into ms\n            time_population_rate = time_population_rate * 1000\n            time_arr0 = np.arange(t_start, t_start + duration, dt)\n            if len(time_population_rate) &gt; 1:\n                ### interpolate\n                interpolate_func = interp1d(\n                    time_population_rate,\n                    population_rate,\n                    kind=\"linear\",\n                    bounds_error=False,\n                    fill_value=(population_rate[0], population_rate[-1]),\n                )\n                population_rate_arr = interpolate_func(time_arr0)\n            else:\n                population_rate_arr = np.zeros(len(time_arr0))\n                mask = time_arr0 == time_population_rate[0]\n                population_rate_arr[mask] = population_rate[0]\n\n            ret = population_rate_arr\n    else:\n        if t_start == None or t_end == None:\n            return None\n        else:\n            duration = t_end - t_start\n            ret = np.zeros(int(duration / dt))\n\n    return (np.arange(t_start, t_start + duration, dt), ret)\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.plot_recordings","title":"<code>plot_recordings(figname, recordings, recording_times, chunk, shape, plan, time_lim=None, dpi=300)</code>","text":"<p>Plots the recordings of a single chunk from recordings. Plotted variables are specified in plan.</p> <p>Parameters:</p> Name Type Description Default <code>figname</code> <code>str</code> <p>path + name of figure (e.g. \"figures/my_figure.png\")</p> required <code>recordings</code> <code>list</code> <p>a recordings list from CompNeuroPy obtained with the function get_recordings() from a CompNeuroMonitors object.</p> required <code>recording_times</code> <code>object</code> <p>recording_times object from CompNeuroPy obtained with the function get_recording_times() from a CompNeuroMonitors object.</p> required <code>chunk</code> <code>int</code> <p>which chunk of recordings should be used (the index of chunk)</p> required <code>shape</code> <code>tuple</code> <p>Defines the subplot arrangement e.g. (3,2) = 3 rows, 2 columns</p> required <code>plan</code> <code>list of strings</code> <p>Defines which recordings are plotted in which subplot and how. Entries of the list have the structure:     \"subplot_nr;model_component_name;variable_to_plot;format\",     e.g. \"1,my_pop1;v;line\".     mode: defines how the data is plotted, available modes:         - for spike data: raster, mean, hybrid         - for other data: line, mean, matrix         - only for projection data: matrix_mean</p> required <code>time_lim</code> <code>tuple</code> <p>Defines the x-axis for all subplots. The list contains two numbers: start and end time in ms. The times have to be within the chunk. Default: None, i.e., time lims of chunk</p> <code>None</code> <code>dpi</code> <code>int</code> <p>The dpi of the saved figure. Default: 300</p> <code>300</code> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>@check_types()\ndef plot_recordings(\n    figname: str,\n    recordings: list,\n    recording_times: RecordingTimes,\n    chunk: int,\n    shape: tuple,\n    plan: list[str],\n    time_lim: None | tuple = None,\n    dpi: int = 300,\n):\n    \"\"\"\n    Plots the recordings of a single chunk from recordings. Plotted variables are\n    specified in plan.\n\n    Args:\n        figname (str):\n            path + name of figure (e.g. \"figures/my_figure.png\")\n        recordings (list):\n            a recordings list from CompNeuroPy obtained with the function\n            get_recordings() from a CompNeuroMonitors object.\n        recording_times (object):\n            recording_times object from CompNeuroPy obtained with the\n            function get_recording_times() from a CompNeuroMonitors object.\n        chunk (int):\n            which chunk of recordings should be used (the index of chunk)\n        shape (tuple):\n            Defines the subplot arrangement e.g. (3,2) = 3 rows, 2 columns\n        plan (list of strings):\n            Defines which recordings are plotted in which subplot and how.\n            Entries of the list have the structure:\n                \"subplot_nr;model_component_name;variable_to_plot;format\",\n                e.g. \"1,my_pop1;v;line\".\n                mode: defines how the data is plotted, available modes:\n                    - for spike data: raster, mean, hybrid\n                    - for other data: line, mean, matrix\n                    - only for projection data: matrix_mean\n        time_lim (tuple, optional):\n            Defines the x-axis for all subplots. The list contains two\n            numbers: start and end time in ms. The times have to be\n            within the chunk. Default: None, i.e., time lims of chunk\n        dpi (int, optional):\n            The dpi of the saved figure. Default: 300\n    \"\"\"\n    proc = Process(\n        target=_plot_recordings,\n        args=(figname, recordings, recording_times, chunk, shape, plan, time_lim, dpi),\n    )\n    proc.start()\n    proc.join()\n    if proc.exitcode != 0:\n        quit()\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_number_of_zero_decimals","title":"<code>get_number_of_zero_decimals(nr)</code>","text":"<p>For numbers which are smaller than zero get the number of digits after the decimal point which are zero (plus 1). For the number 0 or numbers &gt;=1 return zero, e.g.:</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>the number from which the number of digits are obtained</p> required <p>Returns:</p> Name Type Description <code>decimals</code> <code>int</code> <p>number of digits after the decimal point which are zero (plus 1)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_number_of_zero_decimals(0.12)\n1\n&gt;&gt;&gt; get_number_of_zero_decimals(0.012)\n2\n&gt;&gt;&gt; get_number_of_zero_decimals(1.012)\n0\n</code></pre> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_number_of_zero_decimals(nr):\n    \"\"\"\n    For numbers which are smaller than zero get the number of digits after the decimal\n    point which are zero (plus 1). For the number 0 or numbers &gt;=1 return zero, e.g.:\n\n    Args:\n        nr (float or int):\n            the number from which the number of digits are obtained\n\n    Returns:\n        decimals (int):\n            number of digits after the decimal point which are zero (plus 1)\n\n    Examples:\n        &gt;&gt;&gt; get_number_of_zero_decimals(0.12)\n        1\n        &gt;&gt;&gt; get_number_of_zero_decimals(0.012)\n        2\n        &gt;&gt;&gt; get_number_of_zero_decimals(1.012)\n        0\n    \"\"\"\n    decimals = 0\n    if nr != 0:\n        while abs(nr) &lt; 1:\n            nr = nr * 10\n            decimals = decimals + 1\n\n    return decimals\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_number_of_decimals","title":"<code>get_number_of_decimals(nr)</code>","text":"<p>Get number of digits after the decimal point.</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>the number from which the number of digits are obtained</p> required <p>Returns:</p> Name Type Description <code>decimals</code> <code>int</code> <p>number of digits after the decimal point</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_number_of_decimals(5)\n0\n&gt;&gt;&gt; get_number_of_decimals(5.1)\n1\n&gt;&gt;&gt; get_number_of_decimals(0.0101)\n4\n</code></pre> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_number_of_decimals(nr):\n    \"\"\"\n    Get number of digits after the decimal point.\n\n    Args:\n        nr (float or int):\n            the number from which the number of digits are obtained\n\n    Returns:\n        decimals (int):\n            number of digits after the decimal point\n\n    Examples:\n        &gt;&gt;&gt; get_number_of_decimals(5)\n        0\n        &gt;&gt;&gt; get_number_of_decimals(5.1)\n        1\n        &gt;&gt;&gt; get_number_of_decimals(0.0101)\n        4\n    \"\"\"\n\n    if nr != int(nr):\n        decimals = len(str(nr).split(\".\")[1])\n    else:\n        decimals = 0\n\n    return decimals\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.sample_data_with_timestep","title":"<code>sample_data_with_timestep(time_arr, data_arr, timestep)</code>","text":"<p>Samples a data array each timestep using interpolation</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>array</code> <p>array with data values from which will be sampled</p> required <code>timestep</code> <code>float or int</code> <p>timestep in ms for sampling</p> required <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>sampled time array</p> <code>data_arr</code> <code>array</code> <p>sampled data array</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def sample_data_with_timestep(time_arr, data_arr, timestep):\n    \"\"\"\n    Samples a data array each timestep using interpolation\n\n    Args:\n        time_arr (array):\n            times of data_arr in ms\n        data_arr (array):\n            array with data values from which will be sampled\n        timestep (float or int):\n            timestep in ms for sampling\n\n    Returns:\n        time_arr (array):\n            sampled time array\n        data_arr (array):\n            sampled data array\n    \"\"\"\n    interpolate_func = interp1d(\n        time_arr, data_arr, bounds_error=False, fill_value=\"extrapolate\"\n    )\n    min_time = round(\n        round(time_arr[0] / timestep, 0) * timestep,\n        get_number_of_decimals(timestep),\n    )\n    max_time = round(\n        round(time_arr[-1] / timestep, 0) * timestep,\n        get_number_of_decimals(timestep),\n    )\n    new_time_arr = np.arange(min_time, max_time + timestep, timestep)\n    new_data_arr = interpolate_func(new_time_arr)\n\n    return (new_time_arr, new_data_arr)\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.time_data_add_nan","title":"<code>time_data_add_nan(time_arr, data_arr, fill_time_step=None, axis=0)</code>","text":"<p>If there are gaps in time_arr --&gt; fill them with respective time values. Fill the corresponding data_arr values with nan.</p> <p>By default it is tried to fill the time array with continuously increasing times based on the smallest time difference found there can still be discontinuities after filling the arrays (because existing time values are not changed).</p> <p>But one can also give a fixed fill time step.</p> <p>Parameters:</p> Name Type Description Default <code>time_arr</code> <code>1D array</code> <p>times of data_arr in ms</p> required <code>data_arr</code> <code>nD array</code> <p>the size of the specified dimension of data array must have the same length as time_arr</p> required <code>fill_time_step</code> <code>number, optional, default=None</code> <p>if there are gaps they are filled with this time step</p> <code>None</code> <code>axis</code> <code>int</code> <p>which dimension of the data_arr belongs to the time_arr</p> <code>0</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>1D array</code> <p>time array with gaps filled</p> <code>data_arr</code> <code>nD array</code> <p>data array with gaps filled</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def time_data_add_nan(time_arr, data_arr, fill_time_step=None, axis=0):\n    \"\"\"\n    If there are gaps in time_arr --&gt; fill them with respective time values.\n    Fill the corresponding data_arr values with nan.\n\n    By default it is tried to fill the time array with continuously increasing times\n    based on the smallest time difference found there can still be discontinuities after\n    filling the arrays (because existing time values are not changed).\n\n    But one can also give a fixed fill time step.\n\n    Args:\n        time_arr (1D array):\n            times of data_arr in ms\n        data_arr (nD array):\n            the size of the specified dimension of data array must have the same length\n            as time_arr\n        fill_time_step (number, optional, default=None):\n            if there are gaps they are filled with this time step\n        axis (int):\n            which dimension of the data_arr belongs to the time_arr\n\n    Returns:\n        time_arr (1D array):\n            time array with gaps filled\n        data_arr (nD array):\n            data array with gaps filled\n    \"\"\"\n    time_arr = time_arr.astype(float)\n    data_arr = data_arr.astype(float)\n    data_arr_shape = data_arr.shape\n\n    if data_arr_shape[axis] != time_arr.size:\n        print(\n            \"ERROR time_data_add_nan: time_arr must have same length as specified axis (default=0) of data_arr!\"\n        )\n        quit()\n\n    ### find gaps\n    time_diff_arr = np.round(np.diff(time_arr), 6)\n    if isinstance(fill_time_step, type(None)):\n        time_diff_min = time_diff_arr.min()\n    else:\n        time_diff_min = fill_time_step\n    gaps_arr = time_diff_arr &gt; time_diff_min\n\n    ### split arrays at gaps\n    time_arr_split = np.split(\n        time_arr, indices_or_sections=np.where(gaps_arr)[0] + 1, axis=0\n    )\n    data_arr_split = np.split(\n        data_arr, indices_or_sections=np.where(gaps_arr)[0] + 1, axis=axis\n    )\n\n    ### fill gaps between splits\n    data_arr_append_shape = list(data_arr_shape)\n    for split_arr_idx in range(len(time_arr_split) - 1):\n        ### get gaps boundaries\n        current_end = time_arr_split[split_arr_idx][-1]\n        next_start = time_arr_split[split_arr_idx + 1][0]\n        ### create gap filling arrays\n        time_arr_append = np.arange(\n            current_end + time_diff_min, next_start, time_diff_min\n        )\n        data_arr_append_shape[axis] = time_arr_append.size\n        data_arr_append = np.zeros(tuple(data_arr_append_shape)) * np.nan\n        ### append gap filling arrays to splitted arrays\n        time_arr_split[split_arr_idx] = np.append(\n            arr=time_arr_split[split_arr_idx],\n            values=time_arr_append,\n            axis=0,\n        )\n        data_arr_split[split_arr_idx] = np.append(\n            arr=data_arr_split[split_arr_idx],\n            values=data_arr_append,\n            axis=axis,\n        )\n\n    ### combine splitted arrays again\n    time_arr = np.concatenate(time_arr_split, axis=0)\n    data_arr = np.concatenate(data_arr_split, axis=axis)\n\n    return (time_arr, data_arr)\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.rmse","title":"<code>rmse(a, b)</code>","text":"<p>Calculates the root-mean-square error between two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array</code> <p>first array</p> required <code>b</code> <code>array</code> <p>second array</p> required <p>Returns:</p> Name Type Description <code>rmse</code> <code>float</code> <p>root-mean-square error</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def rmse(a, b):\n    \"\"\"\n    Calculates the root-mean-square error between two arrays.\n\n    Args:\n        a (array):\n            first array\n        b (array):\n            second array\n\n    Returns:\n        rmse (float):\n            root-mean-square error\n    \"\"\"\n\n    return np.sqrt(np.mean((a - b) ** 2))\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.rsse","title":"<code>rsse(a, b)</code>","text":"<p>Calculates the root-sum-square error between two arrays.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>array</code> <p>first array</p> required <code>b</code> <code>array</code> <p>second array</p> required <p>Returns:</p> Name Type Description <code>rsse</code> <code>float</code> <p>root-sum-square error</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def rsse(a, b):\n    \"\"\"\n    Calculates the root-sum-square error between two arrays.\n\n    Args:\n        a (array):\n            first array\n        b (array):\n            second array\n\n    Returns:\n        rsse (float):\n            root-sum-square error\n    \"\"\"\n\n    return np.sqrt(np.sum((a - b) ** 2))\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_minimum","title":"<code>get_minimum(input_data)</code>","text":"<p>Returns the minimum of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>list, np.ndarray, tuple, or float</code> <p>The input data from which the minimum is to be obtained.</p> required <p>Returns:</p> Name Type Description <code>minimum</code> <code>float</code> <p>The minimum of the input data.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_minimum(input_data: list | np.ndarray | tuple | float):\n    \"\"\"\n    Returns the minimum of the input data.\n\n    Args:\n        input_data (list, np.ndarray, tuple, or float):\n            The input data from which the minimum is to be obtained.\n\n    Returns:\n        minimum (float):\n            The minimum of the input data.\n    \"\"\"\n    if isinstance(input_data, (list, np.ndarray, tuple)):\n        # If the input is a list, numpy array, or tuple, we handle them as follows\n        flattened_list = [\n            item\n            for sublist in input_data\n            for item in (\n                sublist if isinstance(sublist, (list, np.ndarray, tuple)) else [sublist]\n            )\n        ]\n        return float(min(flattened_list))\n    else:\n        # If the input is a single value, return it as the minimum\n        return float(input_data)\n</code></pre>"},{"location":"additional/analysis_functions/#CompNeuroPy.analysis_functions.get_maximum","title":"<code>get_maximum(input_data)</code>","text":"<p>Returns the maximum of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>list, np.ndarray, tuple, or float</code> <p>The input data from which the maximum is to be obtained.</p> required <p>Returns:</p> Name Type Description <code>maximum</code> <code>float</code> <p>The maximum of the input data.</p> Source code in <code>src/CompNeuroPy/analysis_functions.py</code> <pre><code>def get_maximum(input_data: list | np.ndarray | tuple | float):\n    \"\"\"\n    Returns the maximum of the input data.\n\n    Args:\n        input_data (list, np.ndarray, tuple, or float):\n            The input data from which the maximum is to be obtained.\n\n    Returns:\n        maximum (float):\n            The maximum of the input data.\n    \"\"\"\n\n    if isinstance(input_data, (list, np.ndarray, tuple)):\n        # If the input is a list, numpy array, or tuple, we handle them as follows\n        flattened_list = [\n            item\n            for sublist in input_data\n            for item in (\n                sublist if isinstance(sublist, (list, np.ndarray, tuple)) else [sublist]\n            )\n        ]\n        return float(max(flattened_list))\n    else:\n        # If the input is a single value, return it as the maximum\n        return float(input_data)\n</code></pre>"},{"location":"additional/extra_functions/","title":"Extra Functions","text":""},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.Cmap","title":"<code>Cmap</code>","text":"<p>Class to create a colormap with a given name and range. The colormap can be called with a value between 0 and 1 to get the corresponding rgb value.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class Cmap:\n    \"\"\"\n    Class to create a colormap with a given name and range. The colormap can be called\n    with a value between 0 and 1 to get the corresponding rgb value.\n    \"\"\"\n\n    def __init__(self, cmap_name, vmin, vmax):\n        \"\"\"\n        Args:\n            cmap_name (str):\n                Name of the colormap\n            vmin (float):\n                Lower limit of the colormap\n            vmax (float):\n                Upper limit of the colormap\n        \"\"\"\n        self.cmap_name = cmap_name\n        self.cmap = plt.get_cmap(cmap_name)\n        self.norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n        self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n\n    def __call__(self, x, alpha=1):\n        \"\"\"\n        Returns the rgba value of the colormap at the given value.\n\n        Args:\n            x (float):\n                Value between 0 and 1\n            alpha (float):\n                Alpha value of the rgba value\n\n        Returns:\n            rgba (tuple):\n                RGBA value of the colormap at the given value\n        \"\"\"\n        vals = self.get_rgb(x)\n        if isinstance(vals, tuple):\n            vals = vals[:3] + (alpha,)\n        else:\n            vals[:, -1] = alpha\n        return vals\n\n    def get_rgb(self, val):\n        \"\"\"\n        Returns the rgb value of the colormap at the given value.\n\n        Args:\n            val (float):\n                Value between 0 and 1\n\n        Returns:\n            rgb (tuple):\n                RGB value of the colormap at the given value\n        \"\"\"\n        return self.scalarMap.to_rgba(val)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.Cmap.__init__","title":"<code>__init__(cmap_name, vmin, vmax)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>cmap_name</code> <code>str</code> <p>Name of the colormap</p> required <code>vmin</code> <code>float</code> <p>Lower limit of the colormap</p> required <code>vmax</code> <code>float</code> <p>Upper limit of the colormap</p> required Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self, cmap_name, vmin, vmax):\n    \"\"\"\n    Args:\n        cmap_name (str):\n            Name of the colormap\n        vmin (float):\n            Lower limit of the colormap\n        vmax (float):\n            Upper limit of the colormap\n    \"\"\"\n    self.cmap_name = cmap_name\n    self.cmap = plt.get_cmap(cmap_name)\n    self.norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n    self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.Cmap.__call__","title":"<code>__call__(x, alpha=1)</code>","text":"<p>Returns the rgba value of the colormap at the given value.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>Value between 0 and 1</p> required <code>alpha</code> <code>float</code> <p>Alpha value of the rgba value</p> <code>1</code> <p>Returns:</p> Name Type Description <code>rgba</code> <code>tuple</code> <p>RGBA value of the colormap at the given value</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __call__(self, x, alpha=1):\n    \"\"\"\n    Returns the rgba value of the colormap at the given value.\n\n    Args:\n        x (float):\n            Value between 0 and 1\n        alpha (float):\n            Alpha value of the rgba value\n\n    Returns:\n        rgba (tuple):\n            RGBA value of the colormap at the given value\n    \"\"\"\n    vals = self.get_rgb(x)\n    if isinstance(vals, tuple):\n        vals = vals[:3] + (alpha,)\n    else:\n        vals[:, -1] = alpha\n    return vals\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.Cmap.get_rgb","title":"<code>get_rgb(val)</code>","text":"<p>Returns the rgb value of the colormap at the given value.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>float</code> <p>Value between 0 and 1</p> required <p>Returns:</p> Name Type Description <code>rgb</code> <code>tuple</code> <p>RGB value of the colormap at the given value</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_rgb(self, val):\n    \"\"\"\n    Returns the rgb value of the colormap at the given value.\n\n    Args:\n        val (float):\n            Value between 0 and 1\n\n    Returns:\n        rgb (tuple):\n            RGB value of the colormap at the given value\n    \"\"\"\n    return self.scalarMap.to_rgba(val)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTree","title":"<code>DecisionTree</code>","text":"<p>Class to create a decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class DecisionTree:\n    \"\"\"\n    Class to create a decision tree.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Create a new empty decision tree.\n        \"\"\"\n        ### node list is a list of lists\n        ### first idx = level of tree\n        ### second idx = all nodes in the level\n        self.node_list = [[]]\n\n    def node(self, parent=None, prob=0, name=None):\n        \"\"\"\n        Create a new node in the decision tree.\n\n        Args:\n            parent (node object):\n                Parent node of the new node\n            prob (float):\n                Probability of the new node\n            name (str):\n                Name of the new node\n\n        Returns:\n            new_node (node object):\n                The new node\n        \"\"\"\n\n        ### create new node\n        new_node = DecisionTreeNode(tree=self, parent=parent, prob=prob, name=name)\n        ### add it to node_list\n        if len(self.node_list) == new_node.level:\n            self.node_list.append([])\n        self.node_list[new_node.level].append(new_node)\n        ### return the node object\n        return new_node\n\n    def get_path_prod(self, name):\n        \"\"\"\n        Get the path and path product of a node with a given name.\n\n        Args:\n            name (str):\n                Name of the node\n\n        Returns:\n            path (str):\n                Path to the node\n            path_prod (float):\n                Path product of the node\n        \"\"\"\n\n        ### search for all nodes with name\n        ### start from behind\n        search_node_list = []\n        path_list = []\n        path_prod_list = []\n        for level in range(len(self.node_list) - 1, -1, -1):\n            for node in self.node_list[level]:\n                if node.name == name:\n                    search_node_list.append(node)\n        ### get the paths and path products for the found nodes\n        for node in search_node_list:\n            path, path_prod = self._get_path_prod_rec(node)\n            path_list.append(path)\n            path_prod_list.append(path_prod)\n        ### return the paths and path products\n        return [\n            [path_list[idx], path_prod_list[idx]]\n            for idx in range(len(search_node_list))\n        ]\n\n    def _get_path_prod_rec(self, node):\n        \"\"\"\n        Recursive function to get the path and path product of a node.\n\n        Args:\n            node (node object):\n                Node to get the path and path product of\n\n        Returns:\n            path_str (str):\n                Path to the node\n            prob (float):\n                Path product of the node\n        \"\"\"\n        node: DecisionTreeNode = node\n\n        if node.parent == None:\n            return [\"/\" + node.name, node.prob]\n        else:\n            path_str, prob = self._get_path_prod_rec(node.parent)\n            return [path_str + \"/\" + node.name, prob * node.prob]\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTree.__init__","title":"<code>__init__()</code>","text":"<p>Create a new empty decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Create a new empty decision tree.\n    \"\"\"\n    ### node list is a list of lists\n    ### first idx = level of tree\n    ### second idx = all nodes in the level\n    self.node_list = [[]]\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTree.node","title":"<code>node(parent=None, prob=0, name=None)</code>","text":"<p>Create a new node in the decision tree.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>node object</code> <p>Parent node of the new node</p> <code>None</code> <code>prob</code> <code>float</code> <p>Probability of the new node</p> <code>0</code> <code>name</code> <code>str</code> <p>Name of the new node</p> <code>None</code> <p>Returns:</p> Name Type Description <code>new_node</code> <code>node object</code> <p>The new node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def node(self, parent=None, prob=0, name=None):\n    \"\"\"\n    Create a new node in the decision tree.\n\n    Args:\n        parent (node object):\n            Parent node of the new node\n        prob (float):\n            Probability of the new node\n        name (str):\n            Name of the new node\n\n    Returns:\n        new_node (node object):\n            The new node\n    \"\"\"\n\n    ### create new node\n    new_node = DecisionTreeNode(tree=self, parent=parent, prob=prob, name=name)\n    ### add it to node_list\n    if len(self.node_list) == new_node.level:\n        self.node_list.append([])\n    self.node_list[new_node.level].append(new_node)\n    ### return the node object\n    return new_node\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTree.get_path_prod","title":"<code>get_path_prod(name)</code>","text":"<p>Get the path and path product of a node with a given name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the node</p> required <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>Path to the node</p> <code>path_prod</code> <code>float</code> <p>Path product of the node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_path_prod(self, name):\n    \"\"\"\n    Get the path and path product of a node with a given name.\n\n    Args:\n        name (str):\n            Name of the node\n\n    Returns:\n        path (str):\n            Path to the node\n        path_prod (float):\n            Path product of the node\n    \"\"\"\n\n    ### search for all nodes with name\n    ### start from behind\n    search_node_list = []\n    path_list = []\n    path_prod_list = []\n    for level in range(len(self.node_list) - 1, -1, -1):\n        for node in self.node_list[level]:\n            if node.name == name:\n                search_node_list.append(node)\n    ### get the paths and path products for the found nodes\n    for node in search_node_list:\n        path, path_prod = self._get_path_prod_rec(node)\n        path_list.append(path)\n        path_prod_list.append(path_prod)\n    ### return the paths and path products\n    return [\n        [path_list[idx], path_prod_list[idx]]\n        for idx in range(len(search_node_list))\n    ]\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTreeNode","title":"<code>DecisionTreeNode</code>","text":"<p>Class to create a node in a decision tree.</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>class DecisionTreeNode:\n    \"\"\"\n    Class to create a node in a decision tree.\n    \"\"\"\n\n    id_counter = 0\n\n    def __init__(self, tree: DecisionTree, parent=None, prob=0, name=\"\"):\n        \"\"\"\n        Create a new node in a decision tree.\n\n        Args:\n            tree (DecisionTree object):\n                Decision tree the node belongs to\n            parent (node object):\n                Parent node of the new node\n            prob (float):\n                Probability of the new node\n            name (str):\n                Name of the new node\n        \"\"\"\n        self.tree = tree\n        parent: DecisionTreeNode = parent\n        self.parent = parent\n        self.prob = prob\n        self.name = name\n        self.id = int(self.id_counter)\n        self.id_counter += 1\n        if parent != None:\n            self.level = int(parent.level + 1)\n        else:\n            self.level = int(0)\n\n    def add(self, name, prob):\n        \"\"\"\n        Add a child node to the node.\n\n        Args:\n            name (str):\n                Name of the new node\n            prob (float):\n                Probability of the new node\n\n        Returns:\n            new_node (node object):\n                The new node\n        \"\"\"\n\n        return self.tree.node(parent=self, prob=prob, name=name)\n\n    def get_path_prod(self):\n        \"\"\"\n        Get the path and path product of the node.\n\n        Returns:\n            path (str):\n                Path to the node\n            path_prod (float):\n                Path product of the node\n        \"\"\"\n        return self.tree._get_path_prod_rec(self)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTreeNode.__init__","title":"<code>__init__(tree, parent=None, prob=0, name='')</code>","text":"<p>Create a new node in a decision tree.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>DecisionTree object</code> <p>Decision tree the node belongs to</p> required <code>parent</code> <code>node object</code> <p>Parent node of the new node</p> <code>None</code> <code>prob</code> <code>float</code> <p>Probability of the new node</p> <code>0</code> <code>name</code> <code>str</code> <p>Name of the new node</p> <code>''</code> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def __init__(self, tree: DecisionTree, parent=None, prob=0, name=\"\"):\n    \"\"\"\n    Create a new node in a decision tree.\n\n    Args:\n        tree (DecisionTree object):\n            Decision tree the node belongs to\n        parent (node object):\n            Parent node of the new node\n        prob (float):\n            Probability of the new node\n        name (str):\n            Name of the new node\n    \"\"\"\n    self.tree = tree\n    parent: DecisionTreeNode = parent\n    self.parent = parent\n    self.prob = prob\n    self.name = name\n    self.id = int(self.id_counter)\n    self.id_counter += 1\n    if parent != None:\n        self.level = int(parent.level + 1)\n    else:\n        self.level = int(0)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTreeNode.add","title":"<code>add(name, prob)</code>","text":"<p>Add a child node to the node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the new node</p> required <code>prob</code> <code>float</code> <p>Probability of the new node</p> required <p>Returns:</p> Name Type Description <code>new_node</code> <code>node object</code> <p>The new node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def add(self, name, prob):\n    \"\"\"\n    Add a child node to the node.\n\n    Args:\n        name (str):\n            Name of the new node\n        prob (float):\n            Probability of the new node\n\n    Returns:\n        new_node (node object):\n            The new node\n    \"\"\"\n\n    return self.tree.node(parent=self, prob=prob, name=name)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.DecisionTreeNode.get_path_prod","title":"<code>get_path_prod()</code>","text":"<p>Get the path and path product of the node.</p> <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>Path to the node</p> <code>path_prod</code> <code>float</code> <p>Path product of the node</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def get_path_prod(self):\n    \"\"\"\n    Get the path and path product of the node.\n\n    Returns:\n        path (str):\n            Path to the node\n        path_prod (float):\n            Path product of the node\n    \"\"\"\n    return self.tree._get_path_prod_rec(self)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.print_df","title":"<code>print_df(df)</code>","text":"<p>Prints the complete dataframe df</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas dataframe</code> <p>Dataframe to be printed</p> required Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def print_df(df):\n    \"\"\"\n    Prints the complete dataframe df\n\n    Args:\n        df (pandas dataframe):\n            Dataframe to be printed\n    \"\"\"\n    with pd.option_context(\n        \"display.max_rows\", None\n    ):  # more options can be specified also\n        print(df)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.flatten_list","title":"<code>flatten_list(lst)</code>","text":"<p>Retuns flattened list</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <code>list of lists or mixed</code> <p>values and lists): List to be flattened</p> required <p>Returns:</p> Name Type Description <code>new_list</code> <code>list</code> <p>Flattened list</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def flatten_list(lst):\n    \"\"\"\n    Retuns flattened list\n\n    Args:\n        lst (list of lists or mixed: values and lists):\n            List to be flattened\n\n    Returns:\n        new_list (list):\n            Flattened list\n    \"\"\"\n\n    ### if lists in lst --&gt; upack them and retunr flatten_list of new list\n    new_lst = []\n    list_in_lst = False\n    for val in lst:\n        if isinstance(val, list):\n            list_in_lst = True\n            for sub_val in val:\n                new_lst.append(sub_val)\n        else:\n            new_lst.append(val)\n\n    if list_in_lst:\n        return flatten_list(new_lst)\n    ### else return lst\n    else:\n        return lst\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.remove_key","title":"<code>remove_key(d, key)</code>","text":"<p>Removes an element from a dict, returns the new dict</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>Dict to be modified</p> required <code>key</code> <code>str</code> <p>Key to be removed</p> required <p>Returns:</p> Name Type Description <code>r</code> <code>dict</code> <p>Modified dict</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def remove_key(d, key):\n    \"\"\"\n    Removes an element from a dict, returns the new dict\n\n    Args:\n        d (dict):\n            Dict to be modified\n        key (str):\n            Key to be removed\n\n    Returns:\n        r (dict):\n            Modified dict\n    \"\"\"\n    r = dict(d)\n    del r[key]\n    return r\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.suppress_stdout","title":"<code>suppress_stdout()</code>","text":"<p>Suppresses the print output of a function</p> <p>Examples:</p> <pre><code>with suppress_stdout():\n    print(\"this will not be printed\")\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>@contextmanager\ndef suppress_stdout():\n    \"\"\"\n    Suppresses the print output of a function\n\n    Examples:\n        ```python\n        with suppress_stdout():\n            print(\"this will not be printed\")\n        ```\n    \"\"\"\n    with open(os.devnull, \"w\") as devnull:\n        old_stdout = sys.stdout\n        sys.stdout = devnull\n        try:\n            yield\n        finally:\n            sys.stdout = old_stdout\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.sci","title":"<code>sci(nr)</code>","text":"<p>Rounds a number to a single decimal. If number is smaller than 0 it is converted to scientific notation with 1 decimal.</p> <p>Parameters:</p> Name Type Description Default <code>nr</code> <code>float or int</code> <p>Number to be converted</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>String of the number in scientific notation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sci(0.0001)\n'1.0e-4'\n&gt;&gt;&gt; sci(1.77)\n'1.8'\n&gt;&gt;&gt; sci(1.77e-5)\n'1.8e-5'\n&gt;&gt;&gt; sci(177.22)\n'177.2'\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def sci(nr):\n    \"\"\"\n    Rounds a number to a single decimal.\n    If number is smaller than 0 it is converted to scientific notation with 1 decimal.\n\n    Args:\n        nr (float or int):\n            Number to be converted\n\n    Returns:\n        str (str):\n            String of the number in scientific notation\n\n    Examples:\n        &gt;&gt;&gt; sci(0.0001)\n        '1.0e-4'\n        &gt;&gt;&gt; sci(1.77)\n        '1.8'\n        &gt;&gt;&gt; sci(1.77e-5)\n        '1.8e-5'\n        &gt;&gt;&gt; sci(177.22)\n        '177.2'\n    \"\"\"\n    if af.get_number_of_zero_decimals(nr) == 0:\n        return str(round(nr, 1))\n    else:\n        return f\"{nr*10**af.get_number_of_zero_decimals(nr):.1f}e-{af.get_number_of_zero_decimals(nr)}\"\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.create_cm","title":"<code>create_cm(colors, name='my_cmap', N=256, gamma=1.0, vmin=0, vmax=1)</code>","text":"<p>Create a <code>LinearSegmentedColormap</code> from a list of colors.</p> <p>Parameters:</p> Name Type Description Default <code>colors</code> <code>array-like of colors or array-like of (value, color</code> <p>If only colors are given, they are equidistantly mapped from the range :math:<code>[0, 1]</code>; i.e. 0 maps to <code>colors[0]</code> and 1 maps to <code>colors[-1]</code>. If (value, color) pairs are given, the mapping is from value to color. This can be used to divide the range unevenly.</p> required <code>name</code> <code>str</code> <p>The name of the colormap, by default 'my_cmap'.</p> <code>'my_cmap'</code> <code>N</code> <code>int</code> <p>The number of rgb quantization levels, by default 256.</p> <code>256</code> <code>gamma</code> <code>float</code> <p>Gamma correction value, by default 1.0.</p> <code>1.0</code> <code>vmin</code> <code>float</code> <p>The minimum value of the colormap, by default 0.</p> <code>0</code> <code>vmax</code> <code>float</code> <p>The maximum value of the colormap, by default 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>linear_colormap</code> <code>_LinearColormapClass</code> <p>The colormap object</p> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def create_cm(colors, name=\"my_cmap\", N=256, gamma=1.0, vmin=0, vmax=1):\n    \"\"\"\n    Create a `LinearSegmentedColormap` from a list of colors.\n\n    Args:\n        colors (array-like of colors or array-like of (value, color)):\n            If only colors are given, they are equidistantly mapped from the\n            range :math:`[0, 1]`; i.e. 0 maps to ``colors[0]`` and 1 maps to\n            ``colors[-1]``.\n            If (value, color) pairs are given, the mapping is from *value*\n            to *color*. This can be used to divide the range unevenly.\n        name (str, optional):\n            The name of the colormap, by default 'my_cmap'.\n        N (int, optional):\n            The number of rgb quantization levels, by default 256.\n        gamma (float, optional):\n            Gamma correction value, by default 1.0.\n        vmin (float, optional):\n            The minimum value of the colormap, by default 0.\n        vmax (float, optional):\n            The maximum value of the colormap, by default 1.\n\n    Returns:\n        linear_colormap (_LinearColormapClass):\n            The colormap object\n    \"\"\"\n    if not np.iterable(colors):\n        raise ValueError(\"colors must be iterable\")\n\n    if (\n        isinstance(colors[0], Sized)\n        and len(colors[0]) == 2\n        and not isinstance(colors[0], str)\n    ):\n        # List of value, color pairs\n        vals, colors = zip(*colors)\n        vals = np.array(vals).astype(float)\n        colors = list(colors)\n        ### insert values for 0 and 1 if not given\n        ### they equal the colors of the borders of the given range\n        if vals.min() != 0.0:\n            colors = [colors[np.argmin(vals)]] + colors\n            vals = np.insert(vals, 0, 0.0)\n        if vals.max() != 1.0:\n            colors = colors + [colors[np.argmax(vals)]]\n            vals = np.insert(vals, len(vals), 1.0)\n    else:\n        vals = np.linspace(0, 1, len(colors))\n\n    ### sort values and colors, they have to increase\n    sort_idx = np.argsort(vals)\n    vals = vals[sort_idx]\n    colors = [colors[idx] for idx in sort_idx]\n\n    r_g_b_a = np.zeros((len(colors), 4))\n    for color_idx, color in enumerate(colors):\n        if isinstance(color, str):\n            ### color given by name\n            r_g_b_a[color_idx] = to_rgba_array(color)\n        else:\n            ### color given by rgb(maybe a) value\n            color = np.array(color).astype(float)\n            ### check color size\n            if len(color) != 3 and len(color) != 4:\n                raise ValueError(\n                    \"colors must be names or consist of 3 (rgb) or 4 (rgba) numbers\"\n                )\n            if color.max() &gt; 1:\n                ### assume that max value is 255\n                color[:3] = color[:3] / 255\n            if len(color) == 4:\n                ### gamma already given\n                r_g_b_a[color_idx] = color\n            else:\n                ### add gamma\n                r_g_b_a[color_idx] = np.concatenate([color, np.array([gamma])])\n    r = r_g_b_a[:, 0]\n    g = r_g_b_a[:, 1]\n    b = r_g_b_a[:, 2]\n    a = r_g_b_a[:, 3]\n\n    cdict = {\n        \"red\": np.column_stack([vals, r, r]),\n        \"green\": np.column_stack([vals, g, g]),\n        \"blue\": np.column_stack([vals, b, b]),\n        \"alpha\": np.column_stack([vals, a, a]),\n    }\n\n    return _LinearColormapClass(name, cdict, N, gamma, vmin, vmax)\n</code></pre>"},{"location":"additional/extra_functions/#CompNeuroPy.extra_functions.evaluate_expression_with_dict","title":"<code>evaluate_expression_with_dict(expression, value_dict)</code>","text":"<p>Evaluate a mathematical expression using values from a dictionary.</p> <p>This function takes a mathematical expression as a string and a dictionary containing variable names as keys and corresponding values as numpy arrays. It replaces the variable names in the expression with their corresponding values from the dictionary and evaluates the expression.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <code>str</code> <p>A mathematical expression to be evaluated. Variable names in the expression should match the keys in the value_dict.</p> required <code>value_dict</code> <code>dict</code> <p>A dictionary containing variable names (strings) as keys and corresponding numpy arrays or numbers as values.</p> required <p>Returns:</p> Name Type Description <code>result</code> <code>value or array</code> <p>The result of evaluating the expression using the provided values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; my_dict = {\"a\": np.ones(10), \"b\": np.arange(10)}\n&gt;&gt;&gt; my_string = \"a*2-b+10\"\n&gt;&gt;&gt; evaluate_expression_with_dict(my_string, my_dict)\narray([12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.])\n</code></pre> Source code in <code>src/CompNeuroPy/extra_functions.py</code> <pre><code>def evaluate_expression_with_dict(expression, value_dict):\n    \"\"\"\n    Evaluate a mathematical expression using values from a dictionary.\n\n    This function takes a mathematical expression as a string and a dictionary\n    containing variable names as keys and corresponding values as numpy arrays.\n    It replaces the variable names in the expression with their corresponding\n    values from the dictionary and evaluates the expression.\n\n    Args:\n        expression (str):\n            A mathematical expression to be evaluated. Variable\n            names in the expression should match the keys in the value_dict.\n        value_dict (dict):\n            A dictionary containing variable names (strings) as\n            keys and corresponding numpy arrays or numbers as values.\n\n    Returns:\n        result (value or array):\n            The result of evaluating the expression using the provided values.\n\n    Examples:\n        &gt;&gt;&gt; my_dict = {\"a\": np.ones(10), \"b\": np.arange(10)}\n        &gt;&gt;&gt; my_string = \"a*2-b+10\"\n        &gt;&gt;&gt; evaluate_expression_with_dict(my_string, my_dict)\n        array([12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.])\n    \"\"\"\n    # Replace dictionary keys in the expression with their corresponding values\n    ### replace names with dict entries\n    expression = _replace_names_with_dict(\n        expression=expression, name_of_dict=\"value_dict\", dictionary=value_dict\n    )\n\n    ### evaluate the new expression\n    try:\n        result = eval(expression)\n        return result\n    except Exception as e:\n        raise ValueError(f\"Error while evaluating expression: {str(e)}\")\n</code></pre>"},{"location":"additional/model_functions/","title":"Model Functions","text":""},{"location":"additional/model_functions/#CompNeuroPy.model_functions.compile_in_folder","title":"<code>compile_in_folder(folder_name, net=None, clean=False, silent=False)</code>","text":"<p>Creates the compilation folder in annarchy_folders/ or uses existing ones. Compiles the current network.</p> <p>Parameters:</p> Name Type Description Default <code>folder_name</code> <code>str</code> <p>Name of the folder within annarchy_folders/</p> required <code>net</code> <code>ANNarchy network</code> <p>ANNarchy network. Default: None.</p> <code>None</code> <code>clean</code> <code>bool</code> <p>If True, the library is recompiled entirely, else only the changes since last compilation are compiled. Default: False.</p> <code>False</code> <code>silent</code> <code>bool</code> <p>Suppress output. Defaults to False.</p> <code>False</code> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def compile_in_folder(folder_name, net=None, clean=False, silent=False):\n    \"\"\"\n    Creates the compilation folder in annarchy_folders/ or uses existing ones. Compiles\n    the current network.\n\n    Args:\n        folder_name (str):\n            Name of the folder within annarchy_folders/\n        net (ANNarchy network, optional):\n            ANNarchy network. Default: None.\n        clean (bool, optional):\n            If True, the library is recompiled entirely, else only the changes since\n            last compilation are compiled. Default: False.\n        silent (bool, optional):\n            Suppress output. Defaults to False.\n    \"\"\"\n    sf.create_dir(\"annarchy_folders/\" + folder_name, print_info=False)\n    if isinstance(net, type(None)):\n        compile(\"annarchy_folders/\" + folder_name, clean=clean, silent=silent)\n    else:\n        net.compile(\"annarchy_folders/\" + folder_name, clean=clean, silent=silent)\n    if os.getcwd().split(\"/\")[-1] == \"annarchy_folders\":\n        os.chdir(\"../\")\n</code></pre>"},{"location":"additional/model_functions/#CompNeuroPy.model_functions.get_full_model","title":"<code>get_full_model()</code>","text":"<p>Return all current population and projection names.</p> <p>Returns:</p> Name Type Description <code>model_dict</code> <code>dict</code> <p>Dictionary with keys \"populations\" and \"projections\" and values lists of population and projection names, respectively.</p> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def get_full_model():\n    \"\"\"\n    Return all current population and projection names.\n\n    Returns:\n        model_dict (dict):\n            Dictionary with keys \"populations\" and \"projections\" and values lists of\n            population and projection names, respectively.\n    \"\"\"\n    return {\n        \"populations\": [pop.name for pop in populations()],\n        \"projections\": [proj.name for proj in projections()],\n    }\n</code></pre>"},{"location":"additional/model_functions/#CompNeuroPy.model_functions.cnp_clear","title":"<code>cnp_clear(functions=True, neurons=True, synapses=True, constants=True)</code>","text":"<p>Like clear with ANNarchy, but CompNeuroModel objects are also cleared.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>bool</code> <p>If True, all functions are cleared. Default: True.</p> <code>True</code> <code>neurons</code> <code>bool</code> <p>If True, all neurons are cleared. Default: True.</p> <code>True</code> <code>synapses</code> <code>bool</code> <p>If True, all synapses are cleared. Default: True.</p> <code>True</code> <code>constants</code> <code>bool</code> <p>If True, all constants are cleared. Default: True.</p> <code>True</code> Source code in <code>src/CompNeuroPy/model_functions.py</code> <pre><code>def cnp_clear(functions=True, neurons=True, synapses=True, constants=True):\n    \"\"\"\n    Like clear with ANNarchy, but CompNeuroModel objects are also cleared.\n\n    Args:\n        functions (bool, optional):\n            If True, all functions are cleared. Default: True.\n        neurons (bool, optional):\n            If True, all neurons are cleared. Default: True.\n        synapses (bool, optional):\n            If True, all synapses are cleared. Default: True.\n        constants (bool, optional):\n            If True, all constants are cleared. Default: True.\n    \"\"\"\n    clear(functions=functions, neurons=neurons, synapses=synapses, constants=constants)\n    for model_name in CompNeuroModel.initialized_models.keys():\n        CompNeuroModel.initialized_models[model_name] = False\n    for model_name in CompNeuroModel.compiled_models.keys():\n        CompNeuroModel.compiled_models[model_name] = False\n</code></pre>"},{"location":"additional/simulation_functions/","title":"Simulation Functions","text":""},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.current_step","title":"<code>current_step(pop, t1=500, t2=500, a1=0, a2=100)</code>","text":"<p>Stimulates a given population in two periods with two input currents.</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>t1</code> <code>int</code> <p>time in ms before current step</p> <code>500</code> <code>t2</code> <code>int</code> <p>time in ms after current step</p> <code>500</code> <code>a1</code> <code>int</code> <p>current amplitude before current step</p> <code>0</code> <code>a2</code> <code>int</code> <p>current amplitude after current step</p> <code>100</code> <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>duration (int): duration of the simulation</li> </ul> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_step(pop, t1=500, t2=500, a1=0, a2=100):\n    \"\"\"\n    Stimulates a given population in two periods with two input currents.\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        t1 (int):\n            time in ms before current step\n        t2 (int):\n            time in ms after current step\n        a1 (int):\n            current amplitude before current step\n        a2 (int):\n            current amplitude after current step\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - duration (int): duration of the simulation\n    \"\"\"\n\n    ### save prev input current\n    I_prev = get_population(pop).I_app\n\n    ### first/pre current step simulation\n    get_population(pop).I_app = a1\n    simulate(t1)\n\n    ### second/post current step simulation\n    get_population(pop).I_app = a2\n    simulate(t2)\n\n    ### reset input current to previous value\n    get_population(pop).I_app = I_prev\n\n    ### return some additional information which could be usefull\n    return {\"duration\": t1 + t2}\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.current_stim","title":"<code>current_stim(pop, t=500, a=100)</code>","text":"<p>Stimulates a given population during specified period 't' with input current with amplitude 'a', after this stimulation the current is reset to initial value (before stimulation).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>t</code> <code>int</code> <p>duration in ms</p> <code>500</code> <code>a</code> <code>int</code> <p>current amplitude</p> <code>100</code> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_stim(pop, t=500, a=100):\n    \"\"\"\n    Stimulates a given population during specified period 't' with input current with\n    amplitude 'a', after this stimulation the current is reset to initial value\n    (before stimulation).\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        t (int):\n            duration in ms\n        a (int):\n            current amplitude\n    \"\"\"\n\n    return current_step(pop, t1=t, t2=0, a1=a, a2=0)\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.current_ramp","title":"<code>current_ramp(pop, a0, a1, dur, n)</code>","text":"<p>Conducts multiple current stimulations with constantly changing current inputs. After this current_ramp stimulation the current amplitude is reset to the initial value (before current ramp).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>a0</code> <code>int</code> <p>initial current amplitude (of first stimulation)</p> required <code>a1</code> <code>int</code> <p>final current amplitude (of last stimulation)</p> required <code>dur</code> <code>int</code> <p>duration of the complete current ramp (all stimulations)</p> required <code>n</code> <code>int</code> <p>number of stimulations</p> required <p>Warning</p> <p>dur/n should be divisible by the simulation time step without remainder</p> <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>da (int): current step size</li> <li>dur_stim (int): duration of one stimulation</li> </ul> <p>Raises:</p> Type Description <code>AssertionError</code> <p>if resulting duration of one stimulation is not divisible by the simulation time step without remainder</p> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def current_ramp(pop, a0, a1, dur, n):\n    \"\"\"\n    Conducts multiple current stimulations with constantly changing current inputs.\n    After this current_ramp stimulation the current amplitude is reset to the initial\n    value (before current ramp).\n\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        a0 (int):\n            initial current amplitude (of first stimulation)\n        a1 (int):\n            final current amplitude (of last stimulation)\n        dur (int):\n            duration of the complete current ramp (all stimulations)\n        n (int):\n            number of stimulations\n\n    !!! warning\n        dur/n should be divisible by the simulation time step without remainder\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - da (int): current step size\n            - dur_stim (int): duration of one stimulation\n\n    Raises:\n        AssertionError: if resulting duration of one stimulation is not divisible by the\n            simulation time step without remainder\n    \"\"\"\n\n    assert (dur / n) / dt() % 1 == 0, (\n        \"ERROR current_ramp: dur/n should result in a duration (for a single stimulation) which is divisible by the simulation time step (without remainder)\\ncurrent duration = \"\n        + str(dur / n)\n        + \", timestep = \"\n        + str(dt())\n        + \"!\\n\"\n    )\n\n    da = (a1 - a0) / (n - 1)  # for n stimulations only n-1 steps occur\n    dur_stim = dur / n\n    amp = a0\n    for _ in range(n):\n        current_stim(pop, t=dur_stim, a=amp)\n        amp = amp + da\n\n    return {\"da\": da, \"dur_stim\": dur_stim}\n</code></pre>"},{"location":"additional/simulation_functions/#CompNeuroPy.simulation_functions.increasing_current","title":"<code>increasing_current(pop, a0, da, nr_steps, dur_step)</code>","text":"<p>Conducts multiple current stimulations with constantly increasing current inputs. After this increasing_current stimulation the current amplitude is reset to the initial value (before increasing_current).</p> <p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str</code> <p>population name of population, which should be stimulated with input current neuron model of population has to contain \"I_app\" as input current</p> required <code>a0</code> <code>int</code> <p>initial current amplitude (of first stimulation)</p> required <code>da</code> <code>int</code> <p>current step size</p> required <code>nr_steps</code> <code>int</code> <p>number of stimulations</p> required <code>dur_step</code> <code>int</code> <p>duration of one stimulation</p> required <p>Returns:</p> Name Type Description <code>return_dict</code> <code>dict</code> <p>dictionary containing:</p> <ul> <li>current_list (list): list of current amplitudes for each stimulation</li> </ul> Source code in <code>src/CompNeuroPy/simulation_functions.py</code> <pre><code>def increasing_current(pop, a0, da, nr_steps, dur_step):\n    \"\"\"\n    Conducts multiple current stimulations with constantly increasing current inputs.\n    After this increasing_current stimulation the current amplitude is reset to the\n    initial value (before increasing_current).\n\n    Args:\n        pop (str):\n            population name of population, which should be stimulated with input current\n            neuron model of population has to contain \"I_app\" as input current\n        a0 (int):\n            initial current amplitude (of first stimulation)\n        da (int):\n            current step size\n        nr_steps (int):\n            number of stimulations\n        dur_step (int):\n            duration of one stimulation\n\n    Returns:\n        return_dict (dict):\n            dictionary containing:\n\n            - current_list (list): list of current amplitudes for each stimulation\n    \"\"\"\n    current_list = []\n    a = a0\n    for _ in range(nr_steps):\n        current_list.append(a)\n        current_stim(pop, t=dur_step, a=a)\n        a += da\n\n    return {\"current_list\": current_list}\n</code></pre>"},{"location":"additional/simulation_requirements/","title":"Simulation Requirements","text":""},{"location":"additional/simulation_requirements/#CompNeuroPy.simulation_requirements.ReqPopHasAttr","title":"<code>ReqPopHasAttr</code>","text":"<p>Checks if population(s) contains the attribute(s) (parameters or variables)</p> Source code in <code>src/CompNeuroPy/simulation_requirements.py</code> <pre><code>class ReqPopHasAttr:\n    \"\"\"\n    Checks if population(s) contains the attribute(s) (parameters or variables)\n    \"\"\"\n\n    def __init__(self, pop, attr):\n        \"\"\"\n        Args:\n            pop (str or list of strings):\n                population name(s)\n            attr (str or list of strings):\n                attribute name(s)\n        \"\"\"\n        self.pop_name_list = pop\n        self.attr_name_list = attr\n        ### convert single strings into list\n        if not (isinstance(pop, list)):\n            self.pop_name_list = [pop]\n        if not (isinstance(attr, list)):\n            self.attr_name_list = [attr]\n\n    def run(self):\n        \"\"\"\n        Checks if population(s) contains the attribute(s) (parameters or variables)\n\n        Raises:\n            ValueError: if population(s) does not contain the attribute(s)\n        \"\"\"\n        for attr_name in self.attr_name_list:\n            for pop_name in self.pop_name_list:\n                pop: Population = get_population(pop_name)\n                if not (attr_name in pop.attributes):\n                    raise ValueError(\n                        \"Population \"\n                        + pop_name\n                        + \" does not contain attribute \"\n                        + attr_name\n                        + \"!\\n\"\n                    )\n</code></pre>"},{"location":"additional/simulation_requirements/#CompNeuroPy.simulation_requirements.ReqPopHasAttr.__init__","title":"<code>__init__(pop, attr)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>pop</code> <code>str or list of strings</code> <p>population name(s)</p> required <code>attr</code> <code>str or list of strings</code> <p>attribute name(s)</p> required Source code in <code>src/CompNeuroPy/simulation_requirements.py</code> <pre><code>def __init__(self, pop, attr):\n    \"\"\"\n    Args:\n        pop (str or list of strings):\n            population name(s)\n        attr (str or list of strings):\n            attribute name(s)\n    \"\"\"\n    self.pop_name_list = pop\n    self.attr_name_list = attr\n    ### convert single strings into list\n    if not (isinstance(pop, list)):\n        self.pop_name_list = [pop]\n    if not (isinstance(attr, list)):\n        self.attr_name_list = [attr]\n</code></pre>"},{"location":"additional/simulation_requirements/#CompNeuroPy.simulation_requirements.ReqPopHasAttr.run","title":"<code>run()</code>","text":"<p>Checks if population(s) contains the attribute(s) (parameters or variables)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if population(s) does not contain the attribute(s)</p> Source code in <code>src/CompNeuroPy/simulation_requirements.py</code> <pre><code>def run(self):\n    \"\"\"\n    Checks if population(s) contains the attribute(s) (parameters or variables)\n\n    Raises:\n        ValueError: if population(s) does not contain the attribute(s)\n    \"\"\"\n    for attr_name in self.attr_name_list:\n        for pop_name in self.pop_name_list:\n            pop: Population = get_population(pop_name)\n            if not (attr_name in pop.attributes):\n                raise ValueError(\n                    \"Population \"\n                    + pop_name\n                    + \" does not contain attribute \"\n                    + attr_name\n                    + \"!\\n\"\n                )\n</code></pre>"},{"location":"additional/system_functions/","title":"System Functions","text":""},{"location":"additional/system_functions/#CompNeuroPy.system_functions.clear_dir","title":"<code>clear_dir(path)</code>","text":"<p>Deletes all files and subdirectories in the specified folder.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the folder to clear.</p> required Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def clear_dir(path):\n    \"\"\"\n    Deletes all files and subdirectories in the specified folder.\n\n    Args:\n        path (str):\n            Path to the folder to clear.\n    \"\"\"\n    try:\n        if not os.path.exists(path):\n            print(f\"The folder '{path}' does not exist.\")\n            return\n\n        for filename in os.listdir(path):\n            file_path = os.path.join(path, filename)\n            try:\n                if os.path.isfile(file_path) or os.path.islink(file_path):\n                    os.unlink(file_path)\n                elif os.path.isdir(file_path):\n                    shutil.rmtree(file_path)\n            except Exception:\n                print(traceback.format_exc())\n                print(f\"Failed to delete {file_path}\")\n    except Exception:\n        print(traceback.format_exc())\n        print(f\"Failed to clear {path}\")\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.create_dir","title":"<code>create_dir(path, print_info=False, clear=False)</code>","text":"<p>Creates a directory.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the directory to create.</p> required <code>print_info</code> <code>bool</code> <p>Whether to print information about the directory creation. Default: False.</p> <code>False</code> <code>clear</code> <code>bool</code> <p>Whether to clear the directory if it already exists. Default: False.</p> <code>False</code> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def create_dir(path, print_info=False, clear=False):\n    \"\"\"\n    Creates a directory.\n\n    Args:\n        path (str):\n            Path to the directory to create.\n\n        print_info (bool, optional):\n            Whether to print information about the directory creation. Default: False.\n\n        clear (bool, optional):\n            Whether to clear the directory if it already exists. Default: False.\n    \"\"\"\n    try:\n        if isinstance(path, str):\n            if len(path) &gt; 0:\n                os.makedirs(path)\n        else:\n            print(\"create_dir, ERROR: path is no str\")\n    except Exception:\n        if os.path.isdir(path):\n            if print_info:\n                print(path + \" already exists\")\n            if clear:\n                ### clear folder\n                ### do you really want?\n                answer = input(f\"Do you really want to clear {path} (y/n):\")\n                while answer != \"y\" and answer != \"n\":\n                    print(\"please enter y or n\")\n                    answer = input(f\"Do you really want to clear {path} (y/n):\")\n                ### clear or not depending on answer\n                if answer == \"y\":\n                    clear_dir(path)\n                    if print_info:\n                        print(path + \" already exists and was cleared.\")\n                else:\n                    if print_info:\n                        print(path + \" already exists and was not cleared.\")\n        else:\n            print(traceback.format_exc())\n            print(\"could not create \" + path + \" folder\")\n            quit()\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.save_variables","title":"<code>save_variables(variable_list, name_list, path='./')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>variable_list</code> <code>list</code> <p>variables to save</p> required <code>name_list</code> <code>list</code> <p>names of the save files of the variables</p> required <code>path</code> <code>str or list</code> <p>save path for all variables, or save path for each variable of the variable_list. Default: \"./\"</p> <code>'./'</code> <p>Examples:</p> <pre><code>import numpy as np\nfrom CompNeuroPy import save_variables, load_variables\n\n### create variables\nvar1 = np.random.rand(10)\nvar2 = np.random.rand(10)\n\n### save variables\nsave_variables([var1, var2], [\"var1_file\", \"var2_file\"], \"my_variables_folder\")\n\n### load variables\nloaded_variables = load_variables([\"var1\", \"var2\"], \"my_variables_folder\")\n\n### use loaded variables\nprint(loaded_variables[\"var1_file\"])\nprint(loaded_variables[\"var2_file\"])\n</code></pre> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def save_variables(variable_list: list, name_list: list, path: str | list = \"./\"):\n    \"\"\"\n    Args:\n        variable_list (list):\n            variables to save\n        name_list (list):\n            names of the save files of the variables\n        path (str or list):\n            save path for all variables, or save path for each variable of the\n            variable_list. Default: \"./\"\n\n    Examples:\n        ```python\n        import numpy as np\n        from CompNeuroPy import save_variables, load_variables\n\n        ### create variables\n        var1 = np.random.rand(10)\n        var2 = np.random.rand(10)\n\n        ### save variables\n        save_variables([var1, var2], [\"var1_file\", \"var2_file\"], \"my_variables_folder\")\n\n        ### load variables\n        loaded_variables = load_variables([\"var1\", \"var2\"], \"my_variables_folder\")\n\n        ### use loaded variables\n        print(loaded_variables[\"var1_file\"])\n        print(loaded_variables[\"var2_file\"])\n        ```\n    \"\"\"\n    for idx in range(len(variable_list)):\n        ### set save path\n        if isinstance(path, str):\n            save_path = path\n        else:\n            save_path = path[idx]\n        if save_path.endswith(\"/\"):\n            save_path = save_path[:-1]\n        ### set file name\n        file_name = f\"{name_list[idx]}.pkl\"\n        ### set variable\n        variable = variable_list[idx]\n        ### generate save folder\n        create_dir(save_path)\n        ### Saving a variable to a file\n        with open(f\"{save_path}/{file_name}\", \"wb\") as file:\n            pickle.dump(variable, file)\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.load_variables","title":"<code>load_variables(name_list, path='./')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name_list</code> <code>list</code> <p>names of the save files of the variables</p> required <code>path</code> <code>str or list</code> <p>save path for all variables, or save path for each variable of the variable_list. Default: \"./\"</p> <code>'./'</code> <p>Returns:</p> Name Type Description <code>variable_dict</code> <code>dict</code> <p>dictionary with the loaded variables, keys are the names of the files, values are the loaded variables</p> <p>Examples:</p> <pre><code>import numpy as np\nfrom CompNeuroPy import save_variables, load_variables\n\n### create variables\nvar1 = np.random.rand(10)\nvar2 = np.random.rand(10)\n\n### save variables\nsave_variables([var1, var2], [\"var1_file\", \"var2_file\"], \"my_variables_folder\")\n\n### load variables\nloaded_variables = load_variables([\"var1\", \"var2\"], \"my_variables_folder\")\n\n### use loaded variables\nprint(loaded_variables[\"var1_file\"])\nprint(loaded_variables[\"var2_file\"])\n</code></pre> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def load_variables(name_list: list, path: str | list = \"./\"):\n    \"\"\"\n    Args:\n        name_list (list):\n            names of the save files of the variables\n        path (str or list, optional):\n            save path for all variables, or save path for each variable of the\n            variable_list. Default: \"./\"\n\n    Returns:\n        variable_dict (dict):\n            dictionary with the loaded variables, keys are the names of the\n            files, values are the loaded variables\n\n    Examples:\n        ```python\n        import numpy as np\n        from CompNeuroPy import save_variables, load_variables\n\n        ### create variables\n        var1 = np.random.rand(10)\n        var2 = np.random.rand(10)\n\n        ### save variables\n        save_variables([var1, var2], [\"var1_file\", \"var2_file\"], \"my_variables_folder\")\n\n        ### load variables\n        loaded_variables = load_variables([\"var1\", \"var2\"], \"my_variables_folder\")\n\n        ### use loaded variables\n        print(loaded_variables[\"var1_file\"])\n        print(loaded_variables[\"var2_file\"])\n        ```\n    \"\"\"\n    variable_dict = {}\n    for idx in range(len(name_list)):\n        ### set save path\n        if isinstance(path, str):\n            save_path = path\n        else:\n            save_path = path[idx]\n        if save_path.endswith(\"/\"):\n            save_path = save_path[:-1]\n        ### set file name\n        file_name = f\"{name_list[idx]}.pkl\"\n        ### Loading the variable from the file\n        with open(f\"{save_path}/{file_name}\", \"rb\") as file:\n            loaded_variable = pickle.load(file)\n        ### store variable in variable_dict\n        variable_dict[name_list[idx]] = loaded_variable\n\n    return variable_dict\n</code></pre>"},{"location":"additional/system_functions/#CompNeuroPy.system_functions.timing_decorator","title":"<code>timing_decorator(threshold=0.1)</code>","text":"<p>Decorator to measure the execution time of a function.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>Threshold in seconds. If the execution time of the function is larger than this threshold, the execution time is printed. Default: 0.1.</p> <code>0.1</code> Source code in <code>src/CompNeuroPy/system_functions.py</code> <pre><code>def timing_decorator(threshold=0.1):\n    \"\"\"\n    Decorator to measure the execution time of a function.\n\n    Args:\n        threshold (float, optional):\n            Threshold in seconds. If the execution time of the function is\n            larger than this threshold, the execution time is printed. Default: 0.1.\n    \"\"\"\n\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            start_time = time()\n            result = func(*args, **kwargs)\n            end_time = time()\n            execution_time = end_time - start_time\n            if execution_time &gt;= threshold:\n                print(f\"{func.__name__} took {execution_time:.4f} seconds\")\n            return result\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"built_in/neuron_models/","title":"Neuron Models","text":""},{"location":"built_in/neuron_models/#artificial-neurons","title":"Artificial Neurons","text":""},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.IntegratorNeuron","title":"<code>IntegratorNeuron</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Integrator Neuron for stop_condition in spiking models.</p> <p>The variable g_ampa increases for incoming spikes (target ampa) and decreases exponentially with time constant tau. If g_ampa reaches a threshold, the neuron's variable decision, which is by default -1, changes to the neuron_id. This can be used to cause the stop_condition of ANNarchy's simulate_until() function (stop_codnition=\"decision&gt;=0 : any\"). In case of multiple integrator neurons, the neuron_id can be used to identify the neuron that reached the threshold.</p> <p>Warning</p> <p>You have to define the variable neuron_id for each neuron in the Integrator population.</p> <p>Parameters:</p> Name Type Description Default <code>tau</code> <code>float</code> <p>Time constant in ms of the neuron. Default: 1.</p> <code>1</code> <code>threshold</code> <code>float</code> <p>Threshold for the decision g_ampa has to reach. Default: 1.</p> <code>1</code> <p>Examples:</p> <pre><code>from ANNarchy import Population, simulate_until\nfrom CompNeuroPy.neuron_models import Integrator\n\n# Create a population of 10 integrator neurons\nintegrator_neurons = Population(\n    geometry=10,\n    neuron=IntegratorNeuron(tau=1, threshold=1),\n    stop_condition=\"decision&gt;=0 : any\",\n    name=\"integrator_neurons\",)\n\n# set the neuron_id for each neuron\nintegrator_neurons.neuron_id = range(10)\n\n# simulate until one neuron reaches the threshold\nsimulate_until(max_duration=1000, population=integrator_neurons)\n\n# check if simulation stop due to stop_codnition and which neuron reached the\n# threshold\nif (integrator_neurons.decision &gt;= 0).any():\n    neurons_reached_thresh = integrator_neurons.neuron_id[\n        integrator_neurons.decision &gt;= 0\n    ]\n    print(f\"Neuron(s) {neurons_reached_thresh} reached threshold.\")\nelse:\n    print(\"No neuron reached threshold.\")\n</code></pre> Variables to record <ul> <li>g_ampa</li> <li>decision</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class IntegratorNeuron(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    Integrator Neuron for stop_condition in spiking models.\n\n    The variable g_ampa increases for incoming spikes (target ampa) and decreases\n    exponentially with time constant tau. If g_ampa reaches a threshold, the neuron's\n    variable decision, which is by default -1, changes to the neuron_id. This can be\n    used to cause the stop_condition of ANNarchy's simulate_until() function\n    (stop_codnition=\"decision&gt;=0 : any\"). In case of multiple integrator neurons,\n    the neuron_id can be used to identify the neuron that reached the threshold.\n\n    !!! warning\n        You have to define the variable neuron_id for each neuron in the Integrator\n        population.\n\n    Parameters:\n        tau (float, optional):\n            Time constant in ms of the neuron. Default: 1.\n        threshold (float, optional):\n            Threshold for the decision g_ampa has to reach. Default: 1.\n\n    Examples:\n        ```python\n        from ANNarchy import Population, simulate_until\n        from CompNeuroPy.neuron_models import Integrator\n\n        # Create a population of 10 integrator neurons\n        integrator_neurons = Population(\n            geometry=10,\n            neuron=IntegratorNeuron(tau=1, threshold=1),\n            stop_condition=\"decision&gt;=0 : any\",\n            name=\"integrator_neurons\",)\n\n        # set the neuron_id for each neuron\n        integrator_neurons.neuron_id = range(10)\n\n        # simulate until one neuron reaches the threshold\n        simulate_until(max_duration=1000, population=integrator_neurons)\n\n        # check if simulation stop due to stop_codnition and which neuron reached the\n        # threshold\n        if (integrator_neurons.decision &gt;= 0).any():\n            neurons_reached_thresh = integrator_neurons.neuron_id[\n                integrator_neurons.decision &gt;= 0\n            ]\n            print(f\"Neuron(s) {neurons_reached_thresh} reached threshold.\")\n        else:\n            print(\"No neuron reached threshold.\")\n        ```\n\n    Variables to record:\n        - g_ampa\n        - decision\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(self, tau: float = 1, threshold: float = 1):\n        # Create the arguments\n        parameters = f\"\"\"\n            tau = {tau} : population\n            threshold = {threshold} : population\n            neuron_id = 0\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = - g_ampa / tau\n                ddecision/dt = 0 : init = -1\n            \"\"\",\n            spike=\"\"\"\n                g_ampa &gt;= threshold\n            \"\"\",\n            reset=\"\"\"\n                decision = neuron_id\n            \"\"\",\n            name=\"integrator_neuron\",\n            description=\"\"\"\n                Integrator Neuron, which integrates incoming spikes with value g_ampa\n                and emits a spike when reaching a threshold. After spike decision\n                changes, which can be used as for stop condition\"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.IntegratorNeuronSimple","title":"<code>IntegratorNeuronSimple</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Integrator Neuron for stop_condition in spiking models.</p> <p>The variable g_ampa increases for incoming spikes (target ampa) and decreases exponentially with time constant tau. You can check g_ampa and use it for the stop_condition of ANNarchy's simulate_until() function (stop_codnition=\"g_ampa&gt;=some_value : any\"). In case of multiple integrator neurons, the neuron_id can be used to identify the neuron that reached the threshold.</p> <p>Warning</p> <p>You have to define the variable neuron_id for each neuron in the Integrator population.</p> <p>Parameters:</p> Name Type Description Default <code>tau</code> <code>float</code> <p>Time constant in ms of the neuron. Default: 1.</p> <code>1</code> <p>Examples:</p> <pre><code>from ANNarchy import Population, simulate_until\nfrom CompNeuroPy.neuron_models import Integrator\n\n# Create a population of 10 integrator neurons\nintegrator_neurons = Population(\n    geometry=10,\n    neuron=IntegratorNeuronSimple(tau=1),\n    stop_condition=\"g_ampa&gt;=5 : any\",\n    name=\"integrator_neurons\",)\n\n# set the neuron_id for each neuron\nintegrator_neurons.neuron_id = range(10)\n\n# simulate until one neuron reaches the threshold\nsimulate_until(max_duration=1000, population=integrator_neurons)\n\n# check if simulation stop due to stop_codnition and which neuron reached the\n# threshold\nif (integrator_neurons.g_ampa &gt;= 5).any():\n    neurons_reached_thresh = integrator_neurons.neuron_id[\n        integrator_neurons.g_ampa &gt;= 5\n    ]\n    print(f\"Neuron(s) {neurons_reached_thresh} reached threshold.\")\nelse:\n    print(\"No neuron reached threshold.\")\n</code></pre> Variables to record <ul> <li>g_ampa</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class IntegratorNeuronSimple(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    Integrator Neuron for stop_condition in spiking models.\n\n    The variable g_ampa increases for incoming spikes (target ampa) and decreases\n    exponentially with time constant tau. You can check g_ampa and use it for the\n    stop_condition of ANNarchy's simulate_until() function\n    (stop_codnition=\"g_ampa&gt;=some_value : any\"). In case of multiple integrator neurons,\n    the neuron_id can be used to identify the neuron that reached the threshold.\n\n    !!! warning\n        You have to define the variable neuron_id for each neuron in the Integrator\n        population.\n\n    Parameters:\n        tau (float, optional):\n            Time constant in ms of the neuron. Default: 1.\n\n    Examples:\n        ```python\n        from ANNarchy import Population, simulate_until\n        from CompNeuroPy.neuron_models import Integrator\n\n        # Create a population of 10 integrator neurons\n        integrator_neurons = Population(\n            geometry=10,\n            neuron=IntegratorNeuronSimple(tau=1),\n            stop_condition=\"g_ampa&gt;=5 : any\",\n            name=\"integrator_neurons\",)\n\n        # set the neuron_id for each neuron\n        integrator_neurons.neuron_id = range(10)\n\n        # simulate until one neuron reaches the threshold\n        simulate_until(max_duration=1000, population=integrator_neurons)\n\n        # check if simulation stop due to stop_codnition and which neuron reached the\n        # threshold\n        if (integrator_neurons.g_ampa &gt;= 5).any():\n            neurons_reached_thresh = integrator_neurons.neuron_id[\n                integrator_neurons.g_ampa &gt;= 5\n            ]\n            print(f\"Neuron(s) {neurons_reached_thresh} reached threshold.\")\n        else:\n            print(\"No neuron reached threshold.\")\n        ```\n\n    Variables to record:\n        - g_ampa\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(self, tau: float = 1):\n        # Create the arguments\n        parameters = f\"\"\"\n            tau = {tau} : population\n            neuron_id = 0\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = - g_ampa / tau\n                r = 0\n            \"\"\",\n            name=\"integrator_neuron_simple\",\n            description=\"\"\"\n                Integrator Neuron, which integrates incoming spikes with value g_ampa,\n                which can be used as a stop condition\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.PoissonNeuron","title":"<code>PoissonNeuron</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Poisson neuron whose rate can be specified and is reached instantaneous. The neuron emits spikes following a Poisson distribution, the average firing rate is given by the parameter rates.</p> <p>Parameters:</p> Name Type Description Default <code>rates</code> <code>float</code> <p>The average firing rate of the neuron in Hz. Default: 0.</p> <code>0</code> Variables to record <ul> <li>p</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class PoissonNeuron(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    Poisson neuron whose rate can be specified and is reached instantaneous. The\n    neuron emits spikes following a Poisson distribution, the average firing rate\n    is given by the parameter rates.\n\n    Parameters:\n        rates (float, optional):\n            The average firing rate of the neuron in Hz. Default: 0.\n\n    Variables to record:\n        - p\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(self, rates: float = 0):\n        # Create the arguments\n        parameters = f\"\"\"\n            rates = {rates}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                p = Uniform(0.0, 1.0) * 1000.0 / dt\n            \"\"\",\n            spike=\"\"\"\n                p &lt;= rates\n            \"\"\",\n            reset=\"\"\"\n                p = 0.0\n            \"\"\",\n            name=\"poisson_neuron\",\n            description=\"\"\"\n                Poisson neuron whose rate can be specified and is reached instantaneous.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.PoissonNeuronUpDown","title":"<code>PoissonNeuronUpDown</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>The neuron emits spikes following a Poisson distribution, the average firing rate is given by the parameter rates and is reached with time constants tau_up and tau_down.</p> <p>Attributes:</p> Name Type Description <code>rates</code> <code>float</code> <p>The average firing rate of the neuron in Hz. Default: 0.</p> <code>tau_up</code> <code>float</code> <p>Time constant in ms for increasing the firing rate. Default: 1.</p> <code>tau_down</code> <code>float</code> <p>Time constant in ms for decreasing the firing rate. Default: 1.</p> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class PoissonNeuronUpDown(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    The neuron emits spikes following a Poisson distribution, the average firing rate is\n    given by the parameter rates and is reached with time constants tau_up and tau_down.\n\n    Attributes:\n        rates (float, optional):\n            The average firing rate of the neuron in Hz. Default: 0.\n        tau_up (float, optional):\n            Time constant in ms for increasing the firing rate. Default: 1.\n        tau_down (float, optional):\n            Time constant in ms for decreasing the firing rate. Default: 1.\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(self, rates: float = 0, tau_up: float = 1, tau_down: float = 1):\n        # Create the arguments\n        parameters = f\"\"\"\n            rates = {rates}\n            tau_up = {tau_up}\n            tau_down = {tau_down}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                p = Uniform(0.0, 1.0) * 1000.0 / dt\n                dact/dt = if (rates - act) &gt; 0:\n                              (rates - act) / tau_up\n                          else:\n                              (rates - act) / tau_down\n            \"\"\",\n            spike=\"\"\"\n                p &lt;= act\n            \"\"\",\n            reset=\"\"\"\n                p = 0.0\n            \"\"\",\n            name=\"poisson_neuron_up_down\",\n            description=\"\"\"Poisson neuron whose rate can be specified and is reached\n                with time constants tau_up and tau_down.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.artificial_nm.PoissonNeuronSin","title":"<code>PoissonNeuronSin</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Neuron emitting spikes following a Poisson distribution, the average firing rate is given by a sinus function.</p> <p>Parameters:</p> Name Type Description Default <code>amplitude</code> <code>float</code> <p>Amplitude of the sinus function. Default: 0.</p> <code>0</code> <code>base</code> <code>float</code> <p>Base (offset) of the sinus function. Default: 0.</p> <code>0</code> <code>frequency</code> <code>float</code> <p>Frequency of the sinus function. Default: 0.</p> <code>0</code> <code>phase</code> <code>float</code> <p>Phase of the sinus function. Default: 0.</p> <code>0</code> Variables to record <ul> <li>rates</li> <li>p</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/artificial_nm.py</code> <pre><code>class PoissonNeuronSin(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    Neuron emitting spikes following a Poisson distribution, the average firing rate\n    is given by a sinus function.\n\n    Parameters:\n        amplitude (float, optional):\n            Amplitude of the sinus function. Default: 0.\n        base (float, optional):\n            Base (offset) of the sinus function. Default: 0.\n        frequency (float, optional):\n            Frequency of the sinus function. Default: 0.\n        phase (float, optional):\n            Phase of the sinus function. Default: 0.\n\n    Variables to record:\n        - rates\n        - p\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        amplitude: float = 0,\n        base: float = 0,\n        frequency: float = 0,\n        phase: float = 0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            amplitude = {amplitude}\n            base = {base}\n            frequency = {frequency}\n            phase = {phase}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                rates = amplitude * sin((2*pi*frequency)*(t/1000-phase)) + base\n                p     = Uniform(0.0, 1.0) * 1000.0 / dt\n            \"\"\",\n            spike=\"\"\"\n                p &lt;= rates\n            \"\"\",\n            reset=\"\"\"\n                p = 0.0\n            \"\"\",\n            name=\"poisson_neuron_sin\",\n            description=\"Poisson neuron whose rate varies with a sinus function.\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#hodgkin-huxley-neurons","title":"Hodgkin Huxley Neurons","text":""},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronBischop","title":"<code>HHneuronBischop</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Bischop et al. (2012).</p> Variables to record <ul> <li>prev_v</li> <li>I_L</li> <li>alpha_h</li> <li>beta_h</li> <li>h_inf</li> <li>tau_h</li> <li>h</li> <li>alpha_m</li> <li>beta_m</li> <li>m_inf</li> <li>m</li> <li>I_Na</li> <li>alpha_n1</li> <li>beta_n1</li> <li>n1_inf</li> <li>tau_n1</li> <li>n1</li> <li>I_Kv1</li> <li>alpha_n3</li> <li>beta_n3</li> <li>n3_inf</li> <li>tau_n3</li> <li>n3</li> <li>I_Kv3</li> <li>PV</li> <li>PV_Mg</li> <li>dPV_Ca_dt</li> <li>PV_Ca</li> <li>Ca</li> <li>k_inf</li> <li>tau_k</li> <li>k</li> <li>I_SK</li> <li>a_inf</li> <li>a</li> <li>I_Ca</li> <li>v</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronBischop(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Bischop et al. (2012)](https://doi.org/10.3389/fnmol.2012.00078).\n\n    Variables to record:\n        - prev_v\n        - I_L\n        - alpha_h\n        - beta_h\n        - h_inf\n        - tau_h\n        - h\n        - alpha_m\n        - beta_m\n        - m_inf\n        - m\n        - I_Na\n        - alpha_n1\n        - beta_n1\n        - n1_inf\n        - tau_n1\n        - n1\n        - I_Kv1\n        - alpha_n3\n        - beta_n3\n        - n3_inf\n        - tau_n3\n        - n3\n        - I_Kv3\n        - PV\n        - PV_Mg\n        - dPV_Ca_dt\n        - PV_Ca\n        - Ca\n        - k_inf\n        - tau_k\n        - k\n        - I_SK\n        - a_inf\n        - a\n        - I_Ca\n        - v\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.bischop = _BischopStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.bischop.parameters_base\n\n    def _get_equations(self):\n        return self.bischop.equations_base + self.bischop.membrane_base\n\n    def _get_name(self):\n        return \"H_and_H_Bischop\"\n\n    def _get_description(self):\n        return (\n            \"Hodgkin Huxley neuron model for striatal FSI from Bischop et al. (2012).\"\n        )\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronBischopSyn","title":"<code>HHneuronBischopSyn</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Bischop et al. (2012) with conductance-based synapses/currents for AMPA and GABA.</p> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>prev_v</li> <li>I_L</li> <li>alpha_h</li> <li>beta_h</li> <li>h_inf</li> <li>tau_h</li> <li>h</li> <li>alpha_m</li> <li>beta_m</li> <li>m_inf</li> <li>m</li> <li>I_Na</li> <li>alpha_n1</li> <li>beta_n1</li> <li>n1_inf</li> <li>tau_n1</li> <li>n1</li> <li>I_Kv1</li> <li>alpha_n3</li> <li>beta_n3</li> <li>n3_inf</li> <li>tau_n3</li> <li>n3</li> <li>I_Kv3</li> <li>PV</li> <li>PV_Mg</li> <li>dPV_Ca_dt</li> <li>PV_Ca</li> <li>Ca</li> <li>k_inf</li> <li>tau_k</li> <li>k</li> <li>I_SK</li> <li>a_inf</li> <li>a</li> <li>I_Ca</li> <li>v</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronBischopSyn(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Bischop et al. (2012)](https://doi.org/10.3389/fnmol.2012.00078) with\n    conductance-based synapses/currents for AMPA and GABA.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - prev_v\n        - I_L\n        - alpha_h\n        - beta_h\n        - h_inf\n        - tau_h\n        - h\n        - alpha_m\n        - beta_m\n        - m_inf\n        - m\n        - I_Na\n        - alpha_n1\n        - beta_n1\n        - n1_inf\n        - tau_n1\n        - n1\n        - I_Kv1\n        - alpha_n3\n        - beta_n3\n        - n3_inf\n        - tau_n3\n        - n3\n        - I_Kv3\n        - PV\n        - PV_Mg\n        - dPV_Ca_dt\n        - PV_Ca\n        - Ca\n        - k_inf\n        - tau_k\n        - k\n        - I_SK\n        - a_inf\n        - a\n        - I_Ca\n        - v\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.bischop = _BischopStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.bischop.parameters_conductance\n\n    def _get_equations(self):\n        return self.bischop.equations_conductance + self.bischop.membrane_conductance\n\n    def _get_name(self):\n        return \"H_and_H_Bischop_syn\"\n\n    def _get_description(self):\n        return \"\"\"\n                Hodgkin Huxley neuron model for striatal FSI from Bischop et al. (2012)\n                with conductance-based synapses/currents for AMPA and GABA.\n            \"\"\"\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronCorbit","title":"<code>HHneuronCorbit</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016).</p> Variables to record <ul> <li>prev_v</li> <li>I_L</li> <li>m_Na</li> <li>h_Na</li> <li>I_Na</li> <li>n_Kv3_inf</li> <li>tau_n_Kv3_inf</li> <li>n_Kv3</li> <li>I_Kv3</li> <li>m_Kv1</li> <li>h_Kv1</li> <li>I_Kv1</li> <li>v</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronCorbit(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016).\n\n    Variables to record:\n        - prev_v\n        - I_L\n        - m_Na\n        - h_Na\n        - I_Na\n        - n_Kv3_inf\n        - tau_n_Kv3_inf\n        - n_Kv3\n        - I_Kv3\n        - m_Kv1\n        - h_Kv1\n        - I_Kv1\n        - v\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.corbit = _CorbitStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.corbit.parameters_base\n\n    def _get_equations(self):\n        return self.corbit.equations_base + self.corbit.membrane_base\n\n    def _get_name(self):\n        return \"H_and_H_Corbit\"\n\n    def _get_description(self):\n        return \"Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016).\"\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronCorbitSyn","title":"<code>HHneuronCorbitSyn</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016) with conductance-based synapses/currents for AMPA and GABA.</p> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>prev_v</li> <li>I_L</li> <li>m_Na</li> <li>h_Na</li> <li>I_Na</li> <li>n_Kv3_inf</li> <li>tau_n_Kv3_inf</li> <li>n_Kv3</li> <li>I_Kv3</li> <li>m_Kv1</li> <li>h_Kv1</li> <li>I_Kv1</li> <li>v</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronCorbitSyn(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016) with\n    conductance-based synapses/currents for AMPA and GABA.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - prev_v\n        - I_L\n        - m_Na\n        - h_Na\n        - I_Na\n        - n_Kv3_inf\n        - tau_n_Kv3_inf\n        - n_Kv3\n        - I_Kv3\n        - m_Kv1\n        - h_Kv1\n        - I_Kv1\n        - v\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.corbit = _CorbitStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.corbit.parameters_conductance\n\n    def _get_equations(self):\n        return self.corbit.equations_conductance + self.corbit.membrane_conductance\n\n    def _get_name(self):\n        return \"H_and_H_Corbit_syn\"\n\n    def _get_description(self):\n        return \"\"\"\n                Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016)\n                with conductance-based synapses/currents for AMPA and GABA.\n            \"\"\"\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.H_and_H_like_nm.HHneuronCorbitVoltageClamp","title":"<code>HHneuronCorbitVoltageClamp</code>","text":"<p>             Bases: <code>_HHneuron</code></p> <p>PREDEFINED</p> <p>Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016) with voltage clamp. Membrane potential v is clamped and I_inf can be recorded.</p> Variables to record <ul> <li>prev_v</li> <li>I_L</li> <li>m_Na</li> <li>h_Na</li> <li>I_Na</li> <li>n_Kv3_inf</li> <li>tau_n_Kv3_inf</li> <li>n_Kv3</li> <li>I_Kv3</li> <li>m_Kv1</li> <li>h_Kv1</li> <li>I_Kv1</li> <li>v</li> <li>I_inf</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/H_and_H_like_nm.py</code> <pre><code>class HHneuronCorbitVoltageClamp(_HHneuron):\n    \"\"\"\n    PREDEFINED\n\n    Hodgkin Huxley neuron model for striatal FSI from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016) with\n    voltage clamp. Membrane potential v is clamped and I_inf can be recorded.\n\n    Variables to record:\n        - prev_v\n        - I_L\n        - m_Na\n        - h_Na\n        - I_Na\n        - n_Kv3_inf\n        - tau_n_Kv3_inf\n        - n_Kv3\n        - I_Kv3\n        - m_Kv1\n        - h_Kv1\n        - I_Kv1\n        - v\n        - I_inf\n        - r\n    \"\"\"\n\n    def __init__(self):\n        self.corbit = _CorbitStrings()\n\n        super().__init__()\n\n    def _get_parameters(self):\n        return self.corbit.parameters_base\n\n    def _get_equations(self):\n        return self.corbit.equations_base + self.corbit.membrane_voltage_clamp\n\n    def _get_name(self):\n        return \"H_and_H_Corbit_voltage_clamp\"\n\n    def _get_description(self):\n        return \"\"\"\n                Hodgkin Huxley neuron model for striatal FSI from Corbit et al. (2016)\n                with voltage clamp.\n            \"\"\"\n</code></pre>"},{"location":"built_in/neuron_models/#izhikevich-2003-like-neurons","title":"Izhikevich (2003)-like Neurons","text":""},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003FixedNoisyAmpa","title":"<code>Izhikevich2003FixedNoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents with noise in AMPA conductance. Fixed means, the 3 factors of the quadratic equation cannot be changed.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>increase_noise</code> <code>float</code> <p>Increase of the Poisson distributed (equivalent to a Poisson distributed spike train as input) noise in the AMPA conductance.</p> <code>0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the AMPA conductance.</p> <code>0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003FixedNoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents with noise in AMPA\n    conductance. Fixed means, the 3 factors of the quadratic equation cannot be changed.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        increase_noise (float, optional):\n            Increase of the Poisson distributed (equivalent to a Poisson distributed\n            spike train as input) noise in the AMPA conductance.\n        rates_noise (float, optional):\n            Rate of the Poisson distributed noise in the AMPA conductance.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        increase_noise: float = 0,\n        rates_noise: float = 0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app}\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rates_noise, -g_ampa/tau_ampa, -g_ampa/tau_ampa + increase_noise/dt)\n                dg_gaba/dt = -g_gaba / tau_gaba\n                dv/dt      = 0.04 * v * v + 5 * v + 140 - u + I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba))\n                du/dt      = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2003_fixed_noisy_AMPA\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2003) with additional\n                conductance-based synapses for AMPA and GABA currents with noise in AMPA\n                conductance.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyAmpa","title":"<code>Izhikevich2003NoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents with noise in AMPA conductance.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>increase_noise</code> <code>float</code> <p>Increase of the Poisson distributed (equivalent to a Poisson distributed spike train as input) noise in the AMPA conductance.</p> <code>0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the AMPA conductance.</p> <code>0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents with noise in AMPA\n    conductance.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        increase_noise (float, optional):\n            Increase of the Poisson distributed (equivalent to a Poisson distributed\n            spike train as input) noise in the AMPA conductance.\n        rates_noise (float, optional):\n            Rate of the Poisson distributed noise in the AMPA conductance.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        increase_noise: float = 0,\n        rates_noise: float = 0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            n2             = {n2} : population\n            n1             = {n1} : population\n            n0             = {n0} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app}\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rates_noise, -g_ampa/tau_ampa, -g_ampa/tau_ampa + increase_noise/dt)\n                dg_gaba/dt = -g_gaba / tau_gaba\n                dv/dt      = n2 * v * v + n1 * v + n0 - u + I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba))\n                du/dt      = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2003_noisy_AMPA\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents with noise in AMPA conductance.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyAmpaNonlin","title":"<code>Izhikevich2003NoisyAmpaNonlin</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents with noise in AMPA conductance. With nonlinear function for external current.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>increase_noise</code> <code>float</code> <p>Increase of the Poisson distributed (equivalent to a Poisson distributed spike train as input) noise in the AMPA conductance.</p> <code>0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the AMPA conductance.</p> <code>0</code> <code>nonlin</code> <code>float</code> <p>Exponent of the nonlinear function for the external current.</p> <code>1</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyAmpaNonlin(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents with noise in AMPA\n    conductance. With nonlinear function for external current.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        increase_noise (float, optional):\n            Increase of the Poisson distributed (equivalent to a Poisson distributed\n            spike train as input) noise in the AMPA conductance.\n        rates_noise (float, optional):\n            Rate of the Poisson distributed noise in the AMPA conductance.\n        nonlin (float, optional):\n            Exponent of the nonlinear function for the external current.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        increase_noise: float = 0,\n        rates_noise: float = 0,\n        nonlin: float = 1,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            n2             = {n2} : population\n            n1             = {n1} : population\n            n0             = {n0} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app}\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n            nonlin         = {nonlin} : population\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rates_noise, -g_ampa/tau_ampa, -g_ampa/tau_ampa + increase_noise/dt)\n                dg_gaba/dt = -g_gaba / tau_gaba\n                I = I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba))\n                dv/dt      = n2 * v * v + n1 * v + n0 - u + f(I,nonlin)\n                du/dt      = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            functions=\"\"\"\n                f(x,y)=((abs(x))**(1/y))/((x+1e-20)/(abs(x)+ 1e-20))\n            \"\"\",\n            name=\"Izhikevich2003_noisy_AMPA_nonlin\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents with noise in AMPA conductance.\n                With nonlinear function for external current.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyAmpaOscillating","title":"<code>Izhikevich2003NoisyAmpaOscillating</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents with noise in AMPA conductance. With additional oscillation term.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>increase_noise</code> <code>float</code> <p>Increase of the Poisson distributed (equivalent to a Poisson distributed spike train as input) noise in the AMPA conductance.</p> <code>0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the AMPA conductance.</p> <code>0</code> <code>freq</code> <code>float</code> <p>Frequency of the oscillation term.</p> <code>0</code> <code>amp</code> <code>float</code> <p>Amplitude of the oscillation term.</p> <code>6</code> Variables to record <ul> <li>osc</li> <li>g_ampa</li> <li>g_gaba</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyAmpaOscillating(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents with noise in AMPA\n    conductance. With additional oscillation term.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        increase_noise (float, optional):\n            Increase of the Poisson distributed (equivalent to a Poisson distributed\n            spike train as input) noise in the AMPA conductance.\n        rates_noise (float, optional):\n            Rate of the Poisson distributed noise in the AMPA conductance.\n        freq (float, optional):\n            Frequency of the oscillation term.\n        amp (float, optional):\n            Amplitude of the oscillation term.\n\n    Variables to record:\n        - osc\n        - g_ampa\n        - g_gaba\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        increase_noise: float = 0,\n        rates_noise: float = 0,\n        freq: float = 0,\n        amp: float = 6,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            n2             = {n2} : population\n            n1             = {n1} : population\n            n0             = {n0} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app}\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n            freq           = {freq}\n            amp            = {amp}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                osc        = amp * sin(t * 2 * pi * (freq / 1000))\n                dg_ampa/dt = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rates_noise, -g_ampa/tau_ampa, -g_ampa/tau_ampa + increase_noise/dt)\n                dg_gaba/dt = -g_gaba / tau_gaba\n                dv/dt      = n2 * v * v + n1 * v + n0 - u + I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba)) + osc\n                du/dt      = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2003_noisy_AMPA_oscillating\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents with noise in AMPA conductance.\n                With additional oscillation term.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyBase","title":"<code>Izhikevich2003NoisyBase</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents and a noisy baseline current.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>base_mean</code> <code>float</code> <p>Mean of the baseline current.</p> <code>0</code> <code>base_noise</code> <code>float</code> <p>Standard deviation of the baseline current.</p> <code>0</code> <code>rate_base_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the baseline current, i.e. how often the baseline current is changed randomly.</p> <code>0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>offset_base</li> <li>I_base</li> <li>I</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyBase(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents and a noisy baseline\n    current.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        base_mean (float, optional):\n            Mean of the baseline current.\n        base_noise (float, optional):\n            Standard deviation of the baseline current.\n        rate_base_noise (float, optional):\n            Rate of the Poisson distributed noise in the baseline current, i.e. how\n            often the baseline current is changed randomly.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - offset_base\n        - I_base\n        - I\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        base_mean: float = 0,\n        base_noise: float = 0,\n        rate_base_noise: float = 0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a               = {a} : population\n            b               = {b} : population\n            c               = {c} : population\n            d               = {d} : population\n            n2              = {n2} : population\n            n1              = {n1} : population\n            n0              = {n0} : population\n            tau_ampa        = {tau_ampa} : population\n            tau_gaba        = {tau_gaba} : population\n            E_ampa          = {E_ampa} : population\n            E_gaba          = {E_gaba} : population\n            I_app           = {I_app}\n            base_mean       = {base_mean}\n            base_noise      = {base_noise}\n            rate_base_noise = {rate_base_noise}\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt  = -g_ampa/tau_ampa\n                dg_gaba/dt  = -g_gaba / tau_gaba\n                offset_base = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rate_base_noise, offset_base, Normal(0, 1) * base_noise)\n                I_base      = base_mean + offset_base\n                I           = I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba)) + I_base\n                dv/dt       = n2 * v * v + n1 * v + n0 - u + I\n                du/dt       = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2003_noisy_I\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents and a noisy baseline current.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2003_like_nm.Izhikevich2003NoisyBaseNonlin","title":"<code>Izhikevich2003NoisyBaseNonlin</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2003)-like neuron model with additional conductance based synapses for AMPA and GABA currents and a noisy baseline current. With nonlinear function for external current.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>Time constant of the recovery variable u.</p> <code>0</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the membrane potential v.</p> <code>0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential v.</p> <code>0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>0</code> <code>n2</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n1</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>n0</code> <code>float</code> <p>Factor of the quadratic equation of the membrane potential v.</p> <code>0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA conductance.</p> <code>1</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA conductance.</p> <code>1</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA conductance.</p> <code>0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA conductance.</p> <code>0</code> <code>I_app</code> <code>float</code> <p>External applied current.</p> <code>0</code> <code>base_mean</code> <code>float</code> <p>Mean of the baseline current.</p> <code>0</code> <code>base_noise</code> <code>float</code> <p>Standard deviation of the baseline current.</p> <code>0</code> <code>rate_base_noise</code> <code>float</code> <p>Rate of the Poisson distributed noise in the baseline current, i.e. how often the baseline current is changed randomly.</p> <code>0</code> <code>nonlin</code> <code>float</code> <p>Exponent of the nonlinear function for the external current.</p> <code>1</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>offset_base</li> <li>I_base</li> <li>I</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2003_like_nm.py</code> <pre><code>class Izhikevich2003NoisyBaseNonlin(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2003)](https://doi.org/10.1109/TNN.2003.820440)-like neuron model with\n    additional conductance based synapses for AMPA and GABA currents and a noisy baseline\n    current. With nonlinear function for external current.\n\n    Parameters:\n        a (float, optional):\n            Time constant of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential v.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        n2 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n1 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        n0 (float, optional):\n            Factor of the quadratic equation of the membrane potential v.\n        tau_ampa (float, optional):\n            Time constant of the AMPA conductance.\n        tau_gaba (float, optional):\n            Time constant of the GABA conductance.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA conductance.\n        E_gaba (float, optional):\n            Reversal potential of the GABA conductance.\n        I_app (float, optional):\n            External applied current.\n        base_mean (float, optional):\n            Mean of the baseline current.\n        base_noise (float, optional):\n            Standard deviation of the baseline current.\n        rate_base_noise (float, optional):\n            Rate of the Poisson distributed noise in the baseline current, i.e. how\n            often the baseline current is changed randomly.\n        nonlin (float, optional):\n            Exponent of the nonlinear function for the external current.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - offset_base\n        - I_base\n        - I\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        a: float = 0,\n        b: float = 0,\n        c: float = 0,\n        d: float = 0,\n        n2: float = 0,\n        n1: float = 0,\n        n0: float = 0,\n        tau_ampa: float = 1,\n        tau_gaba: float = 1,\n        E_ampa: float = 0,\n        E_gaba: float = 0,\n        I_app: float = 0,\n        base_mean: float = 0,\n        base_noise: float = 0,\n        rate_base_noise: float = 0,\n        nonlin: float = 1,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            a               = {a} : population\n            b               = {b} : population\n            c               = {c} : population\n            d               = {d} : population\n            n2              = {n2} : population\n            n1              = {n1} : population\n            n0              = {n0} : population\n            tau_ampa        = {tau_ampa} : population\n            tau_gaba        = {tau_gaba} : population\n            E_ampa          = {E_ampa} : population\n            E_gaba          = {E_gaba} : population\n            I_app           = {I_app}\n            base_mean       = {base_mean}\n            base_noise      = {base_noise}\n            rate_base_noise = {rate_base_noise}\n            nonlin          = {nonlin} : population\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=\"\"\"\n                dg_ampa/dt  = -g_ampa/tau_ampa\n                dg_gaba/dt  = -g_gaba / tau_gaba\n                offset_base = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rate_base_noise, offset_base, Normal(0, 1) * base_noise)\n                I_base      = base_mean + offset_base\n                I           = I_app - neg(g_ampa*(v - E_ampa)) - pos(g_gaba*(v - E_gaba))\n                dv/dt       = n2 * v * v + n1 * v + n0 - u + f(I,nonlin) + I_base\n                du/dt       = a * (b * v - u)\n            \"\"\",\n            spike=\"\"\"\n                v &gt;= 30\n            \"\"\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            functions=\"\"\"\n                f(x,y)=((abs(x))**(1/y))/((x+1e-20)/(abs(x)+ 1e-20))\n            \"\"\",\n            name=\"Izhikevich2003_noisy_I_nonlin\",\n            description=\"\"\"\n                Neuron model from Izhikevich (2003). With additional conductance based\n                synapses for AMPA and GABA currents and a noisy baseline current.\n                With nonlinear function for external current.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#izhikevich-2007-like-neurons","title":"Izhikevich (2007)-like Neurons","text":""},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007","title":"<code>Izhikevich2007</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> Variables to record <ul> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n\n    Variables to record:\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C      = {C} : population # pF\n            k      = {k} : population # pS * mV**-1\n            v_r    = {v_r} : population # mV\n            v_t    = {v_t} : population # mV\n            a      = {a} : population # ms**-1\n            b      = {b} : population # nS\n            c      = {c} : population # mV\n            d      = {d} : population # pA\n            v_peak = {v_peak} : population # mV\n            I_app  = {I_app} # pA\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(),\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007\",\n            description=\"Neuron model equations from Izhikevich (2007).\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007RecCur","title":"<code>Izhikevich2007RecCur</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with separate currents to record.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> Variables to record <ul> <li>I_v</li> <li>v</li> <li>u</li> <li>I_u</li> <li>I_k</li> <li>I_a</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007RecCur(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with separate currents to record.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n\n    Variables to record:\n        - I_v\n        - v\n        - u\n        - I_u\n        - I_k\n        - I_a\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C      = {C} : population # pF\n            k      = {k} : population # pS * mV**-1\n            v_r    = {v_r} : population # mV\n            v_t    = {v_t} : population # mV\n            a      = {a} : population # ms**-1\n            b      = {b} : population # nS\n            c      = {c} : population # mV\n            d      = {d} : population # pA\n            v_peak = {v_peak} : population # mV\n            I_app  = {I_app} # pA\n        \"\"\"\n\n        affix = \"\"\"\n            I_u = -u\n            I_k = k*(v - v_r)*(v - v_t)\n            I_a = I_app\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(affix=affix),\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_record_currents\",\n            description=\"\"\"\n                Neuron model equations from Izhikevich (2007) with separate\n                currents to record.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007VoltageClamp","title":"<code>Izhikevich2007VoltageClamp</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with voltage clamp to record I_inf.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> Variables to record <ul> <li>I_v</li> <li>v</li> <li>u</li> <li>I_inf</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007VoltageClamp(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with voltage clamp to record I_inf.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n\n    Variables to record:\n        - I_v\n        - v\n        - u\n        - I_inf\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C      = {C} : population # pF\n            k      = {k} : population # pS * mV**-1\n            v_r    = {v_r} : population # mV\n            v_t    = {v_t} : population # mV\n            a      = {a} : population # ms**-1\n            b      = {b} : population # nS\n            c      = {c} : population # mV\n            d      = {d} : population # pA\n            v_peak = {v_peak} : population # mV\n            I_app  = {I_app} # pA\n        \"\"\"\n\n        dv = \"0\"\n        affix = f\"I_inf = {_dv_default}\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(dv=dv, affix=affix),\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_voltage_clamp\",\n            description=\"\"\"\n                Neuron model equations from Izhikevich (2007) with voltage clamp\n                to record I_inf.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007Syn","title":"<code>Izhikevich2007Syn</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based synapses.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>10.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>10.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-90.0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007Syn(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based synapses.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 10.0,\n        tau_gaba: float = 10.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -90.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C      = {C} : population # pF\n            k      = {k} : population # pS\n            v_r    = {v_r} : population\n            v_t    = {v_t} : population\n            a      = {a} : population\n            b      = {b} : population\n            c      = {c} : population\n            d      = {d} : population\n            v_peak = {v_peak} : population\n            I_app  = {I_app} # pA\n            tau_ampa = {tau_ampa} : population\n            tau_gaba = {tau_gaba} : population\n            E_ampa   = {E_ampa} : population\n            E_gaba   = {E_gaba} : population\n        \"\"\"\n\n        syn = _syn_default\n        i_v = f\"I_app {_I_syn}\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(syn=syn, i_v=i_v),\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_syn\",\n            description=\"\"\"\n                Neuron model equations from Izhikevich (2007) with conductance-based\n                AMPA and GABA synapses/currents.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007NoisyAmpa","title":"<code>Izhikevich2007NoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>10.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>10.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-90.0</code> <code>increase_noise</code> <code>float</code> <p>Increase of AMPA conductance due to noise (equal to a Poisson distributed spike train as input).</p> <code>0.0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the noise in the AMPA conductance.</p> <code>0.0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007NoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        increase_noise (float, optional):\n            Increase of AMPA conductance due to noise (equal to a Poisson distributed\n            spike train as input).\n        rates_noise (float, optional):\n            Rate of the noise in the AMPA conductance.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 10.0,\n        tau_gaba: float = 10.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -90.0,\n        increase_noise: float = 0.0,\n        rates_noise: float = 0.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} : population\n            k              = {k} : population\n            v_r            = {v_r} : population\n            v_t            = {v_t} : population\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            v_peak         = {v_peak} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app} # pA\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        syn = _syn_noisy\n        i_v = f\"I_app {_I_syn}\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(syn=syn, i_v=i_v),\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_noisy_AMPA\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in AMPA conductance.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007NoisyBase","title":"<code>Izhikevich2007NoisyBase</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the baseline current.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>100.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>0.7</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-60.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.03</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>100.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>35.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>10.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>10.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-90.0</code> <code>base_mean</code> <code>float</code> <p>Mean of the baseline current.</p> <code>0.0</code> <code>base_noise</code> <code>float</code> <p>Standard deviation of the baseline current noise.</p> <code>0.0</code> <code>rate_base_noise</code> <code>float</code> <p>Rate of the noise update (Poisson distributed) in the baseline current.</p> <code>0.0</code> Variables to record <ul> <li>offset_base</li> <li>I_base</li> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007NoisyBase(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the baseline current.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        base_mean (float, optional):\n            Mean of the baseline current.\n        base_noise (float, optional):\n            Standard deviation of the baseline current noise.\n        rate_base_noise (float, optional):\n            Rate of the noise update (Poisson distributed) in the baseline current.\n\n    Variables to record:\n        - offset_base\n        - I_base\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 100.0,\n        k: float = 0.7,\n        v_r: float = -60.0,\n        v_t: float = -40.0,\n        a: float = 0.03,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 100.0,\n        v_peak: float = 35.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 10.0,\n        tau_gaba: float = 10.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -90.0,\n        base_mean: float = 0.0,\n        base_noise: float = 0.0,\n        rate_base_noise: float = 0.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} : population\n            k              = {k} : population\n            v_r            = {v_r} : population\n            v_t            = {v_t} : population\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            v_peak         = {v_peak} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app} # pA\n            base_mean      = {base_mean}\n            base_noise     = {base_noise}\n            rate_base_noise = {rate_base_noise}\n        \"\"\"\n\n        syn = _syn_default\n        i_v = f\"I_app {_I_syn} + I_base\"\n        prefix = _I_base_noise\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(syn=syn, i_v=i_v, prefix=prefix),\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_noisy_base\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents and noisy\n                baseline current.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007FsiNoisyAmpa","title":"<code>Izhikevich2007FsiNoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model for fast-spiking neurons, with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>20.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>1.0</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-55.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>v_b</code> <code>float</code> <p>Instantaneous activation threshold potential for the recovery variable u.</p> <code>-55.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.1</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>2.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>25.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>2.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>5.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-80.0</code> <code>increase_noise</code> <code>float</code> <p>Increase of AMPA conductance due to noise (equal to a Poisson distributed spike train as input).</p> <code>0.0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the noise in the AMPA conductance.</p> <code>0.0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007FsiNoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    for fast-spiking neurons, with conductance-based AMPA and GABA synapses with noise\n    in the AMPA conductance.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        v_b (float, optional):\n            Instantaneous activation threshold potential for the recovery variable u.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        increase_noise (float, optional):\n            Increase of AMPA conductance due to noise (equal to a Poisson distributed\n            spike train as input).\n        rates_noise (float, optional):\n            Rate of the noise in the AMPA conductance.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 20.0,\n        k: float = 1.0,\n        v_r: float = -55.0,\n        v_t: float = -40.0,\n        v_b: float = -55.0,\n        a: float = 0.1,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 2.0,\n        v_peak: float = 25.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 2.0,\n        tau_gaba: float = 5.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -80.0,\n        increase_noise: float = 0.0,\n        rates_noise: float = 0.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} : population\n            k              = {k} : population\n            v_r            = {v_r} : population\n            v_t            = {v_t} : population\n            v_b            = {v_b} : population\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            v_peak         = {v_peak} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app} # pA\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        syn = _syn_noisy\n        i_v = f\"I_app {_I_syn}\"\n        du = \"if v&lt;v_b: -a * u else: a * (b * (v - v_b)**3 - u)\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(syn=syn, i_v=i_v, du=du),\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_FSI_noisy_AMPA\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in AMPA conductance.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007CorbitFsiNoisyAmpa","title":"<code>Izhikevich2007CorbitFsiNoisyAmpa</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the AMPA conductance. Additional slow currents were added to fit the striatal FSI neuron model from Corbit et al. (2016). The additional currents should allow the neuron to produce late spiking.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>20.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>1.0</code> <code>b_n</code> <code>float</code> <p>Sensitivity of the slow current n to the difference between the slow current s and the recovery variable u.</p> <code>0.1</code> <code>a_s</code> <code>float</code> <p>Time scale of the slow current s.</p> <code>0.1</code> <code>a_n</code> <code>float</code> <p>Time scale of the slow current n.</p> <code>0.1</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-55.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.1</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>2.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>25.0</code> <code>nonlin</code> <code>float</code> <p>Nonlinearity of the input current. (1.0 = linear, 2.0 = square, etc.)</p> <code>0.1</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>2.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>5.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-80.0</code> <code>increase_noise</code> <code>float</code> <p>Increase of AMPA conductance due to noise (equal to a Poisson distributed spike train as input).</p> <code>0.0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the noise in the AMPA conductance.</p> <code>0.0</code> Variables to record <ul> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>s</li> <li>n</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007CorbitFsiNoisyAmpa(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.\n    Additional slow currents were added to fit the striatal FSI neuron model from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016). The\n    additional currents should allow the neuron to produce late spiking.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        b_n (float, optional):\n            Sensitivity of the slow current n to the difference between the slow current\n            s and the recovery variable u.\n        a_s (float, optional):\n            Time scale of the slow current s.\n        a_n (float, optional):\n            Time scale of the slow current n.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        nonlin (float, optional):\n            Nonlinearity of the input current. (1.0 = linear, 2.0 = square, etc.)\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        increase_noise (float, optional):\n            Increase of AMPA conductance due to noise (equal to a Poisson distributed\n            spike train as input).\n        rates_noise (float, optional):\n            Rate of the noise in the AMPA conductance.\n\n    Variables to record:\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - s\n        - n\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 20.0,\n        k: float = 1.0,\n        b_n: float = 0.1,\n        a_s: float = 0.1,\n        a_n: float = 0.1,\n        v_r: float = -55.0,\n        v_t: float = -40.0,\n        a: float = 0.1,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 2.0,\n        v_peak: float = 25.0,\n        nonlin: float = 0.1,\n        I_app: float = 0.0,\n        tau_ampa: float = 2.0,\n        tau_gaba: float = 5.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -80.0,\n        increase_noise: float = 0.0,\n        rates_noise: float = 0.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} : population\n            k              = {k} : population\n            b_n            = {b_n} : population\n            a_s            = {a_s} : population\n            a_n            = {a_n} : population\n            v_r            = {v_r} : population\n            v_t            = {v_t} : population\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            v_peak         = {v_peak} : population\n            nonlin         = {nonlin} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app} # pA\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n        \"\"\"\n\n        syn = _syn_noisy\n        i_v = f\"root_func(I_app {_I_syn}, nonlin) - n\"\n        affix = \"\"\"\n            ds/dt     = a_s*(pos(u)**0.1 - s)\n            dn/dt     = a_n*(b_n*(pos(u)**0.1-s) - n)\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(syn=syn, i_v=i_v, affix=affix),\n            functions=\"\"\"\n                root_func(x,y)=((abs(x))**(1/y))/((x+1e-20)/(abs(x)+ 1e-20))\n            \"\"\",\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_Corbit_FSI_noisy_AMPA\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in AMPA conductance. Additional slow currents were added to fit\n                the striatal FSI neuron model from Corbit et al. (2016).\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007CorbitFsiNoisyBase","title":"<code>Izhikevich2007CorbitFsiNoisyBase</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the baseline current. Additional slow currents were added to fit the striatal FSI neuron model from Corbit et al. (2016). The additional currents should allow the neuron to produce late spiking.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>20.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>1.0</code> <code>b_n</code> <code>float</code> <p>Sensitivity of the slow current n to the difference between the slow current s and the recovery variable u.</p> <code>0.1</code> <code>a_s</code> <code>float</code> <p>Time scale of the slow current s.</p> <code>0.1</code> <code>a_n</code> <code>float</code> <p>Time scale of the slow current n.</p> <code>0.1</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-55.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.1</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>2.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>25.0</code> <code>nonlin</code> <code>float</code> <p>Nonlinearity of the input current. (1.0 = linear, 2.0 = square, etc.)</p> <code>0.1</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>2.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>5.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-80.0</code> <code>base_mean</code> <code>float</code> <p>Mean of the baseline current.</p> <code>0.0</code> <code>base_noise</code> <code>float</code> <p>Standard deviation of the baseline current noise.</p> <code>0.0</code> <code>rate_base_noise</code> <code>float</code> <p>Rate of the noise update (Poisson distributed) in the baseline current.</p> <code>0.0</code> Variables to record <ul> <li>offset_base</li> <li>I_base</li> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>s</li> <li>n</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007CorbitFsiNoisyBase(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the baseline current.\n    Additional slow currents were added to fit the striatal FSI neuron model from\n    [Corbit et al. (2016)](https://doi.org/10.1523/JNEUROSCI.0339-16.2016). The\n    additional currents should allow the neuron to produce late spiking.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        b_n (float, optional):\n            Sensitivity of the slow current n to the difference between the slow current\n            s and the recovery variable u.\n        a_s (float, optional):\n            Time scale of the slow current s.\n        a_n (float, optional):\n            Time scale of the slow current n.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        nonlin (float, optional):\n            Nonlinearity of the input current. (1.0 = linear, 2.0 = square, etc.)\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        base_mean (float, optional):\n            Mean of the baseline current.\n        base_noise (float, optional):\n            Standard deviation of the baseline current noise.\n        rate_base_noise (float, optional):\n            Rate of the noise update (Poisson distributed) in the baseline current.\n\n    Variables to record:\n        - offset_base\n        - I_base\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - s\n        - n\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 20.0,\n        k: float = 1.0,\n        b_n: float = 0.1,\n        a_s: float = 0.1,\n        a_n: float = 0.1,\n        v_r: float = -55.0,\n        v_t: float = -40.0,\n        a: float = 0.1,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 2.0,\n        v_peak: float = 25.0,\n        nonlin: float = 0.1,\n        I_app: float = 0.0,\n        tau_ampa: float = 2.0,\n        tau_gaba: float = 5.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -80.0,\n        base_mean: float = 0.0,\n        base_noise: float = 0.0,\n        rate_base_noise: float = 0.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} : population\n            k              = {k} : population\n            b_n            = {b_n} : population\n            a_s            = {a_s} : population\n            a_n            = {a_n} : population\n            v_r            = {v_r} : population\n            v_t            = {v_t} : population\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            v_peak         = {v_peak} : population\n            nonlin         = {nonlin} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app} # pA\n            base_mean      = {base_mean}\n            base_noise     = {base_noise}\n            rate_base_noise = {rate_base_noise}\n        \"\"\"\n\n        syn = _syn_default\n        i_v = f\"root_func(I_app {_I_syn}, nonlin) - n + I_base\"\n        prefix = _I_base_noise\n        affix = \"\"\"\n            ds/dt     = a_s*(pos(u)**0.1 - s)\n            dn/dt     = a_n*(b_n*(pos(u)**0.1-s) - n)\n        \"\"\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(\n                syn=syn, i_v=i_v, prefix=prefix, affix=affix\n            ),\n            functions=\"\"\"\n                root_func(x,y)=((abs(x))**(1/y))/((x+1e-20)/(abs(x)+ 1e-20))\n            \"\"\",\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_Corbit_FSI_noisy_base\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in the baseline current. Additional slow currents were added to fit\n                the striatal FSI neuron model from Corbit et al. (2016).\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/neuron_models/#CompNeuroPy.neuron_models.final_models.izhikevich_2007_like_nm.Izhikevich2007NoisyAmpaOscillating","title":"<code>Izhikevich2007NoisyAmpaOscillating</code>","text":"<p>             Bases: <code>Neuron</code></p> <p>TEMPLATE</p> <p>Izhikevich (2007)-like neuron model with conductance-based AMPA and GABA synapses with noise in the AMPA conductance. An additional oscillating current was added to the model.</p> <p>Parameters:</p> Name Type Description Default <code>C</code> <code>float</code> <p>Membrane capacitance.</p> <code>20.0</code> <code>k</code> <code>float</code> <p>Scaling factor for the quadratic term in the membrane potential.</p> <code>1.0</code> <code>v_r</code> <code>float</code> <p>Resting membrane potential.</p> <code>-55.0</code> <code>v_t</code> <code>float</code> <p>Instantaneous activation threshold potential.</p> <code>-40.0</code> <code>a</code> <code>float</code> <p>Time scale of the recovery variable u.</p> <code>0.1</code> <code>b</code> <code>float</code> <p>Sensitivity of the recovery variable u to the the membrane potential v.</p> <code>-2.0</code> <code>c</code> <code>float</code> <p>After-spike reset value of the membrane potential.</p> <code>-50.0</code> <code>d</code> <code>float</code> <p>After-spike change of the recovery variable u.</p> <code>2.0</code> <code>v_peak</code> <code>float</code> <p>Spike cut-off value for the membrane potential.</p> <code>25.0</code> <code>I_app</code> <code>float</code> <p>External applied input current.</p> <code>0.0</code> <code>tau_ampa</code> <code>float</code> <p>Time constant of the AMPA synapse.</p> <code>2.0</code> <code>tau_gaba</code> <code>float</code> <p>Time constant of the GABA synapse.</p> <code>5.0</code> <code>E_ampa</code> <code>float</code> <p>Reversal potential of the AMPA synapse.</p> <code>0.0</code> <code>E_gaba</code> <code>float</code> <p>Reversal potential of the GABA synapse.</p> <code>-80.0</code> <code>increase_noise</code> <code>float</code> <p>Increase of AMPA conductance due to noise (equal to a Poisson distributed spike train as input).</p> <code>0.0</code> <code>rates_noise</code> <code>float</code> <p>Rate of the noise in the AMPA conductance.</p> <code>0.0</code> <code>freq</code> <code>float</code> <p>Frequency of the oscillating current.</p> <code>0.0</code> <code>amp</code> <code>float</code> <p>Amplitude of the oscillating current.</p> <code>300.0</code> Variables to record <ul> <li>osc</li> <li>g_ampa</li> <li>g_gaba</li> <li>I_v</li> <li>v</li> <li>u</li> <li>r</li> </ul> Source code in <code>src/CompNeuroPy/neuron_models/final_models/izhikevich_2007_like_nm.py</code> <pre><code>class Izhikevich2007NoisyAmpaOscillating(Neuron):\n    \"\"\"\n    TEMPLATE\n\n    [Izhikevich (2007)](https://isbnsearch.org/isbn/9780262090438)-like neuron model\n    with conductance-based AMPA and GABA synapses with noise in the AMPA conductance.\n    An additional oscillating current was added to the model.\n\n    Parameters:\n        C (float, optional):\n            Membrane capacitance.\n        k (float, optional):\n            Scaling factor for the quadratic term in the membrane potential.\n        v_r (float, optional):\n            Resting membrane potential.\n        v_t (float, optional):\n            Instantaneous activation threshold potential.\n        a (float, optional):\n            Time scale of the recovery variable u.\n        b (float, optional):\n            Sensitivity of the recovery variable u to the the membrane potential v.\n        c (float, optional):\n            After-spike reset value of the membrane potential.\n        d (float, optional):\n            After-spike change of the recovery variable u.\n        v_peak (float, optional):\n            Spike cut-off value for the membrane potential.\n        I_app (float, optional):\n            External applied input current.\n        tau_ampa (float, optional):\n            Time constant of the AMPA synapse.\n        tau_gaba (float, optional):\n            Time constant of the GABA synapse.\n        E_ampa (float, optional):\n            Reversal potential of the AMPA synapse.\n        E_gaba (float, optional):\n            Reversal potential of the GABA synapse.\n        increase_noise (float, optional):\n            Increase of AMPA conductance due to noise (equal to a Poisson distributed\n            spike train as input).\n        rates_noise (float, optional):\n            Rate of the noise in the AMPA conductance.\n        freq (float, optional):\n            Frequency of the oscillating current.\n        amp (float, optional):\n            Amplitude of the oscillating current.\n\n    Variables to record:\n        - osc\n        - g_ampa\n        - g_gaba\n        - I_v\n        - v\n        - u\n        - r\n    \"\"\"\n\n    # For reporting\n    _instantiated = []\n\n    def __init__(\n        self,\n        C: float = 20.0,\n        k: float = 1.0,\n        v_r: float = -55.0,\n        v_t: float = -40.0,\n        a: float = 0.1,\n        b: float = -2.0,\n        c: float = -50.0,\n        d: float = 2.0,\n        v_peak: float = 25.0,\n        I_app: float = 0.0,\n        tau_ampa: float = 2.0,\n        tau_gaba: float = 5.0,\n        E_ampa: float = 0.0,\n        E_gaba: float = -80.0,\n        increase_noise: float = 0.0,\n        rates_noise: float = 0.0,\n        freq: float = 0.0,\n        amp: float = 300.0,\n    ):\n        # Create the arguments\n        parameters = f\"\"\"\n            C              = {C} : population\n            k              = {k} : population\n            v_r            = {v_r} : population\n            v_t            = {v_t} : population\n            a              = {a} : population\n            b              = {b} : population\n            c              = {c} : population\n            d              = {d} : population\n            v_peak         = {v_peak} : population\n            tau_ampa       = {tau_ampa} : population\n            tau_gaba       = {tau_gaba} : population\n            E_ampa         = {E_ampa} : population\n            E_gaba         = {E_gaba} : population\n            I_app          = {I_app} # pA\n            increase_noise = {increase_noise} : population\n            rates_noise    = {rates_noise}\n            freq           = {freq}\n            amp            = {amp}\n        \"\"\"\n\n        syn = _syn_noisy\n        i_v = f\"I_app {_I_syn} + osc\"\n        prefix = \"osc = amp * sin(t * 2 * pi * (freq  /1000))\"\n\n        super().__init__(\n            parameters=parameters,\n            equations=_get_equation_izhikevich_2007(syn=syn, i_v=i_v, prefix=prefix),\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"Izhikevich2007_noisy_AMPA_oscillating\",\n            description=\"\"\"\n                Standard neuron model from Izhikevich (2007) with additional\n                conductance based synapses for AMPA and GABA currents with noise\n                in AMPA conductance. An additional oscillating current was added\n                to the model.\n            \"\"\",\n        )\n\n        # For reporting\n        self._instantiated.append(True)\n</code></pre>"},{"location":"built_in/synapse_models/","title":"Synapse Models","text":""},{"location":"built_in/synapse_models/#CompNeuroPy.synapse_models.synapse_models.FactorSynapse","title":"<code>FactorSynapse</code>","text":"<p>             Bases: <code>Synapse</code></p> <p>Synapse which scales the transmitted value by a specified factor. Factor is equivalent to the connection weight if weight==1.</p> <p>Parameters:</p> Name Type Description Default <code>max_trans</code> <code>float</code> <p>Maximum value that can be transmitted. Default: None.</p> <code>None</code> <code>mod_factor</code> <code>float</code> <p>Factor by which the weight value is multiplied. Default: 0.</p> <code>0</code> Source code in <code>src/CompNeuroPy/synapse_models/synapse_models.py</code> <pre><code>class FactorSynapse(Synapse):\n    \"\"\"\n    Synapse which scales the transmitted value by a specified factor. Factor is\n    equivalent to the connection weight if weight==1.\n\n    Parameters:\n        max_trans (float, optional):\n            Maximum value that can be transmitted. Default: None.\n        mod_factor (float, optional):\n            Factor by which the weight value is multiplied. Default: 0.\n    \"\"\"\n\n    def __init__(self, max_trans: None | float = None, mod_factor: float = 0):\n        super().__init__(\n            parameters=f\"\"\"\n            {f\"max_trans  = {max_trans}\" if max_trans is not None else \"\"}\n            mod_factor = {mod_factor}\n        \"\"\",\n            equations=\"\",\n            pre_spike=f\"\"\"\n            g_target += w * mod_factor {\": max = max_trans\" if max_trans is not None else \"\"}\n        \"\"\",\n            name=\"factor_synapse\",\n            description=\"\"\"\n            Synapse which scales the transmitted value by a specified factor. Factor is\n            equivalent to the connection weight if weight==1.\n        \"\"\",\n        )\n</code></pre>"},{"location":"examples/dbs/","title":"DBS Simulator","text":""},{"location":"examples/dbs/#simple-example","title":"Simple example","text":""},{"location":"examples/dbs/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the DBSstimulator class to implement DBS in a network. It is shown how to create a DBSstimulator, how to use it and how to update pointers. In this simple example only the depolarization of the stimulated population is demostrated. All other possible DBS mechanisms are demonstrated in the other example dbs_stimulator.py.</p>"},{"location":"examples/dbs/#code","title":"Code","text":"<pre><code>from ANNarchy import Population, Izhikevich, compile, simulate\nfrom CompNeuroPy import DBSstimulator\n\nfrom ANNarchy import setup\nfrom CompNeuroPy import CompNeuroMonitors, PlotRecordings\n\nsetup(dt=0.1)\n\n# create populations\npopulation1 = Population(10, neuron=Izhikevich, name=\"my_pop1\")\npopulation2 = Population(10, neuron=Izhikevich, name=\"my_pop2\")\n\n# create DBS stimulator\ndbs = DBSstimulator(\n    stimulated_population=population1,\n    population_proportion=0.5,\n    dbs_depolarization=30,\n    auto_implement=True,\n)\n\n# if you work with names of populations/projections everything will work, but if you\n# want to work with pointers you have to update them after calling the DBSstimulator\npopulation1, population2 = dbs.update_pointers(pointer_list=[population1, population2])\n\n# compile network\ncompile()\n\n# create monitors\nmonitors = CompNeuroMonitors({\"my_pop1\": \"v\", \"my_pop2\": \"v\"})\nmonitors.start()\n\n# run simulation\n# 1000 ms without dbs\nsimulate(1000)\n# 1000 ms with dbs\ndbs.on()\nsimulate(1000)\n# 1000 ms without dbs\ndbs.off()\nsimulate(1000)\n\n# plot recordings\nPlotRecordings(\n    figname=\"dbs_stimulator_simple.png\",\n    recordings=monitors.get_recordings(),\n    recording_times=monitors.get_recording_times(),\n    chunk=0,\n    shape=(2, 1),\n    plan={\n        \"position\": [1, 2],\n        \"compartment\": [\"my_pop1\", \"my_pop2\"],\n        \"variable\": [\"v\", \"v\"],\n        \"format\": [\"matrix\", \"matrix\"],\n    },\n)\n</code></pre>"},{"location":"examples/dbs/#console-output","title":"Console Output","text":"<pre><code>$ python dbs_stimulator_simple.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nCompiling ...  OK \nGenerate fig dbs_stimulator_simple.png... Done\n</code></pre>"},{"location":"examples/dbs/#complex-example","title":"Complex Example","text":""},{"location":"examples/dbs/#introduction_1","title":"Introduction","text":"<p>In this example, the DBS stimulator is tested with a simple spiking and rate-coded model. The spiking model is based on the Izhikevich model with conductance-based synapses. The rate-coded model is based on neurons including membrane potential and a resulting firing rate. The DBS stimulator is tested with different stimulation parameters. The resulting activity of the populations is compared to the expected activity (not part of example, included for testing purposes only). The resulting activity of the populations is plotted. The figures are saved in the DBS_spiking_figure and DBS_rate_figure folders. The different DBS conditions are:     - no stimulation     - orthodromic stimulation of efferents     - orthodromic stimulation of afferents     - orthodromic stimulation of efferents and afferents     - orthodromic stimulation of passing fibres     - depolarization of the stimulated population     - antidromic stimulation of efferents     - antidromic stimulation of afferents     - antidromic stimulation of efferents and afferents     - antidromic stimulation of passing fibres     - antidromic stimulation of passing fibres with lower strength     - full dbs stimulation     - full dbs stimulation without axon spikes (only effective for spiking model)     - full dbs stimulation without axon_rate_amp (only effective for rate-coded model)</p> <p>Warning</p> <p>For rate-coded models, antidromic stimulation of projections is not available.</p>"},{"location":"examples/dbs/#code_1","title":"Code","text":"<pre><code>from ANNarchy import (\n    Neuron,\n    Population,\n    setup,\n    simulate,\n    Projection,\n    get_population,\n    get_projection,\n    DefaultRateCodedSynapse,\n    DefaultSpikingSynapse,\n    dt,\n    Constant,\n)\nfrom CompNeuroPy import (\n    CompNeuroMonitors,\n    PlotRecordings,\n    CompNeuroModel,\n    cnp_clear,\n    DBSstimulator,\n)\nfrom CompNeuroPy.monitors import RecordingTimes\nimport numpy as np\n\n### setup ANNarchy\nsetup(dt=0.1, seed=12345)\n\n\n### create dbs test model\nclass dbs_test_model_class:\n    \"\"\"\n    Class to create dbs test model.\n\n    The used neuron models have the following constraints:\n        The neuron model has to contain the following parameters:\n        - base_mean: mean of the base current\n        - base_noise: standard deviation of the base current noise\n        Spiking neuron models have to contain conductance based synapses using the\n        following conductance variables:\n        - g_ampa: excitatory synapse\n        - g_gaba: inhibitory synapse\n        Rate neuron models have to contain the following input variables:\n        - sum(ampa): excitatory input\n        - sum(gaba): inhibitory input\n        For DBS rate-coded models have to contain a membrane potential variable mp\n        and spiking models have to be Izhihkevich models.\n\n    Model structure:\n    -------------------------\n            POP1       POP2\n            |          |\n            o          v\n    DBS---&gt;POP3------oPOP4\n                .----.\n                |    |\n            POP5   '--&gt;POP6\n\n    -o = inhibitory synapse\n    -&gt; = excitatory synapse\n    .-&gt; = passing fibre excitatory synapse\n\n    Attributes:\n        model (CompNeuroModel):\n            dbs test model\n    \"\"\"\n\n    def __init__(self, mode) -&gt; None:\n        \"\"\"\n        Initialize dbs test model\n\n        Args:\n            mode (str):\n                Mode of the dbs test model, either \"spiking\" or \"rate-coded\"\n        \"\"\"\n        ### constants should still be available after DBSstimulator recreates the model\n        ### test this by creating this constant\n        Constant(\"my_important_const\", 0.0)\n\n        ### check if model to create is spiking or rate-coded\n        if mode == \"spiking\":\n            self.model = CompNeuroModel(\n                model_creation_function=self.create_model,\n                model_kwargs={\n                    \"neuron_model\": self.get_neuron_model_spiking(),\n                    \"base_current_list\": [40, 100, 200, 50, 40, 40],\n                    \"base_current_noise\": 40,\n                },\n                name=\"dbs_test_spiking\",\n                description=\"Simple spiking model to test dbs\",\n                do_compile=False,\n            )\n        elif mode == \"rate-coded\":\n            self.model = CompNeuroModel(\n                model_creation_function=self.create_model,\n                model_kwargs={\n                    \"neuron_model\": self.get_neuron_model_rate_coded(),\n                    \"base_current_list\": [0.35, 0.7, 1.1, 0.85, 0.35, 0.35],\n                    \"base_current_noise\": 0.01,\n                    \"weight_list\": [0.3, 0.4, 0.3, 0.1],\n                    \"prob_list\": [0.5, 0.7, 0.7, 0.5],\n                },\n                name=\"dbs_test_rate-coded\",\n                description=\"Simple rate-coded model to test dbs\",\n                do_compile=False,\n            )\n        else:\n            raise ValueError(\"Neuron model not recognized\")\n\n    def create_model(\n        self,\n        neuron_model: Neuron,\n        pop_size: int = 10,\n        base_current_list: list = [0, 0, 0, 0, 0, 0],\n        base_current_noise: float = 0.0,\n        prob_list: list = [0.5, 0.5, 0.5, 0.5],\n        weight_list: list = [1.0, 1.0, 1.0, 1.0],\n    ):\n        \"\"\"\n        Create dbs test model\n\n        Args:\n            neuron_model (Neuron):\n                Neuron model to use for the dbs test model\n            pop_size (int, optional):\n                Number of neurons in each population. Default: 10\n            base_current_list (list, optional):\n                List of base currents for the four populations.\n                Default: [0, 0, 0, 0, 0, 0]\n            base_current_noise (float, optional):\n                Standard deviation of the base current noise. Default: 0\n            prob_list (list, optional):\n                List of connection probabilities for the inhibitory and excitatory path.\n                Default: [0.5, 0.5, 0.5, 0.5]\n            weight_list (list, optional):\n                List of connection weights for the inhibitory and excitatory path.\n                Default: [0.1, 0.1, 0.1, 0.1]\n        \"\"\"\n        ### create populations\n        pop1 = Population(pop_size, neuron_model, name=f\"pop1_{neuron_model.name}\")\n        pop2 = Population(pop_size, neuron_model, name=f\"pop2_{neuron_model.name}\")\n        pop3 = Population(pop_size, neuron_model, name=f\"pop3_{neuron_model.name}\")\n        pop4 = Population(pop_size, neuron_model, name=f\"pop4_{neuron_model.name}\")\n        pop5 = Population(pop_size, neuron_model, name=f\"pop5_{neuron_model.name}\")\n        pop6 = Population(pop_size, neuron_model, name=f\"pop6_{neuron_model.name}\")\n\n        ### create projections of inhhibitory path\n        proj_1_3 = Projection(\n            pre=pop1,\n            post=pop3,\n            target=\"gaba\",\n            name=f\"proj_1_3_{neuron_model.name}\",\n            synapse=self.get_synapse(neuron_model.name),\n        )\n        proj_1_3.connect_fixed_probability(\n            probability=prob_list[0],\n            weights=weight_list[0],\n        )\n        proj_3_4 = Projection(\n            pre=pop3,\n            post=pop4,\n            target=\"gaba\",\n            name=f\"proj_3_4_{neuron_model.name}\",\n            synapse=self.get_synapse(neuron_model.name),\n        )\n        proj_3_4.connect_fixed_probability(\n            probability=prob_list[1],\n            weights=weight_list[1],\n        )\n        ### create projections of excitatory path\n        proj_2_4 = Projection(\n            pre=pop2,\n            post=pop4,\n            target=\"ampa\",\n            name=f\"proj_2_4_{neuron_model.name}\",\n            synapse=self.get_synapse(neuron_model.name),\n        )\n        proj_2_4.connect_fixed_probability(\n            probability=prob_list[2],\n            weights=weight_list[2],\n        )\n        ### create projection of passing fibres\n        proj_5_6 = Projection(\n            pre=pop5,\n            post=pop6,\n            target=\"ampa\",\n            name=f\"proj_5_6_{neuron_model.name}\",\n            synapse=self.get_synapse(neuron_model.name),\n        )\n        proj_5_6.connect_fixed_probability(\n            probability=prob_list[3],\n            weights=weight_list[3],\n        )\n\n        ### set baseline activity parameters\n        pop1.base_mean = base_current_list[0]\n        pop2.base_mean = base_current_list[1]\n        pop3.base_mean = base_current_list[2]\n        pop4.base_mean = base_current_list[3]\n        pop5.base_mean = base_current_list[4]\n        pop6.base_mean = base_current_list[5]\n        pop1.base_noise = base_current_noise\n        pop2.base_noise = base_current_noise\n        pop3.base_noise = base_current_noise\n        pop4.base_noise = base_current_noise\n        pop5.base_noise = base_current_noise\n        pop6.base_noise = base_current_noise\n\n    def get_neuron_model_spiking(self):\n        \"\"\"\n        Get neuron model with spiking dynamics\n\n        Returns\n            neuron_model (Neuron):\n                Neuron model with spiking dynamics\n        \"\"\"\n        neuron_model = Neuron(\n            parameters=\"\"\"\n                C      = 100     : population # pF\n                k      = 0.7     : population # pS * mV**-1\n                v_r    = -60     : population # mV\n                v_t    = -40     : population # mV\n                a      = 0.03     : population # ms**-1\n                b      = -2     : population # nS\n                c      = -50     : population # mV\n                d      = 100     : population # pA\n                v_peak = 35     : population # mV\n                I_app  = 0     # pA\n                tau_ampa = 10  : population # ms\n                tau_gaba = 10  : population # ms\n                E_ampa   = 0   : population # mV\n                E_gaba   = -90 : population # mV\n                base_mean       = 0 # pA\n                base_noise      = 0 # pA\n                rate_base_noise = 100 # Hz\n            \"\"\",\n            equations=\"\"\"\n                ### noisy base input\n                offset_base = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rate_base_noise, offset_base, Normal(0., 1.) * base_noise)\n                I_base      = base_mean + offset_base + my_important_const\n                ### input conductances\n                dg_ampa/dt = -g_ampa/tau_ampa\n                dg_gaba/dt = -g_gaba/tau_gaba\n                ### input currents\n                I = I_app - g_ampa*neg(v - E_ampa) - g_gaba*pos(v - E_gaba) + I_base\n                ### membrane potential and recovery variable\n                C * dv/dt  = k*(v - v_r)*(v - v_t) - u + I\n                du/dt      = a*(b*(v - v_r) - u)\n            \"\"\",\n            spike=\"v &gt;= v_peak\",\n            reset=\"\"\"\n                v = c\n                u = u + d\n            \"\"\",\n            name=\"spiking\",\n            description=\"\"\"\n                Simple neuron model equations from Izhikevich (2007) using regular-spiking parameters\n                with conductance-based AMPA and GABA synapses/currents.\n            \"\"\",\n        )\n        return neuron_model\n\n    def get_neuron_model_rate_coded(self):\n        \"\"\"\n        Get neuron model with rate-coded dynamics\n\n        Returns:\n            neuron_model (Neuron):\n                Neuron model with rate-coded dynamics\n        \"\"\"\n        neuron_model = Neuron(\n            parameters=\"\"\"\n                tau = 10.0 : population\n                sigma = 0.6 : population\n                I_0 = 0.2 : population\n                I_app = 0.\n                base_mean       = 0\n                base_noise      = 0\n                rate_base_noise = 100 # Hz\n                # = (sigma*I_0 + I_0)/(sigma - sigma*I_0) : population\n                c = (0.6*0.2 + 0.2)/(0.6 - 0.6*0.2) : population\n            \"\"\",\n            equations=\"\"\"\n                ### noisy base input\n                offset_base = ite(Uniform(0.0, 1.0) * 1000.0 / dt &gt; rate_base_noise, offset_base, Normal(0., 1.) * base_noise)\n                I_base      = base_mean + offset_base + my_important_const\n                ### input currents\n                I = sum(ampa) - sum(gaba) + I_base + I_app\n                ### membrane potential\n                tau * dmp/dt = -mp + I\n                mp_r = mp: min=-0.99*sigma\n                ### activation function\n                r = activation(mp_r,sigma,c) : max=1., min=0.\n            \"\"\",\n            name=\"rate-coded\",\n            functions=\"\"\"\n                activation(x,sigma,c) = ((sigma*x + x)/(sigma + x)) * (1 + c) - c\n            \"\"\",\n            description=\"Rate-coded neuron with excitatory (ampa) and inhibitory (gaba) inputs plus baseline and noise.\",\n        )\n        return neuron_model\n\n    def get_synapse(self, mode):\n        \"\"\"\n        Create a synapse.\n\n        Args:\n            mode (str):\n                Mode of the dbs test model, either \"spiking\" or \"rate-coded\"\n\n        Returns:\n            synapse (DefaultRateCodedSynapse or DefaultSpikingSynapse):\n                Synapse object\n        \"\"\"\n        if mode == \"rate-coded\":\n            return DefaultRateCodedSynapse()\n        elif mode == \"spiking\":\n            return DefaultSpikingSynapse()\n        else:\n            raise ValueError(\"Neuron model not recognized\")\n\n\ndef do_simulation(\n    mon: CompNeuroMonitors,\n    dbs: DBSstimulator,\n    dbs_val_list: list[list],\n    dbs_key_list: list[str],\n):\n    \"\"\"\n    Do the simulation\n\n    Args:\n        mon (CompNeuroMonitors):\n            CompNeuroMonitors object\n        dbs (DBSstimulator):\n            DBS stimulator object\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        dbs_key_list (list[str]):\n            List of DBS stimulation keys used by the dbs.on() function\n\n    Returns:\n        recordings (list):\n            List of recordings from the monitors\n        recording_times (RecordingTimes):\n            Recording times object\n    \"\"\"\n    ### run initial ramp up simulation\n    simulate(2000.0)\n\n    ### start monitors\n    mon.start()\n\n    ### loop over trials\n    for trial in range(len(dbs_val_list)):\n        ### 1000 ms with DBS off\n        simulate(1000.0)\n        ### 500 ms with DBS on\n        dbs.on(\n            **{\n                dbs_key_list[i]: dbs_val_list[trial][i]\n                for i in range(len(dbs_key_list))\n            }\n        )\n        simulate(500.0)\n        ### 1000 ms with DBS off\n        dbs.off()\n        simulate(1000.0)\n        mon.reset(model=False)\n\n    ### get data from monitors\n    recordings = mon.get_recordings()\n    recording_times = mon.get_recording_times()\n\n    return recordings, recording_times\n\n\ndef check_dbs_effects_spiking(\n    dbs_val_list: list[list],\n    recordings: list,\n    model: CompNeuroModel,\n    recording_times: RecordingTimes,\n):\n    \"\"\"\n    Check if the dbs effects are as expecteds.\n\n    Args:\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        recordings (list):\n            List of recordings from the monitors\n        model (CompNeuroModel):\n            Model used for the simulation\n        recording_times (RecordingTimes):\n            Recording times object\n    \"\"\"\n    ### effects_on_activity_list contains the expected effects of dbs on the activity of the populations for each trial\n    ### 0 means no effect, 1 means increase, -1 means decrease\n    effects_on_activity = [\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, -1, 0, 0],\n        [0, 0, -1, 1, 0, 0],\n        [0, 0, -1, -1, 0, 0],\n        [0, 0, 0, 0, 0, 1],\n        [0, 0, -1, 1, 0, 0],\n        [0, 0, -1, 1, 0, 0],\n        [-1, 0, 0, 0, 0, 0],\n        [-1, 0, -1, 1, 0, 0],\n        [0, 0, 0, 0, -1, 0],\n        [0, 0, 0, 0, 0, 0],\n        [-1, 0, -1, -1, -1, 1],\n        [0, 0, -1, 1, 0, 0],\n        [-1, 0, -1, -1, -1, 1],\n    ]\n    ### check if the expected effects are present in the data\n    effect_list = []\n    high_effect_list = []\n    low_effect_list = []\n    for trial_idx, trial in enumerate(range(len(dbs_val_list))):\n        effect_list.append([])\n        for pop_name_idx, pop_name in enumerate(model.populations):\n            v_arr = recordings[trial][f\"{pop_name};v\"]\n            ### mean over neurons\n            v_arr = np.mean(v_arr, axis=1)\n            ### mean of first period\n            v_mean_1 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt()))\n                ]\n            )\n            v_std_1 = np.std(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt()))\n                ]\n            )\n            ### mean of second period\n            v_mean_2 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt()))\n                ]\n            )\n            ### mean of third period\n            v_mean_3 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(2000 / dt()))\n                ]\n            )\n            v_std_3 = np.std(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(2000 / dt()))\n                ]\n            )\n            ### get meand depending on dbs\n            mean_on = v_mean_2\n            mean_off = (v_mean_1 + v_mean_3) / 2\n            std_off = (v_std_1 + v_std_3) / 2\n            ### calculate effect\n            effect = (mean_on - mean_off) / std_off\n            if effect &gt; 1:\n                high_effect_list.append(abs(effect))\n                effect = 1\n            elif effect &lt; -1:\n                high_effect_list.append(abs(effect))\n                effect = -1\n            else:\n                low_effect_list.append(abs(effect))\n                effect = 0\n\n            effect_list[trial_idx].append(effect)\n\n    assert (\n        np.array(effects_on_activity).astype(int) == np.array(effect_list).astype(int)\n    ).all(), \"Effects on activity not as expected for spiking model\"\n\n\ndef check_dbs_effects_rate_coded(\n    dbs_val_list: list[list],\n    recordings: list,\n    model: CompNeuroModel,\n    recording_times: RecordingTimes,\n):\n    \"\"\"\n    Check if the dbs effects are as expected.\n\n    Args:\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        recordings (list):\n            List of recordings from the monitors\n        model (CompNeuroModel):\n            Model used for the simulation\n        recording_times (RecordingTimes):\n            Recording times object\n    \"\"\"\n    ### effects_on_activity_list contains the expected effects of dbs on the activity of the populations for each trial\n    ### 0 means no effect, 1 means increase, -1 means decrease\n    effects_on_activity = [\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, -1, 0, 0],\n        [0, 0, -1, 1, 0, 0],\n        [0, 0, -1, -1, 0, 0],\n        [0, 0, 0, 0, 0, 1],\n        [0, 0, -1, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, -1, -1, 0, 1],\n        [0, 0, -1, -1, 0, 1],\n        [0, 0, -1, 1, 0, 0],\n    ]\n    ### check if the expected effects are present in the data\n    effect_list = []\n    high_effect_list = []\n    low_effect_list = []\n    for trial_idx, trial in enumerate(range(len(dbs_val_list))):\n        effect_list.append([])\n        for pop_name_idx, pop_name in enumerate(model.populations):\n            v_arr = recordings[trial][f\"{pop_name};r\"]\n            ### mean over neurons\n            v_arr = np.mean(v_arr, axis=1)\n            ### mean of first period\n            v_mean_1 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt()))\n                ]\n            )\n            v_std_1 = np.std(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt()))\n                ]\n            )\n            ### mean of second period\n            v_mean_2 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1000 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt()))\n                ]\n            )\n            ### mean of third period\n            v_mean_3 = np.mean(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(2000 / dt()))\n                ]\n            )\n            v_std_3 = np.std(\n                v_arr[\n                    recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(1500 / dt())) : recording_times.idx_lims(chunk=trial)[0]\n                    + int(round(2000 / dt()))\n                ]\n            )\n            ### get meand depending on dbs\n            mean_on = v_mean_2\n            mean_off = (v_mean_1 + v_mean_3) / 2\n            std_off = (v_std_1 + v_std_3) / 2\n            ### calculate effect\n            effect = (mean_on - mean_off) / std_off\n            if effect &gt; 2.5:\n                high_effect_list.append(abs(effect))\n                effect = 1\n            elif effect &lt; -2.5:\n                high_effect_list.append(abs(effect))\n                effect = -1\n            else:\n                low_effect_list.append(abs(effect))\n                effect = 0\n\n            effect_list[trial_idx].append(effect)\n    assert (\n        np.array(effects_on_activity).astype(int) == np.array(effect_list).astype(int)\n    ).all(), \"Effects on activity not as expected for rate-coded model\"\n\n\ndef plot_spiking(\n    dbs_val_list: list[list],\n    recordings: list,\n    recording_times: RecordingTimes,\n    model: CompNeuroModel,\n    plotting: bool,\n):\n    \"\"\"\n    Plot spiking data.\n\n    Args:\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        recordings (list):\n            List of recordings from the monitors\n        recording_times (RecordingTimes):\n            Recording times object\n        model (CompNeuroModel):\n            Model used for the simulation\n        plotting (bool):\n            If True, plots are created\n    \"\"\"\n    if not plotting:\n        return\n\n    ### plot data\n    for trial in range(len(dbs_val_list)):\n        PlotRecordings(\n            figname=f\"DBS_spiking_figure/membrane_trial_{trial}.png\",\n            recordings=recordings,\n            recording_times=recording_times,\n            chunk=trial,\n            shape=(3, 2),\n            plan={\n                \"position\": np.arange(len(model.populations), dtype=int) + 1,\n                \"compartment\": model.populations,\n                \"variable\": [\"v\"] * len(model.populations),\n                \"format\": [\"matrix\"] * len(model.populations),\n            },\n            time_lim=(\n                recording_times.time_lims(chunk=trial)[0] + 500,\n                recording_times.time_lims(chunk=trial)[1] - 500,\n            ),\n        )\n        PlotRecordings(\n            figname=f\"DBS_spiking_figure/axon_spikes_{trial}.png\",\n            recordings=recordings,\n            recording_times=recording_times,\n            chunk=trial,\n            shape=(3, 2),\n            plan={\n                \"position\": np.arange(len(model.populations), dtype=int) + 1,\n                \"compartment\": model.populations,\n                \"variable\": [\"axon_spike\"] * len(model.populations),\n                \"format\": [\"raster\"] * len(model.populations),\n            },\n            time_lim=(\n                recording_times.time_lims(chunk=trial)[0] + 1000,\n                recording_times.time_lims(chunk=trial)[0] + 1030,\n            ),\n        )\n\n\ndef plot_rate_coded(\n    dbs_val_list: list[list],\n    recordings: list,\n    recording_times: RecordingTimes,\n    model: CompNeuroModel,\n    plotting: bool,\n):\n    \"\"\"\n    Plot rate-coded data.\n\n    Args:\n        dbs_val_list (list[list]):\n            List of lists with DBS stimulation values used by the dbs.on() function\n        recordings (list):\n            List of recordings from the monitors\n        recording_times (RecordingTimes):\n            Recording times object\n        model (CompNeuroModel):\n            Model used for the simulation\n        plotting (bool):\n            If True, plots are created\n    \"\"\"\n    if not plotting:\n        return\n\n    ### plot data\n    for trial in range(len(dbs_val_list)):\n        PlotRecordings(\n            figname=f\"DBS_rate_figure/activity_trial_{trial}.png\",\n            recordings=recordings,\n            recording_times=recording_times,\n            chunk=trial,\n            shape=(3, 2),\n            plan={\n                \"position\": np.arange(len(model.populations), dtype=int) + 1,\n                \"compartment\": model.populations,\n                \"variable\": [\"r\"] * len(model.populations),\n                \"format\": [\"matrix\"] * len(model.populations),\n            },\n            time_lim=(\n                recording_times.time_lims(chunk=trial)[0] + 500,\n                recording_times.time_lims(chunk=trial)[1] - 500,\n            ),\n        )\n\n\ndef main(plotting: bool = False):\n    \"\"\"\n    Main function\n\n    Args:\n        plotting (bool, optional):\n            If True, plots are created. Default: False\n    \"\"\"\n    ### define simulations\n    ### i.e. the parameters for the dbs stimulator on function\n    ### do simulate calls repeatedly dbs.on() and dbs.off() with different parameters\n    ### specified in dbs_val_list\n    dbs_key_list = [\n        \"population_proportion\",\n        \"dbs_depolarization\",\n        \"orthodromic\",\n        \"antidromic\",\n        \"efferents\",\n        \"afferents\",\n        \"passing_fibres\",\n        \"passing_fibres_strength\",\n        \"axon_spikes_per_pulse\",\n        \"axon_rate_amp\",\n    ]\n    dbs_val_list = [\n        # 0 - nothing\n        [None, 0, False, False, False, False, False, 0.2, 1, 1],\n        # 1 - orthodromic efferents\n        [None, 0, True, False, True, False, False, 0.2, 1, 1],\n        # 2 - orthodromic afferents\n        [None, 0, True, False, False, True, False, 0.2, 1, 1],\n        # 3 - orthodromic efferents and afferents\n        [None, 0, True, False, True, True, False, 0.2, 1, 1],\n        # 4 - orthodromic passing fibres\n        [None, 0, True, False, False, False, True, 0.2, 1, 1],\n        # 5 - depolarization\n        [None, 100, False, False, False, False, False, 0.2, 1, 1],\n        # 6 - antidromic efferents\n        [None, 0, False, True, True, False, False, 0.2, 1, 1],\n        # 7 - antidromic afferents\n        [None, 0, False, True, False, True, False, 0.2, 1, 1],\n        # 8 - antidromic efferents and afferents\n        [None, 0, False, True, True, True, False, 0.2, 1, 1],\n        # 9 - antidromic passing fibres\n        [None, 0, False, True, False, False, True, 0.2, 1, 1],\n        # 10 - antidromic passing fibres lower strength\n        [None, 0, False, True, False, False, True, 0.01, 1, 1],\n        # 11 - all\n        [None, 100, True, True, True, True, True, 0.2, 1, 1],\n        # 12 - all without axon spikes, should not affect rate-coded model\n        [None, 100, True, True, True, True, True, 0.2, 0, 1],\n        # 13 - all without axon_rate_amp, should not affect spiking model\n        [None, 100, True, True, True, True, True, 0.2, 1, 0],\n    ]\n\n    spiking_model = True\n    rate_coded_model = True\n\n    if spiking_model:\n        ### create the spiking network\n        model = dbs_test_model_class(\"spiking\").model\n        dbs = DBSstimulator(\n            stimulated_population=get_population(\"pop3_spiking\"),\n            passing_fibres_list=[get_projection(\"proj_5_6_spiking\")],\n            passing_fibres_strength=0.2,\n            auto_implement=True,\n            model=model,\n        )\n        model = dbs.model\n\n        ### compile model\n        model.compile(compile_folder_name=\"DBS_test_spiking\")\n\n        ### create monitors\n        mon_dict = {}\n        for pop_name in model.populations:\n            mon_dict[pop_name] = [\"v\", \"spike\", \"axon_spike\"]\n        mon = CompNeuroMonitors(mon_dict)\n\n        ### run simulation and get data from monitors\n        recordings, recording_times = do_simulation(\n            mon, dbs, dbs_val_list, dbs_key_list\n        )\n\n        ### plot data\n        plot_spiking(\n            dbs_val_list=dbs_val_list,\n            recordings=recordings,\n            recording_times=recording_times,\n            model=model,\n            plotting=plotting,\n        )\n\n        ### check dbs effects\n        check_dbs_effects_spiking(\n            dbs_val_list,\n            recordings,\n            model,\n            recording_times,\n        )\n\n    if rate_coded_model:\n        ### create the rate-coded network\n        cnp_clear()\n        model = dbs_test_model_class(\"rate-coded\").model\n        dbs = DBSstimulator(\n            stimulated_population=get_population(\"pop3_rate-coded\"),\n            passing_fibres_list=[get_projection(\"proj_5_6_rate-coded\")],\n            passing_fibres_strength=0.2,\n            model=model,\n            auto_implement=True,\n        )\n        model = dbs.model\n\n        ### compile model\n        model.compile(compile_folder_name=\"DBS_test_rate_coded\")\n\n        ### create monitors\n        mon_dict = {}\n        for pop_name in model.populations:\n            mon_dict[pop_name] = [\"r\"]\n        mon = CompNeuroMonitors(mon_dict)\n\n        ### run simulation and get data from monitors\n        recordings, recording_times = do_simulation(\n            mon, dbs, dbs_val_list, dbs_key_list\n        )\n\n        ### plot data\n        plot_rate_coded(\n            dbs_val_list=dbs_val_list,\n            recordings=recordings,\n            recording_times=recording_times,\n            model=model,\n            plotting=plotting,\n        )\n\n        ### check dbs effects\n        check_dbs_effects_rate_coded(\n            dbs_val_list,\n            recordings,\n            model,\n            recording_times,\n        )\n    return 1\n\n\nif __name__ == \"__main__\":\n    main(plotting=True)\n</code></pre>"},{"location":"examples/dbs/#console-output_1","title":"Console Output","text":"<pre><code>$ python dbs_stimulator.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\n\nWARNING during compile of model dbs_test_spiking_dbs: There are initialized models which are not created, thus not compiled! models:\ndbs_test_spiking\n\nCompiling ...  OK \nGenerate fig DBS_spiking_figure/membrane_trial_0.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_0.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_1.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_1.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_2.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_2.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_3.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_3.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_4.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_4.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_5.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_5.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_6.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_6.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_7.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_7.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_8.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_8.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_9.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_9.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_10.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_10.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_11.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_11.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_12.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_12.png... \n  WARNING PlotRecordings: pop1_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop3_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop5_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\nGenerate fig DBS_spiking_figure/membrane_trial_13.png... Done\n\nGenerate fig DBS_spiking_figure/axon_spikes_13.png... \n  WARNING PlotRecordings: pop2_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop4_spiking does not contain any spikes in the given time interval.\n\n  WARNING PlotRecordings: pop6_spiking does not contain any spikes in the given time interval.\nDone\n\n\nWARNING during compile of model dbs_test_rate-coded_dbs: There are initialized models which are not created, thus not compiled! models:\ndbs_test_spiking\ndbs_test_spiking_dbs\ndbs_test_rate-coded\n\nCompiling ...  OK \nGenerate fig DBS_rate_figure/activity_trial_0.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_1.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_2.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_3.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_4.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_5.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_6.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_7.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_8.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_9.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_10.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_11.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_12.png... Done\n\nGenerate fig DBS_rate_figure/activity_trial_13.png... Done\n</code></pre>"},{"location":"examples/experiment/","title":"Define Experiments","text":""},{"location":"examples/experiment/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the CompNeuroExp class to combine simulations, model and recordings in an experiment. It is shown how to define an experiment, how to run it and how to get the results.</p>"},{"location":"examples/experiment/#code","title":"Code","text":"<pre><code>from CompNeuroPy import (\n    CompNeuroExp,\n    CompNeuroSim,\n    CompNeuroMonitors,\n    CompNeuroModel,\n    current_step,\n    current_ramp,\n    PlotRecordings,\n)\nfrom CompNeuroPy.full_models import HHmodelBischop\nfrom ANNarchy import dt, setup, get_population\n\n\n### combine both simulations and recordings in an experiment\nclass MyExp(CompNeuroExp):\n    \"\"\"\n    Define an experiment by inheriting from CompNeuroExp.\n\n    CompNeuroExp provides the attributes:\n\n        monitors (CompNeuroMonitors):\n            a CompNeuroMonitors object to do recordings, define during init otherwise\n            None\n        data (dict):\n            a dictionary for storing any optional data\n\n    and the functions:\n        reset():\n            resets the model and monitors\n        results():\n            returns a results object\n    \"\"\"\n\n    def __init__(\n        self,\n        model: CompNeuroModel,\n        sim_step: CompNeuroSim,\n        sim_ramp: CompNeuroSim,\n        monitors: CompNeuroMonitors,\n    ):\n        \"\"\"\n        Initialize the experiment and additionally store the model and simulations.\n\n        Args:\n            model (CompNeuroModel):\n                a CompNeuroModel object\n            sim_step (CompNeuroSim):\n                a CompNeuroSim object for the step simulation\n            sim_ramp (CompNeuroSim):\n                a CompNeuroSim object for the ramp simulation\n            monitors (CompNeuroMonitors):\n                a CompNeuroMonitors object\n        \"\"\"\n        self.model = model\n        self.sim_step = sim_step\n        self.sim_ramp = sim_ramp\n        super().__init__(monitors)\n\n    def run(self, E_L: float = -68.0):\n        \"\"\"\n        Do the simulations and recordings.\n\n        To use the CompNeuroExp class, you need to define a run function which\n        does the simulations and recordings. The run function should return the\n        results object which can be obtained by calling self.results().\n\n        Args:\n            E_L (float, optional):\n                leak reversal potential of the population, which is set at the beginning\n                of the experiment run. Default: -68 mV\n\n        Returns:\n            results (CompNeuroExp._ResultsCl):\n                results object with attributes:\n                    recordings (list):\n                        list of recordings\n                    recording_times (recording_times_cl):\n                        recording times object\n                    mon_dict (dict):\n                        dict of recorded variables of the monitors\n                    data (dict):\n                        dict with optional data stored during the experiment\n        \"\"\"\n        ### call reset at the beginning of the experiment to ensure that the model\n        ### is in the same state at the beginning of each experiment run\n        self.reset()\n\n        ### also always start the monitors, they are stopped automatically at the end\n        self.monitors.start()\n\n        ### set the leak reversal potential of the population, be aware that this\n        ### will be undone by the reset function if you don't set the parameters\n        ### argument to False\n        get_population(self.model.populations[0]).E_L = E_L\n\n        ### SIMULATION START\n        sim_step.run()\n        ### if you want to reset the model, you should use the objects reset()\n        ### it's the same as the ANNarchy reset + it resets the CompNeuroMonitors\n        ### creating a new chunk, optionally not changing the parameters\n        self.reset(parameters=False)\n        sim_ramp.run()\n        ### SIMULATION END\n\n        ### optional: store anything you want in the data dict, for example information\n        ### about the simulations\n        self.data[\"sim\"] = [sim_step.simulation_info(), sim_ramp.simulation_info()]\n        self.data[\"population_name\"] = self.model.populations[0]\n        self.data[\"time_step\"] = dt()\n\n        ### return results using self.results()\n        return self.results()\n\n\nif __name__ == \"__main__\":\n    ### create and compile a model\n    setup(dt=0.01)\n    model = HHmodelBischop()\n\n    ### define recordings before experiment\n    monitors = CompNeuroMonitors({model.populations[0]: [\"v\"]})\n\n    ### define some simulations e.g. using CompNeuroSim\n    sim_step = CompNeuroSim(\n        simulation_function=current_step,\n        simulation_kwargs={\n            \"pop\": model.populations[0],\n            \"t1\": 500,\n            \"t2\": 500,\n            \"a1\": 0,\n            \"a2\": 50,\n        },\n    )\n    sim_ramp = CompNeuroSim(\n        simulation_function=current_ramp,\n        simulation_kwargs={\n            \"pop\": model.populations[0],\n            \"a0\": 0,\n            \"a1\": 100,\n            \"dur\": 1000,\n            \"n\": 50,\n        },\n    )\n\n    ### init and run the experiment\n    my_exp = MyExp(monitors=monitors, model=model, sim_step=sim_step, sim_ramp=sim_ramp)\n\n    ### one use case is to run an experiment multiple times e.g. with different\n    ### parameters\n    results_run1 = my_exp.run()\n    results_run2 = my_exp.run(E_L=-90.0)\n\n    ### plot of the membrane potential from the first and second chunk using results\n    ### experiment run 1\n    PlotRecordings(\n        figname=\"example_experiment_sim_step.png\",\n        recordings=results_run1.recordings,\n        recording_times=results_run1.recording_times,\n        chunk=0,\n        shape=(1, 1),\n        plan={\n            \"position\": [1],\n            \"compartment\": [results_run1.data[\"population_name\"]],\n            \"variable\": [\"v\"],\n            \"format\": [\"line\"],\n        },\n    )\n    PlotRecordings(\n        figname=\"example_experiment_sim_ramp.png\",\n        recordings=results_run1.recordings,\n        recording_times=results_run1.recording_times,\n        chunk=1,\n        shape=(1, 1),\n        plan={\n            \"position\": [1],\n            \"compartment\": [results_run1.data[\"population_name\"]],\n            \"variable\": [\"v\"],\n            \"format\": [\"line\"],\n        },\n    )\n    ### experiment run 2\n    PlotRecordings(\n        figname=\"example_experiment2_sim_step.png\",\n        recordings=results_run2.recordings,\n        recording_times=results_run2.recording_times,\n        chunk=0,\n        shape=(1, 1),\n        plan={\n            \"position\": [1],\n            \"compartment\": [results_run2.data[\"population_name\"]],\n            \"variable\": [\"v\"],\n            \"format\": [\"line\"],\n        },\n    )\n    PlotRecordings(\n        figname=\"example_experiment2_sim_ramp.png\",\n        recordings=results_run2.recordings,\n        recording_times=results_run2.recording_times,\n        chunk=1,\n        shape=(1, 1),\n        plan={\n            \"position\": [1],\n            \"compartment\": [results_run2.data[\"population_name\"]],\n            \"variable\": [\"v\"],\n            \"format\": [\"line\"],\n        },\n    )\n\n    ### print data and mon_dict from results\n    print(\"\\nrun1:\")\n    print(\"    data:\")\n    for key, value in results_run1.data.items():\n        print(f\"        {key}:\", value)\n    print(\"    mon_dict:\")\n    for key, value in results_run1.mon_dict.items():\n        print(f\"        {key}:\", value)\n    print(\"\\nrun2:\")\n    print(\"    data:\")\n    for key, value in results_run2.data.items():\n        print(f\"        {key}:\", value)\n    print(\"    mon_dict:\")\n    for key, value in results_run2.mon_dict.items():\n        print(f\"        {key}:\", value)\n</code></pre>"},{"location":"examples/experiment/#console-output","title":"Console Output","text":"<pre><code>$ python experiment.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nCompiling ...  OK \nGenerate fig example_experiment_sim_step.png... Done\n\nGenerate fig example_experiment_sim_ramp.png... Done\n\nGenerate fig example_experiment2_sim_step.png... Done\n\nGenerate fig example_experiment2_sim_ramp.png... Done\n\n\nrun1:\n    data:\n        sim: [&lt;CompNeuroPy.generate_simulation.SimInfo object at 0x7f4798dfb700&gt;, &lt;CompNeuroPy.generate_simulation.SimInfo object at 0x7f4798dfad40&gt;]\n        population_name: HH_Bischop\n        time_step: 0.01\n    mon_dict:\n        HH_Bischop: ['v']\n\nrun2:\n    data:\n        sim: [&lt;CompNeuroPy.generate_simulation.SimInfo object at 0x7f4798dfb700&gt;, &lt;CompNeuroPy.generate_simulation.SimInfo object at 0x7f4798dfad40&gt;]\n        population_name: HH_Bischop\n        time_step: 0.01\n    mon_dict:\n        HH_Bischop: ['v']\n</code></pre>"},{"location":"examples/generate_models/","title":"Generate Models","text":""},{"location":"examples/generate_models/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the CompNeuroModel class to create and compile models. It is shown how to define a model creation function, how to initialize, create, compile a model and how to get information about the model.</p> <p>The model \"my_model\" is imported in other examples run_and_monitor_simulations.py.</p>"},{"location":"examples/generate_models/#code","title":"Code","text":"<pre><code>from ANNarchy import Population\nfrom CompNeuroPy import CompNeuroModel\nfrom CompNeuroPy.neuron_models import PoissonNeuron\nfrom tabulate import tabulate\n\n\n### define model_creation_function\ndef two_poisson(params, a):\n    \"\"\"\n    Generates two Poisson neuron populations.\n\n    Args:\n        params (dict):\n            Dictionary containing some paramters for the model with following keys:\n                's1'/'s2' : sizes of pop1/pop2\n                'n1'/'n2' : names of pop1/pop2\n        a (int):\n            Unused parameter for demonstration purposes only.\n    \"\"\"\n    ### create two populations\n    Population(params[\"s1\"], neuron=PoissonNeuron, name=params[\"n1\"])\n    Population(params[\"s2\"], neuron=PoissonNeuron, name=params[\"n2\"])\n    ### print unused parameter\n    print(f\"created model, other parameters: {a}\")\n\n\n### Let's initialize a first model\n### define the parameters argument of the model creation function\nparams = {\"s1\": 3, \"s2\": 3, \"n1\": \"first_poisson\", \"n2\": \"second_poisson\"}\n\n### use CompNeuroModel to initialize the model, not create or compile it yet\nmy_model = CompNeuroModel(\n    model_creation_function=two_poisson,\n    model_kwargs={\n        \"params\": params,\n        \"a\": 1,\n    },\n    name=\"my_model\",\n    description=\"my simple Poisson neuron model\",\n    do_create=False,\n    do_compile=False,\n    compile_folder_name=\"annarchy_my_model\",\n)\n\n### this initialized the first model\n### we could now create and compile it, but we will do this inside main\n### it could also be imported in other scripts and then created/compiled there\n\n\ndef main():\n    ### initialize a second model\n    ### this time directly create it, but not compile it yet, models can only be created\n    ### if not compiled yet\n    params = {\"s1\": 1, \"s2\": 1, \"n1\": \"pop1\", \"n2\": \"pop2\"}\n    my_model2 = CompNeuroModel(\n        model_creation_function=two_poisson,\n        model_kwargs={\"params\": params, \"a\": 2},\n        do_compile=False,\n    )\n\n    ### now create also first model, and compile everything (automatically since we did\n    ### not set do_compile=False)\n    my_model.create()\n\n    ### print some name, description, populations and projections of the models in\n    ### tabular form\n    models_data = [\n        [\n            my_model.name,\n            my_model.description,\n            my_model.populations,\n            my_model.projections,\n        ],\n        [\n            my_model2.name,\n            my_model2.description,\n            my_model2.populations,\n            my_model2.projections,\n        ],\n    ]\n    headers = [\"Model\", \"Description\", \"Populations\", \"Projections\"]\n    print(tabulate(models_data, headers, tablefmt=\"grid\"))\n\n    return 1\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/generate_models/#console-output","title":"Console Output","text":"<pre><code>$ python create_model.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\ncreated model, other parameters: 2\ncreated model, other parameters: 1\nCompiling ...  OK \n+----------+--------------------------------+-------------------------------------+---------------+\n| Model    | Description                    | Populations                         | Projections   |\n+==========+================================+=====================================+===============+\n| my_model | my simple Poisson neuron model | ['first_poisson', 'second_poisson'] | []            |\n+----------+--------------------------------+-------------------------------------+---------------+\n| model1   |                                | ['pop1', 'pop2']                    | []            |\n+----------+--------------------------------+-------------------------------------+---------------+\n</code></pre>"},{"location":"examples/monitor_recordings/","title":"Monitor Recordings","text":""},{"location":"examples/monitor_recordings/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the CompNeuroMonitors class to record variables. It is shown how to start/pause monitors, how to split recordings into chunks and optionally reset the model and how to get recordings during and after simulation.</p>"},{"location":"examples/monitor_recordings/#code","title":"Code","text":"<pre><code>from ANNarchy import Population, setup, simulate, compile\nfrom CompNeuroPy import (\n    CompNeuroMonitors,\n    PlotRecordings,\n)\nfrom CompNeuroPy.neuron_models import Izhikevich2007\n\n\ndef main():\n    ### setup ANNarchy timestep and create results folder\n    setup(dt=0.1)\n\n    ### first we create two populations, each consist of 1 neuron\n    Population(1, neuron=Izhikevich2007(I_app=0), name=\"my_pop1\")\n    Population(1, neuron=Izhikevich2007(I_app=52), name=\"my_pop2\")\n\n    ### compile\n    compile()\n\n    ### after compilation we can define the monitors using the monitor_dictionary\n    ### and the CompNeuroMonitors class\n    ### for my_pop1 we use a recording period of 2 ms\n    ### for my_pop2 we do not give a recording preiod, therefore record every timestep\n    monitor_dictionary = {\"my_pop1;2\": [\"v\", \"spike\"], \"my_pop2\": [\"v\"]}\n    mon = CompNeuroMonitors(monitor_dictionary)\n\n    ### In this part we demonstrate starting/pausing all monitors\n    ### simulate for 100 ms [0, 100]\n    simulate(100)\n\n    ### start all monitors and simulate for 100 ms [100, 200]\n    mon.start()\n    simulate(100)\n\n    ### pause all monitors and simulate for 100 ms [200, 300]\n    mon.pause()\n    simulate(100)\n\n    ### In this part we demonstrate starting single monitors\n    ### start only monitor for my_pop1 and simulate for 100 ms [300, 400]\n    mon.start(compartment_list=[\"my_pop1\"])\n    simulate(100)\n\n    ### start all monitors and simulate for 100 ms [400, 500]\n    mon.start()\n    simulate(100)\n\n    ### In this part we demonstrate pausing single monitors\n    ### pause monitor for my_pop1 and simulate for 100 ms [500, 600]\n    mon.pause(compartment_list=[\"my_pop1\"])\n    simulate(100)\n\n    ### start all monitors and simulate for 100 ms [600, 700]\n    mon.start()\n    simulate(100)\n\n    ### In this part we demonstrate chunking recordings by reset\n    ### reset WITHOUT model, creating new chunk --&gt; first chunk [0, 700]\n    ### also in this chunk do not record the first 100 ms\n    ### WITHOUT model --&gt; time continues at 700 ms [700, 800]\n    mon.reset(model=False)\n    mon.pause()\n    simulate(100)\n\n    ### start all monitors and simulate for 700 ms [800, 1500]\n    mon.start()\n    simulate(700)\n\n    ### reset WITH model, creating new chunk --&gt; second chunk [700, 1500]\n    ### in third chunk time is reset to 0 ms\n    ### also in this chunk do not record the first 100 ms [0, 100]\n    mon.reset(model=True)\n    mon.pause()\n    simulate(100)\n\n    ### start all monitors and simulate for 700 ms [100, 800]\n    mon.start()\n    simulate(700)\n\n    ### Next we demonstrate getting recordings DURING SIMULATION by using\n    ### get_recordings_and_clear\n    ### this also resets the monitors back to their initialized state, i.e. there are no\n    ### recordings and they are not started yet\n    ### recordings1 consists of 3 chunks, third chunk [0, 800]\n    recordings1, recording_times1 = mon.get_recordings_and_clear()\n\n    ### Now continue simulation, creating NEW RECORDINGS, monitors are not started yet\n    ### model was not reset, so time continues at 800 ms\n    ### simulate for 100 ms [800, 900]\n    simulate(100)\n\n    ### start all monitors and simulate for 100 ms [900, 1000]\n    mon.start()\n    simulate(100)\n\n    ### reset monitors and model, creating new chunk --&gt; first chunk [800, 1000]\n    ### simulate for 100 ms [0, 100]\n    mon.reset(model=True)\n    simulate(100)\n\n    ### get recordings using get_recordings_and_clear\n    ### this time directly start recording again\n    ### recordings2 consists of 2 chunks, second chunk [0, 100]\n    recordings2, recording_times2 = mon.get_recordings_and_clear()\n\n    ### Now continue simulation, creating NEW RECORDINGS\n    ### directly start monitors and reset model so time is reset to 0 ms\n    ### simulate for 100 ms [0, 100]\n    mon.start()\n    mon.reset(model=True)\n    simulate(100)\n\n    ### get recordings the normal way (simultions are finished)\n    ### recordings3 consists of 1 chunk [0, 100]\n    recordings3 = mon.get_recordings()\n    recording_times3 = mon.get_recording_times()\n\n    ### print the idx and time lims of the recordings and the sizes of the recorded\n    ### arrays\n    print(\"#################### ALL RECORDINGS INFO ####################\")\n    recordings_list = [recordings1, recordings2, recordings3]\n    for all_times_idx, all_times in enumerate(\n        [recording_times1.all(), recording_times2.all(), recording_times3.all()]\n    ):\n        print(f\"recordings{all_times_idx+1}\")\n        for chunk in range(len(all_times)):\n            print(f\"\\tchunk: {chunk}\")\n            for pop_name in [\"my_pop1\", \"my_pop2\"]:\n                print(f\"\\t\\tpop_name: {pop_name}\")\n                print(\n                    f\"\\t\\trecording_array_size: {recordings_list[all_times_idx][chunk][f'{pop_name};v'].shape}\"\n                )\n                for time_point in [\"start\", \"stop\"]:\n                    print(f\"\\t\\t\\ttime_point: {time_point}\")\n                    for unit in [\"ms\", \"idx\"]:\n                        print(f\"\\t\\t\\t\\tunit: {unit}\")\n                        for period in range(\n                            len(all_times[chunk][pop_name][time_point][unit])\n                        ):\n                            print(\n                                f\"\\t\\t\\t\\t\\tperiod {period}: {all_times[chunk][pop_name][time_point][unit][period]}\"\n                            )\n    print(\"#############################################################\")\n\n    ### plot recordings 1 consisting of 3 chunks\n    for chunk in range(len(recordings1)):\n        ### using plot_recordings which plots the recordings of one chunk\n        PlotRecordings(\n            figname=f\"monitor_recordings_1_chunk{chunk}.png\",\n            recordings=recordings1,\n            recording_times=recording_times1,\n            shape=(2, 2),\n            plan={\n                \"position\": [1, 2, 3],\n                \"compartment\": [\"my_pop1\", \"my_pop2\", \"my_pop1\"],\n                \"variable\": [\"v\", \"v\", \"spike\"],\n                \"format\": [\"line\", \"line\", \"raster\"],\n            },\n            chunk=chunk,\n        )\n\n    ### plot recordings 2 consisting of 2 chunks\n    for chunk in range(len(recordings2)):\n        ### using plot_recordings which plots the recordings of one chunk\n        PlotRecordings(\n            figname=f\"monitor_recordings_2_chunk{chunk}.png\",\n            recordings=recordings2,\n            recording_times=recording_times2,\n            shape=(2, 2),\n            plan={\n                \"position\": [1, 2, 3],\n                \"compartment\": [\"my_pop1\", \"my_pop2\", \"my_pop1\"],\n                \"variable\": [\"v\", \"v\", \"spike\"],\n                \"format\": [\"line\", \"line\", \"raster\"],\n            },\n            chunk=chunk,\n        )\n\n    ### plot recordings 3 consisting of 1 chunk\n    for chunk in range(len(recordings3)):\n        ### using plot_recordings which plots the recordings of one chunk\n        PlotRecordings(\n            figname=f\"monitor_recordings_3_chunk{chunk}.png\",\n            recordings=recordings3,\n            recording_times=recording_times3,\n            shape=(2, 2),\n            plan={\n                \"position\": [1, 2, 3],\n                \"compartment\": [\"my_pop1\", \"my_pop2\", \"my_pop1\"],\n                \"variable\": [\"v\", \"v\", \"spike\"],\n                \"format\": [\"line\", \"line\", \"raster\"],\n            },\n            chunk=chunk,\n        )\n\n    return 1\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/monitor_recordings/#conosole-output","title":"Conosole Output","text":"<pre><code>$ python monitor_recordings.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nCompiling ...  OK \n#################### ALL RECORDINGS INFO ####################\nrecordings1\n    chunk: 0\n        pop_name: my_pop1\n        recording_array_size: (200, 1)\n            time_point: start\n                unit: ms\n                    period 0: 100.0\n                    period 1: 300.0\n                    period 2: 600.0\n                unit: idx\n                    period 0: 0\n                    period 1: 50\n                    period 2: 150\n            time_point: stop\n                unit: ms\n                    period 0: 198.0\n                    period 1: 498.0\n                    period 2: 698.0\n                unit: idx\n                    period 0: 49\n                    period 1: 149\n                    period 2: 199\n        pop_name: my_pop2\n        recording_array_size: (4000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 100.0\n                    period 1: 400.0\n                unit: idx\n                    period 0: 0\n                    period 1: 1000\n            time_point: stop\n                unit: ms\n                    period 0: 199.9\n                    period 1: 699.9\n                unit: idx\n                    period 0: 999\n                    period 1: 3999\n    chunk: 1\n        pop_name: my_pop1\n        recording_array_size: (350, 1)\n            time_point: start\n                unit: ms\n                    period 0: 800.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 1498.0\n                unit: idx\n                    period 0: 349\n        pop_name: my_pop2\n        recording_array_size: (7000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 800.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 1499.9\n                unit: idx\n                    period 0: 6999\n    chunk: 2\n        pop_name: my_pop1\n        recording_array_size: (350, 1)\n            time_point: start\n                unit: ms\n                    period 0: 100.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 798.0\n                unit: idx\n                    period 0: 349\n        pop_name: my_pop2\n        recording_array_size: (7000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 100.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 799.9\n                unit: idx\n                    period 0: 6999\nrecordings2\n    chunk: 0\n        pop_name: my_pop1\n        recording_array_size: (50, 1)\n            time_point: start\n                unit: ms\n                    period 0: 900.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 998.0\n                unit: idx\n                    period 0: 49\n        pop_name: my_pop2\n        recording_array_size: (1000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 900.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 999.9\n                unit: idx\n                    period 0: 999\n    chunk: 1\n        pop_name: my_pop1\n        recording_array_size: (50, 1)\n            time_point: start\n                unit: ms\n                    period 0: 0.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 98.0\n                unit: idx\n                    period 0: 49\n        pop_name: my_pop2\n        recording_array_size: (1000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 0.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 99.9\n                unit: idx\n                    period 0: 999\nrecordings3\n    chunk: 0\n        pop_name: my_pop1\n        recording_array_size: (50, 1)\n            time_point: start\n                unit: ms\n                    period 0: 0.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 98.0\n                unit: idx\n                    period 0: 49\n        pop_name: my_pop2\n        recording_array_size: (1000, 1)\n            time_point: start\n                unit: ms\n                    period 0: 0.0\n                unit: idx\n                    period 0: 0\n            time_point: stop\n                unit: ms\n                    period 0: 99.9\n                unit: idx\n                    period 0: 999\n#############################################################\nGenerate fig monitor_recordings_1_chunk0.png... \n  WARNING PlotRecordings: my_pop1 does not contain any spikes in the given time interval.\nDone\n\nGenerate fig monitor_recordings_1_chunk1.png... \n  WARNING PlotRecordings: my_pop1 does not contain any spikes in the given time interval.\nDone\n\nGenerate fig monitor_recordings_1_chunk2.png... \n  WARNING PlotRecordings: my_pop1 does not contain any spikes in the given time interval.\nDone\n\nGenerate fig monitor_recordings_2_chunk0.png... \n  WARNING PlotRecordings: my_pop1 does not contain any spikes in the given time interval.\nDone\n\nGenerate fig monitor_recordings_2_chunk1.png... Done\n\nGenerate fig monitor_recordings_3_chunk0.png... Done\n</code></pre>"},{"location":"examples/plot_recordings/","title":"Plot Recordings","text":""},{"location":"examples/plot_recordings/#introduction","title":"Introduction","text":"<p>This example demonstrates how to plot recordings (from CompNeuroMonitors) using the PlotRecordings class. The different plotting formats for spiking and non-spiking data (populations and projections) are demonstrated.</p> <p>This example loads data generated with other example run_and_monitor_simulations.py.</p>"},{"location":"examples/plot_recordings/#code","title":"Code","text":"<pre><code>from CompNeuroPy import load_variables, PlotRecordings\n\n\ndef main():\n    ### load data generated with other example \"run_and_monitor_simulations.py\"\n    loaded_dict = load_variables(\n        name_list=[\"recordings\", \"recording_times\", \"increase_rates_pop_info\"],\n        path=\"run_and_monitor_simulations/\",\n    )\n\n    ### define what should be plotted in which subplot, here 14 subplots are defined to\n    ### demonstrate the different plotting formats for spiking and non-spiking variables\n    plan_dict = {\n        \"position\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14],\n        \"compartment\": [\n            \"first_poisson\",\n            \"first_poisson\",\n            \"first_poisson\",\n            \"first_poisson\",\n            \"first_poisson\",\n            \"second_poisson\",\n            \"second_poisson\",\n            \"second_poisson\",\n            \"second_poisson\",\n            \"ampa_proj\",\n            \"ampa_proj\",\n            \"ampa_proj\",\n            \"ampa_proj\",\n        ],\n        \"variable\": [\n            \"spike\",\n            \"spike\",\n            \"spike\",\n            \"spike\",\n            \"spike\",\n            \"p\",\n            \"p\",\n            \"p\",\n            \"p\",\n            \"w\",\n            \"w\",\n            \"w\",\n            \"w\",\n        ],\n        \"format\": [\n            \"raster\",\n            \"mean\",\n            \"hybrid\",\n            \"interspike\",\n            \"cv\",\n            \"line\",\n            \"line_mean\",\n            \"matrix\",\n            \"matrix_mean\",\n            \"line\",\n            \"line_mean\",\n            \"matrix\",\n            \"matrix_mean\",\n        ],\n    }\n\n    ### plot first chunk\n    PlotRecordings(\n        figname=\"run_and_monitor_simulations/my_two_poissons_chunk_0.png\",\n        recordings=loaded_dict[\"recordings\"],\n        recording_times=loaded_dict[\"recording_times\"],\n        shape=(3, 5),\n        plan=plan_dict,\n    )\n    ### plot second chunk\n    PlotRecordings(\n        figname=\"run_and_monitor_simulations/my_two_poissons_chunk_1.png\",\n        recordings=loaded_dict[\"recordings\"],\n        recording_times=loaded_dict[\"recording_times\"],\n        shape=(3, 5),\n        plan=plan_dict,\n        chunk=1,\n    )\n\n    return 1\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/plot_recordings/#console-output","title":"Console Output","text":"<pre><code>$ python plot_recordings.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\nGenerate fig run_and_monitor_simulations/my_two_poissons_chunk_0.png... Done\n\nGenerate fig run_and_monitor_simulations/my_two_poissons_chunk_1.png... Done\n</code></pre>"},{"location":"examples/run_and_monitor_simulations/","title":"Generate Simulations","text":""},{"location":"examples/run_and_monitor_simulations/#introduction","title":"Introduction","text":"<p>This example demonstrates how to use the CompNeuroSim class to define simulations. It is shown how to define the simulation functions, requirements and how to use the simulation information object.</p> <p>This example imports the \"my_model\" from other example create_model.py and saves recorded data used in other example plot_recordings.py.</p>"},{"location":"examples/run_and_monitor_simulations/#code","title":"Code","text":"<pre><code>import numpy as np\nfrom CompNeuroPy import (\n    CompNeuroMonitors,\n    CompNeuroSim,\n    ReqPopHasAttr,\n    save_variables,\n    CompNeuroModel,\n)\nfrom ANNarchy import (\n    simulate,\n    get_population,\n    Population,\n    Neuron,\n    Projection,\n    Synapse,\n    Uniform,\n)\nfrom CompNeuroPy.examples.create_model import my_model\n\n\n### CompNeuroSim is a class to define simulations\n### It requires a simulation function, which we will define here:\ndef set_rates(pop_name: str, rates: float = 0.0, duration: float = 0.0):\n    \"\"\"\n    Sets the rates variable of a population given by pop_name and simulates duration ms.\n\n    Args:\n        pop_name (str):\n            name of the population\n        rates (float, optional):\n            rates variable of the population\n        duration (float, optional):\n            duration of the simulation in ms\n    \"\"\"\n    ### set rates and simulate\n    get_population(pop_name).rates = rates\n    simulate(duration)\n\n\n### Also create a second more complex simulation function\ndef increase_rates(\n    pop_name: str | list[str],\n    rate_step: float = 0.0,\n    time_step: float = 0.0,\n    nr_steps: int = 0,\n):\n    \"\"\"\n    Increase rates variable of population(s).\n\n    Args:\n        pop_name (str or list of str):\n            name of population(s)\n        rate_step (float, optional):\n            increase of rate with each step, initial step = current rates of pop\n        time_step (float, optional):\n            duration of each step in ms\n        nr_steps (int, optional):\n            number of steps\n    \"\"\"\n\n    ### convert single pop into list\n    pop_name_list = pop_name\n    if not (isinstance(pop_name_list, list)):\n        pop_name_list = [pop_name_list]\n\n    ### define initial value for rates for each pop (assume all neurons have same rates)\n    start_rate_arr = np.array(\n        [get_population(pop_name).rates[0] for pop_name in pop_name_list]\n    )\n\n    ### simulate all steps\n    for step in range(nr_steps):\n        ### calculate rates for each pop\n        rates_arr = step * rate_step + start_rate_arr\n        ### set rates variable of all populations\n        for pop_idx, pop_name in enumerate(pop_name_list):\n            set_rates(\n                pop_name, rates=rates_arr[pop_idx], duration=0\n            )  # use already defined simulation set_rates\n        ### then simulate step\n        set_rates(pop_name_list[0], rates=rates_arr[0], duration=time_step)\n\n    ### simulation_functions can return some information which may be helpful later\n    ### the simulation arguments do not need to be returned, since they are accessible\n    ### through the CompNeuroSim object anyway (see below)\n    return {\"duration\": time_step * nr_steps, \"d_rates\": rate_step * nr_steps}\n\n\n### see below why we need this function\ndef extend_model(my_model: CompNeuroModel):\n    \"\"\"\n    Create a simple projections and a projection with decaying weights.\n\n    Args:\n        my_model (CompNeuroModel):\n            model to which the projection should be added\n    \"\"\"\n\n    ### create a simple population for later use\n    Population(1, neuron=Neuron(equations=\"r=0\"), name=\"simple_pop\")\n\n    ### create a projection with decaying weights to demonstrate recording of projection\n    proj = Projection(\n        pre=my_model.populations[0],\n        post=my_model.populations[1],\n        target=\"ampa\",\n        synapse=Synapse(parameters=\"tau=500\", equations=\"dw/dt=-w/tau\"),\n        name=\"ampa_proj\",\n    )\n    proj.connect_all_to_all(weights=Uniform(1.0, 2.0))\n\n\ndef main():\n    ### create and compile the model from other example \"create_model.py\"\n    my_model.create(do_compile=False)\n\n    ### extend the model to demonstrate the functionality of CompNeuroSim requirements\n    ### (see below) and the recording of projections (recorded data will be used in\n    ### other example \"plot_recordings.py\")\n    extend_model(my_model)\n    my_model.compile()\n\n    ### Define Monitors, recording p and spike from both model populations with periods\n    ### of 10 ms and 15 ms and the weights of the ampa projection with period of 10 ms\n    monitor_dictionary = {\n        f\"{my_model.populations[0]};10\": [\"p\", \"spike\"],\n        f\"{my_model.populations[1]};15\": [\"p\", \"spike\"],\n        \"ampa_proj;10\": [\"w\"],\n    }\n    mon = CompNeuroMonitors(monitor_dictionary)\n\n    ### Now use CompNeuroSim to define a simulation. Use the previously defined\n    ### simulation functions and define their arguments as kwargs dictionary. Give the\n    ### simulation a name and description and you can also define requirements for the\n    ### simulation. Here, for example, we require that the populations contain the\n    ### attribute 'rates'. One can define multiple requirements in a list of\n    ### dictionaries. The arguments of the requirements can be inherited from the\n    ### simulation kwargs by using the syntax 'simulation_kwargs.&lt;kwarg_name&gt;'.\n    ### The monitor object is also given to the simulation, so that the simulation\n    ### runs can be automatically associated with the monitor recording chunks.\n    increase_rates_pop = CompNeuroSim(\n        simulation_function=increase_rates,\n        simulation_kwargs={\n            \"pop_name\": my_model.populations[0],\n            \"rate_step\": 10,\n            \"time_step\": 100,\n            \"nr_steps\": 15,\n        },\n        name=\"increase_rates_pop\",\n        description=\"increase rates variable of pop\",\n        requirements=[\n            {\"req\": ReqPopHasAttr, \"pop\": \"simulation_kwargs.pop_name\", \"attr\": \"rates\"}\n        ],\n        monitor_object=mon,\n    )\n\n    ### Now let's use this simulation\n    ### Simulate 500 ms without recordings and then run the simulation\n    simulate(500)\n    mon.start()\n    increase_rates_pop.run()\n\n    ### resetting monitors and model, creating new recording chunk\n    mon.reset()\n\n    ### again simulate 700 ms without recording\n    ### then run the simulation with different simulation kwargs (for all populations)\n    mon.pause()\n    simulate(700)\n    mon.start()\n    increase_rates_pop.run({\"pop_name\": my_model.populations})\n    simulate(500)\n\n    ### now again change the pop_name kwarg but use the simple_pop population without\n    ### the required attribute 'rates'\n    ### this will raise an error\n    try:\n        increase_rates_pop.run({\"pop_name\": \"simple_pop\"})\n    except Exception as e:\n        print(\"\\n###############################################\")\n        print(\n            \"Running simulation with population not containing attribute 'rates' causes the following error:\"\n        )\n        print(e)\n        print(\"###############################################\\n\")\n\n    ### get recordings and recording times from the CompNeuroMonitors object\n    recordings = mon.get_recordings()\n    recording_times = mon.get_recording_times()\n\n    ### get the simulation information object from the CompNeuroSim object\n    increase_rates_pop_info = increase_rates_pop.simulation_info()\n\n    ### save the recordings, recording times and simulation information\n    save_variables(\n        variable_list=[recordings, recording_times, increase_rates_pop_info],\n        name_list=[\"recordings\", \"recording_times\", \"increase_rates_pop_info\"],\n        path=\"run_and_monitor_simulations\",\n    )\n\n    ### print the information contained in the simulation information object\n    print(\"\\nA simulation object contains:\")\n    print(\"name\\n\", increase_rates_pop_info.name)\n    print(\"\\ndescription\\n\", increase_rates_pop_info.description)\n    print(\"\\nstart (for each run)\\n\", increase_rates_pop_info.start)\n    print(\"\\nend (for each run)\\n\", increase_rates_pop_info.end)\n    print(\"\\ninfo (for each run)\\n\", increase_rates_pop_info.info)\n    print(\"\\nkwargs (for each run)\\n\", increase_rates_pop_info.kwargs)\n    print(\"\\nmonitor chunk (for each run)\\n\", increase_rates_pop_info.monitor_chunk)\n\n    return 1\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/run_and_monitor_simulations/#console-output","title":"Console Output","text":"<pre><code>$ python run_and_monitor_simulations.py \nANNarchy 4.7 (4.7.3b) on linux (posix).\ncreated model, other parameters: 1\nCompiling ...  OK \n\n###############################################\nRunning simulation with population not containing attribute 'rates' causes the following error:\nPopulation simple_pop does not contain attribute rates!\n\n###############################################\n\n\nA simulation object contains:\nname\n increase_rates_pop\n\ndescription\n increase rates variable of pop\n\nstart (for each run)\n [500.0, 700.0]\n\nend (for each run)\n [2000.0, 2200.0]\n\ninfo (for each run)\n [{'duration': 1500, 'd_rates': 150}, {'duration': 1500, 'd_rates': 150}]\n\nkwargs (for each run)\n [{'pop_name': 'first_poisson', 'rate_step': 10, 'time_step': 100, 'nr_steps': 15}, {'pop_name': ['first_poisson', 'second_poisson'], 'rate_step': 10, 'time_step': 100, 'nr_steps': 15}]\n\nmonitor chunk (for each run)\n [0, 1]\n</code></pre>"},{"location":"main/dbs_stimulator/","title":"DBS Stimulator","text":""},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator","title":"<code>CompNeuroPy.dbs.DBSstimulator</code>","text":"<p>Class for stimulating a population with DBS.</p> <p>Warning</p> <p>If you use auto_implement, pointers to the populations and projections of the model are not valid anymore (new populations and projections are created)! Use a CompNeuroPy model working with names of populations and projections anyway (recommended) or use the update_pointers method.</p> <p>Examples:</p> <pre><code>from ANNarchy import Population, Izhikevich, compile, simulate, setup\nfrom CompNeuroPy import DBSstimulator\n\n# setup ANNarchy\nsetup(dt=0.1)\n\n# create populations\npopulation1 = Population(10, neuron=Izhikevich, name=\"my_pop1\")\npopulation2 = Population(10, neuron=Izhikevich, name=\"my_pop2\")\n&gt;&gt;&gt;\n# create DBS stimulator\ndbs = DBSstimulator(\n    stimulated_population=population1,\n    population_proportion=0.5,\n    dbs_depolarization=30,\n    auto_implement=True,\n)\n\n# update pointers to correct populations\npopulation1, population2 = dbs.update_pointers(\n    pointer_list=[population1, population2]\n)\n\n# compile network\ncompile()\n\n# run simulation\n# 1000 ms without dbs\nsimulate(1000)\n# 1000 ms with dbs\ndbs.on()\nsimulate(1000)\n# 1000 ms without dbs\ndbs.off()\nsimulate(1000)\n</code></pre> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>class DBSstimulator:\n    \"\"\"\n    Class for stimulating a population with DBS.\n\n    !!! warning\n        If you use auto_implement, pointers to the populations and projections of\n        the model are not valid anymore (new populations and projections are\n        created)! Use a CompNeuroPy model working with names of populations and\n        projections anyway (recommended) or use the update_pointers method.\n\n    Examples:\n        ```python\n        from ANNarchy import Population, Izhikevich, compile, simulate, setup\n        from CompNeuroPy import DBSstimulator\n\n        # setup ANNarchy\n        setup(dt=0.1)\n\n        # create populations\n        population1 = Population(10, neuron=Izhikevich, name=\"my_pop1\")\n        population2 = Population(10, neuron=Izhikevich, name=\"my_pop2\")\n        &gt;&gt;&gt;\n        # create DBS stimulator\n        dbs = DBSstimulator(\n            stimulated_population=population1,\n            population_proportion=0.5,\n            dbs_depolarization=30,\n            auto_implement=True,\n        )\n\n        # update pointers to correct populations\n        population1, population2 = dbs.update_pointers(\n            pointer_list=[population1, population2]\n        )\n\n        # compile network\n        compile()\n\n        # run simulation\n        # 1000 ms without dbs\n        simulate(1000)\n        # 1000 ms with dbs\n        dbs.on()\n        simulate(1000)\n        # 1000 ms without dbs\n        dbs.off()\n        simulate(1000)\n        ```\n    \"\"\"\n\n    @check_types()\n    def __init__(\n        self,\n        stimulated_population: Population,\n        population_proportion: float = 1.0,\n        excluded_populations_list: list[Population] = [],\n        dbs_depolarization: float = 0.0,\n        orthodromic: bool = False,\n        antidromic: bool = False,\n        efferents: bool = False,\n        afferents: bool = False,\n        passing_fibres: bool = False,\n        passing_fibres_list: list[Projection] = [],\n        passing_fibres_strength: float | list[float] = 1.0,\n        sum_branches: bool = True,\n        dbs_pulse_frequency_Hz: float = 130.0,\n        dbs_pulse_width_us: float = 300.0,\n        axon_spikes_per_pulse: float = 1.0,\n        axon_rate_amp: float | dict[Population | str, float] = 1.0,\n        seed: int | None = None,\n        auto_implement: bool = False,\n        model: generate_model | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize DBS stimulator.\n\n        !!! warning\n            Do this before compiling the model!\n\n        Args:\n            stimulated_population (Population):\n                Population which is stimulated by DBS\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: 1.0.\n            excluded_populations_list (list, optional):\n                List of populations which are excluded from DBS effects, they are not\n                affected and their axons do not generate axon spikes. Default: [].\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: 0.0.\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically.\n                Default: False.\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: False.\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: False.\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: False.\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: False.\n            passing_fibres_list (list of Projections, optional):\n                List of projections which pass the DBS stimulated region and therefore\n                are activated by DBS. Default: [], also set passing_fibres True!\n            passing_fibres_strength (float or list of float, optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: 1.\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: True.\n            dbs_pulse_frequency_Hz (float, optional):\n                Frequency of the DBS pulse. Default: 130 Hz.\n            dbs_pulse_width_us (float, optional):\n                Width of the DBS pulse. Default: 300 us.\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: 1.\n            axon_rate_amp (float or dict of float, optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value)\n                You can specify the default value by using the key \"default\", e.g.\n                {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n                pop forward a rate of 1.0 during DBS. Default: 1.0.\n            seed (int, optional):\n                Seed for the random distribution of affected neurons based on\n                population_proportion. Default: None.\n            auto_implement (bool, optional):\n                If True, automatically implement DBS mechanisms to the model. Only\n                supported for Izhikevich spiking models and rate-coded models.\n                Default: False.\n                TODO test what happens with mixed models\n            model (generate_model, optional):\n                CompNeuroPy model which is used to automatically implement DBS\n                mechanisms, should not be compiled!. Default: None, i.e., use all\n                populations and projections of the current magic model\n        \"\"\"\n\n        if auto_implement:\n            ### recreate model with DBS mechanisms\n            ### give all variables containing Populations and Projections\n            ### and also recreate them during recreating the model\n            ### variables are:\n            ### - stimulated_population\n            ### - excluded_populations_list\n            ### - passing_fibres_list\n            ### - axon_rate_amp\n            if not isinstance(model, type(None)):\n                ### CompNeuroPy model given\n                ### recreate model with DBS mechanisms\n                create_dbs_model_obj = _CreateDBSmodelcnp(\n                    model,\n                    stimulated_population,\n                    excluded_populations_list,\n                    passing_fibres_list,\n                    axon_rate_amp,\n                )\n                ### get the new CompNeuroPy model\n                model = create_dbs_model_obj.model\n            else:\n                ### no CompNeuroPy model given --&gt; use all populations and projections of the current magic model\n                ### recreate model with DBS mechanisms\n                create_dbs_model_obj = _CreateDBSmodel(\n                    stimulated_population,\n                    excluded_populations_list,\n                    passing_fibres_list,\n                    axon_rate_amp,\n                )\n            ### get the new variables containing Populations and Projections\n            stimulated_population = create_dbs_model_obj.stimulated_population\n            excluded_populations_list = create_dbs_model_obj.excluded_populations_list\n            passing_fibres_list = create_dbs_model_obj.passing_fibres_list\n            axon_rate_amp = create_dbs_model_obj.axon_rate_amp\n\n        ### set parameters\n        self.stimulated_population = stimulated_population\n        self.population_proportion = population_proportion\n        self.excluded_populations_list = excluded_populations_list\n        self.dbs_depolarization = dbs_depolarization\n        self.orthodromic = orthodromic\n        self.antidromic = antidromic\n        self.efferents = efferents\n        self.afferents = afferents\n        self.passing_fibres = passing_fibres\n        self.passing_fibres_list = passing_fibres_list\n        self.passing_fibres_strength = passing_fibres_strength\n        self.sum_branches = sum_branches\n        self.dbs_pulse_width_us = dbs_pulse_width_us\n        self.axon_spikes_per_pulse = axon_spikes_per_pulse\n        self.axon_rate_amp = axon_rate_amp\n        self.seed = seed\n        self.model = model\n\n        ### ANNarchy constants for DBS\n        self._set_constants(dbs_pulse_frequency_Hz)\n\n        ### randomly select affected neurons i.e. create dbs_on_array\n        self.dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n\n    def _create_dbs_on_array(self, population_proportion: float, seed: int):\n        \"\"\"\n        Create an array with the shape of the stimulated population with ones and zeros\n        randomly distributed with the specified population_proportion.\n\n        Args:\n            population_proportion (float):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly\n            seed (int):\n                Seed for the random distribution of affected neurons based on\n                population_proportion\n\n        Returns:\n            dbs_on_array (np.array):\n                Array with the shape of the stimulated population with ones and zeros\n                randomly distributed with the specified population_proportion\n        \"\"\"\n        ### create random number generator\n        rng = np.random.default_rng(seed)\n        ### create an array of zeros with the shape of the population, then flatten it\n        dbs_on_array = np.zeros(self.stimulated_population.geometry).flatten()\n        ### get the number of affected neurons based on the population_proportion\n        number_of_affected_neurons = population_proportion * dbs_on_array.size\n        ### randomly ceil or floor the number of affected neurons\n        number_of_affected_neurons = int(\n            rng.choice(\n                [\n                    np.ceil(number_of_affected_neurons),\n                    np.floor(number_of_affected_neurons),\n                ]\n            )\n        )\n        ### insert ones to the dbs_on_array\n        dbs_on_array[:number_of_affected_neurons] = 1\n        ### shuffle array\n        rng.shuffle(dbs_on_array)\n        ### reshape array to the shape of the population\n        dbs_on_array = dbs_on_array.reshape(self.stimulated_population.geometry)\n        ### return array\n        return dbs_on_array\n\n    def _set_constants(self, dbs_pulse_frequency_Hz: float):\n        \"\"\"\n        Set constants for DBS.\n\n        Args:\n            dbs_pulse_frequency_Hz (float):\n                Frequency of the DBS pulse in Hz\n        \"\"\"\n        # pulse frequency:\n        Constant(\"dbs_pulse_frequency_Hz\", dbs_pulse_frequency_Hz)\n        # pulse width:\n        # Neumant et al.. 2023: 60us but Meier et al. 2022: 300us... 60us = 0.06ms is very small for ANNarchy simulations\n        Constant(\"dbs_pulse_width_us\", self.dbs_pulse_width_us)\n\n        ### add global function for DBS pulse\n        add_function(\n            \"pulse(time_ms) = ite(modulo(time_ms*1000, 1000000./dbs_pulse_frequency_Hz) &lt; dbs_pulse_width_us, 1., 0.)\"\n        )\n\n    def _axon_spikes_per_pulse_to_prob(self, axon_spikes_per_pulse: float):\n        \"\"\"\n        Convert number of axon spikes per pulse to probability of axon spikes per\n        timestep during DBS pulse\n\n        Args:\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n\n        Returns:\n            prob_axon_spike_time_step (float):\n                Probability of axon spikes per timestep during DBS pulse\n        \"\"\"\n        return np.clip(\n            (axon_spikes_per_pulse * 1000 * dt() / self.dbs_pulse_width_us), 0, 1\n        )\n\n    def _set_depolarization(self, dbs_depolarization: float | None = None):\n        \"\"\"\n        Set depolarization of population.\n\n        Args:\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: None,\n                i.e., use value from initialization\n        \"\"\"\n        ### either use given depolarization or use default value\n        if isinstance(dbs_depolarization, type(None)):\n            dbs_depolarization = self.dbs_depolarization\n\n        ### set depolarization of population\n        for pop in populations():\n            if pop == self.stimulated_population:\n                pop.dbs_depolarization = dbs_depolarization\n            else:\n                pop.dbs_depolarization = 0\n\n    def _set_axon_spikes(\n        self,\n        orthodromic: bool | None = None,\n        antidromic: bool | None = None,\n        efferents: bool | None = None,\n        afferents: bool | None = None,\n        passing_fibres: bool | None = None,\n        passing_fibres_strength: float | list[float] | None = None,\n        sum_branches: bool | None = None,\n        axon_spikes_per_pulse: float | None = None,\n        axon_rate_amp: float | dict[Population | str, float] | None = None,\n    ):\n        \"\"\"\n        Set axon spikes forwarding orthodromic\n\n        Args:\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically,\n                Default: None, i.e., use value from initialization\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: None, i.e., use value from\n                initialization\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: None, i.e., use value from initialization\n            passing_fibres_strength (float | list[float], optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: None, i.e., use value from initialization\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: None, i.e., use value from initialization\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: None, i.e., use\n                value from initialization\n            axon_rate_amp (float | dict[Population | str, float], optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value)\n                You can specify the default value by using the key \"default\", e.g.\n                {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n                pop forward a rate of 1.0 during DBS. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n\n        ### either use given orthodromic or use default value\n        if isinstance(orthodromic, type(None)):\n            orthodromic = self.orthodromic\n        ### either use given antidromic or use default value\n        if isinstance(antidromic, type(None)):\n            antidromic = self.antidromic\n        ### either use given efferents or use default value\n        if isinstance(efferents, type(None)):\n            efferents = self.efferents\n        ### either use given afferents or use default value\n        if isinstance(afferents, type(None)):\n            afferents = self.afferents\n        ### either use given afferents or use default value\n        if isinstance(passing_fibres, type(None)):\n            passing_fibres = self.passing_fibres\n        ### either use given passing_fibres_strength or use default value\n        if isinstance(passing_fibres_strength, type(None)):\n            passing_fibres_strength = self.passing_fibres_strength\n        ### either use given sum_branches or use default value\n        if isinstance(sum_branches, type(None)):\n            sum_branches = self.sum_branches\n        ### either use given axon_spikes_per_pulse or use default value\n        if isinstance(axon_spikes_per_pulse, type(None)):\n            axon_spikes_per_pulse = self.axon_spikes_per_pulse\n        ### either use given axon_rate_amp or use default value\n        if isinstance(axon_rate_amp, type(None)):\n            axon_rate_amp = self.axon_rate_amp\n\n        ### check if passing_fibres_strength is a list\n        if not isinstance(passing_fibres_strength, list):\n            passing_fibres_strength = [passing_fibres_strength] * len(\n                self.passing_fibres_list\n            )\n        ### check if axon_rate_amp is a dict or float\n        if isinstance(axon_rate_amp, dict):\n            ### check if default key is missing\n            if \"default\" not in axon_rate_amp.keys():\n                ### add the key \"default\" with the value 1.0 to the dict\n                axon_rate_amp[\"default\"] = 1.0\n        else:\n            ### create dict with default value\n            axon_rate_amp = {\"default\": axon_rate_amp}\n\n        ### deactivate DBS axon transmission\n        self._deactivate_axon_DBS()\n\n        ### activate orthodromic transmission for all projections\n        if orthodromic:\n            self._set_orthodromic(\n                efferents,\n                afferents,\n                passing_fibres,\n                passing_fibres_strength,\n                axon_spikes_per_pulse,\n                axon_rate_amp,\n            )\n\n        ### activate antidromic transmission for all populations\n        if antidromic:\n            self._set_antidromic(\n                efferents,\n                afferents,\n                passing_fibres,\n                passing_fibres_strength,\n                sum_branches,\n                axon_spikes_per_pulse,\n            )\n\n    def _deactivate_axon_DBS(self):\n        \"\"\"\n        Deactivate axon spikes forwarding for both orthodromic and antidromic.\n        \"\"\"\n        for pop in populations():\n            ### deactivate axon spike genearation for all populations\n            pop.prob_axon_spike = 0\n            pop.axon_rate_amp = 0\n            ### deactivate antidromic transmission for all populations\n            pop.antidromic = 0\n            pop.antidromic_prob = 0\n\n        ### deactivate orthodromic transmission for all projections\n        for proj in projections():\n            proj.axon_transmission = 0\n            proj.p_axon_spike_trans = 0\n\n    def _set_orthodromic(\n        self,\n        efferents: bool,\n        afferents: bool,\n        passing_fibres: bool,\n        passing_fibres_strength: list[float],\n        axon_spikes_per_pulse: float,\n        axon_rate_amp: dict[Population | str, float],\n    ):\n        \"\"\"\n        Set orthodromic axon spikes forwarding.\n\n        Args:\n            efferents (bool):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            afferents (bool):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            passing_fibres (bool):\n                If True, DBS affects the passing fibres of the stimulated population\n                (orthodromic and/or antidromic have to be True too and there have to\n                be passing fibres in the passing_fibres_list)\n            passing_fibres_strength (list[float]):\n                List of float values between 0 and 1 defining how strong the passing\n                fibres are activated by DBS (0: not activated, 1: fully activated\n                like projections in DBS stimulated region)\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n            axon_rate_amp (dict[Population | str, float]):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded\n                on axons caused by DBS. The dictionary has to contain the key\n                \"default\" with the default value for all projections and can contain\n                keys for each population with a different value for the axon_rate of\n                the efferent axons of this population.\n        \"\"\"\n        if efferents:\n            ### activate all efferent projections\n            projection_list = projections(pre=self.stimulated_population)\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.post in self.excluded_populations_list:\n                    continue\n                ### activate axon transmission\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = 1\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n        if afferents:\n            ### activate all afferent projections\n            projection_list = projections(post=self.stimulated_population)\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.pre in self.excluded_populations_list:\n                    continue\n                ### activate axon transmission\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = 1\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n        if passing_fibres:\n            ### activate all passing projections\n            for proj_idx, proj in enumerate(self.passing_fibres_list):\n                proj.axon_transmission = 1\n                proj.p_axon_spike_trans = passing_fibres_strength[proj_idx]\n                ### set prob_axon_spike for spiking model\n                proj.pre.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n                ### set axon_rate_amp for rate-coded model\n                if proj.pre in axon_rate_amp.keys():\n                    ### axon_rate_amp is specified for this population\n                    proj.pre.axon_rate_amp = axon_rate_amp[proj.pre]\n                else:\n                    ### axon_rate_amp is not specified for this population, use default value\n                    proj.pre.axon_rate_amp = axon_rate_amp[\"default\"]\n\n    def _set_antidromic(\n        self,\n        efferents: bool,\n        afferents: bool,\n        passing_fibres: bool,\n        passing_fibres_strength: list[float],\n        sum_branches: bool,\n        axon_spikes_per_pulse: float,\n    ):\n        \"\"\"\n        Set antidromic axon spikes forwarding.\n\n        Args:\n            efferents (bool):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            afferents (bool):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too)\n            passing_fibres (bool):\n                If True, DBS affects the passing fibres of the stimulated population\n                (orthodromic and/or antidromic have to be True too and there have to\n                be passing fibres in the passing_fibres_list)\n            passing_fibres_strength (list[float]):\n                List of float values between 0 and 1 defining how strong the passing\n                fibres are activated by DBS (0: not activated, 1: fully activated\n                like projections in DBS stimulated region)\n            sum_branches (bool):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n            axon_spikes_per_pulse (float):\n                Number of average axon spikes per DBS pulse\n        \"\"\"\n\n        if efferents:\n            ### activate all efferent projections, i.e. antodromic activation of stimulated population\n            pop = self.stimulated_population\n            pop.antidromic = 1\n            pop.antidromic_prob = 1\n            pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                axon_spikes_per_pulse\n            )\n        if afferents:\n            ### activate all afferent projections, i.e. all presynaptic populations of stimulated population\n            ### get presynaptic projections\n            projection_list = projections(post=self.stimulated_population)\n            ### get presynaptic populations from projections\n            presyn_pop_list = []\n            presyn_pop_name_list = []\n            for proj in projection_list:\n                ### skip excluded populations\n                if proj.pre in self.excluded_populations_list:\n                    continue\n                ### check if presynaptic population is already in list\n                if proj.pre.name not in presyn_pop_name_list:\n                    presyn_pop_name_list.append(proj.pre.name)\n                    presyn_pop_list.append(proj.pre)\n            ### set antidromic for all presynaptic populations\n            for pop in presyn_pop_list:\n                pop.antidromic = 1\n                pop.antidromic_prob = np.mean(self.stimulated_population.dbs_on)\n                pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n        if passing_fibres:\n            ### get presynaptic populations from passing fibres projections\n            presyn_pop_list = []\n            presyn_pop_name_list = []\n            for proj in self.passing_fibres_list:\n                ### check if presynaptic population is already in list\n                if proj.pre.name not in presyn_pop_name_list:\n                    presyn_pop_name_list.append(proj.pre.name)\n                    presyn_pop_list.append(proj.pre)\n            ### get antidomic_prob for each presynatic population with the passing_fibres_strength\n            antidromic_prob_list = [0] * len(presyn_pop_list)\n            for pop_idx, pop in enumerate(presyn_pop_list):\n                ### get all passing fibres and their strength of a presynaptic pop\n                passing_fibres_strength_of_pop_list = []\n                for proj_idx, proj in enumerate(self.passing_fibres_list):\n                    if proj.pre.name == pop.name:\n                        passing_fibres_strength_of_pop_list.append(\n                            passing_fibres_strength[proj_idx]\n                        )\n                ### check if the probs of the single axon branches should be summed up\n                ### if for example a presynaptic pop contributes to two passing fibres, the axons of the presynaptic pop split up into two branches\n                ### thus, if these two branches are both stimulated, they both forward APs antidromic\n                ### thus, sum up the antidromic_prob of the single branches to obtain the antidromic spikes which affect the presynaptic pop\n                ### if sum_branches is False, then this would represent that the stimulation at the axon is before it splits up into multiple branches and there should not be different passing_fibres_strengths for the same presynaptic pop\n                if sum_branches:\n                    antidromic_prob_list[pop_idx] = sum(\n                        passing_fibres_strength_of_pop_list\n                    )\n                else:\n                    if len(set(passing_fibres_strength_of_pop_list)) != 1:\n                        ### list contains different values\n                        raise ValueError(\n                            \"Different passing fibres strengths for the same presynaptic population detected. This is not possible if sum_branches is False.\"\n                        )\n                    ### all values are the same, thus take the first one\n                    antidromic_prob_list[pop_idx] = passing_fibres_strength_of_pop_list[\n                        0\n                    ]\n\n                ### TODO\n                ### if summing axon branches leads to a prob &gt; 1, then\n                ### the prob should be set to 1\n                ### the axon spike generation in this pop should be increased\n                ### and all axon spike transmissions from this pop should be decreased by the same factor\n                ### this is not implemented yet... maybe in the future\n                if antidromic_prob_list[pop_idx] &gt; 1:\n                    raise ValueError(\n                        \"Summing the passing fibres strengths of a presynaptic population leads to a antidromic spike probability &gt; 1. This is not possible yet.\"\n                    )\n\n            ### set antidromic for all presynaptic populations\n            for pop_idx, pop in enumerate(presyn_pop_list):\n                pop.antidromic = 1\n                pop.antidromic_prob = antidromic_prob_list[pop_idx]\n                pop.prob_axon_spike = self._axon_spikes_per_pulse_to_prob(\n                    axon_spikes_per_pulse\n                )\n\n    @check_types()\n    def on(\n        self,\n        population_proportion: float | None = None,\n        dbs_depolarization: float | None = None,\n        orthodromic: bool | None = None,\n        antidromic: bool | None = None,\n        efferents: bool | None = None,\n        afferents: bool | None = None,\n        passing_fibres: bool | None = None,\n        passing_fibres_strength: float | list[float] | None = None,\n        sum_branches: bool | None = None,\n        axon_spikes_per_pulse: float | None = None,\n        axon_rate_amp: float | dict[Population | str, float] | None = None,\n        seed: int | None = None,\n    ):\n        \"\"\"\n        Activate DBS.\n\n        Args:\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: None, i.e., use value from\n                initialization\n            dbs_depolarization (float, optional):\n                Depolarization effect of the DBS pulse to local soma. Default: None,\n                i.e., use value from initialization\n            orthodromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded orthodromically.\n                Default: None, i.e., use value from initialization\n            antidromic (bool, optional):\n                If True, DBS causes axonal spikes which are forwarded antidromically,\n                only available in spiking networks. Default: None, i.e., use value from\n                initialization\n            efferents (bool, optional):\n                If True, DBS affects the efferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            afferents (bool, optional):\n                If True, DBS affects the afferents of the stimulated population\n                (orthodromic and/or antidromic have to be True too). Default: None,\n                i.e., use value from initialization\n            passing_fibres (bool, optional):\n                If True, DBS affects the passing fibres of the stimulated region defined\n                in passing_fibres_list (orthodromic and/or antidromic have to be True\n                too). Default: None, i.e., use value from initialization\n            passing_fibres_strength (float | list[float], optional):\n                Single value or list of float values between 0 and 1 defining how strong\n                the passing fibres are activated by DBS (0: not activated, 1: fully\n                activated like the projections in the DBS stimulated region).\n                Default: None, i.e., use value from initialization\n            sum_branches (bool, optional):\n                If True, the antidromic_prob of a presynaptic population (defining how\n                many axon spikes affect the pop antidromically) of passing fibres is\n                the sum of the passing_fibres_strengths of the single axon branches.\n                Default: None, i.e., use value from initialization\n            axon_spikes_per_pulse (float, optional):\n                Number of average axon spikes per DBS pulse. Default: None, i.e., use\n                value from initialization\n            axon_rate_amp (float | dict[Population | str, float], optional):\n                Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n                axons caused by DBS. You can specify this for each population\n                individually by using a dictionary (keys = Population instances)\n                axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n                of 1.5 during DBS (all other affected projections forward the default\n                value). You can specify the default value by using the key \"default\",\n                e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations\n                except pop forward a rate of 1.0 during DBS. Default: None, i.e., use\n                value from initialization\n            seed (int, optional):\n                Seed for the random number generator. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n\n        ### set DBS on for all populations\n        ### also sets the proportion of affected neurons, call this before set_depolarization and set_axon_spikes!\n        self._set_dbs_on(population_proportion, seed)\n\n        ### set depolarization of population\n        self._set_depolarization(dbs_depolarization)\n\n        ### set axon spikes forwarding\n        self._set_axon_spikes(\n            orthodromic,\n            antidromic,\n            efferents,\n            afferents,\n            passing_fibres,\n            passing_fibres_strength,\n            sum_branches,\n            axon_spikes_per_pulse,\n            axon_rate_amp,\n        )\n\n    def _set_dbs_on(self, population_proportion: float | None, seed: int | None):\n        \"\"\"\n        Set DBS on for all populations, for the stimulated population only the specified\n        proportion is affected by DBS.\n\n        Args:\n            population_proportion (float, optional):\n                Proportion of the stimulated population which is affected by DBS,\n                neurons are distributed randomly. Default: None, i.e., use value from\n                initialization\n            seed (int, optional):\n                Seed for the random number generator. Default: None, i.e., use value\n                from initialization\n        \"\"\"\n        ### set parameters for the creation of the DBS on array\n        ### either use given population_proportion or use default value\n        if isinstance(population_proportion, type(None)):\n            population_proportion = self.population_proportion\n        ### either use given seed or use default value\n        if isinstance(seed, type(None)):\n            seed = self.seed\n\n        ### if seed and population_propotion are the same as in the initialization, use the same dbs_on_array\n        if seed == self.seed and population_proportion == self.population_proportion:\n            ### use the same dbs_on_array as in the initialization\n            dbs_on_array = self.dbs_on_array\n        else:\n            ### create new dbs_on_array\n            dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n\n        ### set DBS on for all populations\n        for pop in populations():\n            ### of the stimulated population only the specified proportion is affected by DBS\n            if pop == self.stimulated_population:\n                pop.dbs_on = dbs_on_array\n            else:\n                pop.dbs_on = 1\n\n    def off(self):\n        \"\"\"\n        Deactivate DBS.\n        \"\"\"\n        ### set DBS off for all populations\n        for pop in populations():\n            pop.dbs_on = 0\n            pop.prob_axon_spike = 0\n            pop.axon_rate_amp = 0\n\n        ### deactivate DBS axon transmission\n        self._deactivate_axon_DBS()\n\n    def update_pointers(self, pointer_list):\n        \"\"\"\n        Update pointers to populations and projections after recreating the model.\n\n        Args:\n            pointer_list (list):\n                List of pointers to populations and projections\n\n        Returns:\n            pointer_list_new (list):\n                List of pointers to populations and projections of the new model\n        \"\"\"\n        ### update pointers\n        pointer_list_new: list[Population | Projection] = []\n        for pointer in pointer_list:\n            compartment_name = pointer.name\n            if isinstance(pointer, Population):\n                pointer_list_new.append(get_population(compartment_name))\n            elif isinstance(pointer, Projection):\n                pointer_list_new.append(get_projection(compartment_name))\n            else:\n                raise TypeError(\n                    f\"Pointer {pointer} is neither a Population nor a Projection\"\n                )\n        return pointer_list_new\n</code></pre>"},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator.__init__","title":"<code>__init__(stimulated_population, population_proportion=1.0, excluded_populations_list=[], dbs_depolarization=0.0, orthodromic=False, antidromic=False, efferents=False, afferents=False, passing_fibres=False, passing_fibres_list=[], passing_fibres_strength=1.0, sum_branches=True, dbs_pulse_frequency_Hz=130.0, dbs_pulse_width_us=300.0, axon_spikes_per_pulse=1.0, axon_rate_amp=1.0, seed=None, auto_implement=False, model=None)</code>","text":"<p>Initialize DBS stimulator.</p> <p>Warning</p> <p>Do this before compiling the model!</p> <p>Parameters:</p> Name Type Description Default <code>stimulated_population</code> <code>Population</code> <p>Population which is stimulated by DBS</p> required <code>population_proportion</code> <code>float</code> <p>Proportion of the stimulated population which is affected by DBS, neurons are distributed randomly. Default: 1.0.</p> <code>1.0</code> <code>excluded_populations_list</code> <code>list</code> <p>List of populations which are excluded from DBS effects, they are not affected and their axons do not generate axon spikes. Default: [].</p> <code>[]</code> <code>dbs_depolarization</code> <code>float</code> <p>Depolarization effect of the DBS pulse to local soma. Default: 0.0.</p> <code>0.0</code> <code>orthodromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded orthodromically. Default: False.</p> <code>False</code> <code>antidromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded antidromically, only available in spiking networks. Default: False.</p> <code>False</code> <code>efferents</code> <code>bool</code> <p>If True, DBS affects the efferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>afferents</code> <code>bool</code> <p>If True, DBS affects the afferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>passing_fibres</code> <code>bool</code> <p>If True, DBS affects the passing fibres of the stimulated region defined in passing_fibres_list (orthodromic and/or antidromic have to be True too). Default: False.</p> <code>False</code> <code>passing_fibres_list</code> <code>list of Projections</code> <p>List of projections which pass the DBS stimulated region and therefore are activated by DBS. Default: [], also set passing_fibres True!</p> <code>[]</code> <code>passing_fibres_strength</code> <code>float or list of float</code> <p>Single value or list of float values between 0 and 1 defining how strong the passing fibres are activated by DBS (0: not activated, 1: fully activated like the projections in the DBS stimulated region). Default: 1.</p> <code>1.0</code> <code>sum_branches</code> <code>bool</code> <p>If True, the antidromic_prob of a presynaptic population (defining how many axon spikes affect the pop antidromically) of passing fibres is the sum of the passing_fibres_strengths of the single axon branches. Default: True.</p> <code>True</code> <code>dbs_pulse_frequency_Hz</code> <code>float</code> <p>Frequency of the DBS pulse. Default: 130 Hz.</p> <code>130.0</code> <code>dbs_pulse_width_us</code> <code>float</code> <p>Width of the DBS pulse. Default: 300 us.</p> <code>300.0</code> <code>axon_spikes_per_pulse</code> <code>float</code> <p>Number of average axon spikes per DBS pulse. Default: 1.</p> <code>1.0</code> <code>axon_rate_amp</code> <code>float or dict of float</code> <p>Similar to prob_axon_spike in spiking model. Which rate is forwarded on axons caused by DBS. You can specify this for each population individually by using a dictionary (keys = Population instances) axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate of 1.5 during DBS (all other affected projections forward the default value) You can specify the default value by using the key \"default\", e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except pop forward a rate of 1.0 during DBS. Default: 1.0.</p> <code>1.0</code> <code>seed</code> <code>int</code> <p>Seed for the random distribution of affected neurons based on population_proportion. Default: None.</p> <code>None</code> <code>auto_implement</code> <code>bool</code> <p>If True, automatically implement DBS mechanisms to the model. Only supported for Izhikevich spiking models and rate-coded models. Default: False. TODO test what happens with mixed models</p> <code>False</code> <code>model</code> <code>generate_model</code> <p>CompNeuroPy model which is used to automatically implement DBS mechanisms, should not be compiled!. Default: None, i.e., use all populations and projections of the current magic model</p> <code>None</code> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>@check_types()\ndef __init__(\n    self,\n    stimulated_population: Population,\n    population_proportion: float = 1.0,\n    excluded_populations_list: list[Population] = [],\n    dbs_depolarization: float = 0.0,\n    orthodromic: bool = False,\n    antidromic: bool = False,\n    efferents: bool = False,\n    afferents: bool = False,\n    passing_fibres: bool = False,\n    passing_fibres_list: list[Projection] = [],\n    passing_fibres_strength: float | list[float] = 1.0,\n    sum_branches: bool = True,\n    dbs_pulse_frequency_Hz: float = 130.0,\n    dbs_pulse_width_us: float = 300.0,\n    axon_spikes_per_pulse: float = 1.0,\n    axon_rate_amp: float | dict[Population | str, float] = 1.0,\n    seed: int | None = None,\n    auto_implement: bool = False,\n    model: generate_model | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize DBS stimulator.\n\n    !!! warning\n        Do this before compiling the model!\n\n    Args:\n        stimulated_population (Population):\n            Population which is stimulated by DBS\n        population_proportion (float, optional):\n            Proportion of the stimulated population which is affected by DBS,\n            neurons are distributed randomly. Default: 1.0.\n        excluded_populations_list (list, optional):\n            List of populations which are excluded from DBS effects, they are not\n            affected and their axons do not generate axon spikes. Default: [].\n        dbs_depolarization (float, optional):\n            Depolarization effect of the DBS pulse to local soma. Default: 0.0.\n        orthodromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded orthodromically.\n            Default: False.\n        antidromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded antidromically,\n            only available in spiking networks. Default: False.\n        efferents (bool, optional):\n            If True, DBS affects the efferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: False.\n        afferents (bool, optional):\n            If True, DBS affects the afferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: False.\n        passing_fibres (bool, optional):\n            If True, DBS affects the passing fibres of the stimulated region defined\n            in passing_fibres_list (orthodromic and/or antidromic have to be True\n            too). Default: False.\n        passing_fibres_list (list of Projections, optional):\n            List of projections which pass the DBS stimulated region and therefore\n            are activated by DBS. Default: [], also set passing_fibres True!\n        passing_fibres_strength (float or list of float, optional):\n            Single value or list of float values between 0 and 1 defining how strong\n            the passing fibres are activated by DBS (0: not activated, 1: fully\n            activated like the projections in the DBS stimulated region).\n            Default: 1.\n        sum_branches (bool, optional):\n            If True, the antidromic_prob of a presynaptic population (defining how\n            many axon spikes affect the pop antidromically) of passing fibres is\n            the sum of the passing_fibres_strengths of the single axon branches.\n            Default: True.\n        dbs_pulse_frequency_Hz (float, optional):\n            Frequency of the DBS pulse. Default: 130 Hz.\n        dbs_pulse_width_us (float, optional):\n            Width of the DBS pulse. Default: 300 us.\n        axon_spikes_per_pulse (float, optional):\n            Number of average axon spikes per DBS pulse. Default: 1.\n        axon_rate_amp (float or dict of float, optional):\n            Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n            axons caused by DBS. You can specify this for each population\n            individually by using a dictionary (keys = Population instances)\n            axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n            of 1.5 during DBS (all other affected projections forward the default\n            value)\n            You can specify the default value by using the key \"default\", e.g.\n            {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except\n            pop forward a rate of 1.0 during DBS. Default: 1.0.\n        seed (int, optional):\n            Seed for the random distribution of affected neurons based on\n            population_proportion. Default: None.\n        auto_implement (bool, optional):\n            If True, automatically implement DBS mechanisms to the model. Only\n            supported for Izhikevich spiking models and rate-coded models.\n            Default: False.\n            TODO test what happens with mixed models\n        model (generate_model, optional):\n            CompNeuroPy model which is used to automatically implement DBS\n            mechanisms, should not be compiled!. Default: None, i.e., use all\n            populations and projections of the current magic model\n    \"\"\"\n\n    if auto_implement:\n        ### recreate model with DBS mechanisms\n        ### give all variables containing Populations and Projections\n        ### and also recreate them during recreating the model\n        ### variables are:\n        ### - stimulated_population\n        ### - excluded_populations_list\n        ### - passing_fibres_list\n        ### - axon_rate_amp\n        if not isinstance(model, type(None)):\n            ### CompNeuroPy model given\n            ### recreate model with DBS mechanisms\n            create_dbs_model_obj = _CreateDBSmodelcnp(\n                model,\n                stimulated_population,\n                excluded_populations_list,\n                passing_fibres_list,\n                axon_rate_amp,\n            )\n            ### get the new CompNeuroPy model\n            model = create_dbs_model_obj.model\n        else:\n            ### no CompNeuroPy model given --&gt; use all populations and projections of the current magic model\n            ### recreate model with DBS mechanisms\n            create_dbs_model_obj = _CreateDBSmodel(\n                stimulated_population,\n                excluded_populations_list,\n                passing_fibres_list,\n                axon_rate_amp,\n            )\n        ### get the new variables containing Populations and Projections\n        stimulated_population = create_dbs_model_obj.stimulated_population\n        excluded_populations_list = create_dbs_model_obj.excluded_populations_list\n        passing_fibres_list = create_dbs_model_obj.passing_fibres_list\n        axon_rate_amp = create_dbs_model_obj.axon_rate_amp\n\n    ### set parameters\n    self.stimulated_population = stimulated_population\n    self.population_proportion = population_proportion\n    self.excluded_populations_list = excluded_populations_list\n    self.dbs_depolarization = dbs_depolarization\n    self.orthodromic = orthodromic\n    self.antidromic = antidromic\n    self.efferents = efferents\n    self.afferents = afferents\n    self.passing_fibres = passing_fibres\n    self.passing_fibres_list = passing_fibres_list\n    self.passing_fibres_strength = passing_fibres_strength\n    self.sum_branches = sum_branches\n    self.dbs_pulse_width_us = dbs_pulse_width_us\n    self.axon_spikes_per_pulse = axon_spikes_per_pulse\n    self.axon_rate_amp = axon_rate_amp\n    self.seed = seed\n    self.model = model\n\n    ### ANNarchy constants for DBS\n    self._set_constants(dbs_pulse_frequency_Hz)\n\n    ### randomly select affected neurons i.e. create dbs_on_array\n    self.dbs_on_array = self._create_dbs_on_array(population_proportion, seed)\n</code></pre>"},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator.on","title":"<code>on(population_proportion=None, dbs_depolarization=None, orthodromic=None, antidromic=None, efferents=None, afferents=None, passing_fibres=None, passing_fibres_strength=None, sum_branches=None, axon_spikes_per_pulse=None, axon_rate_amp=None, seed=None)</code>","text":"<p>Activate DBS.</p> <p>Parameters:</p> Name Type Description Default <code>population_proportion</code> <code>float</code> <p>Proportion of the stimulated population which is affected by DBS, neurons are distributed randomly. Default: None, i.e., use value from initialization</p> <code>None</code> <code>dbs_depolarization</code> <code>float</code> <p>Depolarization effect of the DBS pulse to local soma. Default: None, i.e., use value from initialization</p> <code>None</code> <code>orthodromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded orthodromically. Default: None, i.e., use value from initialization</p> <code>None</code> <code>antidromic</code> <code>bool</code> <p>If True, DBS causes axonal spikes which are forwarded antidromically, only available in spiking networks. Default: None, i.e., use value from initialization</p> <code>None</code> <code>efferents</code> <code>bool</code> <p>If True, DBS affects the efferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>afferents</code> <code>bool</code> <p>If True, DBS affects the afferents of the stimulated population (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>passing_fibres</code> <code>bool</code> <p>If True, DBS affects the passing fibres of the stimulated region defined in passing_fibres_list (orthodromic and/or antidromic have to be True too). Default: None, i.e., use value from initialization</p> <code>None</code> <code>passing_fibres_strength</code> <code>float | list[float]</code> <p>Single value or list of float values between 0 and 1 defining how strong the passing fibres are activated by DBS (0: not activated, 1: fully activated like the projections in the DBS stimulated region). Default: None, i.e., use value from initialization</p> <code>None</code> <code>sum_branches</code> <code>bool</code> <p>If True, the antidromic_prob of a presynaptic population (defining how many axon spikes affect the pop antidromically) of passing fibres is the sum of the passing_fibres_strengths of the single axon branches. Default: None, i.e., use value from initialization</p> <code>None</code> <code>axon_spikes_per_pulse</code> <code>float</code> <p>Number of average axon spikes per DBS pulse. Default: None, i.e., use value from initialization</p> <code>None</code> <code>axon_rate_amp</code> <code>float | dict[Population | str, float]</code> <p>Similar to prob_axon_spike in spiking model. Which rate is forwarded on axons caused by DBS. You can specify this for each population individually by using a dictionary (keys = Population instances) axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate of 1.5 during DBS (all other affected projections forward the default value). You can specify the default value by using the key \"default\", e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations except pop forward a rate of 1.0 during DBS. Default: None, i.e., use value from initialization</p> <code>None</code> <code>seed</code> <code>int</code> <p>Seed for the random number generator. Default: None, i.e., use value from initialization</p> <code>None</code> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>@check_types()\ndef on(\n    self,\n    population_proportion: float | None = None,\n    dbs_depolarization: float | None = None,\n    orthodromic: bool | None = None,\n    antidromic: bool | None = None,\n    efferents: bool | None = None,\n    afferents: bool | None = None,\n    passing_fibres: bool | None = None,\n    passing_fibres_strength: float | list[float] | None = None,\n    sum_branches: bool | None = None,\n    axon_spikes_per_pulse: float | None = None,\n    axon_rate_amp: float | dict[Population | str, float] | None = None,\n    seed: int | None = None,\n):\n    \"\"\"\n    Activate DBS.\n\n    Args:\n        population_proportion (float, optional):\n            Proportion of the stimulated population which is affected by DBS,\n            neurons are distributed randomly. Default: None, i.e., use value from\n            initialization\n        dbs_depolarization (float, optional):\n            Depolarization effect of the DBS pulse to local soma. Default: None,\n            i.e., use value from initialization\n        orthodromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded orthodromically.\n            Default: None, i.e., use value from initialization\n        antidromic (bool, optional):\n            If True, DBS causes axonal spikes which are forwarded antidromically,\n            only available in spiking networks. Default: None, i.e., use value from\n            initialization\n        efferents (bool, optional):\n            If True, DBS affects the efferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: None,\n            i.e., use value from initialization\n        afferents (bool, optional):\n            If True, DBS affects the afferents of the stimulated population\n            (orthodromic and/or antidromic have to be True too). Default: None,\n            i.e., use value from initialization\n        passing_fibres (bool, optional):\n            If True, DBS affects the passing fibres of the stimulated region defined\n            in passing_fibres_list (orthodromic and/or antidromic have to be True\n            too). Default: None, i.e., use value from initialization\n        passing_fibres_strength (float | list[float], optional):\n            Single value or list of float values between 0 and 1 defining how strong\n            the passing fibres are activated by DBS (0: not activated, 1: fully\n            activated like the projections in the DBS stimulated region).\n            Default: None, i.e., use value from initialization\n        sum_branches (bool, optional):\n            If True, the antidromic_prob of a presynaptic population (defining how\n            many axon spikes affect the pop antidromically) of passing fibres is\n            the sum of the passing_fibres_strengths of the single axon branches.\n            Default: None, i.e., use value from initialization\n        axon_spikes_per_pulse (float, optional):\n            Number of average axon spikes per DBS pulse. Default: None, i.e., use\n            value from initialization\n        axon_rate_amp (float | dict[Population | str, float], optional):\n            Similar to prob_axon_spike in spiking model. Which rate is forwarded on\n            axons caused by DBS. You can specify this for each population\n            individually by using a dictionary (keys = Population instances)\n            axon_rate_amp = {pop: 1.5} --&gt; the efferent axons of pop forward a rate\n            of 1.5 during DBS (all other affected projections forward the default\n            value). You can specify the default value by using the key \"default\",\n            e.g. {pop: 1.5, \"default\": 1.0} -&gt; efferent axons of all populations\n            except pop forward a rate of 1.0 during DBS. Default: None, i.e., use\n            value from initialization\n        seed (int, optional):\n            Seed for the random number generator. Default: None, i.e., use value\n            from initialization\n    \"\"\"\n\n    ### set DBS on for all populations\n    ### also sets the proportion of affected neurons, call this before set_depolarization and set_axon_spikes!\n    self._set_dbs_on(population_proportion, seed)\n\n    ### set depolarization of population\n    self._set_depolarization(dbs_depolarization)\n\n    ### set axon spikes forwarding\n    self._set_axon_spikes(\n        orthodromic,\n        antidromic,\n        efferents,\n        afferents,\n        passing_fibres,\n        passing_fibres_strength,\n        sum_branches,\n        axon_spikes_per_pulse,\n        axon_rate_amp,\n    )\n</code></pre>"},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator.off","title":"<code>off()</code>","text":"<p>Deactivate DBS.</p> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>def off(self):\n    \"\"\"\n    Deactivate DBS.\n    \"\"\"\n    ### set DBS off for all populations\n    for pop in populations():\n        pop.dbs_on = 0\n        pop.prob_axon_spike = 0\n        pop.axon_rate_amp = 0\n\n    ### deactivate DBS axon transmission\n    self._deactivate_axon_DBS()\n</code></pre>"},{"location":"main/dbs_stimulator/#CompNeuroPy.dbs.DBSstimulator.update_pointers","title":"<code>update_pointers(pointer_list)</code>","text":"<p>Update pointers to populations and projections after recreating the model.</p> <p>Parameters:</p> Name Type Description Default <code>pointer_list</code> <code>list</code> <p>List of pointers to populations and projections</p> required <p>Returns:</p> Name Type Description <code>pointer_list_new</code> <code>list</code> <p>List of pointers to populations and projections of the new model</p> Source code in <code>src/CompNeuroPy/dbs.py</code> <pre><code>def update_pointers(self, pointer_list):\n    \"\"\"\n    Update pointers to populations and projections after recreating the model.\n\n    Args:\n        pointer_list (list):\n            List of pointers to populations and projections\n\n    Returns:\n        pointer_list_new (list):\n            List of pointers to populations and projections of the new model\n    \"\"\"\n    ### update pointers\n    pointer_list_new: list[Population | Projection] = []\n    for pointer in pointer_list:\n        compartment_name = pointer.name\n        if isinstance(pointer, Population):\n            pointer_list_new.append(get_population(compartment_name))\n        elif isinstance(pointer, Projection):\n            pointer_list_new.append(get_projection(compartment_name))\n        else:\n            raise TypeError(\n                f\"Pointer {pointer} is neither a Population nor a Projection\"\n            )\n    return pointer_list_new\n</code></pre>"},{"location":"main/define_experiment/","title":"Define Experiments","text":""},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp","title":"<code>CompNeuroPy.experiment.CompNeuroExp</code>","text":"<p>Experiment combining simulations and recordings.</p> <p>Use this class as a parent class for your experiment. You have to additionally implement a run function which runs the simulations and controlls the recordings. The run function should return the results of the experiment by calling the results function of the CompNeuroExp class.</p> <p>Attributes:</p> Name Type Description <code>monitors</code> <code>CompNeuroMonitors</code> <p>CompNeuroMonitors object for recordings</p> <code>data</code> <code>dict</code> <p>dict for storing optional data</p> <p>Examples:</p> <pre><code>from CompNeuroPy import CompNeuroExp\nfrom ANNarchy import simulate\n\nclass MyExperiment(CompNeuroExp):\n    def run(self):\n        # run simulations and control recordings\n        self.monitors.start()\n        simulate(1000)\n        self.reset()\n        simulate(1000)\n        # store optional data\n        self.data[\"duration\"] = 2000\n        # return results\n        return self.results()\n</code></pre> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>class CompNeuroExp:\n    \"\"\"\n    Experiment combining simulations and recordings.\n\n    Use this class as a parent class for your experiment. You have to additionally\n    implement a run function which runs the simulations and controlls the recordings.\n    The run function should return the results of the experiment by calling the results\n    function of the CompNeuroExp class.\n\n    Attributes:\n        monitors (CompNeuroMonitors):\n            CompNeuroMonitors object for recordings\n        data (dict):\n            dict for storing optional data\n\n    Examples:\n        ```python\n        from CompNeuroPy import CompNeuroExp\n        from ANNarchy import simulate\n\n        class MyExperiment(CompNeuroExp):\n            def run(self):\n                # run simulations and control recordings\n                self.monitors.start()\n                simulate(1000)\n                self.reset()\n                simulate(1000)\n                # store optional data\n                self.data[\"duration\"] = 2000\n                # return results\n                return self.results()\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        monitors: CompNeuroMonitors | None = None,\n    ):\n        \"\"\"\n        Initialize the experiment.\n\n        Args:\n            monitors (CompNeuroMonitors):\n                CompNeuroMonitors object for recordings\n        \"\"\"\n        self.recordings = {}  # save dict for monitor recordings\n        self.monitors = monitors\n        self.data = {}  # dict for optional data\n\n    def reset(\n        self,\n        populations=True,\n        projections=False,\n        synapses=False,\n        model=True,\n        parameters=True,\n    ):\n        \"\"\"\n        Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the\n        experiment.\n\n        !!! warning\n            If you want the network to have the same state at the beginning of each\n            experiment run, you should call this function at the beginning of the run\n            function of the CompNeuroExp class! If you only want to have the same time\n            for the network at the beginning of each experiment run, set populations,\n            projections, and synapses to False.\n\n        Args:\n            populations (bool, optional):\n                reset populations. Defaults to True.\n            projections (bool, optional):\n                reset projections. Defaults to False.\n            synapses (bool, optional):\n                reset synapses. Defaults to False.\n            model (bool, optional):\n                If False, do ignore the arguments populations, projections, and\n                synapses (the network state doesn't change) and only reset the\n                CompNeuroMonitors Default: True.\n            parameters (bool, optional):\n                If False, do not reset the parameters of the model. Default: True.\n        \"\"\"\n        reset_kwargs = {}\n        reset_kwargs[\"populations\"] = populations\n        reset_kwargs[\"projections\"] = projections\n        reset_kwargs[\"synapses\"] = synapses\n        reset_kwargs[\"monitors\"] = True\n\n        ### reset CompNeuroMonitors and ANNarchy model\n        if self.monitors is not None:\n            self.monitors.reset(model=model, parameters=parameters, **reset_kwargs)\n        elif model is True:\n            if parameters is False:\n                ### if parameters=False, get parameters before reset and set them after\n                ### reset\n                parameters = mf._get_all_parameters()\n            reset(**reset_kwargs)\n            if parameters is False:\n                ### if parameters=False, set parameters after reset\n                mf._set_all_parameters(parameters)\n\n    def results(self):\n        \"\"\"\n        !!! warning\n            Call this function at the end of the run function of the CompNeuroExp class!\n\n        !!! warning\n            Calling this function resets the CompNeuroMonitors. For example, if you\n            simulate two recording chunks in the run function and you run the experiment\n            twice, you will get two recording chunks for each experiment run (not two\n            for the first and four for the second run). But ANNarchy is not resetted\n            automatically! So the network time and state (activity etc.) at the\n            beginning of the second run is the same as at the end of the first run. To\n            prevent this use the reset function of the CompNeuroExp class.\n\n        Returns:\n            results_obj (CompNeuroExp._ResultsCl):\n                Object with attributes:\n                    recordings (list):\n                        list of recordings\n                    recording_times (recording_times_cl):\n                        recording times object\n                    mon_dict (dict):\n                        dict of recorded variables of the monitors\n                    data (dict):\n                        dict with optional data stored during the experiment\n        \"\"\"\n        obj = self._ResultsCl()\n        if self.monitors is not None:\n            (\n                obj.recordings,\n                obj.recording_times,\n            ) = self.monitors.get_recordings_and_clear()\n            obj.mon_dict = self.monitors.mon_dict\n        else:\n            obj.recordings = []\n            obj.recording_times = None\n            obj.mon_dict = {}\n        obj.data = self.data\n\n        return obj\n\n    class _ResultsCl:\n        \"\"\"\n        Class for storing the results of the experiment.\n\n        Attributes:\n            recordings (list):\n                list of recordings\n            recording_times (recording_times_cl):\n                recording times object\n            mon_dict (dict):\n                dict of recorded variables of the monitors\n            data (dict):\n                dict with optional data stored during the experiment\n        \"\"\"\n\n        def __init__(self) -&gt; None:\n            self.recordings: list\n            self.recording_times: RecordingTimes\n            self.mon_dict: dict\n            self.data: dict\n\n    def run(self) -&gt; _ResultsCl:\n        \"\"\"\n        !!! warning\n            This function has to be implemented by the user!\n        \"\"\"\n        raise NotImplementedError(\n            \"\"\"\n                You have to implement a run function which runs the simulations and\n                controlls the recordings. The run function should return the results of\n                the experiment by calling the results function of the CompNeuroExp class.\n            \"\"\"\n        )\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.__init__","title":"<code>__init__(monitors=None)</code>","text":"<p>Initialize the experiment.</p> <p>Parameters:</p> Name Type Description Default <code>monitors</code> <code>CompNeuroMonitors</code> <p>CompNeuroMonitors object for recordings</p> <code>None</code> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def __init__(\n    self,\n    monitors: CompNeuroMonitors | None = None,\n):\n    \"\"\"\n    Initialize the experiment.\n\n    Args:\n        monitors (CompNeuroMonitors):\n            CompNeuroMonitors object for recordings\n    \"\"\"\n    self.recordings = {}  # save dict for monitor recordings\n    self.monitors = monitors\n    self.data = {}  # dict for optional data\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.reset","title":"<code>reset(populations=True, projections=False, synapses=False, model=True, parameters=True)</code>","text":"<p>Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the experiment.</p> <p>Warning</p> <p>If you want the network to have the same state at the beginning of each experiment run, you should call this function at the beginning of the run function of the CompNeuroExp class! If you only want to have the same time for the network at the beginning of each experiment run, set populations, projections, and synapses to False.</p> <p>Parameters:</p> Name Type Description Default <code>populations</code> <code>bool</code> <p>reset populations. Defaults to True.</p> <code>True</code> <code>projections</code> <code>bool</code> <p>reset projections. Defaults to False.</p> <code>False</code> <code>synapses</code> <code>bool</code> <p>reset synapses. Defaults to False.</p> <code>False</code> <code>model</code> <code>bool</code> <p>If False, do ignore the arguments populations, projections, and synapses (the network state doesn't change) and only reset the CompNeuroMonitors Default: True.</p> <code>True</code> <code>parameters</code> <code>bool</code> <p>If False, do not reset the parameters of the model. Default: True.</p> <code>True</code> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def reset(\n    self,\n    populations=True,\n    projections=False,\n    synapses=False,\n    model=True,\n    parameters=True,\n):\n    \"\"\"\n    Reset the ANNarchy model and monitors and the CompNeuroMonitors used for the\n    experiment.\n\n    !!! warning\n        If you want the network to have the same state at the beginning of each\n        experiment run, you should call this function at the beginning of the run\n        function of the CompNeuroExp class! If you only want to have the same time\n        for the network at the beginning of each experiment run, set populations,\n        projections, and synapses to False.\n\n    Args:\n        populations (bool, optional):\n            reset populations. Defaults to True.\n        projections (bool, optional):\n            reset projections. Defaults to False.\n        synapses (bool, optional):\n            reset synapses. Defaults to False.\n        model (bool, optional):\n            If False, do ignore the arguments populations, projections, and\n            synapses (the network state doesn't change) and only reset the\n            CompNeuroMonitors Default: True.\n        parameters (bool, optional):\n            If False, do not reset the parameters of the model. Default: True.\n    \"\"\"\n    reset_kwargs = {}\n    reset_kwargs[\"populations\"] = populations\n    reset_kwargs[\"projections\"] = projections\n    reset_kwargs[\"synapses\"] = synapses\n    reset_kwargs[\"monitors\"] = True\n\n    ### reset CompNeuroMonitors and ANNarchy model\n    if self.monitors is not None:\n        self.monitors.reset(model=model, parameters=parameters, **reset_kwargs)\n    elif model is True:\n        if parameters is False:\n            ### if parameters=False, get parameters before reset and set them after\n            ### reset\n            parameters = mf._get_all_parameters()\n        reset(**reset_kwargs)\n        if parameters is False:\n            ### if parameters=False, set parameters after reset\n            mf._set_all_parameters(parameters)\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.results","title":"<code>results()</code>","text":"<p>Warning</p> <p>Call this function at the end of the run function of the CompNeuroExp class!</p> <p>Warning</p> <p>Calling this function resets the CompNeuroMonitors. For example, if you simulate two recording chunks in the run function and you run the experiment twice, you will get two recording chunks for each experiment run (not two for the first and four for the second run). But ANNarchy is not resetted automatically! So the network time and state (activity etc.) at the beginning of the second run is the same as at the end of the first run. To prevent this use the reset function of the CompNeuroExp class.</p> <p>Returns:</p> Name Type Description <code>results_obj</code> <code>_ResultsCl</code> <p>Object with attributes:     recordings (list):         list of recordings     recording_times (recording_times_cl):         recording times object     mon_dict (dict):         dict of recorded variables of the monitors     data (dict):         dict with optional data stored during the experiment</p> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def results(self):\n    \"\"\"\n    !!! warning\n        Call this function at the end of the run function of the CompNeuroExp class!\n\n    !!! warning\n        Calling this function resets the CompNeuroMonitors. For example, if you\n        simulate two recording chunks in the run function and you run the experiment\n        twice, you will get two recording chunks for each experiment run (not two\n        for the first and four for the second run). But ANNarchy is not resetted\n        automatically! So the network time and state (activity etc.) at the\n        beginning of the second run is the same as at the end of the first run. To\n        prevent this use the reset function of the CompNeuroExp class.\n\n    Returns:\n        results_obj (CompNeuroExp._ResultsCl):\n            Object with attributes:\n                recordings (list):\n                    list of recordings\n                recording_times (recording_times_cl):\n                    recording times object\n                mon_dict (dict):\n                    dict of recorded variables of the monitors\n                data (dict):\n                    dict with optional data stored during the experiment\n    \"\"\"\n    obj = self._ResultsCl()\n    if self.monitors is not None:\n        (\n            obj.recordings,\n            obj.recording_times,\n        ) = self.monitors.get_recordings_and_clear()\n        obj.mon_dict = self.monitors.mon_dict\n    else:\n        obj.recordings = []\n        obj.recording_times = None\n        obj.mon_dict = {}\n    obj.data = self.data\n\n    return obj\n</code></pre>"},{"location":"main/define_experiment/#CompNeuroPy.experiment.CompNeuroExp.run","title":"<code>run()</code>","text":"<p>Warning</p> <p>This function has to be implemented by the user!</p> Source code in <code>src/CompNeuroPy/experiment.py</code> <pre><code>def run(self) -&gt; _ResultsCl:\n    \"\"\"\n    !!! warning\n        This function has to be implemented by the user!\n    \"\"\"\n    raise NotImplementedError(\n        \"\"\"\n            You have to implement a run function which runs the simulations and\n            controlls the recordings. The run function should return the results of\n            the experiment by calling the results function of the CompNeuroExp class.\n        \"\"\"\n    )\n</code></pre>"},{"location":"main/generate_models/","title":"Generate Models","text":""},{"location":"main/generate_models/#introduction","title":"Introduction","text":"<p>One can create a CompNeuroPy-model using the <code>CompNeuroModel</code> class. The <code>CompNeuroModel</code> class takes as one argument the <code>model_creation_function</code>. In this function a classical ANNarchy model is created (populations, projections). The <code>CompNeuroModel</code> class only adds a framework to the model. Neccessary for a CompNeuroPy-model is to define unique names for all populations and projections. Models are created in three steps:</p> <ol> <li>model initialization: the initialization of the <code>CompNeuroModel</code> object, initializes the framework of the model without creating the ANNarchy objects (populations, projections)</li> <li>model creation: create the ANNarchy objects (populations, projections), i.e., run the <code>model_creation function</code></li> <li>model compilation: compile all created models</li> </ol>"},{"location":"main/generate_models/#example","title":"Example","text":"<pre><code>from CompNeuroPy import CompNeuroModel\nmy_model = CompNeuroModel(model_creation_function=create_model,  ### the most important part, this function creates the model (populations, projections)\n                          model_kwargs={'a':1, 'b':2},           ### define the two arguments a and b of function create_model\n                          name='my_model',                       ### you can give the model a name\n                          description='my simple example model', ### you can give the model a description\n                          do_create=True,                        ### create the model directly\n                          do_compile=True,                       ### let the model (and all models created before) compile directly\n                          compile_folder_name='my_model')        ### name of the saved compilation folder\n</code></pre> <p>The following function could be the corresponding model_creation_function:</p> <pre><code>from ANNarchy import Population, Izhikevich\ndef create_model(a, b):\n    pop = Population(geometry=a, neuron=Izhikevich, name='Izh_pop_a') ### first population, size a\n    pop.b = 0                                                         ### some parameter adjustment\n    Population(geometry=b, neuron=Izhikevich, name='Izh_pop_b')       ### second population, size b\n</code></pre> <p>Here, two populations are created (both use built-in Izhikevich neuron model of ANNarchy). The function does not require a return value. It is important that all populations and projections have unique names.</p> <p>A more detailed example is available in the Examples.</p>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel","title":"<code>CompNeuroPy.generate_model.CompNeuroModel</code>","text":"<p>Class for creating and compiling a model.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>name of the model</p> <code>description</code> <code>str</code> <p>description of the model</p> <code>populations</code> <code>list</code> <p>list of all populations of the model</p> <code>projections</code> <code>list</code> <p>list of all projections of the model</p> <code>attribute_df</code> <code>pandas dataframe</code> <p>dataframe containing all attributes of the model compartments</p> <code>created</code> <code>bool</code> <p>True if the model is created</p> <code>compiled</code> <code>bool</code> <p>True if the model is compiled</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>class CompNeuroModel:\n    \"\"\"\n    Class for creating and compiling a model.\n\n    Attributes:\n        name (str):\n            name of the model\n        description (str):\n            description of the model\n        populations (list):\n            list of all populations of the model\n        projections (list):\n            list of all projections of the model\n        attribute_df (pandas dataframe):\n            dataframe containing all attributes of the model compartments\n        created (bool):\n            True if the model is created\n        compiled (bool):\n            True if the model is compiled\n    \"\"\"\n\n    initialized_models = {}\n    compiled_models = {}\n\n    def __init__(\n        self,\n        model_creation_function,\n        model_kwargs=None,\n        name=\"model\",\n        description=\"\",\n        do_create=True,\n        do_compile=True,\n        compile_folder_name=\"annarchy\",\n    ):\n        \"\"\"\n        Initializes the CompNeuroModel class.\n\n        Args:\n            model_creation_function (function):\n                Function which creates the model.\n            model_kwargs (dict):\n                Keyword arguments for model_creation_function. Default: None.\n            name (str):\n                Name of the model. Default: \"model\".\n            description (str):\n                Description of the model. Default: \"\".\n            do_create (bool):\n                If True the model is created directly. Default: True.\n            do_compile (bool):\n                If True the model is compiled directly. Default: True.\n            compile_folder_name (str):\n                Name of the folder in which the model is compiled. Default: \"annarchy\".\n        \"\"\"\n        self.name = name\n        if name == \"model\":\n            self.name = name + str(self._nr_models())\n        self.description = description\n        self.model_creation_function = model_creation_function\n        self.compile_folder_name = compile_folder_name\n        self.model_kwargs = model_kwargs\n        self.populations = []\n        self.projections = []\n        self.initialized_models[self.name] = False\n        self.compiled_models[self.name] = False\n        if do_create:\n            self.create(do_compile=do_compile, compile_folder_name=compile_folder_name)\n\n    def __getattr__(self, name):\n        if name == \"created\":\n            return self.initialized_models[self.name]\n        elif name == \"compiled\":\n            return self.compiled_models[self.name]\n        else:\n            # Default behaviour\n            raise AttributeError\n\n    def compile(self, compile_folder_name=None):\n        \"\"\"\n        Compiles a created model.\n\n        Args:\n            compile_folder_name (str, optional):\n                Name of the folder in which the model is compiled. Default: value from\n                initialization.\n        \"\"\"\n        ### check if this model is created\n        if self.initialized_models[self.name]:\n            if compile_folder_name == None:\n                compile_folder_name = self.compile_folder_name\n\n            ### check if other models were initialized but not created --&gt; warn that they are not compiled\n            not_created_model_list = self._check_if_models_created()\n            if len(not_created_model_list) &gt; 0:\n                print(\n                    \"\\nWARNING during compile of model \"\n                    + self.name\n                    + \": There are initialized models which are not created, thus not compiled! models:\\n\"\n                    + \"\\n\".join(not_created_model_list)\n                    + \"\\n\"\n                )\n            mf.compile_in_folder(compile_folder_name)\n            self.compiled_models[self.name] = True\n        else:\n            print(\"\\n\")\n            assert False, (\n                \"ERROR during compile of model \"\n                + self.name\n                + \": Only compile the model after it has been created!\"\n            )\n\n    def create(self, do_compile=True, compile_folder_name=None):\n        \"\"\"\n        Creates a model and optionally compiles it directly.\n\n        Args:\n            do_compile (bool, optional):\n                If True the model is compiled directly. Default: True.\n            compile_folder_name (str, optional):\n                Name of the folder in which the model is compiled. Default: value from\n                initialization.\n        \"\"\"\n        if self.initialized_models[self.name]:\n            print(\"model\", self.name, \"already created!\")\n        else:\n            initial_existing_model = mf.get_full_model()\n            ### create model populations and projections\n            if self.model_kwargs != None:\n                self.model_creation_function(**self.model_kwargs)\n            else:\n                self.model_creation_function()\n            self.initialized_models[self.name] = True\n\n            ### check which populations and projections have been added\n            post_existing_model = mf.get_full_model()\n            ### save only added not all projections/populations\n            for initial_pop in initial_existing_model[\"populations\"]:\n                post_existing_model[\"populations\"].remove(initial_pop)\n            for initial_proj in initial_existing_model[\"projections\"]:\n                post_existing_model[\"projections\"].remove(initial_proj)\n            self.populations = post_existing_model[\"populations\"]\n            self.projections = post_existing_model[\"projections\"]\n\n            self.initialized_models[self.name] = True\n\n            ### check if names of populations and projections are unique\n            self._check_double_compartments()\n\n            ### create parameter dictionary\n            self.attribute_df = self._get_attribute_df()\n\n            if do_compile:\n                self.compile(compile_folder_name)\n\n    def _check_if_models_created(self):\n        \"\"\"\n        Checks which CompNeuroPy models are created\n\n        Returns:\n            not_created_model_list (list):\n                list of names of all initialized CompNeuroPy models which are not\n                created yet\n        \"\"\"\n        not_created_model_list = []\n        for key in self.initialized_models.keys():\n            if self.initialized_models[key] == False:\n                not_created_model_list.append(key)\n\n        return not_created_model_list\n\n    def _nr_models(self):\n        \"\"\"\n        Returns:\n            nr_models (int):\n                The current number of initialized (not considering \"created\")\n                CompNeuroPy models\n        \"\"\"\n        return len(list(self.initialized_models.keys()))\n\n    def set_param(self, compartment, parameter_name, parameter_value):\n        \"\"\"\n        Sets the specified parameter of the specified compartment.\n\n        Args:\n            compartment (str):\n                name of model compartment\n            parameter_name (str):\n                name of parameter of the compartment\n            parameter_value (number or array-like with shape of compartment geometry):\n                the value or values of the parameter\n\n        Raises:\n            AssertionError: if model is not created\n            AssertionError: if compartment is neither a population nor a projection of\n                the model\n        \"\"\"\n        ### catch if model is not created\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR set_param: model {self.name} has to be created before setting parameters!\"\n\n        ### check if compartment is in populations or projections\n        comp_in_pop = compartment in self.populations\n        comp_in_proj = compartment in self.projections\n\n        if comp_in_pop:\n            comp_obj = get_population(compartment)\n        elif comp_in_proj:\n            comp_obj = get_projection(compartment)\n        else:\n            assert (\n                comp_in_pop or comp_in_proj\n            ), f\"ERROR set_param: setting parameter {parameter_name} of compartment {compartment}. The compartment is neither a population nor a projection of the model {self.name}!\"\n\n        ### set the parameter value\n        setattr(comp_obj, parameter_name, parameter_value)\n\n        ### update the model attribute_df\n        self._update_attribute_df(compartment, parameter_name, parameter_value)\n\n    def _update_attribute_df(self, compartment, parameter_name, parameter_value):\n        \"\"\"\n        updates the attribute df for a specific paramter\n\n        Args:\n            compartment (str):\n                name of model compartment\n            parameter_name (str):\n                name of parameter of the compartment\n            parameter_value (number or array-like with shape of compartment geometry):\n                the value or values of the parameter\n        \"\"\"\n        paramter_mask = (\n            (self.attribute_df[\"compartment_name\"] == compartment).astype(int)\n            * (self.attribute_df[\"attribute_name\"] == parameter_name).astype(int)\n        ).astype(bool)\n        parameter_idx = np.arange(paramter_mask.size).astype(int)[paramter_mask][0]\n        min_val = af.get_minimum(parameter_value)\n        max_val = af.get_maximum(parameter_value)\n        if min_val != max_val:\n            self.attribute_df.at[parameter_idx, \"value\"] = f\"[{min_val}, {max_val}]\"\n        else:\n            self.attribute_df.at[parameter_idx, \"value\"] = str(min_val)\n        self.attribute_df.at[parameter_idx, \"definition\"] = \"modified\"\n\n    def _check_double_compartments(self):\n        \"\"\"\n        Goes over all compartments of the model and checks if compartment is only a\n        population or a projection and not both.\n\n        Raises:\n            AssertionError: if model is not created\n            AssertionError: if compartment is both a population and a projection\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR model {self.name}: model has to be created before checking for double compartments!\"\n        ### only have to go over populations and check if they are also projections (go over projections not neccessary)\n        pop_in_projections_list = []\n        pop_in_projections = False\n        for pop_name in self.populations:\n            if pop_name in self.projections:\n                pop_in_projections_list.append(pop_name)\n                pop_in_projections = True\n\n        assert (\n            pop_in_projections == False\n        ), f\"ERROR model {self.name}: One or multiple compartments are both population and projection ({pop_in_projections_list}). Rename them!\"\n\n    def _get_attribute_df(self):\n        \"\"\"\n        Creates a dataframe containing the attributes of all model compartments.\n\n        Returns:\n            attribute_df (pandas dataframe):\n                dataframe containing all attributes of the model compartments\n\n        Raises:\n            AssertionError: if model is not created\n        \"\"\"\n        ### cach if model is not created, only if created populations and projections are available\n        assert (\n            self.initialized_models[self.name] == True\n        ), f\"ERROR model {self.name}: model has to be created before creating paramteer dictionary!\"\n\n        ### create empty paramteter dict\n        attribute_dict = {\n            \"compartment_type\": [],\n            \"compartment_name\": [],\n            \"attribute_name\": [],\n            \"value\": [],\n            \"definition\": [],\n        }\n\n        ### fill paramter dict with population attributes\n        for pop in self.populations:\n            for attribute in vars(get_population(pop))[\"attributes\"]:\n                ### store min and max of attribute\n                ### create numpy array with getattr to use numpy min max function\n                values = np.array(\n                    [getattr(get_population(pop), attribute)]\n                    + [getattr(get_population(pop), attribute)]\n                )\n                attribute_dict[\"compartment_type\"].append(\"population\")\n                attribute_dict[\"compartment_name\"].append(pop)\n                attribute_dict[\"attribute_name\"].append(attribute)\n                if values.min() != values.max():\n                    attribute_dict[\"value\"].append(f\"[{values.min()}, {values.max()}]\")\n                else:\n                    attribute_dict[\"value\"].append(str(values.min()))\n                attribute_dict[\"definition\"].append(\"init\")\n\n        ### fill paramter dict with projection attributes\n        for proj in self.projections:\n            for attribute in vars(get_projection(proj))[\"attributes\"]:\n                ### store min and max of attribute\n                ### create numpy array with getattr to use numpy min max function\n                values = np.array(\n                    [getattr(get_projection(proj), attribute)]\n                    + [getattr(get_projection(proj), attribute)]\n                )\n                attribute_dict[\"compartment_type\"].append(\"projection\")\n                attribute_dict[\"compartment_name\"].append(proj)\n                attribute_dict[\"attribute_name\"].append(attribute)\n                if values.min() != values.max():\n                    attribute_dict[\"value\"].append(f\"[{values.min()}, {values.max()}]\")\n                else:\n                    attribute_dict[\"value\"].append(values.min())\n                attribute_dict[\"definition\"].append(\"init\")\n\n        ### return dataframe\n        return pd.DataFrame(attribute_dict)\n</code></pre>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.__init__","title":"<code>__init__(model_creation_function, model_kwargs=None, name='model', description='', do_create=True, do_compile=True, compile_folder_name='annarchy')</code>","text":"<p>Initializes the CompNeuroModel class.</p> <p>Parameters:</p> Name Type Description Default <code>model_creation_function</code> <code>function</code> <p>Function which creates the model.</p> required <code>model_kwargs</code> <code>dict</code> <p>Keyword arguments for model_creation_function. Default: None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the model. Default: \"model\".</p> <code>'model'</code> <code>description</code> <code>str</code> <p>Description of the model. Default: \"\".</p> <code>''</code> <code>do_create</code> <code>bool</code> <p>If True the model is created directly. Default: True.</p> <code>True</code> <code>do_compile</code> <code>bool</code> <p>If True the model is compiled directly. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: \"annarchy\".</p> <code>'annarchy'</code> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def __init__(\n    self,\n    model_creation_function,\n    model_kwargs=None,\n    name=\"model\",\n    description=\"\",\n    do_create=True,\n    do_compile=True,\n    compile_folder_name=\"annarchy\",\n):\n    \"\"\"\n    Initializes the CompNeuroModel class.\n\n    Args:\n        model_creation_function (function):\n            Function which creates the model.\n        model_kwargs (dict):\n            Keyword arguments for model_creation_function. Default: None.\n        name (str):\n            Name of the model. Default: \"model\".\n        description (str):\n            Description of the model. Default: \"\".\n        do_create (bool):\n            If True the model is created directly. Default: True.\n        do_compile (bool):\n            If True the model is compiled directly. Default: True.\n        compile_folder_name (str):\n            Name of the folder in which the model is compiled. Default: \"annarchy\".\n    \"\"\"\n    self.name = name\n    if name == \"model\":\n        self.name = name + str(self._nr_models())\n    self.description = description\n    self.model_creation_function = model_creation_function\n    self.compile_folder_name = compile_folder_name\n    self.model_kwargs = model_kwargs\n    self.populations = []\n    self.projections = []\n    self.initialized_models[self.name] = False\n    self.compiled_models[self.name] = False\n    if do_create:\n        self.create(do_compile=do_compile, compile_folder_name=compile_folder_name)\n</code></pre>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.compile","title":"<code>compile(compile_folder_name=None)</code>","text":"<p>Compiles a created model.</p> <p>Parameters:</p> Name Type Description Default <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: value from initialization.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def compile(self, compile_folder_name=None):\n    \"\"\"\n    Compiles a created model.\n\n    Args:\n        compile_folder_name (str, optional):\n            Name of the folder in which the model is compiled. Default: value from\n            initialization.\n    \"\"\"\n    ### check if this model is created\n    if self.initialized_models[self.name]:\n        if compile_folder_name == None:\n            compile_folder_name = self.compile_folder_name\n\n        ### check if other models were initialized but not created --&gt; warn that they are not compiled\n        not_created_model_list = self._check_if_models_created()\n        if len(not_created_model_list) &gt; 0:\n            print(\n                \"\\nWARNING during compile of model \"\n                + self.name\n                + \": There are initialized models which are not created, thus not compiled! models:\\n\"\n                + \"\\n\".join(not_created_model_list)\n                + \"\\n\"\n            )\n        mf.compile_in_folder(compile_folder_name)\n        self.compiled_models[self.name] = True\n    else:\n        print(\"\\n\")\n        assert False, (\n            \"ERROR during compile of model \"\n            + self.name\n            + \": Only compile the model after it has been created!\"\n        )\n</code></pre>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.create","title":"<code>create(do_compile=True, compile_folder_name=None)</code>","text":"<p>Creates a model and optionally compiles it directly.</p> <p>Parameters:</p> Name Type Description Default <code>do_compile</code> <code>bool</code> <p>If True the model is compiled directly. Default: True.</p> <code>True</code> <code>compile_folder_name</code> <code>str</code> <p>Name of the folder in which the model is compiled. Default: value from initialization.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def create(self, do_compile=True, compile_folder_name=None):\n    \"\"\"\n    Creates a model and optionally compiles it directly.\n\n    Args:\n        do_compile (bool, optional):\n            If True the model is compiled directly. Default: True.\n        compile_folder_name (str, optional):\n            Name of the folder in which the model is compiled. Default: value from\n            initialization.\n    \"\"\"\n    if self.initialized_models[self.name]:\n        print(\"model\", self.name, \"already created!\")\n    else:\n        initial_existing_model = mf.get_full_model()\n        ### create model populations and projections\n        if self.model_kwargs != None:\n            self.model_creation_function(**self.model_kwargs)\n        else:\n            self.model_creation_function()\n        self.initialized_models[self.name] = True\n\n        ### check which populations and projections have been added\n        post_existing_model = mf.get_full_model()\n        ### save only added not all projections/populations\n        for initial_pop in initial_existing_model[\"populations\"]:\n            post_existing_model[\"populations\"].remove(initial_pop)\n        for initial_proj in initial_existing_model[\"projections\"]:\n            post_existing_model[\"projections\"].remove(initial_proj)\n        self.populations = post_existing_model[\"populations\"]\n        self.projections = post_existing_model[\"projections\"]\n\n        self.initialized_models[self.name] = True\n\n        ### check if names of populations and projections are unique\n        self._check_double_compartments()\n\n        ### create parameter dictionary\n        self.attribute_df = self._get_attribute_df()\n\n        if do_compile:\n            self.compile(compile_folder_name)\n</code></pre>"},{"location":"main/generate_models/#CompNeuroPy.generate_model.CompNeuroModel.set_param","title":"<code>set_param(compartment, parameter_name, parameter_value)</code>","text":"<p>Sets the specified parameter of the specified compartment.</p> <p>Parameters:</p> Name Type Description Default <code>compartment</code> <code>str</code> <p>name of model compartment</p> required <code>parameter_name</code> <code>str</code> <p>name of parameter of the compartment</p> required <code>parameter_value</code> <code>number or array-like with shape of compartment geometry</code> <p>the value or values of the parameter</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>if model is not created</p> <code>AssertionError</code> <p>if compartment is neither a population nor a projection of the model</p> Source code in <code>src/CompNeuroPy/generate_model.py</code> <pre><code>def set_param(self, compartment, parameter_name, parameter_value):\n    \"\"\"\n    Sets the specified parameter of the specified compartment.\n\n    Args:\n        compartment (str):\n            name of model compartment\n        parameter_name (str):\n            name of parameter of the compartment\n        parameter_value (number or array-like with shape of compartment geometry):\n            the value or values of the parameter\n\n    Raises:\n        AssertionError: if model is not created\n        AssertionError: if compartment is neither a population nor a projection of\n            the model\n    \"\"\"\n    ### catch if model is not created\n    assert (\n        self.initialized_models[self.name] == True\n    ), f\"ERROR set_param: model {self.name} has to be created before setting parameters!\"\n\n    ### check if compartment is in populations or projections\n    comp_in_pop = compartment in self.populations\n    comp_in_proj = compartment in self.projections\n\n    if comp_in_pop:\n        comp_obj = get_population(compartment)\n    elif comp_in_proj:\n        comp_obj = get_projection(compartment)\n    else:\n        assert (\n            comp_in_pop or comp_in_proj\n        ), f\"ERROR set_param: setting parameter {parameter_name} of compartment {compartment}. The compartment is neither a population nor a projection of the model {self.name}!\"\n\n    ### set the parameter value\n    setattr(comp_obj, parameter_name, parameter_value)\n\n    ### update the model attribute_df\n    self._update_attribute_df(compartment, parameter_name, parameter_value)\n</code></pre>"},{"location":"main/generate_simulations/","title":"Generate Simulations","text":""},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim","title":"<code>CompNeuroPy.generate_simulation.CompNeuroSim</code>","text":"<p>Class for generating a CompNeuroPy simulation.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>class CompNeuroSim:\n    \"\"\"\n    Class for generating a CompNeuroPy simulation.\n    \"\"\"\n\n    _initialized_simulations = []\n\n    def __init__(\n        self,\n        simulation_function: Callable,\n        simulation_kwargs: dict | None = None,\n        name: str = \"simulation\",\n        description: str = \"\",\n        requirements: list | None = None,\n        kwargs_warning: bool = False,\n        monitor_object: CompNeuroMonitors | None = None,\n    ):\n        \"\"\"\n        Args:\n            simulation_function (function):\n                Function which runs the simulation.\n            simulation_kwargs (dict, optional):\n                Dictionary of arguments for the simulation_function. Default: None.\n            name (str, optional):\n                Name of the simulation. Default: \"simulation\".\n            description (str, optional):\n                Description of the simulation. Default: \"\".\n            requirements (list, optional):\n                List of requirements for the simulation. It's a list of dictionaries\n                which contain the requirement class itself (key: \"req\") and the\n                corresponding arguments (keys are the names of the arguments). The\n                arguments can be inherited from the simulation kwargs by using the\n                syntax 'simulation_kwargs.&lt;kwarg_name&gt;'. Default: None.\n            kwargs_warning (bool, optional):\n                If True, a warning is printed if the simulation_kwargs are changed\n                during the simulation. Default: False.\n            monitor_object (CompNeuroMonitors object, optional):\n                CompNeuroMonitors object to automatically track the recording chunk for each\n                simulation run. Default: None.\n        \"\"\"\n        # set simulation function\n        self.name = name\n        if name == \"simulation\":\n            self.name = name + str(self._nr_simulations())\n        self._initialized_simulations.append(self.name)\n        self.description = description\n        self.simulation_function = simulation_function\n        self.simulation_kwargs = simulation_kwargs\n        if requirements is None:\n            self.requirements = []\n        else:\n            self.requirements = requirements\n        self.start = []\n        self.end = []\n        self.info = []\n        self.kwargs = []\n        if kwargs_warning:\n            self._warned = False\n        else:\n            self._warned = True\n        self.monitor_object = monitor_object\n        if monitor_object is not None:\n            self.monitor_chunk = []\n        else:\n            self.monitor_chunk = None\n\n        ### test initial requirements\n        self._test_req(simulation_kwargs=simulation_kwargs)\n\n    def run(self, simulation_kwargs: dict | None = None):\n        \"\"\"\n        Runs the simulation function. With each run extend start, end list containing\n        start and end time of the corresponding run and the info list containing the\n        return value of the simulation function.\n\n        Args:\n            simulation_kwargs (dict, optional):\n                Temporary simulation kwargs which override the initialized simulation\n                kwargs. Default: None, i.e., use values from initialization.\n        \"\"\"\n\n        ### define the current simulation kwargs\n        if simulation_kwargs is not None:\n            if self.simulation_kwargs is not None:\n                ### not replace initialized kwargs completely but only the kwargs which are given\n                tmp_kwargs = self.simulation_kwargs.copy()\n                for key, val in simulation_kwargs.items():\n                    tmp_kwargs[key] = val\n            else:\n                ### there are no initial kwargs --&gt; only use the kwargs which are given\n                tmp_kwargs = simulation_kwargs\n            if not (self._warned) and len(self.requirements) &gt; 0:\n                print(\n                    \"\\nWARNING! run\",\n                    self.name,\n                    \"changed simulation kwargs, initial requirements may no longer be fulfilled!\\n\",\n                )\n                self._warned = True\n        else:\n            tmp_kwargs = self.simulation_kwargs\n\n        ### before each run, test requirements\n        self._test_req(simulation_kwargs=tmp_kwargs)\n\n        ### and append current simulation kwargs to the kwargs variable\n        self.kwargs.append(tmp_kwargs)\n\n        ### and append the current chunk of the monitors object to the chunk variable\n        if self.monitor_object is not None:\n            self.monitor_chunk.append(self.monitor_object.current_chunk())\n\n        ### run the simulation, store start and end simulation time\n        self.start.append(get_time())\n        if tmp_kwargs is not None:\n            self.info.append(self.simulation_function(**tmp_kwargs))\n        else:\n            self.info.append(self.simulation_function())\n        self.end.append(get_time())\n\n    def _nr_simulations(self):\n        \"\"\"\n        Returns the current number of initialized CompNeuroPy simulations.\n        \"\"\"\n        return len(self._initialized_simulations)\n\n    def _test_req(self, simulation_kwargs=None):\n        \"\"\"\n        Tests the initialized requirements with the current simulation_kwargs.\n        \"\"\"\n\n        if simulation_kwargs is None:  # --&gt; use the initial simulation_kwargs\n            simulation_kwargs = self.simulation_kwargs\n\n        for req in self.requirements:\n            ### check if requirement_kwargs are given besides the requirement itself\n            if len(list(req.keys())) &gt; 1:\n                ### remove the requirement itself from the kwargs\n                req_kwargs = ef.remove_key(req, \"req\")\n                ### check if req_kwargs reference to simulation_kwargs, if yes, use the\n                ### current simulation kwargs instead of the intial ones\n                for key, val in req_kwargs.items():\n                    if isinstance(val, str):\n                        val_split = val.split(\".\")\n                        ### check if val is a reference to simulation_kwargs\n                        if val_split[0] == \"simulation_kwargs\":\n                            if len(val_split) == 1:\n                                ### val is only simulation_kwargs\n                                req_kwargs = simulation_kwargs\n                            elif len(val_split) == 2:\n                                ### val is simulation_kwargs.something\n                                req_kwargs[key] = simulation_kwargs[val_split[1]]\n                            else:\n                                ### val is simulation_kwargs.something.something... e.g. key='pops' and val= 'simulation_kwargs.model.populations'\n                                req_kwargs[key] = eval(\n                                    'simulation_kwargs[\"'\n                                    + val_split[1]\n                                    + '\"].'\n                                    + \".\".join(val_split[2:])\n                                )\n                ### run the requirement using the current req_kwargs\n                req[\"req\"](**req_kwargs).run()\n\n            else:\n                ### a requirement is given without kwargs --&gt; just run it\n                req[\"req\"]().run()\n\n    def get_current_arr(self, dt, flat=False):\n        \"\"\"\n        Method exclusively for current_step simulation functions. Gets the current array\n        (input current value for each time step) of all runs.\n\n        !!! warning\n            This method will be removed soon. Use the get_current_arr method of the\n            SimInfo class instead.\n\n        Args:\n            dt (float):\n                Time step size of the simulation.\n            flat (bool, optional):\n                If True, returns a flattened array. Assumes that all runs are run\n                consecutively without brakes. Default: False, i.e., returns a list of\n                arrays.\n\n        Returns:\n            current_arr (list of arrays):\n                List of arrays containing the current values for each time step of each\n                run. If flat=True, returns a flattened array.\n        \"\"\"\n        assert (\n            self.simulation_function.__name__ == \"current_step\"\n        ), 'ERROR get_current_arr: Simulation has to be \"current_step\"!'\n        ### TODO: remove because deprecated\n        print(\n            \"WARNING get_current_arr function will only be available in SimInfo soon.\"\n        )\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t1 = self.kwargs[run][\"t1\"]\n            t2 = self.kwargs[run][\"t2\"]\n            a1 = self.kwargs[run][\"a1\"]\n            a2 = self.kwargs[run][\"a2\"]\n\n            if t1 &gt; 0 and t2 &gt; 0:\n                current_arr.append(\n                    np.concatenate(\n                        [\n                            np.ones(int(round(t1 / dt))) * a1,\n                            np.ones(int(round(t2 / dt))) * a2,\n                        ]\n                    )\n                )\n            elif t2 &gt; 0:\n                current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n            else:\n                current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    def simulation_info(self):\n        \"\"\"\n        Returns a SimInfo object containing the simulation information.\n\n        Returns:\n            simulation_info_obj (SimInfo):\n                Simulation information object.\n        \"\"\"\n\n        simulation_info_obj = SimInfo(\n            self.name,\n            self.description,\n            self.simulation_function.__name__,\n            self.start,\n            self.end,\n            self.info,\n            self.kwargs,\n            self.monitor_chunk,\n        )\n\n        return simulation_info_obj\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim.__init__","title":"<code>__init__(simulation_function, simulation_kwargs=None, name='simulation', description='', requirements=None, kwargs_warning=False, monitor_object=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>simulation_function</code> <code>function</code> <p>Function which runs the simulation.</p> required <code>simulation_kwargs</code> <code>dict</code> <p>Dictionary of arguments for the simulation_function. Default: None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the simulation. Default: \"simulation\".</p> <code>'simulation'</code> <code>description</code> <code>str</code> <p>Description of the simulation. Default: \"\".</p> <code>''</code> <code>requirements</code> <code>list</code> <p>List of requirements for the simulation. It's a list of dictionaries which contain the requirement class itself (key: \"req\") and the corresponding arguments (keys are the names of the arguments). The arguments can be inherited from the simulation kwargs by using the syntax 'simulation_kwargs.'. Default: None. <code>None</code> <code>kwargs_warning</code> <code>bool</code> <p>If True, a warning is printed if the simulation_kwargs are changed during the simulation. Default: False.</p> <code>False</code> <code>monitor_object</code> <code>CompNeuroMonitors object</code> <p>CompNeuroMonitors object to automatically track the recording chunk for each simulation run. Default: None.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def __init__(\n    self,\n    simulation_function: Callable,\n    simulation_kwargs: dict | None = None,\n    name: str = \"simulation\",\n    description: str = \"\",\n    requirements: list | None = None,\n    kwargs_warning: bool = False,\n    monitor_object: CompNeuroMonitors | None = None,\n):\n    \"\"\"\n    Args:\n        simulation_function (function):\n            Function which runs the simulation.\n        simulation_kwargs (dict, optional):\n            Dictionary of arguments for the simulation_function. Default: None.\n        name (str, optional):\n            Name of the simulation. Default: \"simulation\".\n        description (str, optional):\n            Description of the simulation. Default: \"\".\n        requirements (list, optional):\n            List of requirements for the simulation. It's a list of dictionaries\n            which contain the requirement class itself (key: \"req\") and the\n            corresponding arguments (keys are the names of the arguments). The\n            arguments can be inherited from the simulation kwargs by using the\n            syntax 'simulation_kwargs.&lt;kwarg_name&gt;'. Default: None.\n        kwargs_warning (bool, optional):\n            If True, a warning is printed if the simulation_kwargs are changed\n            during the simulation. Default: False.\n        monitor_object (CompNeuroMonitors object, optional):\n            CompNeuroMonitors object to automatically track the recording chunk for each\n            simulation run. Default: None.\n    \"\"\"\n    # set simulation function\n    self.name = name\n    if name == \"simulation\":\n        self.name = name + str(self._nr_simulations())\n    self._initialized_simulations.append(self.name)\n    self.description = description\n    self.simulation_function = simulation_function\n    self.simulation_kwargs = simulation_kwargs\n    if requirements is None:\n        self.requirements = []\n    else:\n        self.requirements = requirements\n    self.start = []\n    self.end = []\n    self.info = []\n    self.kwargs = []\n    if kwargs_warning:\n        self._warned = False\n    else:\n        self._warned = True\n    self.monitor_object = monitor_object\n    if monitor_object is not None:\n        self.monitor_chunk = []\n    else:\n        self.monitor_chunk = None\n\n    ### test initial requirements\n    self._test_req(simulation_kwargs=simulation_kwargs)\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim.run","title":"<code>run(simulation_kwargs=None)</code>","text":"<p>Runs the simulation function. With each run extend start, end list containing start and end time of the corresponding run and the info list containing the return value of the simulation function.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_kwargs</code> <code>dict</code> <p>Temporary simulation kwargs which override the initialized simulation kwargs. Default: None, i.e., use values from initialization.</p> <code>None</code> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def run(self, simulation_kwargs: dict | None = None):\n    \"\"\"\n    Runs the simulation function. With each run extend start, end list containing\n    start and end time of the corresponding run and the info list containing the\n    return value of the simulation function.\n\n    Args:\n        simulation_kwargs (dict, optional):\n            Temporary simulation kwargs which override the initialized simulation\n            kwargs. Default: None, i.e., use values from initialization.\n    \"\"\"\n\n    ### define the current simulation kwargs\n    if simulation_kwargs is not None:\n        if self.simulation_kwargs is not None:\n            ### not replace initialized kwargs completely but only the kwargs which are given\n            tmp_kwargs = self.simulation_kwargs.copy()\n            for key, val in simulation_kwargs.items():\n                tmp_kwargs[key] = val\n        else:\n            ### there are no initial kwargs --&gt; only use the kwargs which are given\n            tmp_kwargs = simulation_kwargs\n        if not (self._warned) and len(self.requirements) &gt; 0:\n            print(\n                \"\\nWARNING! run\",\n                self.name,\n                \"changed simulation kwargs, initial requirements may no longer be fulfilled!\\n\",\n            )\n            self._warned = True\n    else:\n        tmp_kwargs = self.simulation_kwargs\n\n    ### before each run, test requirements\n    self._test_req(simulation_kwargs=tmp_kwargs)\n\n    ### and append current simulation kwargs to the kwargs variable\n    self.kwargs.append(tmp_kwargs)\n\n    ### and append the current chunk of the monitors object to the chunk variable\n    if self.monitor_object is not None:\n        self.monitor_chunk.append(self.monitor_object.current_chunk())\n\n    ### run the simulation, store start and end simulation time\n    self.start.append(get_time())\n    if tmp_kwargs is not None:\n        self.info.append(self.simulation_function(**tmp_kwargs))\n    else:\n        self.info.append(self.simulation_function())\n    self.end.append(get_time())\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim.get_current_arr","title":"<code>get_current_arr(dt, flat=False)</code>","text":"<p>Method exclusively for current_step simulation functions. Gets the current array (input current value for each time step) of all runs.</p> <p>Warning</p> <p>This method will be removed soon. Use the get_current_arr method of the SimInfo class instead.</p> <p>Parameters:</p> Name Type Description Default <code>dt</code> <code>float</code> <p>Time step size of the simulation.</p> required <code>flat</code> <code>bool</code> <p>If True, returns a flattened array. Assumes that all runs are run consecutively without brakes. Default: False, i.e., returns a list of arrays.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>current_arr</code> <code>list of arrays</code> <p>List of arrays containing the current values for each time step of each run. If flat=True, returns a flattened array.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def get_current_arr(self, dt, flat=False):\n    \"\"\"\n    Method exclusively for current_step simulation functions. Gets the current array\n    (input current value for each time step) of all runs.\n\n    !!! warning\n        This method will be removed soon. Use the get_current_arr method of the\n        SimInfo class instead.\n\n    Args:\n        dt (float):\n            Time step size of the simulation.\n        flat (bool, optional):\n            If True, returns a flattened array. Assumes that all runs are run\n            consecutively without brakes. Default: False, i.e., returns a list of\n            arrays.\n\n    Returns:\n        current_arr (list of arrays):\n            List of arrays containing the current values for each time step of each\n            run. If flat=True, returns a flattened array.\n    \"\"\"\n    assert (\n        self.simulation_function.__name__ == \"current_step\"\n    ), 'ERROR get_current_arr: Simulation has to be \"current_step\"!'\n    ### TODO: remove because deprecated\n    print(\n        \"WARNING get_current_arr function will only be available in SimInfo soon.\"\n    )\n    current_arr = []\n    for run in range(len(self.kwargs)):\n        t1 = self.kwargs[run][\"t1\"]\n        t2 = self.kwargs[run][\"t2\"]\n        a1 = self.kwargs[run][\"a1\"]\n        a2 = self.kwargs[run][\"a2\"]\n\n        if t1 &gt; 0 and t2 &gt; 0:\n            current_arr.append(\n                np.concatenate(\n                    [\n                        np.ones(int(round(t1 / dt))) * a1,\n                        np.ones(int(round(t2 / dt))) * a2,\n                    ]\n                )\n            )\n        elif t2 &gt; 0:\n            current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n        else:\n            current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n    if flat:\n        return np.concatenate(current_arr)\n    else:\n        return current_arr\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.CompNeuroSim.simulation_info","title":"<code>simulation_info()</code>","text":"<p>Returns a SimInfo object containing the simulation information.</p> <p>Returns:</p> Name Type Description <code>simulation_info_obj</code> <code>SimInfo</code> <p>Simulation information object.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def simulation_info(self):\n    \"\"\"\n    Returns a SimInfo object containing the simulation information.\n\n    Returns:\n        simulation_info_obj (SimInfo):\n            Simulation information object.\n    \"\"\"\n\n    simulation_info_obj = SimInfo(\n        self.name,\n        self.description,\n        self.simulation_function.__name__,\n        self.start,\n        self.end,\n        self.info,\n        self.kwargs,\n        self.monitor_chunk,\n    )\n\n    return simulation_info_obj\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.SimInfo","title":"<code>CompNeuroPy.generate_simulation.SimInfo</code>","text":"<p>Class for storing the simulation information.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the simulation.</p> <code>description</code> <code>str</code> <p>Description of the simulation.</p> <code>simulation_function</code> <code>str</code> <p>Name of the simulation function.</p> <code>start</code> <code>list</code> <p>List of start times of the simulation runs.</p> <code>end</code> <code>list</code> <p>List of end times of the simulation runs.</p> <code>info</code> <code>list</code> <p>List of return values of the simulation function of each simulation run.</p> <code>kwargs</code> <code>list</code> <p>List of simulation kwargs of the simulation function of each simulation run.</p> <code>monitor_chunk</code> <code>list</code> <p>List of recording chunks of the used CompNeuroMonitors object of each simulation run.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>class SimInfo:\n    \"\"\"\n    Class for storing the simulation information.\n\n    Attributes:\n        name (str):\n            Name of the simulation.\n        description (str):\n            Description of the simulation.\n        simulation_function (str):\n            Name of the simulation function.\n        start (list):\n            List of start times of the simulation runs.\n        end (list):\n            List of end times of the simulation runs.\n        info (list):\n            List of return values of the simulation function of each simulation run.\n        kwargs (list):\n            List of simulation kwargs of the simulation function of each simulation run.\n        monitor_chunk (list):\n            List of recording chunks of the used CompNeuroMonitors object of each simulation run.\n    \"\"\"\n\n    def __init__(\n        self,\n        name,\n        description,\n        simulation_function,\n        start,\n        end,\n        info,\n        kwargs,\n        monitor_chunk,\n    ):\n        \"\"\"\n        Initialization of the simulation information object.\n\n        Args:\n            name (str):\n                Name of the simulation.\n            description (str):\n                Description of the simulation.\n            simulation_function (str):\n                Name of the simulation function.\n            start (list):\n                List of start times of the simulation runs.\n            end (list):\n                List of end times of the simulation runs.\n            info (list):\n                List of return values of the simulation function of each simulation run.\n            kwargs (list):\n                List of simulation kwargs of the simulation function of each simulation\n                run.\n            monitor_chunk (list):\n                List of recording chunks of the used CompNeuroMonitors object of each simulation\n                run.\n        \"\"\"\n        self.name = name\n        self.description = description\n        self.simulation_function = simulation_function\n        self.start = start\n        self.end = end\n        self.info = info\n        self.kwargs = kwargs\n        self.monitor_chunk = monitor_chunk\n\n    def get_current_arr(self, dt, flat=False):\n        \"\"\"\n        Method exclusively for the following simulation functions (built-in\n        CompNeuroPy):\n            - current_step\n            - current_stim\n            - current_ramp\n        Gets the current array (input current value for each time step) of all runs.\n\n        Args:\n            dt (float):\n                Time step size of the simulation.\n            flat (bool, optional):\n                If True, returns a flattened array. Assumes that all runs are run\n                consecutively without brakes. Default: False, i.e., returns a list of\n                arrays.\n\n        Returns:\n            current_arr (list of arrays):\n                List of arrays containing the current values for each time step of each\n                run. If flat=True, returns a flattened array.\n        \"\"\"\n        assert (\n            self.simulation_function == \"current_step\"\n            or self.simulation_function == \"current_stim\"\n            or self.simulation_function == \"current_ramp\"\n        ), 'ERROR get_current_arr: Simulation has to be \"current_step\", \"current_stim\" or \"current_ramp\"!'\n\n        if self.simulation_function == \"current_step\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                t1 = self.kwargs[run][\"t1\"]\n                t2 = self.kwargs[run][\"t2\"]\n                a1 = self.kwargs[run][\"a1\"]\n                a2 = self.kwargs[run][\"a2\"]\n\n                if t1 &gt; 0 and t2 &gt; 0:\n                    current_arr.append(\n                        np.concatenate(\n                            [\n                                np.ones(int(round(t1 / dt))) * a1,\n                                np.ones(int(round(t2 / dt))) * a2,\n                            ]\n                        )\n                    )\n                elif t2 &gt; 0:\n                    current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n                else:\n                    current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n\n        elif self.simulation_function == \"current_stim\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                t = self.kwargs[run][\"t\"]\n                a = self.kwargs[run][\"a\"]\n\n                if t &gt; 0:\n                    current_arr.append(np.ones(int(round(t / dt))) * a)\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n\n        elif self.simulation_function == \"current_ramp\":\n            current_arr = []\n            for run in range(len(self.kwargs)):\n                amp = self.kwargs[run][\"a0\"]\n                current_arr_ramp = []\n                for stim_idx in range(self.kwargs[run][\"n\"]):\n                    t = self.info[run][\"dur_stim\"]\n                    a = amp\n                    current_arr_ramp.append(np.ones(int(round(t / dt))) * a)\n                    amp = amp + self.info[run][\"da\"]\n                current_arr.append(list(np.concatenate(current_arr_ramp)))\n\n            if flat:\n                return np.concatenate(current_arr)\n            else:\n                return current_arr\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.SimInfo.__init__","title":"<code>__init__(name, description, simulation_function, start, end, info, kwargs, monitor_chunk)</code>","text":"<p>Initialization of the simulation information object.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the simulation.</p> required <code>description</code> <code>str</code> <p>Description of the simulation.</p> required <code>simulation_function</code> <code>str</code> <p>Name of the simulation function.</p> required <code>start</code> <code>list</code> <p>List of start times of the simulation runs.</p> required <code>end</code> <code>list</code> <p>List of end times of the simulation runs.</p> required <code>info</code> <code>list</code> <p>List of return values of the simulation function of each simulation run.</p> required <code>kwargs</code> <code>list</code> <p>List of simulation kwargs of the simulation function of each simulation run.</p> required <code>monitor_chunk</code> <code>list</code> <p>List of recording chunks of the used CompNeuroMonitors object of each simulation run.</p> required Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def __init__(\n    self,\n    name,\n    description,\n    simulation_function,\n    start,\n    end,\n    info,\n    kwargs,\n    monitor_chunk,\n):\n    \"\"\"\n    Initialization of the simulation information object.\n\n    Args:\n        name (str):\n            Name of the simulation.\n        description (str):\n            Description of the simulation.\n        simulation_function (str):\n            Name of the simulation function.\n        start (list):\n            List of start times of the simulation runs.\n        end (list):\n            List of end times of the simulation runs.\n        info (list):\n            List of return values of the simulation function of each simulation run.\n        kwargs (list):\n            List of simulation kwargs of the simulation function of each simulation\n            run.\n        monitor_chunk (list):\n            List of recording chunks of the used CompNeuroMonitors object of each simulation\n            run.\n    \"\"\"\n    self.name = name\n    self.description = description\n    self.simulation_function = simulation_function\n    self.start = start\n    self.end = end\n    self.info = info\n    self.kwargs = kwargs\n    self.monitor_chunk = monitor_chunk\n</code></pre>"},{"location":"main/generate_simulations/#CompNeuroPy.generate_simulation.SimInfo.get_current_arr","title":"<code>get_current_arr(dt, flat=False)</code>","text":"<p>Method exclusively for the following simulation functions (built-in CompNeuroPy):     - current_step     - current_stim     - current_ramp Gets the current array (input current value for each time step) of all runs.</p> <p>Parameters:</p> Name Type Description Default <code>dt</code> <code>float</code> <p>Time step size of the simulation.</p> required <code>flat</code> <code>bool</code> <p>If True, returns a flattened array. Assumes that all runs are run consecutively without brakes. Default: False, i.e., returns a list of arrays.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>current_arr</code> <code>list of arrays</code> <p>List of arrays containing the current values for each time step of each run. If flat=True, returns a flattened array.</p> Source code in <code>src/CompNeuroPy/generate_simulation.py</code> <pre><code>def get_current_arr(self, dt, flat=False):\n    \"\"\"\n    Method exclusively for the following simulation functions (built-in\n    CompNeuroPy):\n        - current_step\n        - current_stim\n        - current_ramp\n    Gets the current array (input current value for each time step) of all runs.\n\n    Args:\n        dt (float):\n            Time step size of the simulation.\n        flat (bool, optional):\n            If True, returns a flattened array. Assumes that all runs are run\n            consecutively without brakes. Default: False, i.e., returns a list of\n            arrays.\n\n    Returns:\n        current_arr (list of arrays):\n            List of arrays containing the current values for each time step of each\n            run. If flat=True, returns a flattened array.\n    \"\"\"\n    assert (\n        self.simulation_function == \"current_step\"\n        or self.simulation_function == \"current_stim\"\n        or self.simulation_function == \"current_ramp\"\n    ), 'ERROR get_current_arr: Simulation has to be \"current_step\", \"current_stim\" or \"current_ramp\"!'\n\n    if self.simulation_function == \"current_step\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t1 = self.kwargs[run][\"t1\"]\n            t2 = self.kwargs[run][\"t2\"]\n            a1 = self.kwargs[run][\"a1\"]\n            a2 = self.kwargs[run][\"a2\"]\n\n            if t1 &gt; 0 and t2 &gt; 0:\n                current_arr.append(\n                    np.concatenate(\n                        [\n                            np.ones(int(round(t1 / dt))) * a1,\n                            np.ones(int(round(t2 / dt))) * a2,\n                        ]\n                    )\n                )\n            elif t2 &gt; 0:\n                current_arr.append(np.ones(int(round(t2 / dt))) * a2)\n            else:\n                current_arr.append(np.ones(int(round(t1 / dt))) * a1)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    elif self.simulation_function == \"current_stim\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            t = self.kwargs[run][\"t\"]\n            a = self.kwargs[run][\"a\"]\n\n            if t &gt; 0:\n                current_arr.append(np.ones(int(round(t / dt))) * a)\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n\n    elif self.simulation_function == \"current_ramp\":\n        current_arr = []\n        for run in range(len(self.kwargs)):\n            amp = self.kwargs[run][\"a0\"]\n            current_arr_ramp = []\n            for stim_idx in range(self.kwargs[run][\"n\"]):\n                t = self.info[run][\"dur_stim\"]\n                a = amp\n                current_arr_ramp.append(np.ones(int(round(t / dt))) * a)\n                amp = amp + self.info[run][\"da\"]\n            current_arr.append(list(np.concatenate(current_arr_ramp)))\n\n        if flat:\n            return np.concatenate(current_arr)\n        else:\n            return current_arr\n</code></pre>"},{"location":"main/monitors_recordings/","title":"Monitors / Recordings","text":""},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors","title":"<code>CompNeuroPy.monitors.CompNeuroMonitors</code>","text":"<p>Class to bring together ANNarchy monitors into one object.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>class CompNeuroMonitors:\n    \"\"\"\n    Class to bring together ANNarchy monitors into one object.\n    \"\"\"\n\n    def __init__(self, mon_dict={}):\n        \"\"\"\n        Initialize CompNeuroMonitors object by creating ANNarchy monitors.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"compartment_name;period\" where period is optional and\n                val=list with variables to record.\n        \"\"\"\n        self.mon = self._add_monitors(mon_dict)\n        self.mon_dict = mon_dict\n        self._init_internals(init_call=True)\n\n    def _init_internals(self, init_call=False):\n        \"\"\"\n        Initialize the following internal variables:\n            - timings (dict):\n                dict with key=\"pop_name\" for populations and \"proj_name\" for projections\n                for each recorded population and projection and\n                val={\"currently_paused\": True, \"start\": [], \"stop\": []}\n            - recordings (list):\n                list with recordings of all chunks. Set to empty list.\n            - recording_times (list):\n                list with recording times of all chunks. Set to empty list.\n            - already_got_recordings (bool):\n                True if recordings were already requested, False otherwise. Set to\n                False.\n            - already_got_recording_times (bool):\n                True if recording_times were already requested, False otherwise. Set to\n                False.\n            - get_recordings_reset_call (bool):\n                True if get_recordings() and get_recording_times() are called within\n                reset(), False otherwise. Set to False.\n\n        Args:\n            init_call (bool, optional):\n                True if called from __init__(), False otherwise. Default: False.\n        \"\"\"\n        if init_call is False:\n            #### pause all ANNarchy monitors because currently paused will be set to False\n            self.pause()\n\n        ### initialize timings\n        timings = {}\n        for key, val in self.mon_dict.items():\n            _, compartment, _ = self._unpack_mon_dict_keys(key)\n            timings[compartment] = {\"currently_paused\": True, \"start\": [], \"stop\": []}\n        self.timings = timings\n\n        ### initialize recordings and recording_times etc.\n        self.recordings = []\n        self.recording_times = []\n        self.already_got_recordings = False\n        self.already_got_recording_times = False\n        self.get_recordings_reset_call = False\n\n    @check_types()\n    def start(self, compartment_list: list | None = None):\n        \"\"\"\n        Start or resume recording of all recorded compartments in compartment_list.\n\n        Args:\n            compartment_list (list, optional):\n                List with compartment names to start or resume recording. Default: None,\n                i.e., all compartments of initialized mon_dict are started or resumed.\n        \"\"\"\n        if compartment_list == None:\n            mon_dict_key_list = list(self.mon_dict.keys())\n            compartment_list = [\n                self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n            ]\n\n        self.timings = self._start_monitors(compartment_list, self.mon, self.timings)\n\n    @check_types()\n    def pause(self, compartment_list: list | None = None):\n        \"\"\"\n        Pause recording of all recorded compartments in compartment_list.\n\n        Args:\n            compartment_list (list, optional):\n                List with compartment names to pause recording. Default: None,\n                i.e., all compartments of initialized mon_dict are paused.\n        \"\"\"\n        if compartment_list == None:\n            mon_dict_key_list = list(self.mon_dict.keys())\n            compartment_list = [\n                self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n            ]\n\n        self.timings = self._pause_monitors(compartment_list, self.mon, self.timings)\n\n    def reset(\n        self,\n        populations=True,\n        projections=False,\n        synapses=False,\n        monitors=True,\n        model=True,\n        parameters=True,\n        net_id=0,\n    ):\n        \"\"\"\n        Create a new recording chunk by getting recordings and recording times of the\n        current chunk and optionally resetting the model. Recordings are automatically\n        resumed in the new chunk if they are not paused.\n\n        Args:\n            populations (bool, optional):\n                If True, reset populations. Default: True.\n            projections (bool, optional):\n                If True, reset projections. Default: False.\n            synapses (bool, optional):\n                If True, reset synapses. Default: False.\n            monitors (bool, optional):\n                If True, reset ANNarchy monitors. Default: True.\n            model (bool, optional):\n                If True, reset model. Default: True.\n            parameters (bool, optional):\n                If True, reset the parameters of popilations and projections. Default:\n                True.\n            net_id (int, optional):\n                Id of the network to reset. Default: 0.\n        \"\"\"\n        ### TODO rename this function to new_chunk() or something like that and let\n        ### recordings and recording times be returned\n        self.get_recordings_reset_call = True\n        self.get_recordings()\n        self.get_recording_times()\n        self.get_recordings_reset_call = False\n        self.already_got_recordings = (\n            False  # after reset one can still update recordings\n        )\n        self.already_got_recording_times = (\n            False  # after reset one can still update recording_times\n        )\n\n        ### reset timings, after reset, add a zero to start if the monitor is still\n        ### running (this is not resetted by reset())\n        ### if the model was not resetted --&gt; do add current time instead of zero\n        for key in self.timings.keys():\n            self.timings[key][\"start\"] = []\n            self.timings[key][\"stop\"] = []\n            if self.timings[key][\"currently_paused\"] == False:\n                if model:\n                    self.timings[key][\"start\"].append(0)\n                else:\n                    self.timings[key][\"start\"].append(\n                        np.round(get_time(), af.get_number_of_decimals(dt()))\n                    )\n\n        ### reset model\n        if model:\n            if parameters is False:\n                ### if parameters=False, get parameters before reset and set them after\n                ### reset\n                parameters_dict = mf._get_all_parameters()\n            reset(populations, projections, synapses, monitors, net_id=net_id)\n            if parameters is False:\n                ### if parameters=False, set parameters after reset\n                mf._set_all_parameters(parameters_dict)\n\n    def current_chunk(self):\n        \"\"\"\n        Get the index of the current chunk.\n\n        Returns:\n            current_chunk_idx (int):\n                Index of the current chunk. If no recordings are currently active,\n                returns None.\n        \"\"\"\n        ### if recordings are currently active --&gt; return chunk in which these recordings will be saved\n        ### check if there are currently active recordings\n        active_recordings = False\n        for key, val in self.mon_dict.items():\n            _, compartment, _ = self._unpack_mon_dict_keys(key)\n            if not (self.timings[compartment][\"currently_paused\"]):\n                ### tere are currently active recordings\n                active_recordings = True\n\n        if active_recordings:\n            current_chunk_idx = len(self.recordings)\n            return current_chunk_idx\n        else:\n            ### if currently no recordings are active return None\n            return None\n\n    def get_recordings(self) -&gt; list[dict]:\n        \"\"\"\n        Get recordings of all recorded compartments.\n\n        Returns:\n            recordings (list):\n                List with recordings of all chunks.\n        \"\"\"\n        ### only if recordings in current chunk and get_recodings was not already called add current chunk to recordings\n        if (\n            self._any_recordings_in_current_chunk()\n            and self.already_got_recordings is False\n        ):\n            ### update recordings\n            self.recordings.append(self._get_monitors(self.mon_dict, self.mon))\n            ### upade already_got_recordings --&gt; it will not update recordings again\n            self.already_got_recordings = True\n\n            if not (self.get_recordings_reset_call):\n                if len(self.recordings) == 0:\n                    print(\n                        \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                    )\n            return self.recordings\n        else:\n            if not (self.get_recordings_reset_call):\n                if len(self.recordings) == 0:\n                    print(\n                        \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                    )\n            return self.recordings\n\n    def get_recording_times(self):\n        \"\"\"\n        Get recording times of all recorded compartments.\n\n        Returns:\n            recording_times (recording_times_cl):\n                Object with recording times of all chunks.\n        \"\"\"\n\n        temp_timings = self._get_temp_timings()\n\n        ### only append temp_timings of current chunk if there are recordings in current chunk at all and if get_recordings was not already called (double call would add the same chunk again)\n        if (\n            self._any_recordings_in_current_chunk()\n            and self.already_got_recording_times is False\n        ):\n            self.recording_times.append(temp_timings)\n\n        ### upade already_got_recording_times --&gt; it will not update recording_times again\n        self.already_got_recording_times = True\n\n        ### generate a object from recording_times and return this instead of the dict\n        recording_times_ob = RecordingTimes(self.recording_times)\n\n        if not (self.get_recordings_reset_call):\n            if len(self.recording_times) == 0:\n                print(\n                    \"WARNING get_recording_times: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return recording_times_ob\n\n    def get_recordings_and_clear(self):\n        \"\"\"\n        The default get_recordings method should be called at the end of the simulation.\n        The get_recordings_and_clear method allows to get several times recordings with\n        the same monitor object and to simulate between the calls. Sets the internal\n        variables back to their initial state. Usefull if you repeat a simulation +\n        recording several times and you do not want to always create new chunks.\n\n        !!! warning\n            If you want to continue recording after calling this method, you have to\n            call start() again.\n\n        Returns:\n            recordings (list):\n                List with recordings of all chunks.\n            recording_times (recording_times_cl):\n                Object with recording times of all chunks.\n        \"\"\"\n        ret0 = self.get_recordings()\n        ret1 = self.get_recording_times()\n        self._init_internals()\n        ret = (ret0, ret1)\n        return ret\n\n    def _correct_start_stop(self, start_time_arr, stop_time_arr, period):\n        \"\"\"\n        Corrects the start and stop times of recordings to the actual start and stop\n        times of recorded values.\n\n        Args:\n            start_time_arr (np.array):\n                Array with start times of recordings, obtained with get_time() function\n                of ANNarchy.\n            stop_time_arr (np.array):\n                Array with stop times of recordings, obtained with get_time() function\n                of ANNarchy.\n            period (float):\n                Time difference between recording values specified by the user.\n\n        Returns:\n            actual_start_time (np.array):\n                Array with actual start times of recorded values.\n            actual_stop_time (np.array):\n                Array with actual stop times of recorded values.\n            nr_rec_vals (np.array):\n                Array with number of recorded values between start and stop.\n        \"\"\"\n        # actual_period = int(period / dt()) * dt()\n        actual_start_time = np.ceil(start_time_arr / period) * period\n\n        actual_stop_time = np.ceil(stop_time_arr / period - 1) * period\n\n        nr_rec_vals = 1 + (actual_stop_time - actual_start_time) / period\n\n        return (actual_start_time, actual_stop_time, nr_rec_vals)\n\n    def _get_temp_timings(self):\n        \"\"\"\n        Generates a timings dictionary with time lims and idx lims for each compartment.\n        Calculates the idx lims of the recordings based on the time lims.\n\n        Returns:\n            temp_timings (dict):\n                Dict with time lims and idx lims for each compartment.\n        \"\"\"\n        temp_timings = {}\n        for key in self.mon_dict.keys():\n            _, compartment, period = self._unpack_mon_dict_keys(key)\n            if len(self.timings[compartment][\"start\"]) &gt; len(\n                self.timings[compartment][\"stop\"]\n            ):\n                ### was started/resumed but never stoped after --&gt; use current time for stop time\n                self.timings[compartment][\"stop\"].append(get_time())\n            ### calculate the idx of the recorded arrays which correspond to the timings and remove 'currently_paused'\n            ### get for each start-stop pair the corrected start stop timings (when teh values were actually recorded, depends on period and timestep)\n            ### and also get the number of recorded values for start-stop pair\n            start_time_arr = np.array(self.timings[compartment][\"start\"])\n            stop_time_arr = np.array(self.timings[compartment][\"stop\"])\n            (\n                start_time_arr,\n                stop_time_arr,\n                nr_rec_vals_arr,\n            ) = self._correct_start_stop(start_time_arr, stop_time_arr, period)\n\n            ### with the number of recorded values -&gt; get start and end idx for each start-stop pair\n            start_idx = [\n                np.sum(nr_rec_vals_arr[0:i]).astype(int)\n                for i in range(nr_rec_vals_arr.size)\n            ]\n            stop_idx = [\n                np.sum(nr_rec_vals_arr[0 : i + 1]).astype(int) - 1\n                for i in range(nr_rec_vals_arr.size)\n            ]\n\n            ### return start-stop pair info in timings format\n            temp_timings[compartment] = {\n                \"start\": {\n                    \"ms\": np.round(\n                        start_time_arr, af.get_number_of_decimals(dt())\n                    ).tolist(),\n                    \"idx\": start_idx,\n                },\n                \"stop\": {\n                    \"ms\": np.round(\n                        stop_time_arr, af.get_number_of_decimals(dt())\n                    ).tolist(),\n                    \"idx\": stop_idx,\n                },\n            }\n        return temp_timings\n\n    def _any_recordings_in_current_chunk(self):\n        \"\"\"\n        Check if there are any recordings in the current chunk.\n\n        Returns:\n            any_recordings (bool):\n                True if there are any recordings in the current chunk, False otherwise.\n        \"\"\"\n        temp_timings = self._get_temp_timings()\n\n        ### generate a temp object of temp timings to check if there were recordings at all\n        recording_times_ob_temp = RecordingTimes([temp_timings])\n        return recording_times_ob_temp._any_recordings(chunk=0)\n\n    def _add_monitors(self, mon_dict: dict):\n        \"\"\"\n        Generate monitors defined by mon_dict.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"compartment_name;period\" where period is optional and\n                val=list with variables to record.\n\n        Returns:\n            mon (dict):\n                dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n        \"\"\"\n        mon = {}\n        for key, val in mon_dict.items():\n            compartmentType, compartment, period = self._unpack_mon_dict_keys(\n                key, warning=True\n            )\n            ### check if compartment is pop\n            if compartmentType == \"pop\":\n                mon[compartment] = Monitor(\n                    get_population(compartment), val, start=False, period=period\n                )\n            ### check if compartment is proj\n            if compartmentType == \"proj\":\n                mon[compartment] = Monitor(\n                    get_projection(compartment), val, start=False, period=period\n                )\n        return mon\n\n    def _start_monitors(self, compartment_list, mon, timings=None):\n        \"\"\"\n        Starts or resumes monitores defined by compartment_list.\n\n        Args:\n            compartment_list (list):\n                List with compartment names to start or resume recording.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n            timings (dict, optional):\n                timings variable of the CompNeuroMonitors object. Default: None.\n\n        Returns:\n            timings (dict):\n                timings variable of the CompNeuroMonitors object.\n        \"\"\"\n        ### for each compartment generate started variable (because compartments can ocure multiple times if multiple variables of them are recorded --&gt; do not start same monitor multiple times)\n        started = {}\n        for compartment_name in compartment_list:\n            started[compartment_name] = False\n\n        if timings == None:\n            ### information about pauses not available, just start\n            for compartment_name in compartment_list:\n                if started[compartment_name] == False:\n                    mon[compartment_name].start()\n                    print(\"start\", compartment_name)\n                    started[compartment_name] = True\n            return None\n        else:\n            ### information about pauses available, start if not paused, resume if paused\n            for compartment_name in compartment_list:\n                if started[compartment_name] == False:\n                    if timings[compartment_name][\"currently_paused\"]:\n                        if len(timings[compartment_name][\"start\"]) &gt; 0:\n                            ### resume\n                            mon[compartment_name].resume()\n                        else:\n                            ### initial start\n                            mon[compartment_name].start()\n                    started[compartment_name] = True\n                    ### update currently_paused\n                    timings[compartment_name][\"currently_paused\"] = False\n                    ### never make start longer than stop+1!... this can be caused if start is called multiple times without pause in between\n                    if len(timings[compartment_name][\"start\"]) &lt;= len(\n                        timings[compartment_name][\"stop\"]\n                    ):\n                        timings[compartment_name][\"start\"].append(get_time())\n            return timings\n\n    def _pause_monitors(self, compartment_list, mon, timings=None):\n        \"\"\"\n        Pause monitores defined by compartment_list.\n\n        Args:\n            compartment_list (list):\n                List with compartment names to pause recording.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n            timings (dict, optional):\n                timings variable of the CompNeuroMonitors object. Default: None.\n\n        Returns:\n            timings (dict):\n                timings variable of the CompNeuroMonitors object.\n        \"\"\"\n        ### for each compartment generate paused variable (because compartments can ocure multiple times if multiple variables of them are recorded --&gt; do not pause same monitor multiple times)\n        paused = {}\n        for compartment_name in compartment_list:\n            paused[compartment_name] = False\n\n        for compartment_name in compartment_list:\n            if paused[compartment_name] == False:\n                mon[compartment_name].pause()\n                paused[compartment_name] = True\n\n        if timings != None:\n            ### information about pauses is available, update it\n            for key, val in paused.items():\n                timings[key][\"currently_paused\"] = True\n                ### never make pause longer than start, this can be caused if pause is called multiple times without start in between\n                if len(timings[key][\"stop\"]) &lt; len(timings[key][\"start\"]):\n                    timings[key][\"stop\"].append(get_time())\n                ### if pause is directly called after start --&gt; start == stop --&gt; remove these entries, this is no actual period\n                if (\n                    len(timings[key][\"stop\"]) == len(timings[key][\"start\"])\n                    and timings[key][\"stop\"][-1] == timings[key][\"start\"][-1]\n                ):\n                    timings[key][\"stop\"] = timings[key][\"stop\"][:-1]\n                    timings[key][\"start\"] = timings[key][\"start\"][:-1]\n            return timings\n        else:\n            return None\n\n    def _get_monitors(self, mon_dict, mon):\n        \"\"\"\n        Get recorded values from ANNarchy monitors defined by mon_dict.\n\n        Args:\n            mon_dict (dict):\n                dict with key=\"compartment_name;period\" where period is optional and\n                val=list with variables to record.\n            mon (dict):\n                Dict with key=\"pop_name\" for populations and key=\"proj_name\" for\n                projections and val=ANNarchy monitor object.\n\n        Returns:\n            recordings (dict):\n                Dict with key=\"compartment_name;variable\" and val=list with recorded\n                values.\n        \"\"\"\n        recordings = {}\n        for key, val in mon_dict.items():\n            compartment_type, compartment, period = self._unpack_mon_dict_keys(key)\n            recordings[f\"{compartment};period\"] = period\n            if compartment_type == \"pop\":\n                pop = get_population(compartment)\n                parameter_dict = {\n                    param_name: getattr(pop, param_name)\n                    for param_name in pop.parameters\n                }\n                recordings[f\"{compartment};parameter_dict\"] = parameter_dict\n            if compartment_type == \"proj\":\n                proj = get_projection(compartment)\n                parameter_dict = {\n                    param_name: getattr(proj, param_name)\n                    for param_name in proj.parameters\n                }\n                recordings[f\"{compartment};parameters\"] = parameter_dict\n            for val_val in val:\n                temp = mon[compartment].get(val_val)\n                recordings[f\"{compartment};{val_val}\"] = temp\n        recordings[\"dt\"] = dt()\n        return recordings\n\n    def _unpack_mon_dict_keys(self, s: str, warning: bool = False):\n        \"\"\"\n        Unpacks a string of the form \"compartment_name;period\" or\n        \"compartment_name\" into its components. If period is not provided\n        it is set to dt() for populations and dt()*1000 for projections.\n\n        Args:\n            s (str):\n                String to be unpacked\n            warning (bool, optional):\n                If True, print warning if period is not provided for projections.\n\n        Returns:\n            compartment_type (str):\n                Compartment type\n            compartment_name (str):\n                Compartment name\n            period (float):\n                Period of the compartment\n        \"\"\"\n        ### split string\n        splitted_s = s.split(\";\")\n\n        ### get name\n        compartment_name = splitted_s[0]\n\n        ### get type\n        pop_list = [pop.name for pop in populations()]\n        proj_list = [proj.name for proj in projections()]\n        if compartment_name in pop_list and compartment_name in proj_list:\n            ### raise error because name is in both lists\n            print(\n                \"ERROR CompNeuroMonitors._unpack_mon_dict_keys(): compartment_name is both populaiton and projection\"\n            )\n            quit()\n        elif compartment_name in pop_list:\n            compartment_type = \"pop\"\n        elif compartment_name in proj_list:\n            compartment_type = \"proj\"\n\n        ### get period\n        if len(splitted_s) == 2:\n            period = float(splitted_s[1])\n        else:\n            period = {\"pop\": dt(), \"proj\": dt() * 1000}[compartment_type]\n            ### print warning for compartment_type proj\n            if compartment_type == \"proj\" and warning:\n                print(\n                    f\"WARNING CompNeuroMonitors: no period provided for projection {compartment_name}, period set to {period} ms\"\n                )\n        period = round(period / dt()) * dt()\n\n        return compartment_type, compartment_name, period\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.__init__","title":"<code>__init__(mon_dict={})</code>","text":"<p>Initialize CompNeuroMonitors object by creating ANNarchy monitors.</p> <p>Parameters:</p> Name Type Description Default <code>mon_dict</code> <code>dict</code> <p>dict with key=\"compartment_name;period\" where period is optional and val=list with variables to record.</p> <code>{}</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def __init__(self, mon_dict={}):\n    \"\"\"\n    Initialize CompNeuroMonitors object by creating ANNarchy monitors.\n\n    Args:\n        mon_dict (dict):\n            dict with key=\"compartment_name;period\" where period is optional and\n            val=list with variables to record.\n    \"\"\"\n    self.mon = self._add_monitors(mon_dict)\n    self.mon_dict = mon_dict\n    self._init_internals(init_call=True)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.start","title":"<code>start(compartment_list=None)</code>","text":"<p>Start or resume recording of all recorded compartments in compartment_list.</p> <p>Parameters:</p> Name Type Description Default <code>compartment_list</code> <code>list</code> <p>List with compartment names to start or resume recording. Default: None, i.e., all compartments of initialized mon_dict are started or resumed.</p> <code>None</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>@check_types()\ndef start(self, compartment_list: list | None = None):\n    \"\"\"\n    Start or resume recording of all recorded compartments in compartment_list.\n\n    Args:\n        compartment_list (list, optional):\n            List with compartment names to start or resume recording. Default: None,\n            i.e., all compartments of initialized mon_dict are started or resumed.\n    \"\"\"\n    if compartment_list == None:\n        mon_dict_key_list = list(self.mon_dict.keys())\n        compartment_list = [\n            self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n        ]\n\n    self.timings = self._start_monitors(compartment_list, self.mon, self.timings)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.pause","title":"<code>pause(compartment_list=None)</code>","text":"<p>Pause recording of all recorded compartments in compartment_list.</p> <p>Parameters:</p> Name Type Description Default <code>compartment_list</code> <code>list</code> <p>List with compartment names to pause recording. Default: None, i.e., all compartments of initialized mon_dict are paused.</p> <code>None</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>@check_types()\ndef pause(self, compartment_list: list | None = None):\n    \"\"\"\n    Pause recording of all recorded compartments in compartment_list.\n\n    Args:\n        compartment_list (list, optional):\n            List with compartment names to pause recording. Default: None,\n            i.e., all compartments of initialized mon_dict are paused.\n    \"\"\"\n    if compartment_list == None:\n        mon_dict_key_list = list(self.mon_dict.keys())\n        compartment_list = [\n            self._unpack_mon_dict_keys(key)[1] for key in mon_dict_key_list\n        ]\n\n    self.timings = self._pause_monitors(compartment_list, self.mon, self.timings)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.reset","title":"<code>reset(populations=True, projections=False, synapses=False, monitors=True, model=True, parameters=True, net_id=0)</code>","text":"<p>Create a new recording chunk by getting recordings and recording times of the current chunk and optionally resetting the model. Recordings are automatically resumed in the new chunk if they are not paused.</p> <p>Parameters:</p> Name Type Description Default <code>populations</code> <code>bool</code> <p>If True, reset populations. Default: True.</p> <code>True</code> <code>projections</code> <code>bool</code> <p>If True, reset projections. Default: False.</p> <code>False</code> <code>synapses</code> <code>bool</code> <p>If True, reset synapses. Default: False.</p> <code>False</code> <code>monitors</code> <code>bool</code> <p>If True, reset ANNarchy monitors. Default: True.</p> <code>True</code> <code>model</code> <code>bool</code> <p>If True, reset model. Default: True.</p> <code>True</code> <code>parameters</code> <code>bool</code> <p>If True, reset the parameters of popilations and projections. Default: True.</p> <code>True</code> <code>net_id</code> <code>int</code> <p>Id of the network to reset. Default: 0.</p> <code>0</code> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def reset(\n    self,\n    populations=True,\n    projections=False,\n    synapses=False,\n    monitors=True,\n    model=True,\n    parameters=True,\n    net_id=0,\n):\n    \"\"\"\n    Create a new recording chunk by getting recordings and recording times of the\n    current chunk and optionally resetting the model. Recordings are automatically\n    resumed in the new chunk if they are not paused.\n\n    Args:\n        populations (bool, optional):\n            If True, reset populations. Default: True.\n        projections (bool, optional):\n            If True, reset projections. Default: False.\n        synapses (bool, optional):\n            If True, reset synapses. Default: False.\n        monitors (bool, optional):\n            If True, reset ANNarchy monitors. Default: True.\n        model (bool, optional):\n            If True, reset model. Default: True.\n        parameters (bool, optional):\n            If True, reset the parameters of popilations and projections. Default:\n            True.\n        net_id (int, optional):\n            Id of the network to reset. Default: 0.\n    \"\"\"\n    ### TODO rename this function to new_chunk() or something like that and let\n    ### recordings and recording times be returned\n    self.get_recordings_reset_call = True\n    self.get_recordings()\n    self.get_recording_times()\n    self.get_recordings_reset_call = False\n    self.already_got_recordings = (\n        False  # after reset one can still update recordings\n    )\n    self.already_got_recording_times = (\n        False  # after reset one can still update recording_times\n    )\n\n    ### reset timings, after reset, add a zero to start if the monitor is still\n    ### running (this is not resetted by reset())\n    ### if the model was not resetted --&gt; do add current time instead of zero\n    for key in self.timings.keys():\n        self.timings[key][\"start\"] = []\n        self.timings[key][\"stop\"] = []\n        if self.timings[key][\"currently_paused\"] == False:\n            if model:\n                self.timings[key][\"start\"].append(0)\n            else:\n                self.timings[key][\"start\"].append(\n                    np.round(get_time(), af.get_number_of_decimals(dt()))\n                )\n\n    ### reset model\n    if model:\n        if parameters is False:\n            ### if parameters=False, get parameters before reset and set them after\n            ### reset\n            parameters_dict = mf._get_all_parameters()\n        reset(populations, projections, synapses, monitors, net_id=net_id)\n        if parameters is False:\n            ### if parameters=False, set parameters after reset\n            mf._set_all_parameters(parameters_dict)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.current_chunk","title":"<code>current_chunk()</code>","text":"<p>Get the index of the current chunk.</p> <p>Returns:</p> Name Type Description <code>current_chunk_idx</code> <code>int</code> <p>Index of the current chunk. If no recordings are currently active, returns None.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def current_chunk(self):\n    \"\"\"\n    Get the index of the current chunk.\n\n    Returns:\n        current_chunk_idx (int):\n            Index of the current chunk. If no recordings are currently active,\n            returns None.\n    \"\"\"\n    ### if recordings are currently active --&gt; return chunk in which these recordings will be saved\n    ### check if there are currently active recordings\n    active_recordings = False\n    for key, val in self.mon_dict.items():\n        _, compartment, _ = self._unpack_mon_dict_keys(key)\n        if not (self.timings[compartment][\"currently_paused\"]):\n            ### tere are currently active recordings\n            active_recordings = True\n\n    if active_recordings:\n        current_chunk_idx = len(self.recordings)\n        return current_chunk_idx\n    else:\n        ### if currently no recordings are active return None\n        return None\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.get_recordings","title":"<code>get_recordings()</code>","text":"<p>Get recordings of all recorded compartments.</p> <p>Returns:</p> Name Type Description <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recordings(self) -&gt; list[dict]:\n    \"\"\"\n    Get recordings of all recorded compartments.\n\n    Returns:\n        recordings (list):\n            List with recordings of all chunks.\n    \"\"\"\n    ### only if recordings in current chunk and get_recodings was not already called add current chunk to recordings\n    if (\n        self._any_recordings_in_current_chunk()\n        and self.already_got_recordings is False\n    ):\n        ### update recordings\n        self.recordings.append(self._get_monitors(self.mon_dict, self.mon))\n        ### upade already_got_recordings --&gt; it will not update recordings again\n        self.already_got_recordings = True\n\n        if not (self.get_recordings_reset_call):\n            if len(self.recordings) == 0:\n                print(\n                    \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return self.recordings\n    else:\n        if not (self.get_recordings_reset_call):\n            if len(self.recordings) == 0:\n                print(\n                    \"WARNING get_recordings: no recordings available, empty list returned. Maybe forgot start()?\"\n                )\n        return self.recordings\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.get_recording_times","title":"<code>get_recording_times()</code>","text":"<p>Get recording times of all recorded compartments.</p> <p>Returns:</p> Name Type Description <code>recording_times</code> <code>recording_times_cl</code> <p>Object with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recording_times(self):\n    \"\"\"\n    Get recording times of all recorded compartments.\n\n    Returns:\n        recording_times (recording_times_cl):\n            Object with recording times of all chunks.\n    \"\"\"\n\n    temp_timings = self._get_temp_timings()\n\n    ### only append temp_timings of current chunk if there are recordings in current chunk at all and if get_recordings was not already called (double call would add the same chunk again)\n    if (\n        self._any_recordings_in_current_chunk()\n        and self.already_got_recording_times is False\n    ):\n        self.recording_times.append(temp_timings)\n\n    ### upade already_got_recording_times --&gt; it will not update recording_times again\n    self.already_got_recording_times = True\n\n    ### generate a object from recording_times and return this instead of the dict\n    recording_times_ob = RecordingTimes(self.recording_times)\n\n    if not (self.get_recordings_reset_call):\n        if len(self.recording_times) == 0:\n            print(\n                \"WARNING get_recording_times: no recordings available, empty list returned. Maybe forgot start()?\"\n            )\n    return recording_times_ob\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.CompNeuroMonitors.get_recordings_and_clear","title":"<code>get_recordings_and_clear()</code>","text":"<p>The default get_recordings method should be called at the end of the simulation. The get_recordings_and_clear method allows to get several times recordings with the same monitor object and to simulate between the calls. Sets the internal variables back to their initial state. Usefull if you repeat a simulation + recording several times and you do not want to always create new chunks.</p> <p>Warning</p> <p>If you want to continue recording after calling this method, you have to call start() again.</p> <p>Returns:</p> Name Type Description <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> <code>recording_times</code> <code>recording_times_cl</code> <p>Object with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def get_recordings_and_clear(self):\n    \"\"\"\n    The default get_recordings method should be called at the end of the simulation.\n    The get_recordings_and_clear method allows to get several times recordings with\n    the same monitor object and to simulate between the calls. Sets the internal\n    variables back to their initial state. Usefull if you repeat a simulation +\n    recording several times and you do not want to always create new chunks.\n\n    !!! warning\n        If you want to continue recording after calling this method, you have to\n        call start() again.\n\n    Returns:\n        recordings (list):\n            List with recordings of all chunks.\n        recording_times (recording_times_cl):\n            Object with recording times of all chunks.\n    \"\"\"\n    ret0 = self.get_recordings()\n    ret1 = self.get_recording_times()\n    self._init_internals()\n    ret = (ret0, ret1)\n    return ret\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes","title":"<code>CompNeuroPy.monitors.RecordingTimes</code>","text":"Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>class RecordingTimes:\n    def __init__(self, recording_times_list):\n        \"\"\"\n        Initialize RecordingTimes object.\n\n        Args:\n            recording_times_list (list):\n                List with recording times of all chunks.\n        \"\"\"\n        self.recording_times_list = recording_times_list\n\n    def time_lims(\n        self,\n        chunk: int | None = None,\n        compartment: str | None = None,\n        period: int | None = None,\n    ):\n        \"\"\"\n        Get the time limits recordings of of a specified chunk/model compartment in ms.\n\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment from\n            monitor.\n        period (int, optional):\n            Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop time of the specified chunk/model compartment.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR time_lims(): No recordings/recording_times available.\"\n        return self._lims(\"ms\", chunk, compartment, period)\n\n    def idx_lims(\n        self,\n        chunk: int | None = None,\n        compartment: str | None = None,\n        period: int | None = None,\n    ):\n        \"\"\"\n        Get the index limits of recordings of a specified chunk/model compartment.\n\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment from\n            monitor.\n        period (int, optional):\n            Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop index of the specified chunk/model\n                compartment.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR idx_lims(): No recordings/recording_times available.\"\n        return self._lims(\"idx\", chunk, compartment, period)\n\n    def all(self):\n        \"\"\"\n        Get the recording times of all chunks, compartments, periods in ms and index.\n\n        Returns:\n            recording_times_list (list):\n                List with recording times of all chunks.\n        \"\"\"\n        return self.recording_times_list\n\n    def nr_periods(self, chunk=None, compartment=None):\n        \"\"\"\n        Get the number of recording periods (start-pause) of a specified chunk/model\n        compartment.\n\n        Args:\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n            compartment (str, optional):\n                Name of the compartment. Default: None, i.e., first model compartment\n                from monitor.\n\n        Returns:\n            nr_periods (int):\n                Number of recording periods (start-pause) of a specified chunk/model\n                compartment.\n        \"\"\"\n        chunk = self._check_chunk(chunk)\n        compartment = self.__check_compartment__(compartment, chunk)\n        return self._get_nr_periods(chunk, compartment)\n\n    def combine_chunks(\n        self, recordings: list, recording_data_str: str, mode=\"sequential\"\n    ):\n        \"\"\"\n        Combines the data of all chunks of recordings, only possible if no pauses in\n        between.\n\n        Args:\n            recordings (list):\n                List with recordings of all chunks.\n            recording_data_str (str):\n                String specifying the compartment name and the variable to combine.\n                Format: \"compartment_name;variable_name\"\n            mode (str, optional):\n                How should the time array be generated. Can be \"sequential\" or\n                \"consecutive\". Default: \"sequential\".\n                - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;\n                    [0, 1, ..., 100, 0, 1, ..., 250]\n                - \"consecutive\": each chunk starts at the last stop time of the previous\n                    chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]\n\n        Returns:\n            time_arr (np.array):\n                Array with time values in ms.\n            data_arr (np.array):\n                Array with the recorded variable.\n        \"\"\"\n        assert (\n            len(self.recording_times_list) &gt; 0\n        ), \"ERROR combine_chunks(): No recordings/recording_times available.\"\n\n        compartment = recording_data_str.split(\";\")[0]\n        period_time = recordings[0][f\"{compartment};period\"]\n        time_step = recordings[0][\"dt\"]\n        nr_chunks = self._get_nr_chunks()\n        data_list = []\n        time_list = []\n        pre_chunk_start_time = 0\n\n        for chunk in range(nr_chunks):\n            ### append data list with data of all periods of this chunk\n            data_list.append(recordings[chunk][recording_data_str])\n\n            ### nr of periods in this chunk\n            nr_periods = self._get_nr_periods(chunk, compartment)\n\n            ### start time of chunk depends on mode\n            if mode == \"sequential\":\n                chunk_start_time = 0\n            elif mode == \"consecutive\":\n                if chunk == 0:\n                    chunk_start_time = 0\n                else:\n                    last_stop_time = self.recording_times_list[chunk - 1][compartment][\n                        \"stop\"\n                    ][\"ms\"][-1]\n                    chunk_start_time = (\n                        pre_chunk_start_time + last_stop_time + period_time\n                    )\n                    pre_chunk_start_time = chunk_start_time\n            else:\n                print(\"ERROR recording_times.combine_data, Wrong mode.\")\n                quit()\n\n            ### append the time list with all times of the periods\n            for period in range(nr_periods):\n                start_time = (\n                    self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                        0\n                    ]\n                    + chunk_start_time\n                )\n                end_time = (\n                    self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                        1\n                    ]\n                    + chunk_start_time\n                )\n                start_time = round(start_time, af.get_number_of_decimals(time_step))\n                end_time = round(end_time, af.get_number_of_decimals(time_step))\n                times = np.arange(start_time, end_time + period_time, period_time)\n                time_list.append(times)\n\n        ### flatten the two lists\n        data_arr = np.concatenate(data_list, 0)\n        time_arr = np.concatenate(time_list, 0)\n\n        ### check if there are gaps in the time array\n        ### fill them with the corersponding times and\n        ### the data array with nan values\n        time_arr, data_arr = af.time_data_add_nan(\n            time_arr,\n            data_arr,\n            fill_time_step=period_time,\n        )\n\n        return time_arr, data_arr\n\n    def _lims(self, string, chunk=None, compartment=None, period=None):\n        \"\"\"\n        Get the limits of recordings of a specified chunk/model compartment.\n\n        Args:\n            string (str):\n                String specifying the type of limits to return. Can be \"ms\" for time\n                limits in ms or \"idx\" for index limits.\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n            compartment (str, optional):\n                Name of the compartment. Default: None, i.e., first model compartment\n                from monitor.\n            period (int, optional):\n                Index of the period. Default: None, i.e., all periods.\n\n        Returns:\n            lims (tuple):\n                Tuple with start and stop time/index of the specified chunk/model\n                compartment.\n        \"\"\"\n\n        chunk = self._check_chunk(chunk)\n        compartment = self.__check_compartment__(compartment, chunk)\n        period_0, period_1 = self._check_period(period, chunk, compartment)\n        lims = (\n            self.recording_times_list[chunk][compartment][\"start\"][string][period_0],\n            self.recording_times_list[chunk][compartment][\"stop\"][string][period_1],\n        )\n        return lims\n\n    def __check_compartment__(self, compartment, chunk):\n        if compartment == None:\n            ### by default just use the first compartment\n            compartment = list(self.recording_times_list[chunk].keys())[0]\n        elif compartment in list(self.recording_times_list[chunk].keys()):\n            compartment = compartment\n        else:\n            print(\n                'ERROR recording_times, given compartment \"'\n                + str(compartment)\n                + '\" not available'\n            )\n            quit()\n\n        return compartment\n\n    def _check_period(self, period, chunk, compartment):\n        \"\"\"\n        Check if period is given.\n\n        Args:\n            period (int, optional):\n                Index of the period. Default: None, i.e., all periods.\n            chunk (int):\n                Index of the chunk.\n            compartment (str):\n                Name of the compartment.\n\n        Returns:\n            period_0 (int):\n                Index of the first period.\n            period_1 (int):\n                Index of the last period. If perios is given, period_0 == period_1.\n        \"\"\"\n        if period == None:\n            ### by default use all periods\n            period_0 = 0\n            period_1 = (\n                len(self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]) - 1\n            )\n        elif period &lt; len(\n            self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]\n        ):\n            period_0 = period\n            period_1 = period\n        else:\n            print(\"ERROR recording_times, given period not available\")\n            quit()\n\n        return period_0, period_1\n\n    def _check_chunk(self, chunk):\n        \"\"\"\n        Check if chunk is given.\n\n        Args:\n            chunk (int, optional):\n                Index of the chunk. Default: None, i.e., first chunk.\n\n        Returns:\n            chunk (int):\n                Index of the chunk.\n        \"\"\"\n        if chunk is None:\n            ### by default use first chunk\n            chunk = 0\n        elif chunk &lt; self._get_nr_chunks():\n            chunk = chunk\n        else:\n            print(\"ERROR recording_times, given chunk not available\")\n            quit()\n\n        return chunk\n\n    def _get_nr_chunks(self):\n        \"\"\"\n        Get the number of chunks of the recordings.\n\n        Returns:\n            nr_chunks (int):\n                Number of chunks.\n        \"\"\"\n        return len(self.recording_times_list)\n\n    def _get_nr_periods(self, chunk, compartment):\n        \"\"\"\n        Get the number of recording periods (start-pause) of a specified chunk/model\n        compartment.\n\n        Args:\n            chunk (int):\n                Index of the chunk.\n            compartment (str):\n                Name of the compartment.\n\n        Returns:\n            nr_periods (int):\n                Number of recording periods (start-pause) of a specified chunk/model\n                compartment.\n        \"\"\"\n        return len(self.recording_times_list[chunk][compartment][\"start\"][\"idx\"])\n\n    def _any_recordings(self, chunk):\n        \"\"\"\n        Check all periods and compartments if there are any recordings.\n\n        Args:\n            chunk (int):\n                Index of the chunk.\n\n        Returns:\n            found_recordings (bool):\n                True if there are any recordings in the chunk, False otherwise.\n        \"\"\"\n        compartment_list = list(self.recording_times_list[chunk].keys())\n        found_recordings = False\n        for compartment in compartment_list:\n            nr_periods_of_compartment = len(\n                self.recording_times_list[chunk][compartment][\"start\"][\"idx\"]\n            )\n\n            for period_idx in range(nr_periods_of_compartment):\n                idx_lims = self.idx_lims(\n                    chunk=chunk, compartment=compartment, period=period_idx\n                )\n                if np.diff(idx_lims)[0] &gt; 0:\n                    found_recordings = True\n\n        return found_recordings\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.__init__","title":"<code>__init__(recording_times_list)</code>","text":"<p>Initialize RecordingTimes object.</p> <p>Parameters:</p> Name Type Description Default <code>recording_times_list</code> <code>list</code> <p>List with recording times of all chunks.</p> required Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def __init__(self, recording_times_list):\n    \"\"\"\n    Initialize RecordingTimes object.\n\n    Args:\n        recording_times_list (list):\n            List with recording times of all chunks.\n    \"\"\"\n    self.recording_times_list = recording_times_list\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.time_lims","title":"<code>time_lims(chunk=None, compartment=None, period=None)</code>","text":"<p>Get the time limits recordings of of a specified chunk/model compartment in ms.</p> <p>chunk (int, optional):     Index of the chunk. Default: None, i.e., first chunk. compartment (str, optional):     Name of the compartment. Default: None, i.e., first model compartment from     monitor. period (int, optional):     Index of the period. Default: None, i.e., all periods.</p> <p>Returns:</p> Name Type Description <code>lims</code> <code>tuple</code> <p>Tuple with start and stop time of the specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def time_lims(\n    self,\n    chunk: int | None = None,\n    compartment: str | None = None,\n    period: int | None = None,\n):\n    \"\"\"\n    Get the time limits recordings of of a specified chunk/model compartment in ms.\n\n    chunk (int, optional):\n        Index of the chunk. Default: None, i.e., first chunk.\n    compartment (str, optional):\n        Name of the compartment. Default: None, i.e., first model compartment from\n        monitor.\n    period (int, optional):\n        Index of the period. Default: None, i.e., all periods.\n\n    Returns:\n        lims (tuple):\n            Tuple with start and stop time of the specified chunk/model compartment.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR time_lims(): No recordings/recording_times available.\"\n    return self._lims(\"ms\", chunk, compartment, period)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.idx_lims","title":"<code>idx_lims(chunk=None, compartment=None, period=None)</code>","text":"<p>Get the index limits of recordings of a specified chunk/model compartment.</p> <p>chunk (int, optional):     Index of the chunk. Default: None, i.e., first chunk. compartment (str, optional):     Name of the compartment. Default: None, i.e., first model compartment from     monitor. period (int, optional):     Index of the period. Default: None, i.e., all periods.</p> <p>Returns:</p> Name Type Description <code>lims</code> <code>tuple</code> <p>Tuple with start and stop index of the specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def idx_lims(\n    self,\n    chunk: int | None = None,\n    compartment: str | None = None,\n    period: int | None = None,\n):\n    \"\"\"\n    Get the index limits of recordings of a specified chunk/model compartment.\n\n    chunk (int, optional):\n        Index of the chunk. Default: None, i.e., first chunk.\n    compartment (str, optional):\n        Name of the compartment. Default: None, i.e., first model compartment from\n        monitor.\n    period (int, optional):\n        Index of the period. Default: None, i.e., all periods.\n\n    Returns:\n        lims (tuple):\n            Tuple with start and stop index of the specified chunk/model\n            compartment.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR idx_lims(): No recordings/recording_times available.\"\n    return self._lims(\"idx\", chunk, compartment, period)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.all","title":"<code>all()</code>","text":"<p>Get the recording times of all chunks, compartments, periods in ms and index.</p> <p>Returns:</p> Name Type Description <code>recording_times_list</code> <code>list</code> <p>List with recording times of all chunks.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def all(self):\n    \"\"\"\n    Get the recording times of all chunks, compartments, periods in ms and index.\n\n    Returns:\n        recording_times_list (list):\n            List with recording times of all chunks.\n    \"\"\"\n    return self.recording_times_list\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.nr_periods","title":"<code>nr_periods(chunk=None, compartment=None)</code>","text":"<p>Get the number of recording periods (start-pause) of a specified chunk/model compartment.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>int</code> <p>Index of the chunk. Default: None, i.e., first chunk.</p> <code>None</code> <code>compartment</code> <code>str</code> <p>Name of the compartment. Default: None, i.e., first model compartment from monitor.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>nr_periods</code> <code>int</code> <p>Number of recording periods (start-pause) of a specified chunk/model compartment.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def nr_periods(self, chunk=None, compartment=None):\n    \"\"\"\n    Get the number of recording periods (start-pause) of a specified chunk/model\n    compartment.\n\n    Args:\n        chunk (int, optional):\n            Index of the chunk. Default: None, i.e., first chunk.\n        compartment (str, optional):\n            Name of the compartment. Default: None, i.e., first model compartment\n            from monitor.\n\n    Returns:\n        nr_periods (int):\n            Number of recording periods (start-pause) of a specified chunk/model\n            compartment.\n    \"\"\"\n    chunk = self._check_chunk(chunk)\n    compartment = self.__check_compartment__(compartment, chunk)\n    return self._get_nr_periods(chunk, compartment)\n</code></pre>"},{"location":"main/monitors_recordings/#CompNeuroPy.monitors.RecordingTimes.combine_chunks","title":"<code>combine_chunks(recordings, recording_data_str, mode='sequential')</code>","text":"<p>Combines the data of all chunks of recordings, only possible if no pauses in between.</p> <p>Parameters:</p> Name Type Description Default <code>recordings</code> <code>list</code> <p>List with recordings of all chunks.</p> required <code>recording_data_str</code> <code>str</code> <p>String specifying the compartment name and the variable to combine. Format: \"compartment_name;variable_name\"</p> required <code>mode</code> <code>str</code> <p>How should the time array be generated. Can be \"sequential\" or \"consecutive\". Default: \"sequential\". - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;     [0, 1, ..., 100, 0, 1, ..., 250] - \"consecutive\": each chunk starts at the last stop time of the previous     chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]</p> <code>'sequential'</code> <p>Returns:</p> Name Type Description <code>time_arr</code> <code>array</code> <p>Array with time values in ms.</p> <code>data_arr</code> <code>array</code> <p>Array with the recorded variable.</p> Source code in <code>src/CompNeuroPy/monitors.py</code> <pre><code>def combine_chunks(\n    self, recordings: list, recording_data_str: str, mode=\"sequential\"\n):\n    \"\"\"\n    Combines the data of all chunks of recordings, only possible if no pauses in\n    between.\n\n    Args:\n        recordings (list):\n            List with recordings of all chunks.\n        recording_data_str (str):\n            String specifying the compartment name and the variable to combine.\n            Format: \"compartment_name;variable_name\"\n        mode (str, optional):\n            How should the time array be generated. Can be \"sequential\" or\n            \"consecutive\". Default: \"sequential\".\n            - \"sequential\": each chunk starts at zero e.g.: [0,100] + [0,250] --&gt;\n                [0, 1, ..., 100, 0, 1, ..., 250]\n            - \"consecutive\": each chunk starts at the last stop time of the previous\n                chunk e.g.: [0,100] + [0,250] --&gt; [0, 1, ..., 100, 101, 102, ..., 350]\n\n    Returns:\n        time_arr (np.array):\n            Array with time values in ms.\n        data_arr (np.array):\n            Array with the recorded variable.\n    \"\"\"\n    assert (\n        len(self.recording_times_list) &gt; 0\n    ), \"ERROR combine_chunks(): No recordings/recording_times available.\"\n\n    compartment = recording_data_str.split(\";\")[0]\n    period_time = recordings[0][f\"{compartment};period\"]\n    time_step = recordings[0][\"dt\"]\n    nr_chunks = self._get_nr_chunks()\n    data_list = []\n    time_list = []\n    pre_chunk_start_time = 0\n\n    for chunk in range(nr_chunks):\n        ### append data list with data of all periods of this chunk\n        data_list.append(recordings[chunk][recording_data_str])\n\n        ### nr of periods in this chunk\n        nr_periods = self._get_nr_periods(chunk, compartment)\n\n        ### start time of chunk depends on mode\n        if mode == \"sequential\":\n            chunk_start_time = 0\n        elif mode == \"consecutive\":\n            if chunk == 0:\n                chunk_start_time = 0\n            else:\n                last_stop_time = self.recording_times_list[chunk - 1][compartment][\n                    \"stop\"\n                ][\"ms\"][-1]\n                chunk_start_time = (\n                    pre_chunk_start_time + last_stop_time + period_time\n                )\n                pre_chunk_start_time = chunk_start_time\n        else:\n            print(\"ERROR recording_times.combine_data, Wrong mode.\")\n            quit()\n\n        ### append the time list with all times of the periods\n        for period in range(nr_periods):\n            start_time = (\n                self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                    0\n                ]\n                + chunk_start_time\n            )\n            end_time = (\n                self.time_lims(chunk=chunk, compartment=compartment, period=period)[\n                    1\n                ]\n                + chunk_start_time\n            )\n            start_time = round(start_time, af.get_number_of_decimals(time_step))\n            end_time = round(end_time, af.get_number_of_decimals(time_step))\n            times = np.arange(start_time, end_time + period_time, period_time)\n            time_list.append(times)\n\n    ### flatten the two lists\n    data_arr = np.concatenate(data_list, 0)\n    time_arr = np.concatenate(time_list, 0)\n\n    ### check if there are gaps in the time array\n    ### fill them with the corersponding times and\n    ### the data array with nan values\n    time_arr, data_arr = af.time_data_add_nan(\n        time_arr,\n        data_arr,\n        fill_time_step=period_time,\n    )\n\n    return time_arr, data_arr\n</code></pre>"},{"location":"main/optimize_neuron/","title":"Optimize a neuron model","text":""},{"location":"main/optimize_neuron/#CompNeuroPy.opt_neuron.OptNeuron","title":"<code>CompNeuroPy.opt_neuron.OptNeuron</code>","text":"<p>This class is used to optimize neuron models with ANNarchy.</p> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>class OptNeuron:\n    \"\"\"\n    This class is used to optimize neuron models with ANNarchy.\n    \"\"\"\n\n    opt_created = []\n\n    def __init__(\n        self,\n        experiment: Type[CompNeuroExp],\n        get_loss_function: Callable[[Any, Any], float | list[float]],\n        variables_bounds: dict[str, float | list[float]],\n        neuron_model: Neuron,\n        results_soll: Any | None = None,\n        target_neuron_model: Neuron | None = None,\n        time_step: float | None = 1.0,\n        compile_folder_name: str = \"annarchy_OptNeuron\",\n        num_rep_loss: int = 1,\n        method: str = \"hyperopt\",\n        prior=None,\n        fv_space: list = None,\n        record: list[str] = [],\n    ):\n        \"\"\"\n        This prepares the optimization. To run the optimization call the run function.\n\n        Args:\n            experiment (CompNeuroExp class):\n                CompNeuroExp class containing a 'run' function which defines the\n                simulations and recordings\n\n            get_loss_function (function):\n                function which takes results_ist and results_soll as arguments and\n                calculates/returns the loss\n\n            variables_bounds (dict):\n                Dictionary with parameter names (keys) and their bounds (values). If\n                single values are given as values, the parameter is constant, i.e., not\n                optimized. If a list is given as value, the parameter is optimized and\n                the list contains the lower and upper bound of the parameter (order is\n                not important).\n\n            neuron_model (ANNarchy Neuron):\n                The neuron model whose parameters should be optimized.\n\n            results_soll (Any, optional):\n                Some variable which contains the target data and can be used by the\n                get_loss_function (second argument of get_loss_function)\n                !!! warning\n                    Either provide results_soll or a target_neuron_model not both!\n                Default: None.\n\n            target_neuron_model (ANNarchy Neuron, optional):\n                The neuron model which produces the target data by running the\n                experiment.\n                !!! warning\n                    Either provide results_soll or a target_neuron_model not both!\n                Default: None.\n\n            time_step (float, optional):\n                The time step for the simulation in ms. Default: 1.\n\n            compile_folder_name (string, optional):\n                The name of the annarchy compilation folder within annarchy_folders/.\n                Default: 'annarchy_OptNeuron'.\n\n            num_rep_loss (int, optional):\n                Only interesting for noisy simulations/models. How often should the\n                simulaiton be run to calculate the loss (the defined number of losses\n                is obtained and averaged). Default: 1.\n\n            method (str, optional):\n                Either 'sbi' or 'hyperopt'. If 'sbi' is used, the optimization is\n                performed with sbi. If 'hyperopt' is used, the optimization is\n                performed with hyperopt. Default: 'hyperopt'.\n\n            prior (distribution, optional):\n                The prior distribution used by sbi. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n\n            fv_space (list, optional):\n                The search space for hyperopt. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n\n            record (list, optional):\n                List of strings which define what variables of the tuned neuron should\n                be recorded. Default: [].\n        \"\"\"\n\n        if len(self.opt_created) &gt; 0:\n            print(\n                \"OptNeuron: Error: Already another OptNeuron created. Only create one per python session!\"\n            )\n            quit()\n        else:\n            print(\n                \"OptNeuron: Initialize OptNeuron... do not create anything with ANNarchy before!\"\n            )\n\n            ### set object variables\n            self.opt_created.append(1)\n            self.record = record\n            self.results_soll = results_soll\n            self.variables_bounds = variables_bounds\n            self.fitting_variables_name_list = self._get_fitting_variables_name_list()\n            self.method = method\n            if method == \"hyperopt\":\n                if fv_space is None:\n                    self.fv_space = self._get_hyperopt_space()\n                else:\n                    self.fv_space = fv_space\n            self.const_params = self._get_const_params()\n            self.num_rep_loss = num_rep_loss\n            self.neuron_model = neuron_model\n            if method == \"sbi\":\n                self.prior = self._get_prior(prior)\n            self.target_neuron = target_neuron_model\n            self.compile_folder_name = compile_folder_name\n            self.__get_loss__ = get_loss_function\n\n            ### check target_neuron/results_soll\n            self._check_target()\n            ### check neuron models\n            self._check_neuron_models()\n\n            ### setup ANNarchy\n            setup(dt=time_step)\n\n            ### create and compile model\n            ### if neuron models and target neuron model --&gt; create both models then\n            ### test, then clear and create only model for neuron model\n            model, target_model, monitors = self._generate_models()\n\n            self.pop = model.populations[0]\n            if target_model is not None:\n                self.pop_target = target_model.populations[0]\n            else:\n                self.pop_target = None\n            ### create experiment with current monitors\n            self.experiment = experiment(monitors=monitors)\n\n            ### check variables of model\n            self._test_variables()\n\n            ### check neuron models, experiment, get_loss\n            ### if results_soll is None -_&gt; generate results_soll\n            self._check_get_loss_function()\n\n            ### after checking neuron models, experiment, get_loss\n            ### if two models exist --&gt; clear ANNarchy and create/compile again only\n            ### standard model, thus recreate also monitors and experiment\n            clear()\n            model, _, monitors = self._generate_models()\n            self.monitors = monitors\n            self.experiment = experiment(monitors=monitors)\n\n    def _generate_models(self):\n        \"\"\"\n        Generates the tuned model and the target_model (only if results_soll is None).\n\n        Returns:\n            model (CompNeuroModel):\n                The model which is used for the optimization.\n\n            target_model (CompNeuroModel):\n                The model which is used to generate the target data. If results_soll is\n                provided, target_model is None.\n\n            monitors (CompNeuroMonitors):\n                The monitors which are used to record the data. If no variables are\n                recorded, monitors is None.\n        \"\"\"\n        with ef.suppress_stdout():\n            model = None\n            target_model = None\n            monitors = None\n            if self.results_soll is None:\n                ### create two models\n                model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\"neuron\": self.neuron_model, \"name\": \"model_neuron\"},\n                    name=\"standard_model\",\n                    do_create=True,\n                    do_compile=False,\n                    compile_folder_name=self.compile_folder_name,\n                )\n\n                target_model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\n                        \"neuron\": self.target_neuron,\n                        \"name\": \"target_model_neuron\",\n                    },\n                    name=\"target_model\",\n                    do_create=True,\n                    do_compile=True,\n                    compile_folder_name=self.compile_folder_name,\n                )\n\n                ### create monitors\n                if len(self.record) &gt; 0:\n                    monitors = CompNeuroMonitors(\n                        {\n                            pop_name: self.record\n                            for pop_name in [\n                                model.populations[0],\n                                target_model.populations[0],\n                            ]\n                        }\n                    )\n\n            else:\n                ### create one model\n                model = CompNeuroModel(\n                    model_creation_function=self._raw_neuron,\n                    model_kwargs={\"neuron\": self.neuron_model, \"name\": \"model_neuron\"},\n                    name=\"single_model\",\n                    do_create=True,\n                    do_compile=True,\n                    compile_folder_name=self.compile_folder_name,\n                )\n                ### create monitors\n                if len(self.record) &gt; 0:\n                    monitors = CompNeuroMonitors({model.populations[0]: self.record})\n\n        return model, target_model, monitors\n\n    def _check_neuron_models(self):\n        \"\"\"\n        Checks if the neuron models are ANNarchy neuron models.\n        \"\"\"\n        if not (isinstance(self.neuron_model, type(Neuron()))) or (\n            self.target_neuron is not None\n            and not (isinstance(self.target_neuron, type(Neuron())))\n        ):\n            print(\n                \"OptNeuron: Error: neuron_model and/or target_neuron_model have to be ANNarchy neuron models\"\n            )\n            quit()\n\n    def _check_target(self):\n        \"\"\"\n        Check if either results_soll or target_neuron are provided and not both.\n        \"\"\"\n        if self.target_neuron is None and self.results_soll is None:\n            print(\n                \"OptNeuron: Error: Either provide results_soll or target_neuron_model\"\n            )\n            quit()\n        elif self.target_neuron is not None and self.results_soll is not None:\n            print(\n                \"OptNeuron: Error: Either provide results_soll or target_neuron_model, not both\"\n            )\n            quit()\n\n    def _get_prior(self, prior):\n        \"\"\"\n        Get the prior distribution used by sbi. If no prior is given, uniform\n        distributions between the variable bounds are assumed. If a prior is given,\n        this prior is used.\n\n        Args:\n            prior (distribution, optional):\n                The prior distribution used by sbi. Default: None, i.e., uniform\n                distributions between the variable bounds are assumed.\n\n        Returns:\n            prior (distribution):\n                The prior distribution used by sbi.\n        \"\"\"\n        if prior is None:\n            prior_min = []\n            prior_max = []\n            for _, param_bounds in self.variables_bounds.items():\n                if isinstance(param_bounds, list):\n                    prior_min.append(param_bounds[0])\n                    prior_max.append(param_bounds[1])\n\n            return utils.BoxUniform(\n                low=torch.as_tensor(prior_min), high=torch.as_tensor(prior_max)\n            )\n        else:\n            return prior\n\n    def _get_fitting_variables_name_list(self):\n        \"\"\"\n        Returns a list with the names of the fitting variables.\n\n        Returns:\n            fitting_variables_name_list (list):\n                list with names of fitting variables\n        \"\"\"\n        name_list = []\n        for param_name, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                name_list.append(param_name)\n        return name_list\n\n    def _get_hyperopt_space(self):\n        \"\"\"\n        Generates the hyperopt variable space from the fitting variable bounds. The\n        variable space is a uniform distribution between the bounds.\n\n        Returns:\n            fitting_variables_space (list):\n                list with hyperopt variables\n        \"\"\"\n        fitting_variables_space = []\n        for param_name, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                fitting_variables_space.append(\n                    hp.uniform(param_name, min(param_bounds), max(param_bounds))\n                )\n        return fitting_variables_space\n\n    def _get_const_params(self):\n        \"\"\"\n        Returns:\n            const_params (dict):\n                Dictionary with constant variables. The keys are the parameter names\n                and the values are the parameter values.\n        \"\"\"\n        const_params = {}\n        for param_name, param_bounds in self.variables_bounds.items():\n            if not (isinstance(param_bounds, list)):\n                const_params[param_name] = param_bounds\n        return const_params\n\n    def _check_get_loss_function(self):\n        \"\"\"\n        Checks if the get_loss_function is compatible to the experiment and the neuron\n        model(s). To test, the experiment is run once with the tuned neuron model\n        (generating results_ist) and once with the target neuron model (if provided,\n        generating results_soll). Then, the get_loss_function is called with the\n        results_ist and results_soll.\n        \"\"\"\n        print(\"checking neuron_models, experiment, get_loss...\", end=\"\")\n\n        fitparams = []\n        for bounds in self.variables_bounds.values():\n            if isinstance(bounds, list):\n                fitparams.append(bounds[0])\n\n        if self.results_soll is not None:\n            ### only generate results_ist with standard neuron model\n            results_ist = self._run_simulator_with_results(fitparams)[\"results\"]\n        else:\n            ### run simulator with both populations (standard neuron model and target\n            ### neuron model) and generatate results_ist and results_soll\n            results_ist = self._run_simulator_with_results(fitparams)[\"results\"]\n            self.results_soll = self._run_simulator_with_results(\n                fitparams, pop=self.pop_target\n            )[\"results\"]\n\n        try:\n            self.__get_loss__(results_ist, self.results_soll)\n        except:\n            print(\n                \"\\nThe get_loss_function, experiment and neuron model(s) are not compatible:\\n\"\n            )\n            traceback.print_exc()\n            quit()\n        print(\"Done\\n\")\n\n    def _raw_neuron(self, neuron, name):\n        \"\"\"\n        Generates a population with one neuron of the given neuron model.\n\n        Args:\n            neuron (ANNarchy Neuron):\n                The neuron model.\n\n            name (str):\n                The name of the population.\n        \"\"\"\n        Population(1, neuron=neuron, name=name)\n\n    def _test_variables(self):\n        \"\"\"\n        Check if the tuned neuron model contains all parameters which are defined in\n        variables_bounds or even more.\n        \"\"\"\n        ### collect all names\n        all_vars_names = np.concatenate(\n            [\n                np.array(list(self.const_params.keys())),\n                np.array(self.fitting_variables_name_list),\n            ]\n        ).tolist()\n        ### check if pop has these parameters\n        pop_parameter_names = get_population(self.pop).attributes.copy()\n        for name in pop_parameter_names.copy():\n            if name in all_vars_names:\n                all_vars_names.remove(name)\n                pop_parameter_names.remove(name)\n        if len(pop_parameter_names) &gt; 0:\n            print(\n                \"OptNeuron: WARNING: attributes\",\n                pop_parameter_names,\n                \"are not used/initialized.\",\n            )\n        if len(all_vars_names) &gt; 0:\n            print(\n                \"OptNeuron: WARNING: The neuron_model does not contain parameters\",\n                all_vars_names,\n                \"!\",\n            )\n\n    def _run_simulator(self, fitparams):\n        \"\"\"\n        Runs the function simulator with the multiprocessing manager (if function is\n        called multiple times this saves memory, otherwise same as calling simulator\n        directly).\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters\n\n        Returns:\n            return_dict (dict):\n                dictionary needed for optimization with hyperopt, containing the loss,\n                the loss variance (in case of noisy models with multiple runs per loss\n                calculation), and the status (STATUS_OK for hyperopt).\n        \"\"\"\n\n        ### initialize manager and generate m_list = dictionary to save data\n        manager = multiprocessing.Manager()\n        m_list = manager.dict()\n\n        ### in case of noisy models, here optionally run multiple simulations, to mean the loss\n        lossAr = np.zeros(self.num_rep_loss)\n\n        return_results = False\n        for nr_run in range(self.num_rep_loss):\n            ### initialize for each run a new rng (--&gt; not always have same noise in case of noisy models/simulations)\n            rng = np.random.default_rng()\n            ### run simulator with multiprocessign manager\n            proc = Process(\n                target=self._simulator, args=(fitparams, rng, m_list, return_results)\n            )\n            proc.start()\n            proc.join()\n            ### get simulation results/loss\n            lossAr[nr_run] = m_list[0]\n\n        ### calculate mean and std of loss\n        if self.num_rep_loss &gt; 1:\n            loss = np.mean(lossAr)\n            std = np.std(lossAr)\n        else:\n            loss = lossAr[0]\n            std = None\n\n        ### return loss and other things for optimization\n        if self.num_rep_loss &gt; 1:\n            return {\"status\": STATUS_OK, \"loss\": loss, \"loss_variance\": std}\n        else:\n            return {\"status\": STATUS_OK, \"loss\": loss}\n\n    def _sbi_simulation_wrapper(self, fitparams):\n        \"\"\"\n        This function is called by sbi. It calls the simulator function and\n        returns the loss and adjusts the format of the input parameters.\n\n        Args:\n            fitparams (tensor):\n                either a batch of parameters (tensor with two dimensions) or a single\n                parameter set\n\n        Returns:\n            loss (tensor):\n                loss as tensor for sbi inference\n        \"\"\"\n        fitparams = np.asarray(fitparams)\n        if len(fitparams.shape) == 2:\n            ### batch parameters!\n            data = []\n            for idx in range(fitparams.shape[0]):\n                data.append(self._run_simulator(fitparams[idx])[\"loss\"])\n        else:\n            ### single parameter set!\n            data = [self._run_simulator(fitparams)[\"loss\"]]\n\n        return torch.as_tensor(data)\n\n    def _run_simulator_with_results(self, fitparams, pop=None):\n        \"\"\"\n        Runs the function simulator with the multiprocessing manager (if function is\n        called multiple times this saves memory, otherwise same as calling simulator\n        directly) and also returns the results.\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters\n\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n\n        Returns:\n            return_dict (dict):\n                dictionary needed for optimization with hyperopt, containing the loss,\n                the loss variance (in case of noisy models with multiple runs per loss\n                calculation), and the status (STATUS_OK for hyperopt) and the results\n                generated by the experiment.\n        \"\"\"\n        ### check if pop is given\n        if pop is None:\n            pop = self.pop\n        ### initialize manager and generate m_list = dictionary to save data\n        manager = multiprocessing.Manager()\n        m_list = manager.dict()\n\n        ### in case of noisy models, here optionally run multiple simulations, to mean the loss\n        lossAr = np.zeros(self.num_rep_loss)\n        all_loss_list = []\n        return_results = True\n        for nr_run in range(self.num_rep_loss):\n            ### initialize for each run a new rng (--&gt; not always have same noise in case of noisy models/simulations)\n            rng = np.random.default_rng()\n            ### run simulator with multiprocessign manager\n            proc = Process(\n                target=self._simulator,\n                args=(fitparams, rng, m_list, return_results, pop),\n            )\n            proc.start()\n            proc.join()\n            ### get simulation results/loss\n            lossAr[nr_run] = m_list[0]\n            results_ist = m_list[1]\n            all_loss_list.append(m_list[2])\n\n        all_loss_arr = np.array(all_loss_list)\n        ### calculate mean and std of loss\n        if self.num_rep_loss &gt; 1:\n            loss = np.mean(lossAr)\n            std = np.std(lossAr)\n            all_loss = np.mean(all_loss_arr, 0)\n        else:\n            loss = lossAr[0]\n            std = None\n            all_loss = all_loss_arr[0]\n\n        ### return loss and other things for optimization and results\n        if self.num_rep_loss &gt; 1:\n            return {\n                \"status\": STATUS_OK,\n                \"loss\": loss,\n                \"loss_variance\": std,\n                \"std\": std,\n                \"all_loss\": all_loss,\n                \"results\": results_ist,\n            }\n        else:\n            return {\n                \"status\": STATUS_OK,\n                \"loss\": loss,\n                \"std\": std,\n                \"all_loss\": all_loss,\n                \"results\": results_ist,\n            }\n\n    def _simulator(\n        self, fitparams, rng, m_list=[0, 0, 0], return_results=False, pop=None\n    ):\n        \"\"\"\n        Runs the experiment with the given parameters and 'returns' the loss and\n        optionally the results and all individual losses of the get_loss_function. The\n        'returned' values are saved in m_list.\n\n        Args:\n            fitparams (list):\n                list with values for fitting parameters\n\n            rng (numpy random generator):\n                random generator for the simulation\n\n            m_list (list, optional):\n                list with the loss, the results, and the all_loss. Default: [0, 0, 0].\n\n            return_results (bool, optional):\n                If True, the results are returned. Default: False.\n\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n        \"\"\"\n        ### TODO use rng here and add it to CompNeuroExp\n        ### check if pop is given\n        if pop is None:\n            pop = self.pop\n\n        ### set parameters which should not be optimized and parameters which should be\n        ### optimized before the experiment, they should not be resetted by the\n        ### experiment!\n        self._set_fitting_parameters(fitparams, pop=pop)\n\n        ### conduct loaded experiment\n        results = self.experiment.run(pop)\n\n        if self.results_soll is not None:\n            ### compute loss\n            all_loss = self.__get_loss__(results, self.results_soll)\n            if isinstance(all_loss, list) or isinstance(all_loss, type(np.zeros(1))):\n                loss = sum(all_loss)\n            else:\n                loss = all_loss\n        else:\n            all_loss = 999\n            loss = 999\n        ### \"return\" loss and other optional things\n        m_list[0] = loss\n        if return_results:\n            m_list[1] = results\n            m_list[2] = all_loss\n\n    def _set_fitting_parameters(\n        self,\n        fitparams,\n        pop=None,\n    ):\n        \"\"\"\n        Sets all given parameters for the population pop.\n\n        Args:\n            pop (str, optional):\n                ANNarchy population name. Default: None, i.e., the tuned population\n                is used.\n        \"\"\"\n        if pop is None:\n            pop = self.pop\n\n        ### get all variables dict (combine fitting variables and const variables)\n        all_variables_dict = self.const_params.copy()\n\n        for fitting_variable_idx, fitting_variable_name in enumerate(\n            self.fitting_variables_name_list\n        ):\n            all_variables_dict[fitting_variable_name] = fitparams[fitting_variable_idx]\n\n        ### evaluate variables defined by a str\n        for key, val in all_variables_dict.items():\n            if isinstance(val, str):\n                all_variables_dict[key] = ef.evaluate_expression_with_dict(\n                    val, all_variables_dict\n                )\n\n        ### only set parameters of the fitted neuron model (in case target neuron model is given)\n        if pop == self.pop:\n            ### set parameters\n            for param_name, param_val in all_variables_dict.items():\n                pop_parameter_names = get_population(pop).attributes\n                ### only if param_name in parameter attributes\n                if param_name in pop_parameter_names:\n                    setattr(\n                        get_population(pop),\n                        param_name,\n                        param_val,\n                    )\n\n    def _test_fit(self, fitparams_dict):\n        \"\"\"\n        Runs the experiment with the optimized parameters obtained with hyperopt and\n        returns the loss, the results and all individual losses of the\n        get_loss_function.\n\n        Args:\n            fitparams_dict (dict):\n                dictionary with parameter names (keys) and their values (values)\n\n        Returns:\n            fit (dict):\n                dictionary containing the loss, the loss variance (in case of noisy\n                models with multiple runs per loss calculation), and the status\n                (STATUS_OK for hyperopt) and the results generated by the experiment.\n        \"\"\"\n        return self._run_simulator_with_results(\n            [fitparams_dict[name] for name in self.fitting_variables_name_list]\n        )\n\n    def _run_with_sbi(self, max_evals, sbi_plot_file):\n        \"\"\"\n        Runs the optimization with sbi.\n\n        Args:\n            max_evals (int):\n                number of runs the optimization method performs\n\n            sbi_plot_file (str):\n                If you use \"sbi\": the name of the figure which will be saved and shows\n                the posterior.\n\n        Returns:\n            best (dict):\n                dictionary containing the optimized parameters and the posterior.\n        \"\"\"\n        ### get prior bounds\n        prior_min = []\n        prior_max = []\n        for _, param_bounds in self.variables_bounds.items():\n            if isinstance(param_bounds, list):\n                prior_min.append(param_bounds[0])\n                prior_max.append(param_bounds[1])\n\n        ### run sbi\n        simulator, prior = prepare_for_sbi(\n            self._sbi_simulation_wrapper,\n            self.prior,\n            {\n                \"lower_bound\": torch.as_tensor(prior_min),\n                \"upper_bound\": torch.as_tensor(prior_max),\n            },\n        )\n        inference = SNPE(prior, density_estimator=\"mdn\")\n        theta, x = simulate_for_sbi(\n            simulator=simulator,\n            proposal=prior,\n            num_simulations=max_evals,\n            num_workers=1,\n        )\n        density_estimator = inference.append_simulations(theta, x).train()\n        posterior = inference.build_posterior(density_estimator)\n        x_o = torch.as_tensor([0])  # data which should be obtained: loss==0\n        posterior = posterior.set_default_x(x_o)\n\n        ### get best params\n        posterior_samples = posterior.sample(\n            (10000,)\n        )  # posterior = distribution P(params|data) --&gt; set data and then sample possible parameters\n        best_params = posterior_samples[\n            torch.argmax(posterior.log_prob(posterior_samples))\n        ].numpy()  # sampled parameters with highest prob in posterior\n\n        ### create best dict with best parameters\n        best = {}\n        for param_idx, param_name in enumerate(self.fitting_variables_name_list):\n            best[param_name] = best_params[param_idx]\n\n        ### also return posterior\n        best[\"posterior\"] = posterior\n\n        ### plot posterior\n        plot_limits = [\n            [prior_min[idx], prior_max[idx]] for idx in range(len(prior_max))\n        ]\n        analysis.pairplot(\n            posterior_samples,\n            limits=plot_limits,\n            ticks=plot_limits,\n            fig_size=(5, 5),\n            labels=self.fitting_variables_name_list,\n        )\n\n        ### save plot\n        sf.create_dir(\"/\".join(sbi_plot_file.split(\"/\")[:-1]))\n        plt.savefig(sbi_plot_file)\n\n        return best\n\n    @check_types()\n    def run(\n        self,\n        max_evals: int,\n        results_file_name=\"best.npy\",\n        sbi_plot_file=\"posterior.svg\",\n    ):\n        \"\"\"\n        Runs the optimization.\n\n        Args:\n            max_evals (int):\n                number of runs the optimization method performs\n\n            results_file_name (str, optional):\n                name of the file which is saved. The file contains the optimized and\n                target results, the obtained parameters, the loss, and the SD of the\n                loss (in case of noisy models with multiple runs per loss calculation)\n                Default: \"best.npy\".\n\n            sbi_plot_file (str, optional):\n                If you use \"sbi\": the name of the figure which will be saved and shows\n                the posterior. Default: \"posterior.svg\".\n\n        Returns:\n            best (dict):\n                dictionary containing the optimized parameters (as keys) and:\n\n                - \"loss\": the loss\n                - \"all_loss\": the individual losses of the get_loss_function\n                - \"std\": the SD of the loss (in case of noisy models with multiple\n                    runs per loss calculation)\n                - \"results\": the results generated by the experiment\n                - \"results_soll\": the target results\n        \"\"\"\n        if self.method == \"hyperopt\":\n            ### run optimization with hyperopt and return best dict\n            best = fmin(\n                fn=self._run_simulator,\n                space=self.fv_space,\n                algo=tpe.suggest,\n                max_evals=max_evals,\n            )\n        elif self.method == \"sbi\":\n            ### run optimization with sbi and return best dict\n            best = self._run_with_sbi(max_evals, sbi_plot_file)\n        else:\n            print(\"ERROR run; method should be 'hyperopt' or 'sbi'\")\n            quit()\n        fit = self._test_fit(best)\n        best[\"loss\"] = fit[\"loss\"]\n        if self.method == \"sbi\":\n            print(\"\\tbest loss:\", best[\"loss\"])\n        best[\"all_loss\"] = fit[\"all_loss\"]\n        best[\"std\"] = fit[\"std\"]\n        best[\"results\"] = fit[\"results\"]\n        best[\"results_soll\"] = self.results_soll\n        self.results = best\n\n        ### SAVE OPTIMIZED PARAMS AND LOSS\n        sf.save_variables([best], [results_file_name], \"parameter_fit\")\n\n        return best\n</code></pre>"},{"location":"main/optimize_neuron/#CompNeuroPy.opt_neuron.OptNeuron.__init__","title":"<code>__init__(experiment, get_loss_function, variables_bounds, neuron_model, results_soll=None, target_neuron_model=None, time_step=1.0, compile_folder_name='annarchy_OptNeuron', num_rep_loss=1, method='hyperopt', prior=None, fv_space=None, record=[])</code>","text":"<p>This prepares the optimization. To run the optimization call the run function.</p> <p>Parameters:</p> Name Type Description Default <code>experiment</code> <code>CompNeuroExp class</code> <p>CompNeuroExp class containing a 'run' function which defines the simulations and recordings</p> required <code>get_loss_function</code> <code>function</code> <p>function which takes results_ist and results_soll as arguments and calculates/returns the loss</p> required <code>variables_bounds</code> <code>dict</code> <p>Dictionary with parameter names (keys) and their bounds (values). If single values are given as values, the parameter is constant, i.e., not optimized. If a list is given as value, the parameter is optimized and the list contains the lower and upper bound of the parameter (order is not important).</p> required <code>neuron_model</code> <code>ANNarchy Neuron</code> <p>The neuron model whose parameters should be optimized.</p> required <code>results_soll</code> <code>Any</code> <p>Some variable which contains the target data and can be used by the get_loss_function (second argument of get_loss_function)</p> <p>Warning</p> <p>Either provide results_soll or a target_neuron_model not both!</p> <p>Default: None.</p> <code>None</code> <code>target_neuron_model</code> <code>ANNarchy Neuron</code> <p>The neuron model which produces the target data by running the experiment.</p> <p>Warning</p> <p>Either provide results_soll or a target_neuron_model not both!</p> <p>Default: None.</p> <code>None</code> <code>time_step</code> <code>float</code> <p>The time step for the simulation in ms. Default: 1.</p> <code>1.0</code> <code>compile_folder_name</code> <code>string</code> <p>The name of the annarchy compilation folder within annarchy_folders/. Default: 'annarchy_OptNeuron'.</p> <code>'annarchy_OptNeuron'</code> <code>num_rep_loss</code> <code>int</code> <p>Only interesting for noisy simulations/models. How often should the simulaiton be run to calculate the loss (the defined number of losses is obtained and averaged). Default: 1.</p> <code>1</code> <code>method</code> <code>str</code> <p>Either 'sbi' or 'hyperopt'. If 'sbi' is used, the optimization is performed with sbi. If 'hyperopt' is used, the optimization is performed with hyperopt. Default: 'hyperopt'.</p> <code>'hyperopt'</code> <code>prior</code> <code>distribution</code> <p>The prior distribution used by sbi. Default: None, i.e., uniform distributions between the variable bounds are assumed.</p> <code>None</code> <code>fv_space</code> <code>list</code> <p>The search space for hyperopt. Default: None, i.e., uniform distributions between the variable bounds are assumed.</p> <code>None</code> <code>record</code> <code>list</code> <p>List of strings which define what variables of the tuned neuron should be recorded. Default: [].</p> <code>[]</code> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>def __init__(\n    self,\n    experiment: Type[CompNeuroExp],\n    get_loss_function: Callable[[Any, Any], float | list[float]],\n    variables_bounds: dict[str, float | list[float]],\n    neuron_model: Neuron,\n    results_soll: Any | None = None,\n    target_neuron_model: Neuron | None = None,\n    time_step: float | None = 1.0,\n    compile_folder_name: str = \"annarchy_OptNeuron\",\n    num_rep_loss: int = 1,\n    method: str = \"hyperopt\",\n    prior=None,\n    fv_space: list = None,\n    record: list[str] = [],\n):\n    \"\"\"\n    This prepares the optimization. To run the optimization call the run function.\n\n    Args:\n        experiment (CompNeuroExp class):\n            CompNeuroExp class containing a 'run' function which defines the\n            simulations and recordings\n\n        get_loss_function (function):\n            function which takes results_ist and results_soll as arguments and\n            calculates/returns the loss\n\n        variables_bounds (dict):\n            Dictionary with parameter names (keys) and their bounds (values). If\n            single values are given as values, the parameter is constant, i.e., not\n            optimized. If a list is given as value, the parameter is optimized and\n            the list contains the lower and upper bound of the parameter (order is\n            not important).\n\n        neuron_model (ANNarchy Neuron):\n            The neuron model whose parameters should be optimized.\n\n        results_soll (Any, optional):\n            Some variable which contains the target data and can be used by the\n            get_loss_function (second argument of get_loss_function)\n            !!! warning\n                Either provide results_soll or a target_neuron_model not both!\n            Default: None.\n\n        target_neuron_model (ANNarchy Neuron, optional):\n            The neuron model which produces the target data by running the\n            experiment.\n            !!! warning\n                Either provide results_soll or a target_neuron_model not both!\n            Default: None.\n\n        time_step (float, optional):\n            The time step for the simulation in ms. Default: 1.\n\n        compile_folder_name (string, optional):\n            The name of the annarchy compilation folder within annarchy_folders/.\n            Default: 'annarchy_OptNeuron'.\n\n        num_rep_loss (int, optional):\n            Only interesting for noisy simulations/models. How often should the\n            simulaiton be run to calculate the loss (the defined number of losses\n            is obtained and averaged). Default: 1.\n\n        method (str, optional):\n            Either 'sbi' or 'hyperopt'. If 'sbi' is used, the optimization is\n            performed with sbi. If 'hyperopt' is used, the optimization is\n            performed with hyperopt. Default: 'hyperopt'.\n\n        prior (distribution, optional):\n            The prior distribution used by sbi. Default: None, i.e., uniform\n            distributions between the variable bounds are assumed.\n\n        fv_space (list, optional):\n            The search space for hyperopt. Default: None, i.e., uniform\n            distributions between the variable bounds are assumed.\n\n        record (list, optional):\n            List of strings which define what variables of the tuned neuron should\n            be recorded. Default: [].\n    \"\"\"\n\n    if len(self.opt_created) &gt; 0:\n        print(\n            \"OptNeuron: Error: Already another OptNeuron created. Only create one per python session!\"\n        )\n        quit()\n    else:\n        print(\n            \"OptNeuron: Initialize OptNeuron... do not create anything with ANNarchy before!\"\n        )\n\n        ### set object variables\n        self.opt_created.append(1)\n        self.record = record\n        self.results_soll = results_soll\n        self.variables_bounds = variables_bounds\n        self.fitting_variables_name_list = self._get_fitting_variables_name_list()\n        self.method = method\n        if method == \"hyperopt\":\n            if fv_space is None:\n                self.fv_space = self._get_hyperopt_space()\n            else:\n                self.fv_space = fv_space\n        self.const_params = self._get_const_params()\n        self.num_rep_loss = num_rep_loss\n        self.neuron_model = neuron_model\n        if method == \"sbi\":\n            self.prior = self._get_prior(prior)\n        self.target_neuron = target_neuron_model\n        self.compile_folder_name = compile_folder_name\n        self.__get_loss__ = get_loss_function\n\n        ### check target_neuron/results_soll\n        self._check_target()\n        ### check neuron models\n        self._check_neuron_models()\n\n        ### setup ANNarchy\n        setup(dt=time_step)\n\n        ### create and compile model\n        ### if neuron models and target neuron model --&gt; create both models then\n        ### test, then clear and create only model for neuron model\n        model, target_model, monitors = self._generate_models()\n\n        self.pop = model.populations[0]\n        if target_model is not None:\n            self.pop_target = target_model.populations[0]\n        else:\n            self.pop_target = None\n        ### create experiment with current monitors\n        self.experiment = experiment(monitors=monitors)\n\n        ### check variables of model\n        self._test_variables()\n\n        ### check neuron models, experiment, get_loss\n        ### if results_soll is None -_&gt; generate results_soll\n        self._check_get_loss_function()\n\n        ### after checking neuron models, experiment, get_loss\n        ### if two models exist --&gt; clear ANNarchy and create/compile again only\n        ### standard model, thus recreate also monitors and experiment\n        clear()\n        model, _, monitors = self._generate_models()\n        self.monitors = monitors\n        self.experiment = experiment(monitors=monitors)\n</code></pre>"},{"location":"main/optimize_neuron/#CompNeuroPy.opt_neuron.OptNeuron.run","title":"<code>run(max_evals, results_file_name='best.npy', sbi_plot_file='posterior.svg')</code>","text":"<p>Runs the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>max_evals</code> <code>int</code> <p>number of runs the optimization method performs</p> required <code>results_file_name</code> <code>str</code> <p>name of the file which is saved. The file contains the optimized and target results, the obtained parameters, the loss, and the SD of the loss (in case of noisy models with multiple runs per loss calculation) Default: \"best.npy\".</p> <code>'best.npy'</code> <code>sbi_plot_file</code> <code>str</code> <p>If you use \"sbi\": the name of the figure which will be saved and shows the posterior. Default: \"posterior.svg\".</p> <code>'posterior.svg'</code> <p>Returns:</p> Name Type Description <code>best</code> <code>dict</code> <p>dictionary containing the optimized parameters (as keys) and:</p> <ul> <li>\"loss\": the loss</li> <li>\"all_loss\": the individual losses of the get_loss_function</li> <li>\"std\": the SD of the loss (in case of noisy models with multiple     runs per loss calculation)</li> <li>\"results\": the results generated by the experiment</li> <li>\"results_soll\": the target results</li> </ul> Source code in <code>src/CompNeuroPy/opt_neuron.py</code> <pre><code>@check_types()\ndef run(\n    self,\n    max_evals: int,\n    results_file_name=\"best.npy\",\n    sbi_plot_file=\"posterior.svg\",\n):\n    \"\"\"\n    Runs the optimization.\n\n    Args:\n        max_evals (int):\n            number of runs the optimization method performs\n\n        results_file_name (str, optional):\n            name of the file which is saved. The file contains the optimized and\n            target results, the obtained parameters, the loss, and the SD of the\n            loss (in case of noisy models with multiple runs per loss calculation)\n            Default: \"best.npy\".\n\n        sbi_plot_file (str, optional):\n            If you use \"sbi\": the name of the figure which will be saved and shows\n            the posterior. Default: \"posterior.svg\".\n\n    Returns:\n        best (dict):\n            dictionary containing the optimized parameters (as keys) and:\n\n            - \"loss\": the loss\n            - \"all_loss\": the individual losses of the get_loss_function\n            - \"std\": the SD of the loss (in case of noisy models with multiple\n                runs per loss calculation)\n            - \"results\": the results generated by the experiment\n            - \"results_soll\": the target results\n    \"\"\"\n    if self.method == \"hyperopt\":\n        ### run optimization with hyperopt and return best dict\n        best = fmin(\n            fn=self._run_simulator,\n            space=self.fv_space,\n            algo=tpe.suggest,\n            max_evals=max_evals,\n        )\n    elif self.method == \"sbi\":\n        ### run optimization with sbi and return best dict\n        best = self._run_with_sbi(max_evals, sbi_plot_file)\n    else:\n        print(\"ERROR run; method should be 'hyperopt' or 'sbi'\")\n        quit()\n    fit = self._test_fit(best)\n    best[\"loss\"] = fit[\"loss\"]\n    if self.method == \"sbi\":\n        print(\"\\tbest loss:\", best[\"loss\"])\n    best[\"all_loss\"] = fit[\"all_loss\"]\n    best[\"std\"] = fit[\"std\"]\n    best[\"results\"] = fit[\"results\"]\n    best[\"results_soll\"] = self.results_soll\n    self.results = best\n\n    ### SAVE OPTIMIZED PARAMS AND LOSS\n    sf.save_variables([best], [results_file_name], \"parameter_fit\")\n\n    return best\n</code></pre>"}]}