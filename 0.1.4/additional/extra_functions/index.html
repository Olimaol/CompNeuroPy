
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://olimaol.github.io/CompNeuroPy/0.1.4/additional/extra_functions/">
      
      
        <link rel="prev" href="../system_functions/">
      
      
        <link rel="next" href="../statistic_functions/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.35">
    
    
      
        <title>Extra Functions - CompNeuroPy</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.35f28582.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#CompNeuroPy.extra_functions" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="CompNeuroPy" class="md-header__button md-logo" aria-label="CompNeuroPy" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CompNeuroPy
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Extra Functions
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/Olimaol/CompNeuroPy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="CompNeuroPy" class="md-nav__button md-logo" aria-label="CompNeuroPy" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    CompNeuroPy
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Olimaol/CompNeuroPy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Main Features
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Main Features
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../main/generate_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generate Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../main/generate_simulations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generate Simulations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../main/monitors_recordings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Monitors / Recordings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../main/optimize_neuron/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimize a neuron model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../main/define_experiment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Define Experiments
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../main/dbs_stimulator/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DBS Stimulator
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../main/model_configurator/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Configurator
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Built-in Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Built-in Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../built_in/models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Full Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../built_in/neuron_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neuron Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../built_in/synapse_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Synapse Models
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Additional Features
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Additional Features
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../simulation_functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simulation Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../simulation_requirements/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simulation Requirements
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../analysis_functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Analysis Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../system_functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    System Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Extra Functions
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Extra Functions
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions" class="md-nav__link">
    <span class="md-ellipsis">
      extra_functions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.Cmap" class="md-nav__link">
    <span class="md-ellipsis">
      Cmap
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cmap">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.Cmap.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.Cmap.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.Cmap.get_rgb" class="md-nav__link">
    <span class="md-ellipsis">
      get_rgb
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTree" class="md-nav__link">
    <span class="md-ellipsis">
      DecisionTree
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DecisionTree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTree.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTree.node" class="md-nav__link">
    <span class="md-ellipsis">
      node
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTree.get_path_prod" class="md-nav__link">
    <span class="md-ellipsis">
      get_path_prod
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTreeNode" class="md-nav__link">
    <span class="md-ellipsis">
      DecisionTreeNode
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DecisionTreeNode">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTreeNode.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTreeNode.add" class="md-nav__link">
    <span class="md-ellipsis">
      add
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTreeNode.get_path_prod" class="md-nav__link">
    <span class="md-ellipsis">
      get_path_prod
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DeapCma" class="md-nav__link">
    <span class="md-ellipsis">
      DeapCma
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DeapCma">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DeapCma.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DeapCma.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.VClampParamSearch" class="md-nav__link">
    <span class="md-ellipsis">
      VClampParamSearch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VClampParamSearch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.VClampParamSearch.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.InteractivePlot" class="md-nav__link">
    <span class="md-ellipsis">
      InteractivePlot
    </span>
  </a>
  
    <nav class="md-nav" aria-label="InteractivePlot">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.InteractivePlot.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.RNG" class="md-nav__link">
    <span class="md-ellipsis">
      RNG
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RNG">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.RNG.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.RNG.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.print_df" class="md-nav__link">
    <span class="md-ellipsis">
      print_df
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.flatten_list" class="md-nav__link">
    <span class="md-ellipsis">
      flatten_list
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.remove_key" class="md-nav__link">
    <span class="md-ellipsis">
      remove_key
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.suppress_stdout" class="md-nav__link">
    <span class="md-ellipsis">
      suppress_stdout
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.sci" class="md-nav__link">
    <span class="md-ellipsis">
      sci
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.create_cm" class="md-nav__link">
    <span class="md-ellipsis">
      create_cm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.evaluate_expression_with_dict" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate_expression_with_dict
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.efel_loss" class="md-nav__link">
    <span class="md-ellipsis">
      efel_loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.find_x_bound" class="md-nav__link">
    <span class="md-ellipsis">
      find_x_bound
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../statistic_functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statistic Functions
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/generate_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generate Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/run_and_monitor_simulations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generate Simulations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/monitor_recordings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Monitor Recordings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/plot_recordings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Plot Recordings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/experiment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Define Experiments
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/dbs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DBS Simulator
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/opt_neuron/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimize a neuron model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/deap_cma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cma Optimization
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../license/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    License
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions" class="md-nav__link">
    <span class="md-ellipsis">
      extra_functions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.Cmap" class="md-nav__link">
    <span class="md-ellipsis">
      Cmap
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cmap">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.Cmap.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.Cmap.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.Cmap.get_rgb" class="md-nav__link">
    <span class="md-ellipsis">
      get_rgb
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTree" class="md-nav__link">
    <span class="md-ellipsis">
      DecisionTree
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DecisionTree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTree.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTree.node" class="md-nav__link">
    <span class="md-ellipsis">
      node
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTree.get_path_prod" class="md-nav__link">
    <span class="md-ellipsis">
      get_path_prod
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTreeNode" class="md-nav__link">
    <span class="md-ellipsis">
      DecisionTreeNode
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DecisionTreeNode">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTreeNode.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTreeNode.add" class="md-nav__link">
    <span class="md-ellipsis">
      add
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DecisionTreeNode.get_path_prod" class="md-nav__link">
    <span class="md-ellipsis">
      get_path_prod
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DeapCma" class="md-nav__link">
    <span class="md-ellipsis">
      DeapCma
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DeapCma">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DeapCma.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.DeapCma.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.VClampParamSearch" class="md-nav__link">
    <span class="md-ellipsis">
      VClampParamSearch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VClampParamSearch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.VClampParamSearch.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.InteractivePlot" class="md-nav__link">
    <span class="md-ellipsis">
      InteractivePlot
    </span>
  </a>
  
    <nav class="md-nav" aria-label="InteractivePlot">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.InteractivePlot.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.RNG" class="md-nav__link">
    <span class="md-ellipsis">
      RNG
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RNG">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.RNG.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.RNG.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.print_df" class="md-nav__link">
    <span class="md-ellipsis">
      print_df
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.flatten_list" class="md-nav__link">
    <span class="md-ellipsis">
      flatten_list
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.remove_key" class="md-nav__link">
    <span class="md-ellipsis">
      remove_key
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.suppress_stdout" class="md-nav__link">
    <span class="md-ellipsis">
      suppress_stdout
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.sci" class="md-nav__link">
    <span class="md-ellipsis">
      sci
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.create_cm" class="md-nav__link">
    <span class="md-ellipsis">
      create_cm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.evaluate_expression_with_dict" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate_expression_with_dict
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.efel_loss" class="md-nav__link">
    <span class="md-ellipsis">
      efel_loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#CompNeuroPy.extra_functions.find_x_bound" class="md-nav__link">
    <span class="md-ellipsis">
      find_x_bound
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Extra Functions</h1>

<div class="doc doc-object doc-module">



<a id="CompNeuroPy.extra_functions"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="CompNeuroPy.extra_functions.Cmap" class="doc doc-heading">
            <code>Cmap</code>


<a href="#CompNeuroPy.extra_functions.Cmap" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">


        <p>Class to create a colormap with a given name and range. The colormap can be called
with a value between 0 and 1 to get the corresponding rgb value.</p>

              <details class="quote">
                <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Cmap</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to create a colormap with a given name and range. The colormap can be called</span>
<span class="sd">    with a value between 0 and 1 to get the corresponding rgb value.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cmap_name</span><span class="p">,</span> <span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            cmap_name (str):</span>
<span class="sd">                Name of the colormap</span>
<span class="sd">            vmin (float):</span>
<span class="sd">                Lower limit of the colormap</span>
<span class="sd">            vmax (float):</span>
<span class="sd">                Upper limit of the colormap</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cmap_name</span> <span class="o">=</span> <span class="n">cmap_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="n">cmap_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalarMap</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">ScalarMappable</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cmap</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the rgba value of the colormap at the given value.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (float):</span>
<span class="sd">                Value between 0 and 1</span>
<span class="sd">            alpha (float):</span>
<span class="sd">                Alpha value of the rgba value</span>

<span class="sd">        Returns:</span>
<span class="sd">            rgba (tuple):</span>
<span class="sd">                RGBA value of the colormap at the given value</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_rgb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">vals</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">alpha</span><span class="p">,)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vals</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="k">return</span> <span class="n">vals</span>

    <span class="k">def</span> <span class="nf">get_rgb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the rgb value of the colormap at the given value.</span>

<span class="sd">        Args:</span>
<span class="sd">            val (float):</span>
<span class="sd">                Value between 0 and 1</span>

<span class="sd">        Returns:</span>
<span class="sd">            rgb (tuple):</span>
<span class="sd">                RGB value of the colormap at the given value</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scalarMap</span><span class="o">.</span><span class="n">to_rgba</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.Cmap.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">cmap_name</span><span class="p">,</span> <span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.Cmap.__init__" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>cmap_name</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the colormap</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>vmin</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lower limit of the colormap</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>vmax</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Upper limit of the colormap</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cmap_name</span><span class="p">,</span> <span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        cmap_name (str):</span>
<span class="sd">            Name of the colormap</span>
<span class="sd">        vmin (float):</span>
<span class="sd">            Lower limit of the colormap</span>
<span class="sd">        vmax (float):</span>
<span class="sd">            Upper limit of the colormap</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cmap_name</span> <span class="o">=</span> <span class="n">cmap_name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="n">cmap_name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scalarMap</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">ScalarMappable</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cmap</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.Cmap.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.Cmap.__call__" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Returns the rgba value of the colormap at the given value.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>x</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Value between 0 and 1</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>alpha</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Alpha value of the rgba value</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>rgba</code></td>            <td>
                  <code>tuple</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>RGBA value of the colormap at the given value</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the rgba value of the colormap at the given value.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (float):</span>
<span class="sd">            Value between 0 and 1</span>
<span class="sd">        alpha (float):</span>
<span class="sd">            Alpha value of the rgba value</span>

<span class="sd">    Returns:</span>
<span class="sd">        rgba (tuple):</span>
<span class="sd">            RGBA value of the colormap at the given value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_rgb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">vals</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">alpha</span><span class="p">,)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">vals</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span>
    <span class="k">return</span> <span class="n">vals</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.Cmap.get_rgb" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_rgb</span><span class="p">(</span><span class="n">val</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.Cmap.get_rgb" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Returns the rgb value of the colormap at the given value.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>val</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Value between 0 and 1</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>rgb</code></td>            <td>
                  <code>tuple</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>RGB value of the colormap at the given value</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_rgb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the rgb value of the colormap at the given value.</span>

<span class="sd">    Args:</span>
<span class="sd">        val (float):</span>
<span class="sd">            Value between 0 and 1</span>

<span class="sd">    Returns:</span>
<span class="sd">        rgb (tuple):</span>
<span class="sd">            RGB value of the colormap at the given value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scalarMap</span><span class="o">.</span><span class="n">to_rgba</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="CompNeuroPy.extra_functions.DecisionTree" class="doc doc-heading">
            <code>DecisionTree</code>


<a href="#CompNeuroPy.extra_functions.DecisionTree" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">


        <p>Class to create a decision tree.</p>

              <details class="quote">
                <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DecisionTree</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to create a decision tree.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new empty decision tree.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### node list is a list of lists</span>
        <span class="c1">### first idx = level of tree</span>
        <span class="c1">### second idx = all nodes in the level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_list</span> <span class="o">=</span> <span class="p">[[]]</span>

    <span class="k">def</span> <span class="nf">node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new node in the decision tree.</span>

<span class="sd">        Args:</span>
<span class="sd">            parent (node object):</span>
<span class="sd">                Parent node of the new node</span>
<span class="sd">            prob (float):</span>
<span class="sd">                Probability of the new node</span>
<span class="sd">            name (str):</span>
<span class="sd">                Name of the new node</span>

<span class="sd">        Returns:</span>
<span class="sd">            new_node (node object):</span>
<span class="sd">                The new node</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">### create new node</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">DecisionTreeNode</span><span class="p">(</span><span class="n">tree</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="n">parent</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="n">prob</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="c1">### add it to node_list</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="p">)</span> <span class="o">==</span> <span class="n">new_node</span><span class="o">.</span><span class="n">level</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="p">[</span><span class="n">new_node</span><span class="o">.</span><span class="n">level</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>
        <span class="c1">### return the node object</span>
        <span class="k">return</span> <span class="n">new_node</span>

    <span class="k">def</span> <span class="nf">get_path_prod</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the path and path product of a node with a given name.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str):</span>
<span class="sd">                Name of the node</span>

<span class="sd">        Returns:</span>
<span class="sd">            path (str):</span>
<span class="sd">                Path to the node</span>
<span class="sd">            path_prod (float):</span>
<span class="sd">                Path product of the node</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">### search for all nodes with name</span>
        <span class="c1">### start from behind</span>
        <span class="n">search_node_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">path_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">path_prod_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="p">[</span><span class="n">level</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
                    <span class="n">search_node_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
        <span class="c1">### get the paths and path products for the found nodes</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">search_node_list</span><span class="p">:</span>
            <span class="n">path</span><span class="p">,</span> <span class="n">path_prod</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_path_prod_rec</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            <span class="n">path_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">path_prod_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path_prod</span><span class="p">)</span>
        <span class="c1">### return the paths and path products</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">[</span><span class="n">path_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">path_prod_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">search_node_list</span><span class="p">))</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">_get_path_prod_rec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Recursive function to get the path and path product of a node.</span>

<span class="sd">        Args:</span>
<span class="sd">            node (node object):</span>
<span class="sd">                Node to get the path and path product of</span>

<span class="sd">        Returns:</span>
<span class="sd">            path_str (str):</span>
<span class="sd">                Path to the node</span>
<span class="sd">            prob (float):</span>
<span class="sd">                Path product of the node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">node</span><span class="p">:</span> <span class="n">DecisionTreeNode</span> <span class="o">=</span> <span class="n">node</span>

        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">parent</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">prob</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">path_str</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_path_prod_rec</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">path_str</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">node</span><span class="o">.</span><span class="n">prob</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.DecisionTree.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">()</span></code>

<a href="#CompNeuroPy.extra_functions.DecisionTree.__init__" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Create a new empty decision tree.</p>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a new empty decision tree.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">### node list is a list of lists</span>
    <span class="c1">### first idx = level of tree</span>
    <span class="c1">### second idx = all nodes in the level</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">node_list</span> <span class="o">=</span> <span class="p">[[]]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.DecisionTree.node" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">node</span><span class="p">(</span><span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.DecisionTree.node" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Create a new node in the decision tree.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>parent</code></td>
            <td>
                  <code>node object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Parent node of the new node</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prob</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Probability of the new node</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>name</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the new node</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>new_node</code></td>            <td>
                  <code>node object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The new node</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a new node in the decision tree.</span>

<span class="sd">    Args:</span>
<span class="sd">        parent (node object):</span>
<span class="sd">            Parent node of the new node</span>
<span class="sd">        prob (float):</span>
<span class="sd">            Probability of the new node</span>
<span class="sd">        name (str):</span>
<span class="sd">            Name of the new node</span>

<span class="sd">    Returns:</span>
<span class="sd">        new_node (node object):</span>
<span class="sd">            The new node</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">### create new node</span>
    <span class="n">new_node</span> <span class="o">=</span> <span class="n">DecisionTreeNode</span><span class="p">(</span><span class="n">tree</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="n">parent</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="n">prob</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="c1">### add it to node_list</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="p">)</span> <span class="o">==</span> <span class="n">new_node</span><span class="o">.</span><span class="n">level</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="p">[</span><span class="n">new_node</span><span class="o">.</span><span class="n">level</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>
    <span class="c1">### return the node object</span>
    <span class="k">return</span> <span class="n">new_node</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.DecisionTree.get_path_prod" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_path_prod</span><span class="p">(</span><span class="n">name</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.DecisionTree.get_path_prod" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Get the path and path product of a node with a given name.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>name</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the node</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>path</code></td>            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to the node</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>path_prod</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path product of the node</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_path_prod</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the path and path product of a node with a given name.</span>

<span class="sd">    Args:</span>
<span class="sd">        name (str):</span>
<span class="sd">            Name of the node</span>

<span class="sd">    Returns:</span>
<span class="sd">        path (str):</span>
<span class="sd">            Path to the node</span>
<span class="sd">        path_prod (float):</span>
<span class="sd">            Path product of the node</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">### search for all nodes with name</span>
    <span class="c1">### start from behind</span>
    <span class="n">search_node_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">path_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">path_prod_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_list</span><span class="p">[</span><span class="n">level</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">search_node_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
    <span class="c1">### get the paths and path products for the found nodes</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">search_node_list</span><span class="p">:</span>
        <span class="n">path</span><span class="p">,</span> <span class="n">path_prod</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_path_prod_rec</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
        <span class="n">path_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">path_prod_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path_prod</span><span class="p">)</span>
    <span class="c1">### return the paths and path products</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="p">[</span><span class="n">path_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">path_prod_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">search_node_list</span><span class="p">))</span>
    <span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="CompNeuroPy.extra_functions.DecisionTreeNode" class="doc doc-heading">
            <code>DecisionTreeNode</code>


<a href="#CompNeuroPy.extra_functions.DecisionTreeNode" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">


        <p>Class to create a node in a decision tree.</p>

              <details class="quote">
                <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DecisionTreeNode</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to create a node in a decision tree.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">id_counter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tree</span><span class="p">:</span> <span class="n">DecisionTree</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new node in a decision tree.</span>

<span class="sd">        Args:</span>
<span class="sd">            tree (DecisionTree object):</span>
<span class="sd">                Decision tree the node belongs to</span>
<span class="sd">            parent (node object):</span>
<span class="sd">                Parent node of the new node</span>
<span class="sd">            prob (float):</span>
<span class="sd">                Probability of the new node</span>
<span class="sd">            name (str):</span>
<span class="sd">                Name of the new node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span>
        <span class="n">parent</span><span class="p">:</span> <span class="n">DecisionTreeNode</span> <span class="o">=</span> <span class="n">parent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="n">parent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id_counter</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">id_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">level</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">prob</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a child node to the node.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str):</span>
<span class="sd">                Name of the new node</span>
<span class="sd">            prob (float):</span>
<span class="sd">                Probability of the new node</span>

<span class="sd">        Returns:</span>
<span class="sd">            new_node (node object):</span>
<span class="sd">                The new node</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">parent</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="n">prob</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_path_prod</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the path and path product of the node.</span>

<span class="sd">        Returns:</span>
<span class="sd">            path (str):</span>
<span class="sd">                Path to the node</span>
<span class="sd">            path_prod (float):</span>
<span class="sd">                Path product of the node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">_get_path_prod_rec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.DecisionTreeNode.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.DecisionTreeNode.__init__" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Create a new node in a decision tree.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>tree</code></td>
            <td>
                  <code>DecisionTree object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Decision tree the node belongs to</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>parent</code></td>
            <td>
                  <code>node object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Parent node of the new node</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prob</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Probability of the new node</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>name</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the new node</p>
              </div>
            </td>
            <td>
                  <code>&#39;&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tree</span><span class="p">:</span> <span class="n">DecisionTree</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a new node in a decision tree.</span>

<span class="sd">    Args:</span>
<span class="sd">        tree (DecisionTree object):</span>
<span class="sd">            Decision tree the node belongs to</span>
<span class="sd">        parent (node object):</span>
<span class="sd">            Parent node of the new node</span>
<span class="sd">        prob (float):</span>
<span class="sd">            Probability of the new node</span>
<span class="sd">        name (str):</span>
<span class="sd">            Name of the new node</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span>
    <span class="n">parent</span><span class="p">:</span> <span class="n">DecisionTreeNode</span> <span class="o">=</span> <span class="n">parent</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="n">parent</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id_counter</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">id_counter</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">parent</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">level</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.DecisionTreeNode.add" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">add</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.DecisionTreeNode.add" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Add a child node to the node.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>name</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the new node</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prob</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Probability of the new node</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>new_node</code></td>            <td>
                  <code>node object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The new node</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">prob</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add a child node to the node.</span>

<span class="sd">    Args:</span>
<span class="sd">        name (str):</span>
<span class="sd">            Name of the new node</span>
<span class="sd">        prob (float):</span>
<span class="sd">            Probability of the new node</span>

<span class="sd">    Returns:</span>
<span class="sd">        new_node (node object):</span>
<span class="sd">            The new node</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="n">parent</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="n">prob</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.DecisionTreeNode.get_path_prod" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_path_prod</span><span class="p">()</span></code>

<a href="#CompNeuroPy.extra_functions.DecisionTreeNode.get_path_prod" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Get the path and path product of the node.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>path</code></td>            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to the node</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>path_prod</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path product of the node</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_path_prod</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the path and path product of the node.</span>

<span class="sd">    Returns:</span>
<span class="sd">        path (str):</span>
<span class="sd">            Path to the node</span>
<span class="sd">        path_prod (float):</span>
<span class="sd">            Path product of the node</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">_get_path_prod_rec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="CompNeuroPy.extra_functions.DeapCma" class="doc doc-heading">
            <code>DeapCma</code>


<a href="#CompNeuroPy.extra_functions.DeapCma" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">


        <p>Class to run the deap Covariance Matrix Adaptation Evolution Strategy optimization.</p>
<p>Using the <a href="https://deap.readthedocs.io/en/master/api/algo.html#module-deap.cma">CMAES</a> algorithm from <a href="https://github.com/deap/deap">deap</a></p>
<ul>
<li>Fortin, F. A., De Rainville, F. M., Gardner, M. A. G., Parizeau, M., &amp; Gagné, C. (2012). DEAP: Evolutionary algorithms made easy. The Journal of Machine Learning Research, 13(1), 2171-2175. <a href="https://www.jmlr.org/papers/volume13/fortin12a/fortin12a.pdf">pdf</a></li>
</ul>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="CompNeuroPy.extra_functions.DeapCma.deap_dict">deap_dict</span></code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary containing the toolbox, the hall of fame, the statistics, the
lower and upper bounds, the parameter names, the inverse scaler and the
strategy.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <p>For complete example see <a href="../../examples/deap_cma/">here</a>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">CompNeuroPy</span> <span class="kn">import</span> <span class="n">DeapCma</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="c1">### for DeapCma we need to define the evaluate_function</span>
<span class="k">def</span> <span class="nf">evaluate_function</span><span class="p">(</span><span class="n">population</span><span class="p">):</span>
    <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1">### the population is a list of individuals which are lists of parameters</span>
    <span class="k">for</span> <span class="n">individual</span> <span class="ow">in</span> <span class="n">population</span><span class="p">:</span>
        <span class="n">loss_of_individual</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">individual</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">individual</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">individual</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">loss_of_individual</span><span class="p">,))</span>
    <span class="k">return</span> <span class="n">loss_list</span>


<span class="c1">### define lower bounds of paramters to optimize</span>
<span class="n">lb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1">### define upper bounds of paramters to optimize</span>
<span class="n">ub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="c1">### create an &quot;minimal&quot; instance of the DeapCma class</span>
<span class="n">deap_cma</span> <span class="o">=</span> <span class="n">DeapCma</span><span class="p">(</span>
    <span class="n">lower</span><span class="o">=</span><span class="n">lb</span><span class="p">,</span>
    <span class="n">upper</span><span class="o">=</span><span class="n">ub</span><span class="p">,</span>
    <span class="n">evaluate_function</span><span class="o">=</span><span class="n">evaluate_function</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">### run the optimization</span>
<span class="n">deap_cma_result</span> <span class="o">=</span> <span class="n">deap_cma</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">max_evals</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></p>
</details>
              <details class="quote">
                <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DeapCma</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to run the deap Covariance Matrix Adaptation Evolution Strategy optimization.</span>

<span class="sd">    Using the [CMAES](https://deap.readthedocs.io/en/master/api/algo.html#module-deap.cma) algorithm from [deap](https://github.com/deap/deap)</span>

<span class="sd">    * Fortin, F. A., De Rainville, F. M., Gardner, M. A. G., Parizeau, M., &amp; Gagné, C. (2012). DEAP: Evolutionary algorithms made easy. The Journal of Machine Learning Research, 13(1), 2171-2175. [pdf](https://www.jmlr.org/papers/volume13/fortin12a/fortin12a.pdf)</span>

<span class="sd">    Attributes:</span>
<span class="sd">        deap_dict (dict):</span>
<span class="sd">            Dictionary containing the toolbox, the hall of fame, the statistics, the</span>
<span class="sd">            lower and upper bounds, the parameter names, the inverse scaler and the</span>
<span class="sd">            strategy.</span>

<span class="sd">    Example:</span>
<span class="sd">        For complete example see [here](../examples/deap_cma.md)</span>
<span class="sd">        ```python</span>
<span class="sd">        from CompNeuroPy import DeapCma</span>
<span class="sd">        import numpy as np</span>


<span class="sd">        ### for DeapCma we need to define the evaluate_function</span>
<span class="sd">        def evaluate_function(population):</span>
<span class="sd">            loss_list = []</span>
<span class="sd">            ### the population is a list of individuals which are lists of parameters</span>
<span class="sd">            for individual in population:</span>
<span class="sd">                loss_of_individual = float(individual[0] + individual[1] + individual[2])</span>
<span class="sd">                loss_list.append((loss_of_individual,))</span>
<span class="sd">            return loss_list</span>


<span class="sd">        ### define lower bounds of paramters to optimize</span>
<span class="sd">        lb = np.array([0, 0, 0])</span>

<span class="sd">        ### define upper bounds of paramters to optimize</span>
<span class="sd">        ub = np.array([10, 10, 10])</span>

<span class="sd">        ### create an &quot;minimal&quot; instance of the DeapCma class</span>
<span class="sd">        deap_cma = DeapCma(</span>
<span class="sd">            lower=lb,</span>
<span class="sd">            upper=ub,</span>
<span class="sd">            evaluate_function=evaluate_function,</span>
<span class="sd">        )</span>

<span class="sd">        ### run the optimization</span>
<span class="sd">        deap_cma_result = deap_cma.run(max_evals=1000)</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_types</span><span class="p">()</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lower</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">upper</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">evaluate_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">max_evals</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">p0</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sig0</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">param_names</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">learn_rate_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">damping_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">plot_file</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cma_params_dict</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">source_solutions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">hard_bounds</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">display_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            lower (np.ndarray):</span>
<span class="sd">                Lower bounds of the parameters</span>
<span class="sd">            upper (np.ndarray):</span>
<span class="sd">                Upper bounds of the parameters</span>
<span class="sd">            evaluate_function (Callable):</span>
<span class="sd">                Function evaluating the losses of a population of individuals. Return value</span>
<span class="sd">                should be a list of tuples with the losses of the individuals.</span>
<span class="sd">            max_evals (int, optional):</span>
<span class="sd">                Maximum number of evaluations. If not given here, it has to be given in</span>
<span class="sd">                the run function. By default None.</span>
<span class="sd">            p0 (None | np.ndarray, optional):</span>
<span class="sd">                Initial guess for the parameters. By default the mean of lower and upper</span>
<span class="sd">                bounds.</span>
<span class="sd">            sig0 (None | float, optional):</span>
<span class="sd">                Initial guess for the standard deviation of the parameters. It will be</span>
<span class="sd">                scaled by the range of the parameters. By default 0.25, i.e. 25% of the</span>
<span class="sd">                range (for each parameter).</span>
<span class="sd">            param_names (None | list[str], optional):</span>
<span class="sd">                Names of the parameters. By default None, i.e. the parameters are named</span>
<span class="sd">                &quot;param0&quot;, &quot;param1&quot;, ...</span>
<span class="sd">            learn_rate_factor (float, optional):</span>
<span class="sd">                Learning rate factor (decrease -&gt; slower). By default 1.</span>
<span class="sd">            damping_factor (float, optional):</span>
<span class="sd">                Damping factor (increase -&gt; slower). By default 1.</span>
<span class="sd">            verbose (bool, optional):</span>
<span class="sd">                Whether or not to print details. By default False.</span>
<span class="sd">            plot_file (None | str, optional):</span>
<span class="sd">                File to save the deap plot to. If not given here, it has to be given in</span>
<span class="sd">                the run function. By default None.</span>
<span class="sd">            cma_params_dict (dict, optional):</span>
<span class="sd">                Parameters for the deap cma strategy (deap.cma.Strategy). See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy) for more</span>
<span class="sd">                details</span>
<span class="sd">            source_solutions (list[tuple[np.ndarray, float]], optional):</span>
<span class="sd">                List of tuples with the parameters and losses of source solutions. These</span>
<span class="sd">                solutions are used to initialize the covariance matrix. Using source</span>
<span class="sd">                solutions ignores the initial guess p0 and sets the cma parameter</span>
<span class="sd">                &#39;cmatrix&#39; (which will also be ignored if given in cma_params_dict). By</span>
<span class="sd">                default [].</span>
<span class="sd">            hard_bounds (bool, optional):</span>
<span class="sd">                Whether or not to use hard bounds (parmeters are clipped to lower and</span>
<span class="sd">                upper bounds). By default False.</span>
<span class="sd">            display_progress_bar (bool, optional):</span>
<span class="sd">                Whether or not to display a progress bar. By default True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### store attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_evals</span> <span class="o">=</span> <span class="n">max_evals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">=</span> <span class="n">lower</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">=</span> <span class="n">upper</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_function</span> <span class="o">=</span> <span class="n">evaluate_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p0</span> <span class="o">=</span> <span class="n">p0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sig0</span> <span class="o">=</span> <span class="n">sig0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_names</span> <span class="o">=</span> <span class="n">param_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learn_rate_factor</span> <span class="o">=</span> <span class="n">learn_rate_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">damping_factor</span> <span class="o">=</span> <span class="n">damping_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span> <span class="o">=</span> <span class="n">plot_file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cma_params_dict</span> <span class="o">=</span> <span class="n">cma_params_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source_solutions</span> <span class="o">=</span> <span class="n">source_solutions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hard_bounds</span> <span class="o">=</span> <span class="n">hard_bounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">display_progress_bar</span> <span class="o">=</span> <span class="n">display_progress_bar</span>

        <span class="c1">### prepare the optimization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deap_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_prepare</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepares the deap Covariance Matrix Adaptation Evolution Strategy optimization.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict:</span>
<span class="sd">                Dictionary containing the toolbox, the hall of fame, the statistics, the</span>
<span class="sd">                lower and upper bounds, the parameter names, the inverse scaler and the</span>
<span class="sd">                strategy.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">### get attributes</span>
        <span class="n">lower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span>
        <span class="n">upper</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span>
        <span class="n">evaluate_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_function</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p0</span>
        <span class="n">sig0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sig0</span>
        <span class="n">param_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_names</span>
        <span class="n">learn_rate_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learn_rate_factor</span>
        <span class="n">damping_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">damping_factor</span>
        <span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>
        <span class="n">cma_params_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cma_params_dict</span>

        <span class="c1">### create scaler to scale parameters into range [0,1] based on lower and upper bounds</span>
        <span class="n">upper_orig</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">upper</span><span class="p">)</span>
        <span class="n">lower_orig</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">lower</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">scaler</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">diff</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">diff</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">lower_orig</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">upper_orig</span> <span class="o">-</span> <span class="n">lower_orig</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">upper_orig</span> <span class="o">-</span> <span class="n">lower_orig</span><span class="p">)</span>

        <span class="c1">### create inverse scaler to scale parameters back into original range [lower,upper]</span>
        <span class="k">def</span> <span class="nf">inv_scaler</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">diff</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">diff</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">upper_orig</span> <span class="o">-</span> <span class="n">lower_orig</span><span class="p">)</span> <span class="o">+</span> <span class="n">lower_orig</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">upper_orig</span> <span class="o">-</span> <span class="n">lower_orig</span><span class="p">)</span>

        <span class="c1">### scale upper and lower bounds</span>
        <span class="n">lower</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">(</span><span class="n">lower</span><span class="p">)</span>
        <span class="n">upper</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">(</span><span class="n">upper</span><span class="p">)</span>

        <span class="c1">### create the individual class, since this is eventually called multiple times</span>
        <span class="c1">### deactivate warnings (it warns that the classes already exist)</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
            <span class="n">creator</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s2">&quot;FitnessMin&quot;</span><span class="p">,</span> <span class="n">base</span><span class="o">.</span><span class="n">Fitness</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,))</span>
            <span class="n">creator</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s2">&quot;Individual&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">fitness</span><span class="o">=</span><span class="n">creator</span><span class="o">.</span><span class="n">FitnessMin</span><span class="p">)</span>

        <span class="c1">### create the toolbox</span>
        <span class="n">toolbox</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">Toolbox</span><span class="p">()</span>
        <span class="c1">### function calculating losses from individuals (from whole population)</span>
        <span class="n">toolbox</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;evaluate&quot;</span><span class="p">,</span> <span class="n">evaluate_function</span><span class="p">)</span>
        <span class="c1">### search strategy</span>
        <span class="c1">### warm start with initial source solutions</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source_solutions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1">### scale source solutions</span>
            <span class="k">for</span> <span class="n">source_solution_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source_solutions</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">source_solutions</span><span class="p">[</span><span class="n">source_solution_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">scaler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source_solutions</span><span class="p">[</span><span class="n">source_solution_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">source_solutions</span><span class="p">[</span><span class="n">source_solution_idx</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="n">centroid</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cmatrix</span> <span class="o">=</span> <span class="n">cmaes</span><span class="o">.</span><span class="n">get_warm_start_mgd</span><span class="p">(</span>
                <span class="n">source_solutions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">source_solutions</span><span class="p">,</span>
                <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">cma_params_dict</span><span class="p">[</span><span class="s2">&quot;cmatrix&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cmatrix</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hard_bounds</span><span class="p">:</span>
                <span class="c1">### clip centroid to [0,1]</span>
                <span class="n">centroid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">centroid</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">### lower + upper / 2 is always 0.5 since lower and upper are scaled</span>
            <span class="n">centroid</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">lower</span> <span class="o">+</span> <span class="n">upper</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
                <span class="k">else</span> <span class="p">(</span>
                    <span class="n">scaler</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">))</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hard_bounds</span>
                    <span class="k">else</span> <span class="n">scaler</span><span class="p">(</span><span class="n">p0</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sig0</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span> <span class="k">else</span> <span class="n">sig0</span>

        <span class="c1">### create the strategy</span>
        <span class="n">strategy</span> <span class="o">=</span> <span class="n">cma</span><span class="o">.</span><span class="n">Strategy</span><span class="p">(</span>
            <span class="n">centroid</span><span class="o">=</span><span class="n">centroid</span><span class="p">,</span>
            <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span>
            <span class="o">**</span><span class="n">cma_params_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Starting optimization with:</span><span class="se">\n</span><span class="s2">centroid: </span><span class="si">{</span><span class="n">inv_scaler</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">centroid</span><span class="p">)</span><span class="si">}</span><span class="s2">, (scaled: </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">centroid</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">sigma: </span><span class="si">{</span><span class="n">inv_scaler</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span><span class="n">diff</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">}</span><span class="s2">, (scaled: </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">sigma</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>

        <span class="c1">### slow down the learning rate and increase the damping</span>
        <span class="n">strategy</span><span class="o">.</span><span class="n">ccov1</span> <span class="o">*=</span> <span class="n">learn_rate_factor</span>
        <span class="n">strategy</span><span class="o">.</span><span class="n">ccovmu</span> <span class="o">*=</span> <span class="n">learn_rate_factor</span>
        <span class="n">strategy</span><span class="o">.</span><span class="n">damps</span> <span class="o">*=</span> <span class="n">damping_factor</span>  <span class="c1"># TODO what slows down?</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;lambda (The number of children to produce at each generation): </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">lambda_</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;mu (The number of parents to keep from the lambda children): </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">mu</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;weights: </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">weights</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mueff: </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">mueff</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ccum (Cumulation constant for covariance matrix.): </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">cc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cs (Cumulation constant for step-size): </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">cs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ccov1 (Learning rate for rank-one update): </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">ccov1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ccovmu (Learning rate for rank-mu update): </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">ccovmu</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;damps (Damping for step-size): </span><span class="si">{</span><span class="n">strategy</span><span class="o">.</span><span class="n">damps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1">### function generating a population during optimization</span>
        <span class="n">toolbox</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;generate&quot;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">.</span><span class="n">generate</span><span class="p">,</span> <span class="n">creator</span><span class="o">.</span><span class="n">Individual</span><span class="p">)</span>
        <span class="c1">### function updating the search strategy</span>
        <span class="n">toolbox</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;update&quot;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">.</span><span class="n">update</span><span class="p">)</span>
        <span class="c1">### hall of fame to track best individual i.e. parameters</span>
        <span class="n">hof</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">HallOfFame</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1">### statistics to track evolution of loss</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">Statistics</span><span class="p">(</span><span class="k">lambda</span> <span class="n">ind</span><span class="p">:</span> <span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;avg&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;std&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">)</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;toolbox&quot;</span><span class="p">:</span> <span class="n">toolbox</span><span class="p">,</span>
            <span class="s2">&quot;hof&quot;</span><span class="p">:</span> <span class="n">hof</span><span class="p">,</span>
            <span class="s2">&quot;stats&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="p">,</span>
            <span class="s2">&quot;lower&quot;</span><span class="p">:</span> <span class="n">lower</span><span class="p">,</span>
            <span class="s2">&quot;upper&quot;</span><span class="p">:</span> <span class="n">upper</span><span class="p">,</span>
            <span class="s2">&quot;param_names&quot;</span><span class="p">:</span> <span class="n">param_names</span><span class="p">,</span>
            <span class="s2">&quot;inv_scaler&quot;</span><span class="p">:</span> <span class="n">inv_scaler</span><span class="p">,</span>
            <span class="s2">&quot;strategy&quot;</span><span class="p">:</span> <span class="n">strategy</span><span class="p">,</span>
            <span class="s2">&quot;hard_bounds&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">hard_bounds</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_evals</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">plot_file</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the optimization with deap.</span>

<span class="sd">        Args:</span>
<span class="sd">            max_evals (int):</span>
<span class="sd">                Number of runs (here generations) a single optimization performs. By</span>
<span class="sd">                default None, i.e. the value from the initialization is used.</span>
<span class="sd">            verbose (bool, optional):</span>
<span class="sd">                Whether or not to print details. By default None, i.e. the value from</span>
<span class="sd">                the initialization is used.</span>
<span class="sd">            plot_file (str):</span>
<span class="sd">                Path to save the logbook plot to. By default None, i.e. the value from</span>
<span class="sd">                the initialization is used.</span>

<span class="sd">        Returns:</span>
<span class="sd">            best (dict):</span>
<span class="sd">                Dictionary containing the best parameters (as key and value pairs),</span>
<span class="sd">                the logbook of the optimization (key = &#39;logbook&#39;), the last population</span>
<span class="sd">                of individuals (key = &#39;deap_pop&#39;) and the best fitness (key =</span>
<span class="sd">                &#39;best_fitness&#39;).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">### get attributes</span>
        <span class="n">max_evals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_evals</span> <span class="k">if</span> <span class="n">max_evals</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_evals</span>
        <span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">verbose</span>
        <span class="n">plot_file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span> <span class="k">if</span> <span class="n">plot_file</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">plot_file</span>
        <span class="n">deap_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deap_dict</span>

        <span class="c1">### run the search algorithm with the prepared deap_dict</span>
        <span class="n">pop</span><span class="p">,</span> <span class="n">logbook</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_deap_ea_generate_update</span><span class="p">(</span>
            <span class="n">deap_dict</span><span class="p">,</span>
            <span class="n">ngen</span><span class="o">=</span><span class="n">max_evals</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1">### scale parameters of hall of fame back into original range [lower,upper]</span>
        <span class="n">hof_final</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;inv_scaler&quot;</span><span class="p">](</span><span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;hof&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">best_fitness</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;hof&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1">### get best parameters, last population of inidividuals and logbook</span>
        <span class="n">best</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">param_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">])):</span>
            <span class="k">if</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;param_names&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param_key</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;param_names&quot;</span><span class="p">][</span><span class="n">param_idx</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">param_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;param</span><span class="si">{</span><span class="n">param_idx</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">best</span><span class="p">[</span><span class="n">param_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">hof_final</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span>
        <span class="n">best</span><span class="p">[</span><span class="s2">&quot;logbook&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">logbook</span>
        <span class="n">best</span><span class="p">[</span><span class="s2">&quot;deap_pop&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pop</span>
        <span class="n">best</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_fitness</span>

        <span class="c1">### skip plotting if plot_file is None</span>
        <span class="k">if</span> <span class="n">plot_file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">best</span>

        <span class="c1">### plot logbook with logaritmic y-axis</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">),</span> <span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">),</span> <span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;avg&quot;</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;avg&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">),</span> <span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;max&quot;</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Generation&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">create_dir</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">plot_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">plot_file</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">best</span>

    <span class="k">def</span> <span class="nf">_deap_ea_generate_update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">deap_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">ngen</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function is copied from deap.algorithms.eaGenerateUpdate and modified.</span>
<span class="sd">        This is algorithm implements the ask-tell model proposed in</span>
<span class="sd">        [Colette2010]_, where ask is called `generate` and tell is called `update`.</span>

<span class="sd">        .. [Colette2010] Collette, Y., N. Hansen, G. Pujol, D. Salazar Aponte and</span>
<span class="sd">        R. Le Riche (2010). On Object-Oriented Programming of Optimizers -</span>
<span class="sd">        Examples in Scilab. In P. Breitkopf and R. F. Coelho, eds.:</span>
<span class="sd">        Multidisciplinary Design Optimization in Computational Mechanics,</span>
<span class="sd">        Wiley, pp. 527-565;</span>

<span class="sd">        Args:</span>
<span class="sd">            deap_dict (dict):</span>
<span class="sd">                Dictionary containing the deap toolbox, hall of fame, statistics, lower</span>
<span class="sd">                and upper bounds, parameter names, inverse scaler and strategy.</span>
<span class="sd">            ngen (int):</span>
<span class="sd">                number of runs (here generations) a single optimization performs</span>
<span class="sd">            verbose (bool, optional):</span>
<span class="sd">                Whether or not to print details. By default False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            population:</span>
<span class="sd">                A list of individuals.</span>
<span class="sd">            logbook:</span>
<span class="sd">                A Logbook() object that contains the evolution statistics.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">### get variables from deap_dict</span>
        <span class="n">toolbox</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;toolbox&quot;</span><span class="p">]</span>
        <span class="n">lower</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span>
        <span class="n">upper</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span>
        <span class="n">inv_scaler</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;inv_scaler&quot;</span><span class="p">]</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;stats&quot;</span><span class="p">]</span>
        <span class="n">halloffame</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;hof&quot;</span><span class="p">]</span>
        <span class="n">strategy</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;strategy&quot;</span><span class="p">]</span>
        <span class="n">hard_bounds</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;hard_bounds&quot;</span><span class="p">]</span>

        <span class="c1">### init logbook</span>
        <span class="n">logbook</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">Logbook</span><span class="p">()</span>
        <span class="n">logbook</span><span class="o">.</span><span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;gen&quot;</span><span class="p">,</span> <span class="s2">&quot;nevals&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">fields</span> <span class="k">if</span> <span class="n">stats</span> <span class="k">else</span> <span class="p">[])</span>

        <span class="c1">### define progress bar</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">progress_bar</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">ngen</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">display_progress_bar</span><span class="p">:</span>
            <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">ngen</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="n">ngen</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;gen&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">progress_bar</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">ngen</span><span class="p">)</span>
        <span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1">### loop over generations</span>
        <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
            <span class="c1">### Generate a new population</span>
            <span class="n">population</span> <span class="o">=</span> <span class="n">toolbox</span><span class="o">.</span><span class="n">generate</span><span class="p">()</span>
            <span class="c1">### clip individuals of population to variable bounds</span>
            <span class="c1">### TODO only if bounds are hard</span>
            <span class="k">if</span> <span class="n">hard_bounds</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">population</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ind</span><span class="p">):</span>
                        <span class="n">ind</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">lower</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">upper</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="c1">### Evaluate the individuals (here whole population at once)</span>
            <span class="c1">### scale parameters back into original range [lower,upper]</span>
            <span class="n">population_inv_scaled</span> <span class="o">=</span> <span class="p">[</span><span class="n">inv_scaler</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">population</span><span class="p">)]</span>
            <span class="n">fitnesses</span> <span class="o">=</span> <span class="n">toolbox</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">population_inv_scaled</span><span class="p">)</span>

            <span class="c1">### set fitnesses of individuals</span>
            <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">fit</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">fitnesses</span><span class="p">):</span>
                <span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="n">fit</span>

            <span class="c1">### check if nan in population</span>
            <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">population</span><span class="p">:</span>
                <span class="n">nan_in_pop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="c1">### Update the hall of fame with the generated individuals</span>
            <span class="k">if</span> <span class="n">halloffame</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">nan_in_pop</span><span class="p">:</span>
                <span class="n">halloffame</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>

            <span class="c1">### Update the strategy with the evaluated individuals</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">toolbox</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="c1">### stop if update fails</span>
                <span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>

            <span class="c1">### Stop if diagD is too small</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">diagD</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">:</span>
                <span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>

            <span class="c1">### Append the current generation statistics to the logbook</span>
            <span class="n">record</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">population</span><span class="p">)</span> <span class="k">if</span> <span class="n">stats</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
            <span class="n">logbook</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">gen</span><span class="o">=</span><span class="n">gen</span><span class="p">,</span> <span class="n">nevals</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">population</span><span class="p">),</span> <span class="o">**</span><span class="n">record</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="c1">### print logbook</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">logbook</span><span class="o">.</span><span class="n">stream</span><span class="p">)</span>
                <span class="c1">### print evaluated individuals and their fitnesses</span>
                <span class="n">print_dict</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="sa">f</span><span class="s2">&quot;ind_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">population_inv_scaled</span><span class="p">))</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">print_dict</span><span class="p">):</span>
                    <span class="n">print_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fitnesses</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">print_df</span><span class="p">(</span><span class="n">print_dict</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

            <span class="c1">### update progress bar with current best loss</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">display_progress_bar</span><span class="p">:</span>
                <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_postfix_str</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;best loss: </span><span class="si">{</span><span class="n">halloffame</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">early_stop</span> <span class="ow">and</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Stopping because convergence is reached.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">population</span><span class="p">,</span> <span class="n">logbook</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.DeapCma.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">evaluate_function</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sig0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">param_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learn_rate_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">damping_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cma_params_dict</span><span class="o">=</span><span class="p">{},</span> <span class="n">source_solutions</span><span class="o">=</span><span class="p">[],</span> <span class="n">hard_bounds</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">display_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.DeapCma.__init__" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>lower</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lower bounds of the parameters</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>upper</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Upper bounds of the parameters</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>evaluate_function</code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function evaluating the losses of a population of individuals. Return value
should be a list of tuples with the losses of the individuals.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>max_evals</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of evaluations. If not given here, it has to be given in
the run function. By default None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>p0</code></td>
            <td>
                  <code>None | <span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial guess for the parameters. By default the mean of lower and upper
bounds.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>sig0</code></td>
            <td>
                  <code>None | float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial guess for the standard deviation of the parameters. It will be
scaled by the range of the parameters. By default 0.25, i.e. 25% of the
range (for each parameter).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>param_names</code></td>
            <td>
                  <code>None | list[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Names of the parameters. By default None, i.e. the parameters are named
"param0", "param1", ...</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>learn_rate_factor</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Learning rate factor (decrease -&gt; slower). By default 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>damping_factor</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Damping factor (increase -&gt; slower). By default 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>verbose</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to print details. By default False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>plot_file</code></td>
            <td>
                  <code>None | str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>File to save the deap plot to. If not given here, it has to be given in
the run function. By default None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cma_params_dict</code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Parameters for the deap cma strategy (deap.cma.Strategy). See <a href="https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy">here</a> for more
details</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>source_solutions</code></td>
            <td>
                  <code>list[tuple[<span title="numpy.ndarray">ndarray</span>, float]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of tuples with the parameters and losses of source solutions. These
solutions are used to initialize the covariance matrix. Using source
solutions ignores the initial guess p0 and sets the cma parameter
'cmatrix' (which will also be ignored if given in cma_params_dict). By
default [].</p>
              </div>
            </td>
            <td>
                  <code>[]</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>hard_bounds</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to use hard bounds (parmeters are clipped to lower and
upper bounds). By default False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>display_progress_bar</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to display a progress bar. By default True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@check_types</span><span class="p">()</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lower</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">upper</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">evaluate_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">max_evals</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">p0</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sig0</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">param_names</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">learn_rate_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">damping_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">plot_file</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cma_params_dict</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">source_solutions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">hard_bounds</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">display_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        lower (np.ndarray):</span>
<span class="sd">            Lower bounds of the parameters</span>
<span class="sd">        upper (np.ndarray):</span>
<span class="sd">            Upper bounds of the parameters</span>
<span class="sd">        evaluate_function (Callable):</span>
<span class="sd">            Function evaluating the losses of a population of individuals. Return value</span>
<span class="sd">            should be a list of tuples with the losses of the individuals.</span>
<span class="sd">        max_evals (int, optional):</span>
<span class="sd">            Maximum number of evaluations. If not given here, it has to be given in</span>
<span class="sd">            the run function. By default None.</span>
<span class="sd">        p0 (None | np.ndarray, optional):</span>
<span class="sd">            Initial guess for the parameters. By default the mean of lower and upper</span>
<span class="sd">            bounds.</span>
<span class="sd">        sig0 (None | float, optional):</span>
<span class="sd">            Initial guess for the standard deviation of the parameters. It will be</span>
<span class="sd">            scaled by the range of the parameters. By default 0.25, i.e. 25% of the</span>
<span class="sd">            range (for each parameter).</span>
<span class="sd">        param_names (None | list[str], optional):</span>
<span class="sd">            Names of the parameters. By default None, i.e. the parameters are named</span>
<span class="sd">            &quot;param0&quot;, &quot;param1&quot;, ...</span>
<span class="sd">        learn_rate_factor (float, optional):</span>
<span class="sd">            Learning rate factor (decrease -&gt; slower). By default 1.</span>
<span class="sd">        damping_factor (float, optional):</span>
<span class="sd">            Damping factor (increase -&gt; slower). By default 1.</span>
<span class="sd">        verbose (bool, optional):</span>
<span class="sd">            Whether or not to print details. By default False.</span>
<span class="sd">        plot_file (None | str, optional):</span>
<span class="sd">            File to save the deap plot to. If not given here, it has to be given in</span>
<span class="sd">            the run function. By default None.</span>
<span class="sd">        cma_params_dict (dict, optional):</span>
<span class="sd">            Parameters for the deap cma strategy (deap.cma.Strategy). See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy) for more</span>
<span class="sd">            details</span>
<span class="sd">        source_solutions (list[tuple[np.ndarray, float]], optional):</span>
<span class="sd">            List of tuples with the parameters and losses of source solutions. These</span>
<span class="sd">            solutions are used to initialize the covariance matrix. Using source</span>
<span class="sd">            solutions ignores the initial guess p0 and sets the cma parameter</span>
<span class="sd">            &#39;cmatrix&#39; (which will also be ignored if given in cma_params_dict). By</span>
<span class="sd">            default [].</span>
<span class="sd">        hard_bounds (bool, optional):</span>
<span class="sd">            Whether or not to use hard bounds (parmeters are clipped to lower and</span>
<span class="sd">            upper bounds). By default False.</span>
<span class="sd">        display_progress_bar (bool, optional):</span>
<span class="sd">            Whether or not to display a progress bar. By default True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">### store attributes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_evals</span> <span class="o">=</span> <span class="n">max_evals</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">=</span> <span class="n">lower</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">=</span> <span class="n">upper</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_function</span> <span class="o">=</span> <span class="n">evaluate_function</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p0</span> <span class="o">=</span> <span class="n">p0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sig0</span> <span class="o">=</span> <span class="n">sig0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">param_names</span> <span class="o">=</span> <span class="n">param_names</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learn_rate_factor</span> <span class="o">=</span> <span class="n">learn_rate_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">damping_factor</span> <span class="o">=</span> <span class="n">damping_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span> <span class="o">=</span> <span class="n">plot_file</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cma_params_dict</span> <span class="o">=</span> <span class="n">cma_params_dict</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">source_solutions</span> <span class="o">=</span> <span class="n">source_solutions</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hard_bounds</span> <span class="o">=</span> <span class="n">hard_bounds</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">display_progress_bar</span> <span class="o">=</span> <span class="n">display_progress_bar</span>

    <span class="c1">### prepare the optimization</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">deap_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.DeapCma.run" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">run</span><span class="p">(</span><span class="n">max_evals</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">plot_file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.DeapCma.run" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Runs the optimization with deap.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>max_evals</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of runs (here generations) a single optimization performs. By
default None, i.e. the value from the initialization is used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>verbose</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to print details. By default None, i.e. the value from
the initialization is used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>plot_file</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to save the logbook plot to. By default None, i.e. the value from
the initialization is used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>best</code></td>            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary containing the best parameters (as key and value pairs),
the logbook of the optimization (key = 'logbook'), the last population
of individuals (key = 'deap_pop') and the best fitness (key =
'best_fitness').</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">max_evals</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">plot_file</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs the optimization with deap.</span>

<span class="sd">    Args:</span>
<span class="sd">        max_evals (int):</span>
<span class="sd">            Number of runs (here generations) a single optimization performs. By</span>
<span class="sd">            default None, i.e. the value from the initialization is used.</span>
<span class="sd">        verbose (bool, optional):</span>
<span class="sd">            Whether or not to print details. By default None, i.e. the value from</span>
<span class="sd">            the initialization is used.</span>
<span class="sd">        plot_file (str):</span>
<span class="sd">            Path to save the logbook plot to. By default None, i.e. the value from</span>
<span class="sd">            the initialization is used.</span>

<span class="sd">    Returns:</span>
<span class="sd">        best (dict):</span>
<span class="sd">            Dictionary containing the best parameters (as key and value pairs),</span>
<span class="sd">            the logbook of the optimization (key = &#39;logbook&#39;), the last population</span>
<span class="sd">            of individuals (key = &#39;deap_pop&#39;) and the best fitness (key =</span>
<span class="sd">            &#39;best_fitness&#39;).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">### get attributes</span>
    <span class="n">max_evals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_evals</span> <span class="k">if</span> <span class="n">max_evals</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_evals</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">verbose</span>
    <span class="n">plot_file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span> <span class="k">if</span> <span class="n">plot_file</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">plot_file</span>
    <span class="n">deap_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deap_dict</span>

    <span class="c1">### run the search algorithm with the prepared deap_dict</span>
    <span class="n">pop</span><span class="p">,</span> <span class="n">logbook</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_deap_ea_generate_update</span><span class="p">(</span>
        <span class="n">deap_dict</span><span class="p">,</span>
        <span class="n">ngen</span><span class="o">=</span><span class="n">max_evals</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1">### scale parameters of hall of fame back into original range [lower,upper]</span>
    <span class="n">hof_final</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;inv_scaler&quot;</span><span class="p">](</span><span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;hof&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">best_fitness</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;hof&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1">### get best parameters, last population of inidividuals and logbook</span>
    <span class="n">best</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">param_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">])):</span>
        <span class="k">if</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;param_names&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_key</span> <span class="o">=</span> <span class="n">deap_dict</span><span class="p">[</span><span class="s2">&quot;param_names&quot;</span><span class="p">][</span><span class="n">param_idx</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">param_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;param</span><span class="si">{</span><span class="n">param_idx</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">best</span><span class="p">[</span><span class="n">param_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">hof_final</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span>
    <span class="n">best</span><span class="p">[</span><span class="s2">&quot;logbook&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">logbook</span>
    <span class="n">best</span><span class="p">[</span><span class="s2">&quot;deap_pop&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pop</span>
    <span class="n">best</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_fitness</span>

    <span class="c1">### skip plotting if plot_file is None</span>
    <span class="k">if</span> <span class="n">plot_file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">best</span>

    <span class="c1">### plot logbook with logaritmic y-axis</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">),</span> <span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">),</span> <span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;avg&quot;</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;avg&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">),</span> <span class="n">logbook</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;max&quot;</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Generation&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">sf</span><span class="o">.</span><span class="n">create_dir</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">plot_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">plot_file</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">best</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="CompNeuroPy.extra_functions.VClampParamSearch" class="doc doc-heading">
            <code>VClampParamSearch</code>


<a href="#CompNeuroPy.extra_functions.VClampParamSearch" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">


        <p>Class to obtain the parameters of some neuron model equations (describing the change
of the membrane potential v) by simulating voltage steps with a given neuron_model.
An voltage clamp version of the equations is used to calculate instantaneous and
holding "currents" for specific voltage steps. The parameters are then optimized
to fit the calculated "currents" to the measured currents from the simulated neuron
model.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="CompNeuroPy.extra_functions.VClampParamSearch.p_opt">p_opt</span></code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optimized parameters</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span>
<span class="normal">2075</span>
<span class="normal">2076</span>
<span class="normal">2077</span>
<span class="normal">2078</span>
<span class="normal">2079</span>
<span class="normal">2080</span>
<span class="normal">2081</span>
<span class="normal">2082</span>
<span class="normal">2083</span>
<span class="normal">2084</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">VClampParamSearch</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to obtain the parameters of some neuron model equations (describing the change</span>
<span class="sd">    of the membrane potential v) by simulating voltage steps with a given neuron_model.</span>
<span class="sd">    An voltage clamp version of the equations is used to calculate instantaneous and</span>
<span class="sd">    holding &quot;currents&quot; for specific voltage steps. The parameters are then optimized</span>
<span class="sd">    to fit the calculated &quot;currents&quot; to the measured currents from the simulated neuron</span>
<span class="sd">    model.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        p_opt (dict):</span>
<span class="sd">            The optimized parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_types</span><span class="p">()</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">neuron_model</span><span class="p">:</span> <span class="n">ann</span><span class="o">.</span><span class="n">Neuron</span><span class="p">,</span>
        <span class="n">equations</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        C*dv/dt = k*(v - v_r)*(v - v_t) - u + I</span>
<span class="s2">        du/dt = a*(b*(v - v_r) - u)</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">,</span>
        <span class="n">external_current_var</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span>
        <span class="n">bounds</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
            <span class="s2">&quot;v_r&quot;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">),</span>
            <span class="s2">&quot;v_t&quot;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">),</span>
            <span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="p">},</span>
        <span class="n">p0</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_evals</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">m</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">do_plot</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">results_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;v_clamp_search_results&quot;</span><span class="p">,</span>
        <span class="n">plot_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;v_clamp_search_plot.png&quot;</span><span class="p">,</span>
        <span class="n">cma_params_dict</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;learn_rate_factor&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;damping_factor&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
        <span class="n">compile_folder_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;VClampParamSearch&quot;</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            neuron_model (Neuron):</span>
<span class="sd">                The neuron model which is simulated to obtain the parameters for the</span>
<span class="sd">                equations</span>
<span class="sd">            equations (str, optional):</span>
<span class="sd">                The equations whose parameters should be obtained. Default: Izhikevich</span>
<span class="sd">                2007 neuron model</span>
<span class="sd">            external_current_var (str, optional):</span>
<span class="sd">                The name of the variable in the neuron model which is used as the</span>
<span class="sd">                external current. Has to be used in the neuron model and the given</span>
<span class="sd">                equations Default: &quot;I&quot;</span>
<span class="sd">            bounds (dict, optional):</span>
<span class="sd">                The bounds for the parameters. For each parameter of the equation a</span>
<span class="sd">                bound should be given (except for the external current variable)!</span>
<span class="sd">                Default: Izhikevich 2007 neuron model</span>
<span class="sd">            p0 (dict, optional):</span>
<span class="sd">                The initial guess for the parameters. Dict keys should be the same as</span>
<span class="sd">                the keys of bounds. The values can be either a single number for each</span>
<span class="sd">                parameter or a list of numbers. If lists are given, all have to have</span>
<span class="sd">                the same length, which will be the number of initial guesses for the</span>
<span class="sd">                parameters, i.e. how often the optimization is run. Default: None,</span>
<span class="sd">                i.e. the mid of the bounds is used as a single initial guess.</span>
<span class="sd">            max_evals (int, optional):</span>
<span class="sd">                The maximum number of evaluations for a single optimization run.</span>
<span class="sd">                Default: 100</span>
<span class="sd">            m (int, optional):</span>
<span class="sd">                The number of initial voltages for the voltage step simulations.</span>
<span class="sd">                Default: 20</span>
<span class="sd">            n (int, optional):</span>
<span class="sd">                The number of voltage steps for the voltage step simulations.</span>
<span class="sd">                Defaults: 20</span>
<span class="sd">            do_plot (bool, optional):</span>
<span class="sd">                If True, plots are created. Default: False</span>
<span class="sd">            results_file (str, optional):</span>
<span class="sd">                The name of the file where the results are stored, without file ending.</span>
<span class="sd">                Default: &quot;v_clamp_search_results&quot;</span>
<span class="sd">            plot_file (str, optional):</span>
<span class="sd">                The name of the file where the plot is stored, with file ending.</span>
<span class="sd">                Default: &quot;v_clamp_search_plot.png&quot;</span>
<span class="sd">            cma_params_dict (dict, optional):</span>
<span class="sd">                Parameters for the deap cma strategy (deap.cma.Strategy). See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy)</span>
<span class="sd">                for more details. Additional parameters are learn_rate_factor and</span>
<span class="sd">                damping_factor. Default: {&quot;learn_rate_factor&quot;: 1, &quot;damping_factor&quot;: 1}</span>
<span class="sd">            compile_folder_name (str, optional):</span>
<span class="sd">                The name of the folder within &quot;annarchy_folders&quot; where the ANNarchy</span>
<span class="sd">                network is compiled to. Default: &quot;VClampParamSearch&quot;</span>
<span class="sd">            verbose (bool, optional):</span>
<span class="sd">                If True, print details. Default: False</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_verbose_extreme</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1">### store the given neuron model and a voltage clamp version of it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neuron_model</span> <span class="o">=</span> <span class="n">neuron_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span> <span class="o">=</span> <span class="n">external_current_var</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">neuron_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_neuron_model_clamp</span><span class="p">()</span>

        <span class="c1">### store other attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">equations</span> <span class="o">=</span> <span class="n">equations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p0</span> <span class="o">=</span> <span class="n">p0</span>
        <span class="c1">### check if p0 is correct and if lists are given, create also lists single</span>
        <span class="c1">### numbers which are given</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_p0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_p0</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_evals</span> <span class="o">=</span> <span class="n">max_evals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">bounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_plot</span> <span class="o">=</span> <span class="n">do_plot</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results_file</span> <span class="o">=</span> <span class="n">results_file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span> <span class="o">=</span> <span class="n">plot_file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cma_params_dict</span> <span class="o">=</span> <span class="n">cma_params_dict</span>
        <span class="c1">### check if file names are correct</span>
        <span class="k">if</span> <span class="s2">&quot;.&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">results_file</span> <span class="ow">or</span> <span class="s2">&quot;.&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;results_file should not contain file ending and plot_file should!&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compile_folder_name</span> <span class="o">=</span> <span class="n">compile_folder_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="mf">0.001</span>

        <span class="c1">### create folder for plots</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_plot</span><span class="p">:</span>
            <span class="n">sf</span><span class="o">.</span><span class="n">create_dir</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">plot_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

        <span class="c1">### create the functions for I_clamp_inst and I_clamp_hold using the given</span>
        <span class="c1">### izhikevich equations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_f_inst</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f_hold</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f_variables</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_I_clamp_functions</span><span class="p">()</span>

        <span class="c1">### create the voltage step arrays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_v_0_arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_voltage_step_arrays</span><span class="p">()</span>

        <span class="c1">### for each neuron model create a population</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating models...&quot;</span><span class="p">)</span>
        <span class="n">mf</span><span class="o">.</span><span class="n">cnp_clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_normal</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_model</span><span class="p">()</span>

        <span class="c1">### perform resting state and voltage step simulations to obtain I_clamp_inst,</span>
        <span class="c1">### I_clamp_hold and v_rest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_inst_arr</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_arr</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Performing simulations...&quot;</span><span class="p">)</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_v_rest</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_inst_arr</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_arr</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_unique</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_unique</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_simulations</span><span class="p">()</span>

        <span class="c1">### tune the free paramters of the functions for I_clamp_inst and I_clamp_hold</span>
        <span class="c1">### to fit the data</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tuning parameters...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_p_opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tune_I_clamp_functions</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">param_name</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_p_opt</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_p_opt</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span>

        <span class="c1">### print and save optimized parameters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimized parameters: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1">### save as pkl file</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">save_variables</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span><span class="p">],</span>
            <span class="p">[</span><span class="n">results_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
            <span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">results_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="s2">&quot;/&quot;</span> <span class="ow">in</span> <span class="n">results_file</span> <span class="k">else</span> <span class="s2">&quot;./&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1">### save human readable as json file</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span><span class="p">,</span>
            <span class="nb">open</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">results_file</span><span class="si">}</span><span class="s2">.json&quot;</span><span class="p">,</span>
                <span class="s2">&quot;w&quot;</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1">### create a neuron model with the tuned parameters and the given equations</span>
        <span class="c1">### then run the simulations again with this neuron model to do the plots</span>
        <span class="c1">### with the tuned parameters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running simulations with tuned parameters...&quot;</span><span class="p">)</span>
        <span class="n">mf</span><span class="o">.</span><span class="n">cnp_clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_neuron_model_with_tuned_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_neuron_model_clamp</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_normal</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_simulations</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_p0</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if p0 is correct and if lists are given, create also lists single numbers</span>
<span class="sd">        which are given.</span>

<span class="sd">        Returns:</span>
<span class="sd">            _p0 (dict):</span>
<span class="sd">                The corrected p0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_p0</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1">### collect lengths of lists</span>
            <span class="n">list_lengths</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p0</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">list_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val</span><span class="p">))</span>
            <span class="c1">### check if all lists have the same length</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">list_lengths</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All lists in p0 should have the same length!&quot;</span><span class="p">)</span>
            <span class="c1">### create new p0 with lists for all parameters</span>
            <span class="n">_p0</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">_p0</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">_p0</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">val</span><span class="p">]</span> <span class="o">*</span> <span class="n">list_lengths</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">list_lengths</span> <span class="k">else</span> <span class="p">[</span><span class="n">val</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_p0</span>

    <span class="k">def</span> <span class="nf">_create_neuron_model_with_tuned_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a neuron model with the tuned parameters and the given equations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            neuron_mondel (Neuron):</span>
<span class="sd">                the neuron model with the tuned parameters and the given equations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### create the neuron with the tuned parameters, if a parameter is not tuned</span>
        <span class="c1">### use the mid of the bounds (these parameters should not affect I_clamp_inst</span>
        <span class="c1">### and I_clamp_hold)</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_p_opt</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="c1">### also add the external current variable</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span><span class="si">}</span><span class="s2"> = 0&quot;</span>
        <span class="n">neuron_mondel</span> <span class="o">=</span> <span class="n">ann</span><span class="o">.</span><span class="n">Neuron</span><span class="p">(</span>
            <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
            <span class="n">equations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">equations</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">r=0&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Neuron model with tuned parameters:</span><span class="se">\n</span><span class="si">{</span><span class="n">neuron_mondel</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">neuron_mondel</span>

    <span class="k">def</span> <span class="nf">_tune_I_clamp_functions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tune the free paramters of the functions for I_clamp_inst and I_clamp_hold</span>
<span class="sd">        to fit the data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### get the names of the free parameters which will be tuned</span>
        <span class="n">sub_var_names_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f_variables</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="ow">or</span> <span class="nb">str</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;v_r&quot;</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">sub_var_names_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">var</span><span class="p">))</span>

        <span class="c1">### target array for the error function below</span>
        <span class="n">target_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_inst_arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_unique</span><span class="p">])</span>

        <span class="c1">### create a function for the error</span>
        <span class="k">def</span> <span class="nf">error_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose_extreme</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current guess: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1">### set the free parameters of the functions</span>
            <span class="n">p_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">var_name</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="n">var_idx</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">var_idx</span><span class="p">,</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sub_var_names_list</span><span class="p">)</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose_extreme</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current guess dict: </span><span class="si">{</span><span class="n">p_dict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">var_dict</span> <span class="o">=</span> <span class="p">{</span><span class="nb">str</span><span class="p">(</span><span class="n">var</span><span class="p">):</span> <span class="n">p_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">var</span><span class="p">))</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f_variables</span><span class="p">}</span>
            <span class="n">var_dict</span><span class="p">[</span><span class="s2">&quot;v_r&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_rest</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose_extreme</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;var_dict: </span><span class="si">{</span><span class="n">var_dict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;f_variables: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_f_variables</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1">### calculate the voltage clamp values</span>
            <span class="c1">### 1st f_inst, it depends on v_0 and v_step</span>
            <span class="n">var_dict</span><span class="p">[</span><span class="s2">&quot;v_0&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_0_arr</span>
            <span class="n">var_dict</span><span class="p">[</span><span class="s2">&quot;v_step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_arr</span>
            <span class="n">f_inst_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f_inst</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">var_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
            <span class="c1">### 2nd f_hold, it depends only on v_step</span>
            <span class="n">var_dict</span><span class="p">[</span><span class="s2">&quot;v_0&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_0_arr</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_v_0_arr</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
            <span class="n">var_dict</span><span class="p">[</span><span class="s2">&quot;v_step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_unique</span>
            <span class="n">f_hold_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f_hold</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">var_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

            <span class="c1">### calculate the error</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">af</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">target_arr</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">f_inst_arr</span><span class="p">,</span> <span class="n">f_hold_arr</span><span class="p">]))</span>
            <span class="k">return</span> <span class="n">error</span>

        <span class="k">def</span> <span class="nf">error_function_deap</span><span class="p">(</span><span class="n">population</span><span class="p">):</span>
            <span class="n">error_list</span> <span class="o">=</span> <span class="p">[(</span><span class="n">error_function</span><span class="p">(</span><span class="n">individual</span><span class="p">),)</span> <span class="k">for</span> <span class="n">individual</span> <span class="ow">in</span> <span class="n">population</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">error_list</span>

        <span class="c1">### perform the optimization</span>
        <span class="c1">### set bounds</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">var_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">sub_var_names_list</span><span class="p">])</span>
        <span class="c1">### set initial guess</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_p0</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)):</span>
            <span class="c1">### if no initial guess is given use the middle of the bounds</span>
            <span class="n">initial_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">var_name</span><span class="p">])</span> <span class="o">/</span> <span class="mf">2.0</span> <span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">sub_var_names_list</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">### initial guess is an array 1st dimension is the number of tuned parameters</span>
            <span class="c1">### 2nd dimension is the number of initial guesses</span>
            <span class="n">initial_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_p0</span><span class="p">[</span><span class="n">var_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">sub_var_names_list</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;p0: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">p0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_p0: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_p0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bounds: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial guess: </span><span class="si">{</span><span class="n">initial_guess</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bounds: </span><span class="si">{</span><span class="n">bounds</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1">### run the optimization multiple times with different initial guesses</span>
        <span class="n">print_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">best_fitness</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">for</span> <span class="n">initial_guess_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">initial_guess</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">deap_cma</span> <span class="o">=</span> <span class="n">DeapCma</span><span class="p">(</span>
                <span class="n">max_evals</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_evals</span><span class="p">,</span>
                <span class="n">lower</span><span class="o">=</span><span class="n">bounds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                <span class="n">upper</span><span class="o">=</span><span class="n">bounds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">evaluate_function</span><span class="o">=</span><span class="n">error_function_deap</span><span class="p">,</span>
                <span class="n">p0</span><span class="o">=</span><span class="n">initial_guess</span><span class="p">[:,</span> <span class="n">initial_guess_idx</span><span class="p">],</span>
                <span class="n">param_names</span><span class="o">=</span><span class="n">sub_var_names_list</span><span class="p">,</span>
                <span class="n">learn_rate_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cma_params_dict</span><span class="p">[</span><span class="s2">&quot;learn_rate_factor&quot;</span><span class="p">],</span>
                <span class="n">damping_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cma_params_dict</span><span class="p">[</span><span class="s2">&quot;damping_factor&quot;</span><span class="p">],</span>
                <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">plot_file</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;_logbook_</span><span class="si">{</span><span class="n">initial_guess_idx</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">cma_params_dict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cma_params_dict</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">deap_cma</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="n">print_results_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">var_name</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="n">var_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">sub_var_names_list</span>
            <span class="p">}</span>
            <span class="n">print_results_dict</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span>
            <span class="n">print_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">print_results_dict</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">best_fitness</span><span class="p">:</span>
                <span class="n">best_fitness</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span>
                <span class="n">best_result</span> <span class="o">=</span> <span class="n">result</span>
        <span class="n">result_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">var_name</span><span class="p">:</span> <span class="n">best_result</span><span class="p">[</span><span class="n">var_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">sub_var_names_list</span>
        <span class="p">}</span>
        <span class="n">result_dict</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_result</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span>
        <span class="n">result_dict</span><span class="p">[</span><span class="s2">&quot;v_r&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_rest</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Results:&quot;</span><span class="p">)</span>
            <span class="n">print_df</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">print_results</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result: </span><span class="si">{</span><span class="n">result_dict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result_dict</span>

    <span class="k">def</span> <span class="nf">_create_I_clamp_functions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create the functions for I_clamp_inst and I_clamp_hold using the given</span>
<span class="sd">        izhikevich equations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            f_inst (Callable):</span>
<span class="sd">                Function for I_clamp_inst</span>
<span class="sd">            f_hold (Callable):</span>
<span class="sd">                Function for I_clamp_hold</span>
<span class="sd">            variables (list):</span>
<span class="sd">                List of variables used for the functions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### obtain all variables and parameters from the equation string</span>
        <span class="n">variables_name_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_variables_from_eq</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">equations</span><span class="p">)</span>

        <span class="c1">### split equations into lines, remove whitespace and only keep entries with</span>
        <span class="c1">### length &gt; 0</span>
        <span class="n">eq_line_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equations</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
        <span class="n">eq_line_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">eq_line_list</span><span class="p">]</span>
        <span class="n">eq_line_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">eq_line_list</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>

        <span class="c1">### create a dictionary with the variables as keys and the sympy symbols as</span>
        <span class="c1">### values</span>
        <span class="n">variables_sympy_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">Symbol</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">variables_name_list</span><span class="p">}</span>

        <span class="c1">### also create sympy symbols for v_0 and v_step</span>
        <span class="n">variables_sympy_dict</span><span class="p">[</span><span class="s2">&quot;v_0&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Symbol</span><span class="p">(</span><span class="s2">&quot;v_0&quot;</span><span class="p">)</span>
        <span class="n">variables_sympy_dict</span><span class="p">[</span><span class="s2">&quot;v_step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Symbol</span><span class="p">(</span><span class="s2">&quot;v_step&quot;</span><span class="p">)</span>

        <span class="c1">### sympify equations</span>
        <span class="n">eq_sympy_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">variables_to_solve_for_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">instant_update_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">line_idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eq_line_list</span><span class="p">):</span>
            <span class="n">left_side</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">right_side</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="c1">### check if line contains dv/dt, replace it with 0 and add external current</span>
            <span class="c1">### variable to variables_to_solve_for_list, also set instant_update to True</span>
            <span class="k">if</span> <span class="s2">&quot;dv/dt&quot;</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
                <span class="n">variables_to_solve_for_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span><span class="p">)</span>
                <span class="n">left_side</span> <span class="o">=</span> <span class="n">left_side</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;dv/dt&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">)</span>
                <span class="n">instant_update_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1">### check if line contains any other derivative with syntax &quot;d&lt;var&gt;/dt&quot;</span>
            <span class="c1">### using re, replace it with 0 and add the variable to</span>
            <span class="c1">### variables_to_solve_for_list, also set instant_update to False</span>
            <span class="k">elif</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;d\w+/dt&quot;</span><span class="p">,</span> <span class="n">line</span><span class="p">):</span>
                <span class="n">variables_to_solve_for_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;d(\w+)/dt&quot;</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">left_side</span> <span class="o">=</span> <span class="n">left_side</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
                    <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;d(\w+)/dt&quot;</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;0&quot;</span>
                <span class="p">)</span>
                <span class="n">instant_update_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
            <span class="c1">### else it is a &quot;normal&quot; equation (&lt;var&gt; = &lt;expression&gt;), not changing</span>
            <span class="c1">### anything, add the variable to variables_to_solve_for_list and set</span>
            <span class="c1">### instant_update to True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">variables_to_solve_for_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">instant_update_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1">### create the sympy equation, move everything on one side (other side = 0)</span>
            <span class="n">eq_sympy_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Eq</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sympify</span><span class="p">(</span><span class="n">right_side</span><span class="p">)</span> <span class="o">-</span> <span class="n">sympify</span><span class="p">(</span><span class="n">left_side</span><span class="p">)))</span>

        <span class="c1">### 1st find solution of variables for holding v_0</span>
        <span class="n">eq_sympy_list_hold_v_0</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">eq_sympy_list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">line_idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eq_sympy_list_hold_v_0</span><span class="p">):</span>
            <span class="n">eq_sympy_list_hold_v_0</span><span class="p">[</span><span class="n">line_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span>
                <span class="p">{</span><span class="n">variables_sympy_dict</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">]:</span> <span class="n">variables_sympy_dict</span><span class="p">[</span><span class="s2">&quot;v_0&quot;</span><span class="p">]}</span>
            <span class="p">)</span>
        <span class="c1">### solve</span>
        <span class="n">solution_hold_v_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_v_clamp_equations</span><span class="p">(</span>
            <span class="n">eq_sympy_list_hold_v_0</span><span class="p">,</span> <span class="n">variables_to_solve_for_list</span><span class="p">,</span> <span class="s2">&quot;holding v_0&quot;</span>
        <span class="p">)</span>

        <span class="c1">### 2nd for I_clamp_inst set v to v_step only in equations which are</span>
        <span class="c1">### updated instantaneously  (I_clamp and all non-derivatives), for all</span>
        <span class="c1">### derivatives use the solution for holding v_0</span>
        <span class="n">eq_sympy_list_inst</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">eq_sympy_list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">line_idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eq_sympy_list_inst</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">instant_update_list</span><span class="p">[</span><span class="n">line_idx</span><span class="p">]:</span>
                <span class="c1">### variable is updated instantaneously -&gt; set v to v_step</span>
                <span class="n">eq_sympy_list_inst</span><span class="p">[</span><span class="n">line_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="n">variables_sympy_dict</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">]:</span> <span class="n">variables_sympy_dict</span><span class="p">[</span><span class="s2">&quot;v_step&quot;</span><span class="p">],</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">### variable is not updated instantaneously -&gt; use solution for hold v_0</span>
                <span class="n">current_variable_name</span> <span class="o">=</span> <span class="n">variables_to_solve_for_list</span><span class="p">[</span><span class="n">line_idx</span><span class="p">]</span>
                <span class="n">current_variable</span> <span class="o">=</span> <span class="n">variables_sympy_dict</span><span class="p">[</span><span class="n">current_variable_name</span><span class="p">]</span>
                <span class="n">eq_sympy_list_inst</span><span class="p">[</span><span class="n">line_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">Eq</span><span class="p">(</span>
                    <span class="mi">0</span><span class="p">,</span> <span class="n">solution_hold_v_0</span><span class="p">[</span><span class="n">current_variable</span><span class="p">]</span> <span class="o">-</span> <span class="n">current_variable</span>
                <span class="p">)</span>
        <span class="c1">### solve</span>
        <span class="n">solution_inst</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_v_clamp_equations</span><span class="p">(</span>
            <span class="n">eq_sympy_list_inst</span><span class="p">,</span> <span class="n">variables_to_solve_for_list</span><span class="p">,</span> <span class="s2">&quot;step from v_0 to v_step&quot;</span>
        <span class="p">)</span>

        <span class="c1">### 3rd for I_clamp_hold (i.e. holding v_step) set v to v_step in all</span>
        <span class="c1">### equations</span>
        <span class="n">eq_sympy_list_hold</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">eq_sympy_list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">line_idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eq_sympy_list_hold</span><span class="p">):</span>
            <span class="n">eq_sympy_list_hold</span><span class="p">[</span><span class="n">line_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span>
                <span class="p">{</span><span class="n">variables_sympy_dict</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">]:</span> <span class="n">variables_sympy_dict</span><span class="p">[</span><span class="s2">&quot;v_step&quot;</span><span class="p">]}</span>
            <span class="p">)</span>
        <span class="c1">### solve</span>
        <span class="n">solution_hold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_v_clamp_equations</span><span class="p">(</span>
            <span class="n">eq_sympy_list_hold</span><span class="p">,</span> <span class="n">variables_to_solve_for_list</span><span class="p">,</span> <span class="s2">&quot;holding v_step&quot;</span>
        <span class="p">)</span>

        <span class="c1">### get the equations for I_clamp_inst and I_clamp_hold (i.e. the external</span>
        <span class="c1">### current variable)</span>
        <span class="n">eq_I_clamp_inst</span> <span class="o">=</span> <span class="n">solution_inst</span><span class="p">[</span><span class="n">variables_sympy_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span><span class="p">]]</span>
        <span class="n">eq_I_clamp_hold</span> <span class="o">=</span> <span class="n">solution_hold</span><span class="p">[</span><span class="n">variables_sympy_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span><span class="p">]]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Equation for I_clamp_inst: </span><span class="si">{</span><span class="n">factor</span><span class="p">(</span><span class="n">eq_I_clamp_inst</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Equation for I_clamp_hold: </span><span class="si">{</span><span class="n">factor</span><span class="p">(</span><span class="n">eq_I_clamp_hold</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1">### create functions for I_clamp_inst and I_clamp_hold</span>
        <span class="c1">### 1st obtain all variables from the equations for I_clamp_inst and I_clamp_hold</span>
        <span class="n">f_variables</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">eq_I_clamp_inst</span><span class="o">.</span><span class="n">free_symbols</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">eq_I_clamp_hold</span><span class="o">.</span><span class="n">free_symbols</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="c1">### 2nd create a function for each equation</span>
        <span class="n">f_inst</span> <span class="o">=</span> <span class="n">lambdify</span><span class="p">(</span><span class="n">f_variables</span><span class="p">,</span> <span class="n">eq_I_clamp_inst</span><span class="p">)</span>
        <span class="n">f_hold</span> <span class="o">=</span> <span class="n">lambdify</span><span class="p">(</span><span class="n">f_variables</span><span class="p">,</span> <span class="n">eq_I_clamp_hold</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">f_inst</span><span class="p">,</span> <span class="n">f_hold</span><span class="p">,</span> <span class="n">f_variables</span>

    <span class="k">def</span> <span class="nf">_solve_v_clamp_equations</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">eq_sympy_list</span><span class="p">,</span> <span class="n">variables_to_solve_for_list</span><span class="p">,</span> <span class="n">name</span>
    <span class="p">):</span>
        <span class="n">solution</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span>
            <span class="n">eq_sympy_list</span><span class="p">,</span>
            <span class="n">variables_to_solve_for_list</span><span class="p">,</span>
            <span class="nb">dict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">solution</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">solution</span> <span class="o">=</span> <span class="n">solution</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">solution</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Multiple solutions for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not solve equations for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">solution</span>

    <span class="k">def</span> <span class="nf">_get_variables_from_eq</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eq</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get a list of all variable names from the given equation string.</span>

<span class="sd">        Args:</span>
<span class="sd">            eq (str):</span>
<span class="sd">                the equation string</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### split equations into lines</span>
        <span class="n">eq_line_list</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>

        <span class="c1">### loop over lines</span>
        <span class="n">variables_name_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">eq_line_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;=&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="c1">### split line at = and only take right side (e.g. not use dv/dt)</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="c1">### remove whitespaces</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="c1">### replace all kind of special characters with a space</span>
            <span class="n">special_characters</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;+&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">,</span> <span class="s2">&quot;(&quot;</span><span class="p">,</span> <span class="s2">&quot;)&quot;</span><span class="p">,</span> <span class="s2">&quot;[&quot;</span><span class="p">,</span> <span class="s2">&quot;]&quot;</span><span class="p">,</span> <span class="s2">&quot;=&quot;</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">special_character</span> <span class="ow">in</span> <span class="n">special_characters</span><span class="p">:</span>
                <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">special_character</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="c1">### split line at spaces</span>
            <span class="n">line_split</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
            <span class="c1">### append to list</span>
            <span class="n">variables_name_list</span> <span class="o">+=</span> <span class="n">line_split</span>

        <span class="c1">### remove duplicates</span>
        <span class="n">variables_name_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">variables_name_list</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">variables_name_list</span>

    <span class="k">def</span> <span class="nf">_simulations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform the resting state and voltage step simulations to obtain I_clamp_inst,</span>
<span class="sd">        I_clamp_hold and v_rest.</span>

<span class="sd">        Returns:</span>
<span class="sd">            v_rest (float):</span>
<span class="sd">                resting state voltage</span>
<span class="sd">            I_clamp_inst (np.array):</span>
<span class="sd">                array of the voltage clamp values directly after the voltage step</span>
<span class="sd">            I_clamp_hold (np.array):</span>
<span class="sd">                array of the voltage clamp values after the holding period</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">duration</span> <span class="o">=</span> <span class="mi">200</span>
        <span class="c1">### simulate both models at the same time</span>
        <span class="c1">### for pop_normal nothing happens (resting state)</span>
        <span class="c1">### for pop_clamp the voltage is set to v_0 and then to v_step for each neuron</span>
        <span class="n">ann</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="s2">&quot;pop_clamp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_0_arr</span>
        <span class="n">ann</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">duration</span><span class="p">)</span>
        <span class="n">ann</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="s2">&quot;pop_clamp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_arr</span>
        <span class="n">ann</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span><span class="p">)</span>
        <span class="n">I_clamp_inst_arr</span> <span class="o">=</span> <span class="n">ann</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="s2">&quot;pop_clamp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">I_clamp</span>
        <span class="n">ann</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">duration</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span><span class="p">)</span>
        <span class="n">I_clamp_hold_arr</span> <span class="o">=</span> <span class="n">ann</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="s2">&quot;pop_clamp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">I_clamp</span>
        <span class="n">v_rest</span> <span class="o">=</span> <span class="n">ann</span><span class="o">.</span><span class="n">get_population</span><span class="p">(</span><span class="s2">&quot;pop_normal&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1">### get unique values of v_step and their indices</span>
        <span class="n">v_step_unique</span><span class="p">,</span> <span class="n">v_step_unique_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_arr</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="c1">### get the corresponding values of I_clamp_hold (because it does only depend on</span>
        <span class="c1">### v_step)</span>
        <span class="n">I_clamp_hold_unique</span> <span class="o">=</span> <span class="n">I_clamp_hold_arr</span><span class="p">[</span><span class="n">v_step_unique_idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_plot</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_inst_arr</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.4</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">4.8</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
            <span class="c1">### create a 2D color-coded plot of the data for I_clamp_inst and I_clamp_hold</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_0_arr</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_arr</span>

            <span class="c1">### create 2 subplots for original I_clamp_inst and I_clamp_hold</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plot_I_clamp_subplot</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_inst_arr</span><span class="p">,</span>
                <span class="s2">&quot;I_clamp_inst original&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">234</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plot_I_clamp_subplot</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_arr</span><span class="p">,</span>
                <span class="s2">&quot;I_clamp_hold original&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1">### create 2 subplots for tuned I_clamp_inst and I_clamp_hold</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">232</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plot_I_clamp_subplot</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">I_clamp_inst_arr</span><span class="p">,</span>
                <span class="s2">&quot;I_clamp_inst tuned&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">235</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plot_I_clamp_subplot</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">I_clamp_hold_arr</span><span class="p">,</span>
                <span class="s2">&quot;I_clamp_hold tuned&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1">### create 2 subplots for differences</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">233</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plot_I_clamp_subplot</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_inst_arr</span> <span class="o">-</span> <span class="n">I_clamp_inst_arr</span><span class="p">,</span>
                <span class="s2">&quot;I_clamp_inst diff&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">236</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plot_I_clamp_subplot</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_arr</span> <span class="o">-</span> <span class="n">I_clamp_hold_arr</span><span class="p">,</span>
                <span class="s2">&quot;I_clamp_hold diff&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_data.&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">v_rest</span><span class="p">,</span>
            <span class="n">I_clamp_inst_arr</span><span class="p">,</span>
            <span class="n">I_clamp_hold_arr</span><span class="p">,</span>
            <span class="n">v_step_unique</span><span class="p">,</span>
            <span class="n">I_clamp_hold_unique</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_plot_I_clamp_subplot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

        <span class="n">ci</span> <span class="o">=</span> <span class="n">c</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="c1"># Define the grid for interpolation</span>
            <span class="n">xi</span><span class="p">,</span> <span class="n">yi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Perform the interpolation</span>
            <span class="n">ci</span> <span class="o">=</span> <span class="n">griddata</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">c</span><span class="p">,</span> <span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>

            <span class="c1"># Plot the interpolated surface</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span>
                <span class="n">xi</span><span class="p">,</span>
                <span class="n">yi</span><span class="p">,</span>
                <span class="n">ci</span><span class="p">,</span>
                <span class="n">levels</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;bwr&quot;</span><span class="p">,</span>
                <span class="n">vmin</span><span class="o">=-</span><span class="n">af</span><span class="o">.</span><span class="n">get_maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">ci</span><span class="p">)),</span>
                <span class="n">vmax</span><span class="o">=</span><span class="n">af</span><span class="o">.</span><span class="n">get_maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">ci</span><span class="p">)),</span>
            <span class="p">)</span>

        <span class="c1"># Plot also the original data points</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;bwr&quot;</span><span class="p">,</span>
            <span class="n">vmin</span><span class="o">=-</span><span class="n">af</span><span class="o">.</span><span class="n">get_maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">ci</span><span class="p">)),</span>
            <span class="n">vmax</span><span class="o">=</span><span class="n">af</span><span class="o">.</span><span class="n">get_maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">ci</span><span class="p">)),</span>
            <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;v_0&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;v_step&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_voltage_step_arrays</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create the arrays for the initial voltages and the voltage steps.</span>

<span class="sd">        Returns:</span>
<span class="sd">            v_0_arr (np.array):</span>
<span class="sd">                array of the initial voltages</span>
<span class="sd">            v_step_arr (np.array):</span>
<span class="sd">                array of the voltage steps</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### create the unique values of v_step and v_0</span>
        <span class="n">v_0_arr_unique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
        <span class="n">v_step_arr_unique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>

        <span class="c1">### create a 2D array of all combinations of v_0 and v_step</span>
        <span class="n">v_0_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">v_0_arr_unique</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
        <span class="n">v_step_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">v_step_arr_unique</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">v_0_arr</span><span class="p">,</span> <span class="n">v_step_arr</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a population (single neuron) for each neuron model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            model_normal (CompNeuroModel):</span>
<span class="sd">                model containing the population with the normal neuron model</span>
<span class="sd">            model_clamp (CompNeuroModel):</span>
<span class="sd">                model containing the population with the voltage clamped neuron model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### setup ANNarchy</span>
        <span class="n">ann</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">dt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
        <span class="c1">### create a population with the normal neuron model</span>
        <span class="n">model_normal</span> <span class="o">=</span> <span class="n">CompNeuroModel</span><span class="p">(</span>
            <span class="n">model_creation_function</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">ann</span><span class="o">.</span><span class="n">Population</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;pop_normal&quot;</span>
            <span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model_normal&quot;</span><span class="p">,</span>
            <span class="n">do_compile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1">### create a population with the voltage clamped neuron model</span>
        <span class="n">model_clamp</span> <span class="o">=</span> <span class="n">CompNeuroModel</span><span class="p">(</span>
            <span class="n">model_creation_function</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">ann</span><span class="o">.</span><span class="n">Population</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_v_0_arr</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model_clamp</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;pop_clamp&quot;</span>
            <span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model_clamp&quot;</span><span class="p">,</span>
            <span class="n">compile_folder_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">compile_folder_name</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">model_normal</span><span class="p">,</span> <span class="n">model_clamp</span>

    <span class="k">def</span> <span class="nf">_get_neuron_model_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neuron_model</span><span class="p">:</span> <span class="n">ann</span><span class="o">.</span><span class="n">Neuron</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get a list of the attributes (parameters and variables) of the given neuron</span>
<span class="sd">        model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            attributes (list):</span>
<span class="sd">                list of the attributes of the given neuron model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">neuron_model</span><span class="o">.</span><span class="n">_analyse</span><span class="p">()</span>
        <span class="n">attributes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">neuron_model</span><span class="o">.</span><span class="n">description</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]:</span>
            <span class="n">attributes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">neuron_model</span><span class="o">.</span><span class="n">description</span><span class="p">[</span><span class="s2">&quot;variables&quot;</span><span class="p">]:</span>
            <span class="n">attributes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">attributes</span>

    <span class="k">def</span> <span class="nf">_get_neuron_model_arguments</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neuron_model</span><span class="p">:</span> <span class="n">ann</span><span class="o">.</span><span class="n">Neuron</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get a dictionary of the initial arguments of the given neuron model.</span>

<span class="sd">        Args:</span>
<span class="sd">            neuron_model (Neuron):</span>
<span class="sd">                the neuron model which should be analyzed</span>

<span class="sd">        Returns:</span>
<span class="sd">            init_arguments_dict (dict):</span>
<span class="sd">                dictionary of the initial arguments of the given neuron model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### get the names of the arguments of a Neuron class</span>
        <span class="n">init_arguments_name_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ann</span><span class="o">.</span><span class="n">Neuron</span><span class="o">.</span><span class="fm">__init__</span><span class="o">.</span><span class="vm">__code__</span><span class="o">.</span><span class="n">co_varnames</span><span class="p">)</span>
        <span class="n">init_arguments_name_list</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;self&quot;</span><span class="p">)</span>
        <span class="n">init_arguments_name_list</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">)</span>
        <span class="n">init_arguments_name_list</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;description&quot;</span><span class="p">)</span>
        <span class="c1">### get these attributes from the given neuron model</span>
        <span class="n">init_arguments_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">init_arguments_name</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">neuron_model</span><span class="p">,</span> <span class="n">init_arguments_name</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">init_arguments_name</span> <span class="ow">in</span> <span class="n">init_arguments_name_list</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">init_arguments_dict</span>

    <span class="k">def</span> <span class="nf">_get_neuron_model_clamp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a neuron model with voltage clamp equations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            neuron_model_clamp (Neuron):</span>
<span class="sd">                the neuron model with voltage clamped equation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### get these attributes from the given neuron model</span>
        <span class="n">init_arguments_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_neuron_model_arguments</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model</span><span class="p">)</span>
        <span class="c1">### split the equations string</span>
        <span class="n">equations_line_split_list</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">init_arguments_dict</span><span class="p">[</span><span class="s2">&quot;equations&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
        <span class="c1">### adjust the equations for voltage clamp</span>
        <span class="n">equations_line_split_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_adjust_equations_for_voltage_clamp</span><span class="p">(</span>
            <span class="n">equations_line_split_list</span>
        <span class="p">)</span>

        <span class="c1">### combine string lines to multiline strings again</span>
        <span class="n">init_arguments_dict</span><span class="p">[</span><span class="s2">&quot;equations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">equations_line_split_list</span><span class="p">)</span>

        <span class="c1">### create neuron model with new equations</span>
        <span class="n">neuron_model_clamp</span> <span class="o">=</span> <span class="n">ann</span><span class="o">.</span><span class="n">Neuron</span><span class="p">(</span><span class="o">**</span><span class="n">init_arguments_dict</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Neuron model with voltage clamp equations:</span><span class="se">\n</span><span class="si">{</span><span class="n">neuron_model_clamp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">neuron_model_clamp</span>

    <span class="k">def</span> <span class="nf">_adjust_equations_for_voltage_clamp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eq_line_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Replaces the &#39;dv/dt&#39; equation with a voltage clamp version (dv/dt=0) in which the</span>
<span class="sd">        new variable &#39;I_clamp&#39; is obtained by solving the &#39;dv/dt&#39; equation for its</span>
<span class="sd">        external current variable.</span>

<span class="sd">        Args:</span>
<span class="sd">            eq_line_list (list):</span>
<span class="sd">                list of the lines of the equations of the neuron model</span>

<span class="sd">        Returns:</span>
<span class="sd">            eq_line_list (list):</span>
<span class="sd">                list of the lines of the equations of the neuron model with voltage clamp</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### check in which lines v is updated</span>
        <span class="n">line_is_v_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">eq_line_list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">line_idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eq_line_list</span><span class="p">):</span>
            <span class="n">line_is_v_list</span><span class="p">[</span><span class="n">line_idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_line_is_v</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
        <span class="c1">### raise error if in no line v is updated or in multiple lines</span>
        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">line_is_v_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">sum</span><span class="p">(</span><span class="n">line_is_v_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Could not find one line with dv/dt or v+= in equations of neuronmodel!&quot;</span>
            <span class="p">)</span>

        <span class="c1">### obtain the line containing v update</span>
        <span class="n">eq_v</span> <span class="o">=</span> <span class="n">eq_line_list</span><span class="p">[</span><span class="n">line_is_v_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>

        <span class="c1">### remove whitespaces</span>
        <span class="n">eq_v</span> <span class="o">=</span> <span class="n">eq_v</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="c1">### split eqatuion at &quot;:&quot; to ignore flags</span>
        <span class="n">eq_v_split</span> <span class="o">=</span> <span class="n">eq_v</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>
        <span class="n">eq_v</span> <span class="o">=</span> <span class="n">eq_v_split</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1">### adjust the equation for voltage clamp</span>
        <span class="n">eq_v</span><span class="p">,</span> <span class="n">eq_I_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_adjust_equation_for_voltage_clamp_dvdt</span><span class="p">(</span><span class="n">eq_v</span><span class="p">)</span>
        <span class="c1">### delete old equation from equation list using the index of the equation</span>
        <span class="n">eq_line_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">line_is_v_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
        <span class="c1">### insert new equation at the same position</span>
        <span class="n">eq_line_list</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">line_is_v_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">eq_v</span><span class="p">)</span>
        <span class="c1">### insert new equation for &quot;I_clamp&quot; at the same position</span>
        <span class="n">eq_line_list</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">line_is_v_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">eq_I_clamp</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">eq_line_list</span>

    <span class="k">def</span> <span class="nf">_adjust_equation_for_voltage_clamp_dvdt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eq_v</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert the v-update equation using &quot;dv/dt&quot; into a voltage clamp version.</span>

<span class="sd">        !!! warning</span>
<span class="sd">            Equation needs to contain dv/dt and the external current variable.</span>

<span class="sd">        Args:</span>
<span class="sd">            eq_v (str):</span>
<span class="sd">                the equation string for updating v (without flags and whitespace)</span>

<span class="sd">        Returns:</span>
<span class="sd">            eq_v (str):</span>
<span class="sd">                the adjusted equation string for updating v (without flags)</span>
<span class="sd">            eq_I_clamp (str):</span>
<span class="sd">                the equation string for &quot;I_clamp&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">### if equation doesn&#39;t start with &quot;dv/dt=&quot; --&gt; need to rearrange equation</span>
        <span class="c1">### set dv/dt to zero and solve the equation for the external current variable</span>
        <span class="c1">### (will be I_clamp)</span>
        <span class="n">eq_v</span> <span class="o">=</span> <span class="n">eq_v</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;dv/dt&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">)</span>

        <span class="c1">### split the equation at &quot;=&quot; and move everything on one side (other side = 0)</span>
        <span class="n">left_side</span><span class="p">,</span> <span class="n">right_side</span> <span class="o">=</span> <span class="n">eq_v</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">)</span>
        <span class="n">eq_v_one_side</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">right_side</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">left_side</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1">### prepare the sympy equation generation</span>
        <span class="n">attributes_name_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_neuron_model_attributes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model</span><span class="p">)</span>
        <span class="c1">### create a sympy symbol for each attribute of the neuron</span>
        <span class="n">attributes_tuple</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attributes_name_list</span><span class="p">))</span>
        <span class="c1">### create a dict with the names as keys and the sympy symbols as values</span>
        <span class="n">attributes_sympy_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">attributes_tuple</span><span class="p">[</span><span class="n">attributes_name_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">key</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">attributes_name_list</span>
        <span class="p">}</span>

        <span class="c1">### now creating the sympy equation</span>
        <span class="n">eq_sympy</span> <span class="o">=</span> <span class="n">sympify</span><span class="p">(</span><span class="n">eq_v_one_side</span><span class="p">)</span>

        <span class="c1">### solve the equation for the external current variable</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attributes_sympy_dict: </span><span class="si">{</span><span class="n">attributes_sympy_dict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span>
            <span class="n">eq_sympy</span><span class="p">,</span> <span class="n">attributes_sympy_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span><span class="p">],</span> <span class="nb">dict</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Could not solve equation of neuronmodel for external current variable </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span><span class="si">}</span><span class="s2">!&quot;</span>
            <span class="p">)</span>

        <span class="c1">### convert result to string</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">attributes_sympy_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span><span class="p">]])</span>

        <span class="c1">### create new equation for dv/dt</span>
        <span class="n">eq_v</span> <span class="o">=</span> <span class="s2">&quot;dv/dt = 0&quot;</span>
        <span class="c1">### create new equation for &quot;I_clamp&quot; with the equation solved for the external</span>
        <span class="c1">### current variable</span>
        <span class="n">eq_I_clamp</span> <span class="o">=</span> <span class="s2">&quot;I_clamp=&quot;</span> <span class="o">+</span> <span class="n">result</span>

        <span class="k">return</span> <span class="n">eq_v</span><span class="p">,</span> <span class="n">eq_I_clamp</span>

    <span class="k">def</span> <span class="nf">_get_line_is_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">line</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if a equation string contains dv/dt or v+=</span>

<span class="sd">        Args:</span>
<span class="sd">            line (str):</span>
<span class="sd">                the equation string</span>

<span class="sd">        Returns:</span>
<span class="sd">            line_is_v (bool):</span>
<span class="sd">                True if the equation string contains dv/dt or v+=, False otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;v&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1">### remove whitespaces</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="c1">### check for dv/dt</span>
        <span class="k">if</span> <span class="s2">&quot;dv/dt&quot;</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1">### check for v update</span>
        <span class="k">if</span> <span class="s2">&quot;v+=&quot;</span> <span class="ow">in</span> <span class="n">line</span> <span class="ow">and</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;v&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.VClampParamSearch.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">neuron_model</span><span class="p">,</span> <span class="n">equations</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">        C*dv/dt = k*(v - v_r)*(v - v_t) - u + I</span><span class="se">\n</span><span class="s1">        du/dt = a*(b*(v - v_r) - u)</span><span class="se">\n</span><span class="s1">        &#39;</span><span class="p">,</span> <span class="n">external_current_var</span><span class="o">=</span><span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="s1">&#39;v_r&#39;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">),</span> <span class="s1">&#39;v_t&#39;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">),</span> <span class="s1">&#39;k&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)},</span> <span class="n">p0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">do_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">results_file</span><span class="o">=</span><span class="s1">&#39;v_clamp_search_results&#39;</span><span class="p">,</span> <span class="n">plot_file</span><span class="o">=</span><span class="s1">&#39;v_clamp_search_plot.png&#39;</span><span class="p">,</span> <span class="n">cma_params_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;learn_rate_factor&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;damping_factor&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="n">compile_folder_name</span><span class="o">=</span><span class="s1">&#39;VClampParamSearch&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.VClampParamSearch.__init__" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>neuron_model</code></td>
            <td>
                  <code>Neuron</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The neuron model which is simulated to obtain the parameters for the
equations</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>equations</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The equations whose parameters should be obtained. Default: Izhikevich
2007 neuron model</p>
              </div>
            </td>
            <td>
                  <code>&#39;\n        C*dv/dt = k*(v - v_r)*(v - v_t) - u + I\n        du/dt = a*(b*(v - v_r) - u)\n        &#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>external_current_var</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the variable in the neuron model which is used as the
external current. Has to be used in the neuron model and the given
equations Default: "I"</p>
              </div>
            </td>
            <td>
                  <code>&#39;I&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bounds</code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The bounds for the parameters. For each parameter of the equation a
bound should be given (except for the external current variable)!
Default: Izhikevich 2007 neuron model</p>
              </div>
            </td>
            <td>
                  <code>{&#39;C&#39;: (0.1, 100), &#39;v_r&#39;: (-90, -40), &#39;v_t&#39;: (-90, -40), &#39;k&#39;: (0.01, 1), &#39;a&#39;: (0.01, 1), &#39;b&#39;: (-5, 5)}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>p0</code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The initial guess for the parameters. Dict keys should be the same as
the keys of bounds. The values can be either a single number for each
parameter or a list of numbers. If lists are given, all have to have
the same length, which will be the number of initial guesses for the
parameters, i.e. how often the optimization is run. Default: None,
i.e. the mid of the bounds is used as a single initial guess.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>max_evals</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The maximum number of evaluations for a single optimization run.
Default: 100</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>m</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of initial voltages for the voltage step simulations.
Default: 20</p>
              </div>
            </td>
            <td>
                  <code>20</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of voltage steps for the voltage step simulations.
Defaults: 20</p>
              </div>
            </td>
            <td>
                  <code>20</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>do_plot</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, plots are created. Default: False</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>results_file</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the file where the results are stored, without file ending.
Default: "v_clamp_search_results"</p>
              </div>
            </td>
            <td>
                  <code>&#39;v_clamp_search_results&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>plot_file</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the file where the plot is stored, with file ending.
Default: "v_clamp_search_plot.png"</p>
              </div>
            </td>
            <td>
                  <code>&#39;v_clamp_search_plot.png&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cma_params_dict</code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Parameters for the deap cma strategy (deap.cma.Strategy). See <a href="https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy">here</a>
for more details. Additional parameters are learn_rate_factor and
damping_factor. Default: {"learn_rate_factor": 1, "damping_factor": 1}</p>
              </div>
            </td>
            <td>
                  <code>{&#39;learn_rate_factor&#39;: 1, &#39;damping_factor&#39;: 1}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>compile_folder_name</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the folder within "annarchy_folders" where the ANNarchy
network is compiled to. Default: "VClampParamSearch"</p>
              </div>
            </td>
            <td>
                  <code>&#39;VClampParamSearch&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>verbose</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, print details. Default: False</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@check_types</span><span class="p">()</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">neuron_model</span><span class="p">:</span> <span class="n">ann</span><span class="o">.</span><span class="n">Neuron</span><span class="p">,</span>
    <span class="n">equations</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    C*dv/dt = k*(v - v_r)*(v - v_t) - u + I</span>
<span class="s2">    du/dt = a*(b*(v - v_r) - u)</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">external_current_var</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
        <span class="s2">&quot;v_r&quot;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">),</span>
        <span class="s2">&quot;v_t&quot;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">),</span>
        <span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="n">p0</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_evals</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">m</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">do_plot</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">results_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;v_clamp_search_results&quot;</span><span class="p">,</span>
    <span class="n">plot_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;v_clamp_search_plot.png&quot;</span><span class="p">,</span>
    <span class="n">cma_params_dict</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;learn_rate_factor&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;damping_factor&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
    <span class="n">compile_folder_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;VClampParamSearch&quot;</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        neuron_model (Neuron):</span>
<span class="sd">            The neuron model which is simulated to obtain the parameters for the</span>
<span class="sd">            equations</span>
<span class="sd">        equations (str, optional):</span>
<span class="sd">            The equations whose parameters should be obtained. Default: Izhikevich</span>
<span class="sd">            2007 neuron model</span>
<span class="sd">        external_current_var (str, optional):</span>
<span class="sd">            The name of the variable in the neuron model which is used as the</span>
<span class="sd">            external current. Has to be used in the neuron model and the given</span>
<span class="sd">            equations Default: &quot;I&quot;</span>
<span class="sd">        bounds (dict, optional):</span>
<span class="sd">            The bounds for the parameters. For each parameter of the equation a</span>
<span class="sd">            bound should be given (except for the external current variable)!</span>
<span class="sd">            Default: Izhikevich 2007 neuron model</span>
<span class="sd">        p0 (dict, optional):</span>
<span class="sd">            The initial guess for the parameters. Dict keys should be the same as</span>
<span class="sd">            the keys of bounds. The values can be either a single number for each</span>
<span class="sd">            parameter or a list of numbers. If lists are given, all have to have</span>
<span class="sd">            the same length, which will be the number of initial guesses for the</span>
<span class="sd">            parameters, i.e. how often the optimization is run. Default: None,</span>
<span class="sd">            i.e. the mid of the bounds is used as a single initial guess.</span>
<span class="sd">        max_evals (int, optional):</span>
<span class="sd">            The maximum number of evaluations for a single optimization run.</span>
<span class="sd">            Default: 100</span>
<span class="sd">        m (int, optional):</span>
<span class="sd">            The number of initial voltages for the voltage step simulations.</span>
<span class="sd">            Default: 20</span>
<span class="sd">        n (int, optional):</span>
<span class="sd">            The number of voltage steps for the voltage step simulations.</span>
<span class="sd">            Defaults: 20</span>
<span class="sd">        do_plot (bool, optional):</span>
<span class="sd">            If True, plots are created. Default: False</span>
<span class="sd">        results_file (str, optional):</span>
<span class="sd">            The name of the file where the results are stored, without file ending.</span>
<span class="sd">            Default: &quot;v_clamp_search_results&quot;</span>
<span class="sd">        plot_file (str, optional):</span>
<span class="sd">            The name of the file where the plot is stored, with file ending.</span>
<span class="sd">            Default: &quot;v_clamp_search_plot.png&quot;</span>
<span class="sd">        cma_params_dict (dict, optional):</span>
<span class="sd">            Parameters for the deap cma strategy (deap.cma.Strategy). See [here](https://deap.readthedocs.io/en/master/api/algo.html#deap.cma.Strategy)</span>
<span class="sd">            for more details. Additional parameters are learn_rate_factor and</span>
<span class="sd">            damping_factor. Default: {&quot;learn_rate_factor&quot;: 1, &quot;damping_factor&quot;: 1}</span>
<span class="sd">        compile_folder_name (str, optional):</span>
<span class="sd">            The name of the folder within &quot;annarchy_folders&quot; where the ANNarchy</span>
<span class="sd">            network is compiled to. Default: &quot;VClampParamSearch&quot;</span>
<span class="sd">        verbose (bool, optional):</span>
<span class="sd">            If True, print details. Default: False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_verbose_extreme</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="c1">### store the given neuron model and a voltage clamp version of it</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">neuron_model</span> <span class="o">=</span> <span class="n">neuron_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">external_current_var</span> <span class="o">=</span> <span class="n">external_current_var</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">neuron_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_neuron_model_clamp</span><span class="p">()</span>

    <span class="c1">### store other attributes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">equations</span> <span class="o">=</span> <span class="n">equations</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p0</span> <span class="o">=</span> <span class="n">p0</span>
    <span class="c1">### check if p0 is correct and if lists are given, create also lists single</span>
    <span class="c1">### numbers which are given</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_p0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_p0</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_evals</span> <span class="o">=</span> <span class="n">max_evals</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">bounds</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_plot</span> <span class="o">=</span> <span class="n">do_plot</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">results_file</span> <span class="o">=</span> <span class="n">results_file</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span> <span class="o">=</span> <span class="n">plot_file</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cma_params_dict</span> <span class="o">=</span> <span class="n">cma_params_dict</span>
    <span class="c1">### check if file names are correct</span>
    <span class="k">if</span> <span class="s2">&quot;.&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">results_file</span> <span class="ow">or</span> <span class="s2">&quot;.&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_file</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;results_file should not contain file ending and plot_file should!&quot;</span>
        <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">compile_folder_name</span> <span class="o">=</span> <span class="n">compile_folder_name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="mf">0.001</span>

    <span class="c1">### create folder for plots</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_plot</span><span class="p">:</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">create_dir</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">plot_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1">### create the functions for I_clamp_inst and I_clamp_hold using the given</span>
    <span class="c1">### izhikevich equations</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_f_inst</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f_hold</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_f_variables</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_I_clamp_functions</span><span class="p">()</span>

    <span class="c1">### create the voltage step arrays</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_v_0_arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_voltage_step_arrays</span><span class="p">()</span>

    <span class="c1">### for each neuron model create a population</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating models...&quot;</span><span class="p">)</span>
    <span class="n">mf</span><span class="o">.</span><span class="n">cnp_clear</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_model_normal</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_model</span><span class="p">()</span>

    <span class="c1">### perform resting state and voltage step simulations to obtain I_clamp_inst,</span>
    <span class="c1">### I_clamp_hold and v_rest</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_inst_arr</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_arr</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Performing simulations...&quot;</span><span class="p">)</span>
    <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_v_rest</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_inst_arr</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_arr</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_v_step_unique</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_I_clamp_hold_unique</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_simulations</span><span class="p">()</span>

    <span class="c1">### tune the free paramters of the functions for I_clamp_inst and I_clamp_hold</span>
    <span class="c1">### to fit the data</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tuning parameters...&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_p_opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tune_I_clamp_functions</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">param_name</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_p_opt</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_p_opt</span><span class="p">[</span><span class="s2">&quot;best_fitness&quot;</span><span class="p">]</span>

    <span class="c1">### print and save optimized parameters</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimized parameters: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1">### save as pkl file</span>
    <span class="n">sf</span><span class="o">.</span><span class="n">save_variables</span><span class="p">(</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span><span class="p">],</span>
        <span class="p">[</span><span class="n">results_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
        <span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">results_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="s2">&quot;/&quot;</span> <span class="ow">in</span> <span class="n">results_file</span> <span class="k">else</span> <span class="s2">&quot;./&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1">### save human readable as json file</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_opt</span><span class="p">,</span>
        <span class="nb">open</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">results_file</span><span class="si">}</span><span class="s2">.json&quot;</span><span class="p">,</span>
            <span class="s2">&quot;w&quot;</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1">### create a neuron model with the tuned parameters and the given equations</span>
    <span class="c1">### then run the simulations again with this neuron model to do the plots</span>
    <span class="c1">### with the tuned parameters</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running simulations with tuned parameters...&quot;</span><span class="p">)</span>
    <span class="n">mf</span><span class="o">.</span><span class="n">cnp_clear</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_neuron_model_with_tuned_parameters</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_model_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_neuron_model_clamp</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_model_normal</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_clamp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_model</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_simulations</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="CompNeuroPy.extra_functions.InteractivePlot" class="doc doc-heading">
            <code>InteractivePlot</code>


<a href="#CompNeuroPy.extra_functions.InteractivePlot" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">


              <details class="quote">
                <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2087</span>
<span class="normal">2088</span>
<span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span>
<span class="normal">2114</span>
<span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span>
<span class="normal">2124</span>
<span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span>
<span class="normal">2143</span>
<span class="normal">2144</span>
<span class="normal">2145</span>
<span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span>
<span class="normal">2169</span>
<span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span>
<span class="normal">2193</span>
<span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span>
<span class="normal">2201</span>
<span class="normal">2202</span>
<span class="normal">2203</span>
<span class="normal">2204</span>
<span class="normal">2205</span>
<span class="normal">2206</span>
<span class="normal">2207</span>
<span class="normal">2208</span>
<span class="normal">2209</span>
<span class="normal">2210</span>
<span class="normal">2211</span>
<span class="normal">2212</span>
<span class="normal">2213</span>
<span class="normal">2214</span>
<span class="normal">2215</span>
<span class="normal">2216</span>
<span class="normal">2217</span>
<span class="normal">2218</span>
<span class="normal">2219</span>
<span class="normal">2220</span>
<span class="normal">2221</span>
<span class="normal">2222</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">InteractivePlot</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nrows</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">ncols</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sliders</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
        <span class="n">create_plot</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">update_loop</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">figure_frequency</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">20.0</span><span class="p">,</span>
        <span class="n">update_frequency</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create an interactive plot with sliders.</span>

<span class="sd">        Args:</span>
<span class="sd">            nrows (int):</span>
<span class="sd">                number of rows of subplots</span>
<span class="sd">            ncols (int):</span>
<span class="sd">                number of columns of subplots</span>
<span class="sd">            sliders (list):</span>
<span class="sd">                list of dictionaries with slider kwargs (see matplotlib.widgets.Slider), at</span>
<span class="sd">                least the following keys have to be present:</span>
<span class="sd">                    - label (str):</span>
<span class="sd">                        label of the slider</span>
<span class="sd">                    - valmin (float):</span>
<span class="sd">                        minimum value of the slider</span>
<span class="sd">                    - valmax (float):</span>
<span class="sd">                        maximum value of the slider</span>
<span class="sd">            create_plot (Callable):</span>
<span class="sd">                function which fills the subplots, has to have the signature</span>
<span class="sd">                create_plot(axs, sliders), where axs is a list of axes (for each subplot)</span>
<span class="sd">                and sliders is the given sliders list with newly added keys &quot;ax&quot; (axes of</span>
<span class="sd">                the slider) and &quot;slider&quot; (the Slider object itself, so that you can access</span>
<span class="sd">                the slider values in the create_plot function using the .val attribute)</span>
<span class="sd">            update_loop (Callable, optional):</span>
<span class="sd">                Function which is called periodically. After each call the plot is updated.</span>
<span class="sd">                If None, the plot is only updated when a slider is changed. Default is None.</span>
<span class="sd">            figure_frequency (float, optional):</span>
<span class="sd">                Frequency of the figure update in Hz. Default is 20.0.</span>
<span class="sd">            update_frequency (float, optional):</span>
<span class="sd">                Frequency of the update loop in Hz. Default is np.inf.</span>

<span class="sd">        Example:</span>
<span class="sd">            ```python</span>
<span class="sd">            def create_plot(axs, sliders):</span>
<span class="sd">                axs[0].axhline(sliders[0][&quot;slider&quot;].val, color=&quot;r&quot;)</span>
<span class="sd">                axs[1].axvline(sliders[1][&quot;slider&quot;].val, color=&quot;r&quot;)</span>

<span class="sd">            interactive_plot(</span>
<span class="sd">                nrows=2,</span>
<span class="sd">                ncols=1,</span>
<span class="sd">                sliders=[</span>
<span class="sd">                    {&quot;label&quot;: &quot;a&quot;, &quot;valmin&quot;: 0.0, &quot;valmax&quot;: 1.0, &quot;valinit&quot;: 0.3},</span>
<span class="sd">                    {&quot;label&quot;: &quot;b&quot;, &quot;valmin&quot;: 0.0, &quot;valmax&quot;: 1.0, &quot;valinit&quot;: 0.7},</span>
<span class="sd">                ],</span>
<span class="sd">                create_plot=create_plot,</span>
<span class="sd">            )</span>
<span class="sd">            ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_plot</span> <span class="o">=</span> <span class="n">create_plot</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_waiter</span> <span class="o">=</span> <span class="n">_Waiter</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">on_finish</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_recreate_plot</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>

        <span class="c1">### create the figure as large as the screen</span>
        <span class="n">screen_width</span><span class="p">,</span> <span class="n">screen_height</span> <span class="o">=</span> <span class="n">get_monitors</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">get_monitors</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">height</span>
        <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="n">screen_width</span> <span class="o">/</span> <span class="mi">100</span><span class="p">,</span> <span class="n">screen_height</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fig</span> <span class="o">=</span> <span class="n">fig</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span>

        <span class="c1">### create the sliders figure, set the axes for the sliders</span>
        <span class="n">fig_sliders</span><span class="p">,</span> <span class="n">axs_sliders</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">sliders</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.4</span><span class="p">,</span> <span class="mf">4.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">sliders</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sliders</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">axs_sliders</span> <span class="o">=</span> <span class="p">[</span><span class="n">axs_sliders</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">slider_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sliders</span><span class="p">)):</span>
            <span class="n">sliders</span><span class="p">[</span><span class="n">slider_idx</span><span class="p">][</span><span class="s2">&quot;ax&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">axs_sliders</span><span class="p">[</span><span class="n">slider_idx</span><span class="p">]</span>

        <span class="c1">### initialize the sliders</span>
        <span class="k">for</span> <span class="n">slider_idx</span><span class="p">,</span> <span class="n">slider_kwargs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sliders</span><span class="p">):</span>
            <span class="c1">### if init out of min max, change min max</span>
            <span class="k">if</span> <span class="s2">&quot;valinit&quot;</span> <span class="ow">in</span> <span class="n">slider_kwargs</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valinit&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valmin&quot;</span><span class="p">]:</span>
                    <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valmin&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valinit&quot;</span><span class="p">]</span>
                <span class="k">elif</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valinit&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valmax&quot;</span><span class="p">]:</span>
                    <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valmax&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valinit&quot;</span><span class="p">]</span>
            <span class="n">slider</span> <span class="o">=</span> <span class="n">Slider</span><span class="p">(</span><span class="o">**</span><span class="n">slider_kwargs</span><span class="p">)</span>
            <span class="n">slider</span><span class="o">.</span><span class="n">on_changed</span><span class="p">(</span><span class="k">lambda</span> <span class="n">val</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_waiter</span><span class="o">.</span><span class="n">start</span><span class="p">())</span>
            <span class="n">sliders</span><span class="p">[</span><span class="n">slider_idx</span><span class="p">][</span><span class="s2">&quot;slider&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">slider</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sliders</span> <span class="o">=</span> <span class="n">sliders</span>

        <span class="c1">### create the plot</span>
        <span class="n">create_plot</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">sliders</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">update_loop</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1">### show the plot</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ani</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">,</span>
                <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">frame</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="n">frames</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">interval</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">figure_frequency</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span>
                <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">### run update loop until figure is closed</span>
            <span class="n">figure_pause</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">figure_frequency</span>
            <span class="n">max_updates_per_pause</span> <span class="o">=</span> <span class="n">update_frequency</span> <span class="o">/</span> <span class="n">figure_frequency</span>
            <span class="k">while</span> <span class="n">plt</span><span class="o">.</span><span class="n">fignum_exists</span><span class="p">(</span><span class="n">fig</span><span class="o">.</span><span class="n">number</span><span class="p">):</span>
                <span class="c1">### update figure</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_recreate_plot</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="n">figure_pause</span><span class="p">)</span>
                <span class="c1">### in between do the update loop multiple times</span>
                <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">nr_updates</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">while</span> <span class="p">(</span>
                    <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="n">figure_pause</span>
                    <span class="ow">and</span> <span class="n">nr_updates</span> <span class="o">&lt;</span> <span class="n">max_updates_per_pause</span>
                <span class="p">):</span>
                    <span class="n">update_loop</span><span class="p">()</span>
                    <span class="n">nr_updates</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">_recreate_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">### pause the animation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ani</span><span class="o">.</span><span class="n">event_source</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
        <span class="c1">### clear the axes</span>
        <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">():</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
        <span class="c1">### recreate the plot</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sliders</span><span class="p">)</span>
        <span class="c1">### restart the animation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ani</span><span class="o">.</span><span class="n">event_source</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.InteractivePlot.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">sliders</span><span class="p">,</span> <span class="n">create_plot</span><span class="p">,</span> <span class="n">update_loop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">figure_frequency</span><span class="o">=</span><span class="mf">20.0</span><span class="p">,</span> <span class="n">update_frequency</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.InteractivePlot.__init__" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Create an interactive plot with sliders.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>nrows</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of rows of subplots</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ncols</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of columns of subplots</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>sliders</code></td>
            <td>
                  <code>list</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>list of dictionaries with slider kwargs (see matplotlib.widgets.Slider), at
least the following keys have to be present:
    - label (str):
        label of the slider
    - valmin (float):
        minimum value of the slider
    - valmax (float):
        maximum value of the slider</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>create_plot</code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>function which fills the subplots, has to have the signature
create_plot(axs, sliders), where axs is a list of axes (for each subplot)
and sliders is the given sliders list with newly added keys "ax" (axes of
the slider) and "slider" (the Slider object itself, so that you can access
the slider values in the create_plot function using the .val attribute)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>update_loop</code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function which is called periodically. After each call the plot is updated.
If None, the plot is only updated when a slider is changed. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>figure_frequency</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Frequency of the figure update in Hz. Default is 20.0.</p>
              </div>
            </td>
            <td>
                  <code>20.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>update_frequency</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Frequency of the update loop in Hz. Default is np.inf.</p>
              </div>
            </td>
            <td>
                  <code><span title="numpy.inf">inf</span></code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">create_plot</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">sliders</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">sliders</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;slider&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">sliders</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;slider&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>

<span class="n">interactive_plot</span><span class="p">(</span>
    <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sliders</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;valmin&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;valmax&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;valinit&quot;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;valmin&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;valmax&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;valinit&quot;</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">create_plot</span><span class="o">=</span><span class="n">create_plot</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>
</details>
            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span>
<span class="normal">2114</span>
<span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span>
<span class="normal">2124</span>
<span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span>
<span class="normal">2143</span>
<span class="normal">2144</span>
<span class="normal">2145</span>
<span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span>
<span class="normal">2169</span>
<span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span>
<span class="normal">2193</span>
<span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span>
<span class="normal">2201</span>
<span class="normal">2202</span>
<span class="normal">2203</span>
<span class="normal">2204</span>
<span class="normal">2205</span>
<span class="normal">2206</span>
<span class="normal">2207</span>
<span class="normal">2208</span>
<span class="normal">2209</span>
<span class="normal">2210</span>
<span class="normal">2211</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">nrows</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ncols</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">sliders</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">create_plot</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">update_loop</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">figure_frequency</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">20.0</span><span class="p">,</span>
    <span class="n">update_frequency</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create an interactive plot with sliders.</span>

<span class="sd">    Args:</span>
<span class="sd">        nrows (int):</span>
<span class="sd">            number of rows of subplots</span>
<span class="sd">        ncols (int):</span>
<span class="sd">            number of columns of subplots</span>
<span class="sd">        sliders (list):</span>
<span class="sd">            list of dictionaries with slider kwargs (see matplotlib.widgets.Slider), at</span>
<span class="sd">            least the following keys have to be present:</span>
<span class="sd">                - label (str):</span>
<span class="sd">                    label of the slider</span>
<span class="sd">                - valmin (float):</span>
<span class="sd">                    minimum value of the slider</span>
<span class="sd">                - valmax (float):</span>
<span class="sd">                    maximum value of the slider</span>
<span class="sd">        create_plot (Callable):</span>
<span class="sd">            function which fills the subplots, has to have the signature</span>
<span class="sd">            create_plot(axs, sliders), where axs is a list of axes (for each subplot)</span>
<span class="sd">            and sliders is the given sliders list with newly added keys &quot;ax&quot; (axes of</span>
<span class="sd">            the slider) and &quot;slider&quot; (the Slider object itself, so that you can access</span>
<span class="sd">            the slider values in the create_plot function using the .val attribute)</span>
<span class="sd">        update_loop (Callable, optional):</span>
<span class="sd">            Function which is called periodically. After each call the plot is updated.</span>
<span class="sd">            If None, the plot is only updated when a slider is changed. Default is None.</span>
<span class="sd">        figure_frequency (float, optional):</span>
<span class="sd">            Frequency of the figure update in Hz. Default is 20.0.</span>
<span class="sd">        update_frequency (float, optional):</span>
<span class="sd">            Frequency of the update loop in Hz. Default is np.inf.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        def create_plot(axs, sliders):</span>
<span class="sd">            axs[0].axhline(sliders[0][&quot;slider&quot;].val, color=&quot;r&quot;)</span>
<span class="sd">            axs[1].axvline(sliders[1][&quot;slider&quot;].val, color=&quot;r&quot;)</span>

<span class="sd">        interactive_plot(</span>
<span class="sd">            nrows=2,</span>
<span class="sd">            ncols=1,</span>
<span class="sd">            sliders=[</span>
<span class="sd">                {&quot;label&quot;: &quot;a&quot;, &quot;valmin&quot;: 0.0, &quot;valmax&quot;: 1.0, &quot;valinit&quot;: 0.3},</span>
<span class="sd">                {&quot;label&quot;: &quot;b&quot;, &quot;valmin&quot;: 0.0, &quot;valmax&quot;: 1.0, &quot;valinit&quot;: 0.7},</span>
<span class="sd">            ],</span>
<span class="sd">            create_plot=create_plot,</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">create_plot</span> <span class="o">=</span> <span class="n">create_plot</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_waiter</span> <span class="o">=</span> <span class="n">_Waiter</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">on_finish</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_recreate_plot</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>

    <span class="c1">### create the figure as large as the screen</span>
    <span class="n">screen_width</span><span class="p">,</span> <span class="n">screen_height</span> <span class="o">=</span> <span class="n">get_monitors</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">get_monitors</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">height</span>
    <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="n">screen_width</span> <span class="o">/</span> <span class="mi">100</span><span class="p">,</span> <span class="n">screen_height</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fig</span> <span class="o">=</span> <span class="n">fig</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span>

    <span class="c1">### create the sliders figure, set the axes for the sliders</span>
    <span class="n">fig_sliders</span><span class="p">,</span> <span class="n">axs_sliders</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">sliders</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.4</span><span class="p">,</span> <span class="mf">4.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">sliders</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sliders</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">axs_sliders</span> <span class="o">=</span> <span class="p">[</span><span class="n">axs_sliders</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">slider_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sliders</span><span class="p">)):</span>
        <span class="n">sliders</span><span class="p">[</span><span class="n">slider_idx</span><span class="p">][</span><span class="s2">&quot;ax&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">axs_sliders</span><span class="p">[</span><span class="n">slider_idx</span><span class="p">]</span>

    <span class="c1">### initialize the sliders</span>
    <span class="k">for</span> <span class="n">slider_idx</span><span class="p">,</span> <span class="n">slider_kwargs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sliders</span><span class="p">):</span>
        <span class="c1">### if init out of min max, change min max</span>
        <span class="k">if</span> <span class="s2">&quot;valinit&quot;</span> <span class="ow">in</span> <span class="n">slider_kwargs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valinit&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valmin&quot;</span><span class="p">]:</span>
                <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valmin&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valinit&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valinit&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valmax&quot;</span><span class="p">]:</span>
                <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valmax&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">slider_kwargs</span><span class="p">[</span><span class="s2">&quot;valinit&quot;</span><span class="p">]</span>
        <span class="n">slider</span> <span class="o">=</span> <span class="n">Slider</span><span class="p">(</span><span class="o">**</span><span class="n">slider_kwargs</span><span class="p">)</span>
        <span class="n">slider</span><span class="o">.</span><span class="n">on_changed</span><span class="p">(</span><span class="k">lambda</span> <span class="n">val</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_waiter</span><span class="o">.</span><span class="n">start</span><span class="p">())</span>
        <span class="n">sliders</span><span class="p">[</span><span class="n">slider_idx</span><span class="p">][</span><span class="s2">&quot;slider&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">slider</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">sliders</span> <span class="o">=</span> <span class="n">sliders</span>

    <span class="c1">### create the plot</span>
    <span class="n">create_plot</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">sliders</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">update_loop</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1">### show the plot</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ani</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">,</span>
            <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">frame</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">frames</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">interval</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">figure_frequency</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span>
            <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1">### run update loop until figure is closed</span>
        <span class="n">figure_pause</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">figure_frequency</span>
        <span class="n">max_updates_per_pause</span> <span class="o">=</span> <span class="n">update_frequency</span> <span class="o">/</span> <span class="n">figure_frequency</span>
        <span class="k">while</span> <span class="n">plt</span><span class="o">.</span><span class="n">fignum_exists</span><span class="p">(</span><span class="n">fig</span><span class="o">.</span><span class="n">number</span><span class="p">):</span>
            <span class="c1">### update figure</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_recreate_plot</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="n">figure_pause</span><span class="p">)</span>
            <span class="c1">### in between do the update loop multiple times</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">nr_updates</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="p">(</span>
                <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="n">figure_pause</span>
                <span class="ow">and</span> <span class="n">nr_updates</span> <span class="o">&lt;</span> <span class="n">max_updates_per_pause</span>
            <span class="p">):</span>
                <span class="n">update_loop</span><span class="p">()</span>
                <span class="n">nr_updates</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="CompNeuroPy.extra_functions.RNG" class="doc doc-heading">
            <code>RNG</code>


<a href="#CompNeuroPy.extra_functions.RNG" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">


        <p>Resettable random number generator.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="CompNeuroPy.extra_functions.RNG.rng">rng</span></code></td>
            <td>
                  <code><span title="numpy.random.Generator">Generator</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random number generator.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="n">rng</span> <span class="o">=</span> <span class="n">RNG</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">rng</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div>
</details>
              <details class="quote">
                <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2424</span>
<span class="normal">2425</span>
<span class="normal">2426</span>
<span class="normal">2427</span>
<span class="normal">2428</span>
<span class="normal">2429</span>
<span class="normal">2430</span>
<span class="normal">2431</span>
<span class="normal">2432</span>
<span class="normal">2433</span>
<span class="normal">2434</span>
<span class="normal">2435</span>
<span class="normal">2436</span>
<span class="normal">2437</span>
<span class="normal">2438</span>
<span class="normal">2439</span>
<span class="normal">2440</span>
<span class="normal">2441</span>
<span class="normal">2442</span>
<span class="normal">2443</span>
<span class="normal">2444</span>
<span class="normal">2445</span>
<span class="normal">2446</span>
<span class="normal">2447</span>
<span class="normal">2448</span>
<span class="normal">2449</span>
<span class="normal">2450</span>
<span class="normal">2451</span>
<span class="normal">2452</span>
<span class="normal">2453</span>
<span class="normal">2454</span>
<span class="normal">2455</span>
<span class="normal">2456</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">RNG</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resettable random number generator.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        rng (np.random.Generator):</span>
<span class="sd">            Random number generator.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        rng = RNG(seed=1234)</span>
<span class="sd">        print(rng.rng.integers(0, 10, 5))</span>
<span class="sd">        rng.reset()</span>
<span class="sd">        print(rng.rng.integers(0, 10, 5))</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            seed (int):</span>
<span class="sd">                Seed for the random number generator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_original_seed</span> <span class="o">=</span> <span class="n">seed</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset the random number generator to the original seed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">bit_generator</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span>
            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_seed</span>
        <span class="p">)</span><span class="o">.</span><span class="n">bit_generator</span><span class="o">.</span><span class="n">state</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.RNG.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.RNG.__init__" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>seed</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Seed for the random number generator.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2441</span>
<span class="normal">2442</span>
<span class="normal">2443</span>
<span class="normal">2444</span>
<span class="normal">2445</span>
<span class="normal">2446</span>
<span class="normal">2447</span>
<span class="normal">2448</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        seed (int):</span>
<span class="sd">            Seed for the random number generator.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_original_seed</span> <span class="o">=</span> <span class="n">seed</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="CompNeuroPy.extra_functions.RNG.reset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset</span><span class="p">()</span></code>

<a href="#CompNeuroPy.extra_functions.RNG.reset" class="headerlink" title="Permanent link">#</a></h3>


    <div class="doc doc-contents ">

        <p>Reset the random number generator to the original seed.</p>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2450</span>
<span class="normal">2451</span>
<span class="normal">2452</span>
<span class="normal">2453</span>
<span class="normal">2454</span>
<span class="normal">2455</span>
<span class="normal">2456</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reset the random number generator to the original seed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">bit_generator</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_seed</span>
    <span class="p">)</span><span class="o">.</span><span class="n">bit_generator</span><span class="o">.</span><span class="n">state</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.print_df" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">print_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.print_df" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Prints the complete dataframe df</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>df</code></td>
            <td>
                  <code>pandas dataframe or dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataframe to be printed</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">print_df</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prints the complete dataframe df</span>

<span class="sd">    Args:</span>
<span class="sd">        df (pandas dataframe or dict):</span>
<span class="sd">            Dataframe to be printed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pd</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span>
        <span class="s2">&quot;display.max_rows&quot;</span><span class="p">,</span> <span class="kc">None</span>
    <span class="p">):</span>  <span class="c1"># more options can be specified also</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.flatten_list" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">flatten_list</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.flatten_list" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Retuns flattened list</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>lst</code></td>
            <td>
                  <code>list of lists or mixed values and lists</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List to be flattened</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>new_list</code></td>            <td>
                  <code>list</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flattened list</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">flatten_list</span><span class="p">(</span><span class="n">lst</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retuns flattened list</span>

<span class="sd">    Args:</span>
<span class="sd">        lst (list of lists or mixed values and lists):</span>
<span class="sd">            List to be flattened</span>

<span class="sd">    Returns:</span>
<span class="sd">        new_list (list):</span>
<span class="sd">            Flattened list</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">### if lists in lst --&gt; upack them and retunr flatten_list of new list</span>
    <span class="n">new_lst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">list_in_lst</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">list_in_lst</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">sub_val</span> <span class="ow">in</span> <span class="n">val</span><span class="p">:</span>
                <span class="n">new_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sub_val</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">list_in_lst</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">flatten_list</span><span class="p">(</span><span class="n">new_lst</span><span class="p">)</span>
    <span class="c1">### else return lst</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">lst</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.remove_key" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">remove_key</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.remove_key" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Removes an element from a dict, returns the new dict</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>d</code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict to be modified</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>key</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Key to be removed</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>r</code></td>            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Modified dict</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">remove_key</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Removes an element from a dict, returns the new dict</span>

<span class="sd">    Args:</span>
<span class="sd">        d (dict):</span>
<span class="sd">            Dict to be modified</span>
<span class="sd">        key (str):</span>
<span class="sd">            Key to be removed</span>

<span class="sd">    Returns:</span>
<span class="sd">        r (dict):</span>
<span class="sd">            Modified dict</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">r</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">del</span> <span class="n">r</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">r</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.suppress_stdout" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">suppress_stdout</span><span class="p">()</span></code>

<a href="#CompNeuroPy.extra_functions.suppress_stdout" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Suppresses the print output of a function</p>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="n">suppress_stdout</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;this will not be printed&quot;</span><span class="p">)</span>
</code></pre></div>
</details>
            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span> <span class="nf">suppress_stdout</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Suppresses the print output of a function</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        with suppress_stdout():</span>
<span class="sd">            print(&quot;this will not be printed&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">devnull</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">devnull</span><span class="p">:</span>
        <span class="n">old_stdout</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">devnull</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">old_stdout</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.sci" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sci</span><span class="p">(</span><span class="n">nr</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.sci" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Rounds a number to a single decimal.
If number is smaller than 1 it is converted to scientific notation with 1 decimal.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>nr</code></td>
            <td>
                  <code>float or int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number to be converted</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>str</code></td>            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>String of the number in scientific notation</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">sci</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
<span class="go">&#39;1.0e-4&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sci</span><span class="p">(</span><span class="mf">1.77</span><span class="p">)</span>
<span class="go">&#39;1.8&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sci</span><span class="p">(</span><span class="mf">1.77e-5</span><span class="p">)</span>
<span class="go">&#39;1.8e-5&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sci</span><span class="p">(</span><span class="mf">177.22</span><span class="p">)</span>
<span class="go">&#39;177.2&#39;</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sci</span><span class="p">(</span><span class="n">nr</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rounds a number to a single decimal.</span>
<span class="sd">    If number is smaller than 1 it is converted to scientific notation with 1 decimal.</span>

<span class="sd">    Args:</span>
<span class="sd">        nr (float or int):</span>
<span class="sd">            Number to be converted</span>

<span class="sd">    Returns:</span>
<span class="sd">        str (str):</span>
<span class="sd">            String of the number in scientific notation</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; sci(0.0001)</span>
<span class="sd">        &#39;1.0e-4&#39;</span>
<span class="sd">        &gt;&gt;&gt; sci(1.77)</span>
<span class="sd">        &#39;1.8&#39;</span>
<span class="sd">        &gt;&gt;&gt; sci(1.77e-5)</span>
<span class="sd">        &#39;1.8e-5&#39;</span>
<span class="sd">        &gt;&gt;&gt; sci(177.22)</span>
<span class="sd">        &#39;177.2&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">nr</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">nr</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">nr</span><span class="si">:</span><span class="s2">.1e</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.create_cm" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_cm</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_cmap&#39;</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.create_cm" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Create a <code>LinearSegmentedColormap</code> from a list of colors.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>colors</code></td>
            <td>
                  <code>array-like of colors or array-like of (value, color</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If only colors are given, they are equidistantly mapped from the
range :math:<code>[0, 1]</code>; i.e. 0 maps to <code>colors[0]</code> and 1 maps to
<code>colors[-1]</code>.
If (value, color) pairs are given, the mapping is from <em>value</em>
to <em>color</em>. This can be used to divide the range unevenly.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>name</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the colormap, by default 'my_cmap'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;my_cmap&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>N</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of rgb quantization levels, by default 256.</p>
              </div>
            </td>
            <td>
                  <code>256</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>gamma</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Gamma correction value, by default 1.0.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>vmin</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The minimum value of the colormap, by default 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>vmax</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The maximum value of the colormap, by default 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>linear_colormap</code></td>            <td>
                  <code><span title="CompNeuroPy.extra_functions._LinearColormapClass">_LinearColormapClass</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The colormap object</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_cm</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;my_cmap&quot;</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a `LinearSegmentedColormap` from a list of colors.</span>

<span class="sd">    Args:</span>
<span class="sd">        colors (array-like of colors or array-like of (value, color)):</span>
<span class="sd">            If only colors are given, they are equidistantly mapped from the</span>
<span class="sd">            range :math:`[0, 1]`; i.e. 0 maps to ``colors[0]`` and 1 maps to</span>
<span class="sd">            ``colors[-1]``.</span>
<span class="sd">            If (value, color) pairs are given, the mapping is from *value*</span>
<span class="sd">            to *color*. This can be used to divide the range unevenly.</span>
<span class="sd">        name (str, optional):</span>
<span class="sd">            The name of the colormap, by default &#39;my_cmap&#39;.</span>
<span class="sd">        N (int, optional):</span>
<span class="sd">            The number of rgb quantization levels, by default 256.</span>
<span class="sd">        gamma (float, optional):</span>
<span class="sd">            Gamma correction value, by default 1.0.</span>
<span class="sd">        vmin (float, optional):</span>
<span class="sd">            The minimum value of the colormap, by default 0.</span>
<span class="sd">        vmax (float, optional):</span>
<span class="sd">            The maximum value of the colormap, by default 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        linear_colormap (_LinearColormapClass):</span>
<span class="sd">            The colormap object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">iterable</span><span class="p">(</span><span class="n">colors</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;colors must be iterable&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Sized</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="c1"># List of value, color pairs</span>
        <span class="n">vals</span><span class="p">,</span> <span class="n">colors</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">colors</span><span class="p">)</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vals</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">colors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span>
        <span class="c1">### insert values for 0 and 1 if not given</span>
        <span class="c1">### they equal the colors of the borders of the given range</span>
        <span class="k">if</span> <span class="n">vals</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">colors</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">vals</span><span class="p">)]]</span> <span class="o">+</span> <span class="n">colors</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">vals</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">colors</span> <span class="o">=</span> <span class="n">colors</span> <span class="o">+</span> <span class="p">[</span><span class="n">colors</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">vals</span><span class="p">)]]</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vals</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">))</span>

    <span class="c1">### sort values and colors, they have to increase</span>
    <span class="n">sort_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">vals</span><span class="p">)</span>
    <span class="n">vals</span> <span class="o">=</span> <span class="n">vals</span><span class="p">[</span><span class="n">sort_idx</span><span class="p">]</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">colors</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sort_idx</span><span class="p">]</span>

    <span class="n">r_g_b_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">),</span> <span class="mi">4</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">color_idx</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">colors</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">color</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="c1">### color given by name</span>
            <span class="n">r_g_b_a</span><span class="p">[</span><span class="n">color_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_rgba_array</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">### color given by rgb(maybe a) value</span>
            <span class="n">color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">color</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
            <span class="c1">### check color size</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">color</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">color</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;colors must be names or consist of 3 (rgb) or 4 (rgba) numbers&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">color</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1">### assume that max value is 255</span>
                <span class="n">color</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">color</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">/</span> <span class="mi">255</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">color</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="c1">### gamma already given</span>
                <span class="n">r_g_b_a</span><span class="p">[</span><span class="n">color_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">color</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">### add gamma</span>
                <span class="n">r_g_b_a</span><span class="p">[</span><span class="n">color_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">color</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">gamma</span><span class="p">])])</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">r_g_b_a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">r_g_b_a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">r_g_b_a</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">r_g_b_a</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span>

    <span class="n">cdict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;red&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">vals</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">]),</span>
        <span class="s2">&quot;green&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">vals</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">g</span><span class="p">]),</span>
        <span class="s2">&quot;blue&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">vals</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">b</span><span class="p">]),</span>
        <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">vals</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">]),</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">_LinearColormapClass</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">cdict</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.evaluate_expression_with_dict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate_expression_with_dict</span><span class="p">(</span><span class="n">expression</span><span class="p">,</span> <span class="n">value_dict</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.evaluate_expression_with_dict" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Evaluate a mathematical expression using values from a dictionary.</p>
<p>This function takes a mathematical expression as a string and a dictionary
containing variable names as keys and corresponding values as numpy arrays.
It replaces the variable names in the expression with their corresponding
values from the dictionary and evaluates the expression.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>expression</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A mathematical expression to be evaluated. Variable
names in the expression should match the keys in the value_dict.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>value_dict</code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing variable names (strings) as
keys and corresponding numpy arrays or numbers as values.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>result</code></td>            <td>
                  <code>value or array</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The result of evaluating the expression using the provided values.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">my_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_string</span> <span class="o">=</span> <span class="s2">&quot;a*2-b+10&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluate_expression_with_dict</span><span class="p">(</span><span class="n">my_string</span><span class="p">,</span> <span class="n">my_dict</span><span class="p">)</span>
<span class="go">array([12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.])</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_expression_with_dict</span><span class="p">(</span><span class="n">expression</span><span class="p">,</span> <span class="n">value_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate a mathematical expression using values from a dictionary.</span>

<span class="sd">    This function takes a mathematical expression as a string and a dictionary</span>
<span class="sd">    containing variable names as keys and corresponding values as numpy arrays.</span>
<span class="sd">    It replaces the variable names in the expression with their corresponding</span>
<span class="sd">    values from the dictionary and evaluates the expression.</span>

<span class="sd">    Args:</span>
<span class="sd">        expression (str):</span>
<span class="sd">            A mathematical expression to be evaluated. Variable</span>
<span class="sd">            names in the expression should match the keys in the value_dict.</span>
<span class="sd">        value_dict (dict):</span>
<span class="sd">            A dictionary containing variable names (strings) as</span>
<span class="sd">            keys and corresponding numpy arrays or numbers as values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        result (value or array):</span>
<span class="sd">            The result of evaluating the expression using the provided values.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; my_dict = {&quot;a&quot;: np.ones(10), &quot;b&quot;: np.arange(10)}</span>
<span class="sd">        &gt;&gt;&gt; my_string = &quot;a*2-b+10&quot;</span>
<span class="sd">        &gt;&gt;&gt; evaluate_expression_with_dict(my_string, my_dict)</span>
<span class="sd">        array([12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Replace dictionary keys in the expression with their corresponding values</span>
    <span class="c1">### replace names with dict entries</span>
    <span class="n">expression</span> <span class="o">=</span> <span class="n">_replace_names_with_dict</span><span class="p">(</span>
        <span class="n">expression</span><span class="o">=</span><span class="n">expression</span><span class="p">,</span> <span class="n">name_of_dict</span><span class="o">=</span><span class="s2">&quot;value_dict&quot;</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">=</span><span class="n">value_dict</span>
    <span class="p">)</span>

    <span class="c1">### evaluate the new expression</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">expression</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error while evaluating expression: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.efel_loss" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">efel_loss</span><span class="p">(</span><span class="n">trace1</span><span class="p">,</span> <span class="n">trace2</span><span class="p">,</span> <span class="n">feature_list</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.efel_loss" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Calculate the loss between two traces using the features from the feature_list.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>trace1</code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>dictionary with the keys "T" (time), "V" (voltage), "stim_start" (start of
the stimulus), "stim_end" (end of the stimulus)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>trace2</code></td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>dictionary with the keys "T" (time), "V" (voltage), "stim_start" (start of
the stimulus), "stim_end" (end of the stimulus)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature_list</code></td>
            <td>
                  <code>list</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>list of feature names which should be used to calculate the loss (see
https://efel.readthedocs.io/en/latest/eFeatures.html, some of them are
available)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>loss</code></td>            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>array with the loss</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2225</span>
<span class="normal">2226</span>
<span class="normal">2227</span>
<span class="normal">2228</span>
<span class="normal">2229</span>
<span class="normal">2230</span>
<span class="normal">2231</span>
<span class="normal">2232</span>
<span class="normal">2233</span>
<span class="normal">2234</span>
<span class="normal">2235</span>
<span class="normal">2236</span>
<span class="normal">2237</span>
<span class="normal">2238</span>
<span class="normal">2239</span>
<span class="normal">2240</span>
<span class="normal">2241</span>
<span class="normal">2242</span>
<span class="normal">2243</span>
<span class="normal">2244</span>
<span class="normal">2245</span>
<span class="normal">2246</span>
<span class="normal">2247</span>
<span class="normal">2248</span>
<span class="normal">2249</span>
<span class="normal">2250</span>
<span class="normal">2251</span>
<span class="normal">2252</span>
<span class="normal">2253</span>
<span class="normal">2254</span>
<span class="normal">2255</span>
<span class="normal">2256</span>
<span class="normal">2257</span>
<span class="normal">2258</span>
<span class="normal">2259</span>
<span class="normal">2260</span>
<span class="normal">2261</span>
<span class="normal">2262</span>
<span class="normal">2263</span>
<span class="normal">2264</span>
<span class="normal">2265</span>
<span class="normal">2266</span>
<span class="normal">2267</span>
<span class="normal">2268</span>
<span class="normal">2269</span>
<span class="normal">2270</span>
<span class="normal">2271</span>
<span class="normal">2272</span>
<span class="normal">2273</span>
<span class="normal">2274</span>
<span class="normal">2275</span>
<span class="normal">2276</span>
<span class="normal">2277</span>
<span class="normal">2278</span>
<span class="normal">2279</span>
<span class="normal">2280</span>
<span class="normal">2281</span>
<span class="normal">2282</span>
<span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span>
<span class="normal">2293</span>
<span class="normal">2294</span>
<span class="normal">2295</span>
<span class="normal">2296</span>
<span class="normal">2297</span>
<span class="normal">2298</span>
<span class="normal">2299</span>
<span class="normal">2300</span>
<span class="normal">2301</span>
<span class="normal">2302</span>
<span class="normal">2303</span>
<span class="normal">2304</span>
<span class="normal">2305</span>
<span class="normal">2306</span>
<span class="normal">2307</span>
<span class="normal">2308</span>
<span class="normal">2309</span>
<span class="normal">2310</span>
<span class="normal">2311</span>
<span class="normal">2312</span>
<span class="normal">2313</span>
<span class="normal">2314</span>
<span class="normal">2315</span>
<span class="normal">2316</span>
<span class="normal">2317</span>
<span class="normal">2318</span>
<span class="normal">2319</span>
<span class="normal">2320</span>
<span class="normal">2321</span>
<span class="normal">2322</span>
<span class="normal">2323</span>
<span class="normal">2324</span>
<span class="normal">2325</span>
<span class="normal">2326</span>
<span class="normal">2327</span>
<span class="normal">2328</span>
<span class="normal">2329</span>
<span class="normal">2330</span>
<span class="normal">2331</span>
<span class="normal">2332</span>
<span class="normal">2333</span>
<span class="normal">2334</span>
<span class="normal">2335</span>
<span class="normal">2336</span>
<span class="normal">2337</span>
<span class="normal">2338</span>
<span class="normal">2339</span>
<span class="normal">2340</span>
<span class="normal">2341</span>
<span class="normal">2342</span>
<span class="normal">2343</span>
<span class="normal">2344</span>
<span class="normal">2345</span>
<span class="normal">2346</span>
<span class="normal">2347</span>
<span class="normal">2348</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">efel_loss</span><span class="p">(</span><span class="n">trace1</span><span class="p">,</span> <span class="n">trace2</span><span class="p">,</span> <span class="n">feature_list</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the loss between two traces using the features from the feature_list.</span>

<span class="sd">    Args:</span>
<span class="sd">        trace1 (dict):</span>
<span class="sd">            dictionary with the keys &quot;T&quot; (time), &quot;V&quot; (voltage), &quot;stim_start&quot; (start of</span>
<span class="sd">            the stimulus), &quot;stim_end&quot; (end of the stimulus)</span>
<span class="sd">        trace2 (dict):</span>
<span class="sd">            dictionary with the keys &quot;T&quot; (time), &quot;V&quot; (voltage), &quot;stim_start&quot; (start of</span>
<span class="sd">            the stimulus), &quot;stim_end&quot; (end of the stimulus)</span>
<span class="sd">        feature_list (list):</span>
<span class="sd">            list of feature names which should be used to calculate the loss (see</span>
<span class="sd">            https://efel.readthedocs.io/en/latest/eFeatures.html, some of them are</span>
<span class="sd">            available)</span>

<span class="sd">    Returns:</span>
<span class="sd">        loss (np.array):</span>
<span class="sd">            array with the loss</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="c1">### set a plausible &quot;maximum&quot; absolute difference for each feature</span>
    <span class="n">diff_max</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;steady_state_voltage_stimend&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s2">&quot;steady_state_voltage&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s2">&quot;voltage_base&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s2">&quot;voltage_after_stim&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s2">&quot;minimum_voltage&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s2">&quot;time_to_first_spike&quot;</span><span class="p">:</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;stim_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
        <span class="s2">&quot;time_to_second_spike&quot;</span><span class="p">:</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;stim_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
        <span class="s2">&quot;time_to_last_spike&quot;</span><span class="p">:</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;stim_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
        <span class="s2">&quot;spike_count&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]),</span>
        <span class="s2">&quot;spike_count_stimint&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span>
                <span class="p">(</span>
                    <span class="p">(</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;stim_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
                    <span class="o">*</span> <span class="p">(</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;stim_end&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
                <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">),</span>
        <span class="s2">&quot;ISI_CV&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">diff_max: </span><span class="si">{</span><span class="n">diff_max</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">### set a plausible &quot;close&quot; absolute difference for each feature</span>
    <span class="n">diff_close</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;steady_state_voltage_stimend&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s2">&quot;steady_state_voltage&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s2">&quot;voltage_base&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s2">&quot;voltage_after_stim&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s2">&quot;minimum_voltage&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s2">&quot;time_to_first_spike&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span>
            <span class="p">(</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;stim_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span>
        <span class="p">),</span>
        <span class="s2">&quot;time_to_second_spike&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span>
            <span class="p">(</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;stim_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span>
        <span class="p">),</span>
        <span class="s2">&quot;time_to_last_spike&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span>
            <span class="p">(</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;stim_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span>
        <span class="p">),</span>
        <span class="s2">&quot;spike_count&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">((</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="mi">200</span><span class="p">),</span>
        <span class="s2">&quot;spike_count_stimint&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">((</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="mi">200</span><span class="p">),</span>
        <span class="s2">&quot;ISI_CV&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">diff_close: </span><span class="si">{</span><span class="n">diff_close</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">### catch if features from feature_list are not supported</span>
    <span class="n">features_not_supported</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">feature</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">feature_list</span> <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">diff_max</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">features_not_supported</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Features not supported: </span><span class="si">{</span><span class="n">features_not_supported</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">### catch &quot;exploding&quot; neurons by returning max loss of features</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;V&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mi">200</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">trace1</span><span class="p">[</span><span class="s2">&quot;V&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">trace2</span><span class="p">[</span><span class="s2">&quot;V&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mi">200</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">trace2</span><span class="p">[</span><span class="s2">&quot;V&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">feature_list</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">diff_max</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">/</span> <span class="n">diff_close</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_list</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">loss</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="c1">### calculate and return the mean of the differences of the features</span>
    <span class="n">features_1</span><span class="p">,</span> <span class="n">features_2</span> <span class="o">=</span> <span class="n">efel</span><span class="o">.</span><span class="n">get_feature_values</span><span class="p">(</span>
        <span class="p">[</span><span class="n">trace1</span><span class="p">,</span> <span class="n">trace2</span><span class="p">],</span>
        <span class="n">feature_list</span><span class="p">,</span>
        <span class="n">raise_warnings</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">features_1: </span><span class="si">{</span><span class="n">features_1</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;features_2: </span><span class="si">{</span><span class="n">features_2</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">feature_list</span><span class="p">:</span>
        <span class="c1">### if both features are None use 0</span>
        <span class="k">if</span> <span class="n">features_1</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">features_2</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1">### if single feature is None use diff_max</span>
        <span class="k">elif</span> <span class="n">features_1</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">features_2</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">diff_max</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
        <span class="c1">### if features contain multiple values use the mean TODO not tested yet</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_1</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_2</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features with multiple values not tested yet!&quot;</span><span class="p">)</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">features_1</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">-</span> <span class="n">features_2</span><span class="p">[</span><span class="n">feature</span><span class="p">]),</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">features_1</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">-</span> <span class="n">features_2</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
        <span class="c1">### scale the difference by diff_close and add to loss</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">diff_close</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_list</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="CompNeuroPy.extra_functions.find_x_bound" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">find_x_bound</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">y_bound</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">bound_type</span><span class="o">=</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span></code>

<a href="#CompNeuroPy.extra_functions.find_x_bound" class="headerlink" title="Permanent link">#</a></h2>


    <div class="doc doc-contents ">

        <p>Find the x value such that y(x) is closest to y_bound within a given tolerance. The
value y_bound should be reachable by y(x) by increasing x from the initial value x0.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span>[[float], float]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A function that takes a single float argument and returns a single float
value.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>x0</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The initial value of x to start the search.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_bound</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target value of y.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tolerance</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tolerance for the difference between y(x) and y_bound. Defaults to 1e-5.</p>
              </div>
            </td>
            <td>
                  <code>1e-05</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bound_type</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of bound to find. Can be 'equal'(y(x) should be close to y_bound),
'greater'(y(x) should be close to y_bound and greater), or 'less'(y(x) should
be close to y_bound and less). Defaults to 'equal'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;equal&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>x_bound</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The x value such that y(x) is closest to y_bound within the tolerance.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>CompNeuroPy/extra_functions.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2459</span>
<span class="normal">2460</span>
<span class="normal">2461</span>
<span class="normal">2462</span>
<span class="normal">2463</span>
<span class="normal">2464</span>
<span class="normal">2465</span>
<span class="normal">2466</span>
<span class="normal">2467</span>
<span class="normal">2468</span>
<span class="normal">2469</span>
<span class="normal">2470</span>
<span class="normal">2471</span>
<span class="normal">2472</span>
<span class="normal">2473</span>
<span class="normal">2474</span>
<span class="normal">2475</span>
<span class="normal">2476</span>
<span class="normal">2477</span>
<span class="normal">2478</span>
<span class="normal">2479</span>
<span class="normal">2480</span>
<span class="normal">2481</span>
<span class="normal">2482</span>
<span class="normal">2483</span>
<span class="normal">2484</span>
<span class="normal">2485</span>
<span class="normal">2486</span>
<span class="normal">2487</span>
<span class="normal">2488</span>
<span class="normal">2489</span>
<span class="normal">2490</span>
<span class="normal">2491</span>
<span class="normal">2492</span>
<span class="normal">2493</span>
<span class="normal">2494</span>
<span class="normal">2495</span>
<span class="normal">2496</span>
<span class="normal">2497</span>
<span class="normal">2498</span>
<span class="normal">2499</span>
<span class="normal">2500</span>
<span class="normal">2501</span>
<span class="normal">2502</span>
<span class="normal">2503</span>
<span class="normal">2504</span>
<span class="normal">2505</span>
<span class="normal">2506</span>
<span class="normal">2507</span>
<span class="normal">2508</span>
<span class="normal">2509</span>
<span class="normal">2510</span>
<span class="normal">2511</span>
<span class="normal">2512</span>
<span class="normal">2513</span>
<span class="normal">2514</span>
<span class="normal">2515</span>
<span class="normal">2516</span>
<span class="normal">2517</span>
<span class="normal">2518</span>
<span class="normal">2519</span>
<span class="normal">2520</span>
<span class="normal">2521</span>
<span class="normal">2522</span>
<span class="normal">2523</span>
<span class="normal">2524</span>
<span class="normal">2525</span>
<span class="normal">2526</span>
<span class="normal">2527</span>
<span class="normal">2528</span>
<span class="normal">2529</span>
<span class="normal">2530</span>
<span class="normal">2531</span>
<span class="normal">2532</span>
<span class="normal">2533</span>
<span class="normal">2534</span>
<span class="normal">2535</span>
<span class="normal">2536</span>
<span class="normal">2537</span>
<span class="normal">2538</span>
<span class="normal">2539</span>
<span class="normal">2540</span>
<span class="normal">2541</span>
<span class="normal">2542</span>
<span class="normal">2543</span>
<span class="normal">2544</span>
<span class="normal">2545</span>
<span class="normal">2546</span>
<span class="normal">2547</span>
<span class="normal">2548</span>
<span class="normal">2549</span>
<span class="normal">2550</span>
<span class="normal">2551</span>
<span class="normal">2552</span>
<span class="normal">2553</span>
<span class="normal">2554</span>
<span class="normal">2555</span>
<span class="normal">2556</span>
<span class="normal">2557</span>
<span class="normal">2558</span>
<span class="normal">2559</span>
<span class="normal">2560</span>
<span class="normal">2561</span>
<span class="normal">2562</span>
<span class="normal">2563</span>
<span class="normal">2564</span>
<span class="normal">2565</span>
<span class="normal">2566</span>
<span class="normal">2567</span>
<span class="normal">2568</span>
<span class="normal">2569</span>
<span class="normal">2570</span>
<span class="normal">2571</span>
<span class="normal">2572</span>
<span class="normal">2573</span>
<span class="normal">2574</span>
<span class="normal">2575</span>
<span class="normal">2576</span>
<span class="normal">2577</span>
<span class="normal">2578</span>
<span class="normal">2579</span>
<span class="normal">2580</span>
<span class="normal">2581</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">find_x_bound</span><span class="p">(</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">float</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span>
    <span class="n">x0</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">y_bound</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">bound_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;equal&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Find the x value such that y(x) is closest to y_bound within a given tolerance. The</span>
<span class="sd">    value y_bound should be reachable by y(x) by increasing x from the initial value x0.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (Callable[[float], float]):</span>
<span class="sd">            A function that takes a single float argument and returns a single float</span>
<span class="sd">            value.</span>
<span class="sd">        x0 (float):</span>
<span class="sd">            The initial value of x to start the search.</span>
<span class="sd">        y_bound (float):</span>
<span class="sd">            The target value of y.</span>
<span class="sd">        tolerance (float, optional):</span>
<span class="sd">            The tolerance for the difference between y(x) and y_bound. Defaults to 1e-5.</span>
<span class="sd">        bound_type (str, optional):</span>
<span class="sd">            The type of bound to find. Can be &#39;equal&#39;(y(x) should be close to y_bound),</span>
<span class="sd">            &#39;greater&#39;(y(x) should be close to y_bound and greater), or &#39;less&#39;(y(x) should</span>
<span class="sd">            be close to y_bound and less). Defaults to &#39;equal&#39;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        x_bound (float):</span>
<span class="sd">            The x value such that y(x) is closest to y_bound within the tolerance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Catch invalid bound type</span>
    <span class="k">if</span> <span class="n">bound_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;equal&quot;</span><span class="p">,</span> <span class="s2">&quot;greater&quot;</span><span class="p">,</span> <span class="s2">&quot;less&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;bound_type should be &#39;equal&#39;, &#39;greater&#39;, or &#39;less&#39;.&quot;</span><span class="p">)</span>

    <span class="c1"># Check if the initial value y(x0) is already y_bound</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span> <span class="n">y_bound</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tolerance</span><span class="p">):</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;Warning: The initial value is already equal to y_bound.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x0</span><span class="p">,</span> <span class="n">x0</span>

    <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x0: </span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s2">, y0: </span><span class="si">{</span><span class="n">y0</span><span class="si">}</span><span class="s2">, y_bound: </span><span class="si">{</span><span class="n">bound_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">y_bound</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Define a helper function to find x such that y(x) - y_bound = 0</span>
    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_bound</span>

    <span class="c1"># Exponential search to find an interval [a, b] where y(a) &lt; y_bound &lt; y(b)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">x0</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">while</span> <span class="n">func</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">b</span>
        <span class="n">b</span> <span class="o">*=</span> <span class="mi">2</span>
        <span class="k">if</span> <span class="n">b</span> <span class="o">&gt;</span> <span class="mf">1e6</span><span class="p">:</span>  <span class="c1"># Avoid infinite loop in case y_bound is not reachable</span>
            <span class="k">break</span>
    <span class="k">if</span> <span class="n">b</span> <span class="o">&gt;</span> <span class="mf">1e6</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;y_bound cannot be reached, the function saturates below y_bound.&quot;</span>
        <span class="p">)</span>
    <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a: </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2">, b: </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Use brentq to find the root within the interval [a, b]</span>
    <span class="n">x_root</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">brentq</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">y_root</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">x_root</span><span class="p">)</span>
    <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;y(x_root=</span><span class="si">{</span><span class="n">x_root</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">y_root</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># check if y(x_root) is not within the tolerance of y_bound</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">y_root</span><span class="p">,</span> <span class="n">y_bound</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tolerance</span><span class="p">):</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Warning: y(x_root) is not within the tolerance of y_bound (y(x_root)=</span><span class="si">{</span><span class="n">y_root</span><span class="si">}</span><span class="s2">, y_bound=</span><span class="si">{</span><span class="n">y_bound</span><span class="si">}</span><span class="s2">, tolerance=</span><span class="si">{</span><span class="n">tolerance</span><span class="si">}</span><span class="s2">)!&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">bound_type</span> <span class="o">==</span> <span class="s2">&quot;equal&quot;</span><span class="p">:</span>
        <span class="c1"># Return the x value such that y(x) = y_bound</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Returning y(x=</span><span class="si">{</span><span class="n">x_root</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">y_root</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_root</span>

    <span class="k">if</span> <span class="n">bound_type</span> <span class="o">==</span> <span class="s2">&quot;greater&quot;</span> <span class="ow">and</span> <span class="n">y_root</span> <span class="o">&gt;</span> <span class="n">y_bound</span><span class="p">:</span>
        <span class="c1"># Return the x value such that y(x) &gt; y_bound</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Returning y(x=</span><span class="si">{</span><span class="n">x_root</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">y_root</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_root</span>

    <span class="k">if</span> <span class="n">bound_type</span> <span class="o">==</span> <span class="s2">&quot;less&quot;</span> <span class="ow">and</span> <span class="n">y_root</span> <span class="o">&lt;</span> <span class="n">y_bound</span><span class="p">:</span>
        <span class="c1"># Return the x value such that y(x) &lt; y_bound</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Returning y(x=</span><span class="si">{</span><span class="n">x_root</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">y_root</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_root</span>

    <span class="c1"># Calculate the gradient at x_root</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_root</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-3</span>
    <span class="n">grad_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">x_root</span> <span class="o">+</span> <span class="n">dx</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">(</span><span class="n">x_root</span> <span class="o">-</span> <span class="n">dx</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>

    <span class="c1"># Define epsilon based on the gradient</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">tolerance</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">grad_y</span><span class="p">)</span> <span class="k">if</span> <span class="n">grad_y</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">tolerance</span>

    <span class="k">if</span> <span class="n">bound_type</span> <span class="o">==</span> <span class="s2">&quot;greater&quot;</span><span class="p">:</span>
        <span class="c1"># Find the x value such that y(x) &gt; y_bound (thus maybe increase x)</span>
        <span class="c1"># do this by incrementaly increasing x by epsilon until y(x) is greater than</span>
        <span class="c1"># y_bound</span>
        <span class="c1"># if y(x+epsilon)-y(x) is less than the tolerance, increase epsilon</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x_root</span>
        <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">y_val</span> <span class="o">&lt;</span> <span class="n">y_bound</span><span class="p">:</span>
            <span class="n">y_val_prev</span> <span class="o">=</span> <span class="n">y_val</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="n">epsilon</span>
            <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">y_val</span> <span class="o">-</span> <span class="n">y_val_prev</span> <span class="o">&lt;</span> <span class="n">tolerance</span> <span class="o">/</span> <span class="mi">10</span><span class="p">:</span>
                <span class="n">epsilon</span> <span class="o">*=</span> <span class="mi">2</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Returning y(x=</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">y_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">elif</span> <span class="n">bound_type</span> <span class="o">==</span> <span class="s2">&quot;less&quot;</span><span class="p">:</span>
        <span class="c1"># Find the x value such that y(x) &lt; y_bound (thus maybe decrease x)</span>
        <span class="c1"># do this by incrementaly decreasing x by epsilon until y(x) is less than</span>
        <span class="c1"># y_bound</span>
        <span class="c1"># if y(x)-y(x-epsilon) is less than the tolerance, increase epsilon</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x_root</span>
        <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">y_val</span> <span class="o">&gt;</span> <span class="n">y_bound</span><span class="p">:</span>
            <span class="n">y_val_prev</span> <span class="o">=</span> <span class="n">y_val</span>
            <span class="n">x</span> <span class="o">-=</span> <span class="n">epsilon</span>
            <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">y_val_prev</span> <span class="o">-</span> <span class="n">y_val</span> <span class="o">&lt;</span> <span class="n">tolerance</span> <span class="o">/</span> <span class="mi">10</span><span class="p">:</span>
                <span class="n">epsilon</span> <span class="o">*=</span> <span class="mi">2</span>
        <span class="n">sf</span><span class="o">.</span><span class="n">Logger</span><span class="p">()</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Returning y(x=</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">y_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; Oliver Maith
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["header.autohide", "content.code.copy"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"alias": true, "provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.56dfad97.min.js"></script>
      
    
  </body>
</html>